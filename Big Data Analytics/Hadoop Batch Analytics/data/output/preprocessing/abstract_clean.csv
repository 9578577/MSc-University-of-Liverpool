10.1016/j.ijepes.2018.09.041 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054174923&doi=10.1016%2fj.ijepes.2018.09.041&partnerID=40&md5=acf17587ac4bf67191332358f62e7b9a 0,ever increasing rate wind power generation uncertain variable source energy face new challenges power system operation reason optimal real time operation wind integrated power systems profit based markets considering effects probabilistic future variations wind speed one main concerns system operators purpose solutions demand response dr programs energy storage systems ess widely used cover manage wind generation uncertainty dr programs add extra sources uncertainty due unpredictable customer behavior end paper proposes online model based predictive control approach optimal real time operation wind integrated power systems including dr ess facilities discrete time manner optimization characteristic adaptability main features proposed mpc method make well suited address high uncertainties regarding wind power generation customer behavior besides mpc considers interactive effects control facilities accordance expected wind farm output power future prediction horizon maximize wind power utilization enhance social welfare addition uncertain nature wind power modeled using markov chain monte carlo method efficiency evaluation proposed approach simulation implemented matlab software using yalmip optimization toolbox bus test system results confirm acceptable performance proposed approach reducing operation cost optimal uncertainties management â© elsevier ltd
10.1016/j.inffus.2018.04.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046730150&doi=10.1016%2fj.inffus.2018.04.001&partnerID=40&md5=23ef6dde461676fbb0fbe45fb8d33e66 0,conversational data social media contain great deal useful information conversation anomaly detection important research direction field sentiment analysis user specific emotional characteristic studying distribution sampling usersâ€™ emotional transitions simulate specific emotional transitions conversations anomaly detection conversation data refers detecting usersâ€™ abnormal opinions sentiment patterns well special temporal aspects patterns paper proposes hybrid model combines convolutional neural network long short term memory cnn lstm markov chain monte carlo mcmc method identify usersâ€™ emotions sample usersâ€™ emotional transition detect anomalies according transition tensor emotional transition sampling implemented improving mcmc algorithm anomalies detected calculating similarity normal transition tensor current transition tensor user experiment carried four corpora results show emotions well sampled conform user characteristics anomaly detected proposed method model proposed used intelligent conversation systems simulating emotional transition detecting abnormal emotions â© elsevier b v
10.1016/j.ymssp.2018.08.050 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053181074&doi=10.1016%2fj.ymssp.2018.08.050&partnerID=40&md5=186e66b433517feb6795faffa906aee0 0,paper introduces improved version novel inverse approach quantification multivariate interval uncertainty high dimensional models scarce data availability furthermore conceptual practical comparison method well established probabilistic framework bayesian model updating via transitional markov chain monte carlo presented context dlr airmod test structure first shown proposed improvements inverse method alleviate curse dimensionality method factor furthermore comparison bayesian results revealed selection ofthe appropriate method depends largely desired information availability data case large amounts data available analyst desires full joint probabilistic descriptors model parameter uncertainty bayesian method shown performing hand however descriptors needed e g worst case analysis scarce data available interval method shown deliver objective robust bounds uncertain parameters finally also suggestions aid analyst selecting appropriate method inverse uncertainty quantification given â© elsevier ltd
10.1016/j.cam.2018.08.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052538043&doi=10.1016%2fj.cam.2018.08.012&partnerID=40&md5=bcd16988ebc2de6540b3e9a19ed63289 0,new generalization lindley distribution called power lindley distribution proposed ghitany et al offers flexible distribution modeling lifetime data reliability studied classical inferences model based complete data sets however may deal record breaking data sets values smaller larger current extreme value reported paper using record values inter record times develop inference procedures estimation parameters prediction future record values power lindley distribution first maximum likelihood estimate parameters asymptotic confidence intervals obtained next consider bayes estimation symmetric squared error asymmetric linear exponential linex loss functions using joint bivariate density function since closed forms estimates available encounter computational difficulties evaluate bayes estimates parameters involved model reason use tierney kadane method well markov chain monte carlo mcmc procedure compute approximate bayes estimates consider non bayesian bayesian prediction future lower record arising power lindley distribution based record data comparison derived predictors carried using monte carlo simulations real data set analyzed illustration purposes â© elsevier b v
10.1016/j.ejor.2018.07.022 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051047931&doi=10.1016%2fj.ejor.2018.07.022&partnerID=40&md5=4c90dc27d615e3397022daf94a6d74da 0,paper study reliability based measures prognostic problems k n system failure process component depends intrinsic characteristic also operating environment conditions system reliability expected remaining useful lifetime calculated periodic inspection policy system asymptotic availability derived aim providing explicit expressions quantities model allows us incorporate observation information environment evaluation system performances numerical examples show efficiency accuracy method comparing monte carlo simulations pointed environment condition significant effect system reliability based measures system prognostic analysis â© elsevier b v
10.1016/j.physa.2018.09.067 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053836898&doi=10.1016%2fj.physa.2018.09.067&partnerID=40&md5=6bf68ea1b784366c47648719d2db08d7 0,green behavior plays increasingly important role today paper aimed investigating spreading process city resident green behavior applied classical threshold model modified contagion model multiplex network illustrate dynamic process since people always act conformity majorities make decisions take actions consider effects negative individuals positive friends proportion centrist positive friends surpassed local awareness ratio î± become positive also consider influence green awareness facilitate green behavior last least compulsory policy also taken account force specific negative individuals take green behavior theoretical analysis conducted microscopic markov chain approach numerical simulations performed based monte carlo simulation results show intensity policy regulation î plays vital role spreading threshold final green behavior size attain new explanation extinction behaviors may provide advice policy modification â© elsevier b v
10.1016/j.jmva.2018.08.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053157378&doi=10.1016%2fj.jmva.2018.08.014&partnerID=40&md5=d8fecacf78ada9336a63a7ff156cba17 0,performing bayesian data analysis using general linear mixed model resulting posterior density almost always analytically intractable however proper conditionally conjugate priors used simple two block gibbs sampler geometrically ergodic nearly practical settings including situations p n abrahamsen hobert unfortunately conditionally conjugate multivariate gaussian prior î² perform well high dimensional setting pâ‰«n paper consider alternative model multivariate gaussian prior replaced normal gamma shrinkage prior developed griffin brown change leads much complex posterior density develop simple mcmc algorithm exploring algorithm deterministic random scan components easier analyze obvious three step gibbs sampler indeed prove new algorithm geometrically ergodic practical settings â© elsevier inc
10.1016/j.strusafe.2018.05.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051537147&doi=10.1016%2fj.strusafe.2018.05.005&partnerID=40&md5=6fd7208085a72d30244c50a18e4d9a07 0,paper studies non random walk markov chain monte carlo method namely hamiltonian monte carlo hmc method context subset simulation used reliability analysis hmc method relies deterministic mechanism inspired hamiltonian dynamics propose samples following target probability distribution method alleviates random walk behavior achieve effective consistent exploration probability space compared standard gibbs metropolis hastings techniques brief review basic concepts hmc method computational details two algorithms proposed facilitate application hmc method subset simulation reliability analysis next behavior two hmc algorithms illustrated using simple probability distribution models finally accuracy efficiency subset simulation employing two hmc algorithms tested using various reliability examples gaussian non gaussian spaces â© elsevier ltd
10.1016/j.cageo.2018.10.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055337361&doi=10.1016%2fj.cageo.2018.10.006&partnerID=40&md5=cb2a31985db57870ac41cbeca12c67b7 0,many geoscience applications prediction requires building complex surface models complexity often single model built possibly small set variants represent uncertainty recent advancement implicit modeling made construction geological models simpler however automatic assessment visualization uncertainty constrained input geological rules data constraints still active research topic paper propose new method directly assesses visualizes uncertainty geological surfaces means stochastic motion represent geological surfaces addition stochastic implicit conceptual models residual functions subject constraints data geological age relationships two sampling approaches create stochastic motion proposed monte carlo markov chain monte carlo mcmc uncertainty assessed independent realizations drawn monte carlo sampling uncertainty visualized â€œsmoothâ€� movie gradually evolving geological surfaces stationary distribution monte carlo sampled markov chain monte carlo mcmc idea integrated level set equation level sets ideal way represent mathematically complex surfaces without explicit grid representations thereby advantage avoiding tedious topological computations defining connectivity surface illustrate new idea simple synthetic examples taking constraints data geological age relationships consideration finally illustrate idea using synthetic data set copper deposit dense drillholes constrain ore body seven different lithologies method provides direct assessment visualization uncertainty geological surfaces â© elsevier ltd
10.1016/j.sigpro.2018.09.023 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053758525&doi=10.1016%2fj.sigpro.2018.09.023&partnerID=40&md5=5bf544382bc17f44240981fd8824ff53 0,paper adaptive distributed particle filter adpf proposed single acoustic source tracking distributed microphone networks dmns deal spurious effects due reverberation noise modified multiple hypothesis model first investigated exploiting generalized cross correlation gcc function based model time delay arrival tdoa selection performed constituting local observation acoustic source tracking formulated bayesian filtering problem assumption langevin dynamic model source motion next adaptive distributed particle filter adpf presented solve bayesian filtering problem distributed acoustic source tracking improve tracking performance proposed adpf adaptive distributed computation method optimal proposal function designed based gaussian approximation implemented utilizing markov chain monte carlo mcmc sampler consensus filter main advantage proposed acoustic source tracking method combination strength modified tdoa multiple hypothesis model adpf simulation real world recording experiment results show proposed adpf relatively good tracking performance different snr conditions reverberation environments â© elsevier b v
10.1016/j.csda.2018.07.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052476781&doi=10.1016%2fj.csda.2018.07.007&partnerID=40&md5=961b83680af5277c2bd4f83271b12b88 0,multidimensional scaling methods frequently used researchers practitioners project high dimensional data low dimensional space however challenge integrate side information available along dissimilarities perform dimension reduction analysis novel bayesian integrative multidimensional scaling procedure namely bayesian multidimensional scaling variable selection proposed incorporate external information objects analysis use latent multivariate regression structure proposed bayesian procedure allows incorporation covariate information dimension reduction analysis use variable selection strategy efficient computational algorithm implement procedure also developed series simulation experiments real data analysis conducted proposed model shown outperform several benchmark models based measures commonly used literature â© elsevier b v
10.1016/j.strusafe.2018.09.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054435699&doi=10.1016%2fj.strusafe.2018.09.004&partnerID=40&md5=ade4053039f788ccd7438d2ab6c1778d 0,civil engineering structures commonly monitored assess structural behaviour using alarm thresholds indicate contingency actions needed improve safety however need guidelines establish thresholds ensure sufficient safety paper therefore proposes general computational algorithm establishment reliability based alarm thresholds civil engineering structures algorithm based subset simulation independent component markov chain monte carlo simulation applicable analytical structural models finite element models reliability based alarm thresholds straightforwardly used monitoring plans developed design phase construction project particular sequentially loaded structures staged construction embankments reliability based alarm thresholds contingency actions implemented needed satisfy target probability failure â© authors
10.1007/978-3-319-99272-3_28 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052213633&doi=10.1007%2f978-3-319-99272-3_28&partnerID=40&md5=d818679f1c8181042be98bf0a741813e 0,analyzed problem identification fault parameters taking account stochastic characteristic system objective estimate unbalance parameters unbalance moment phase angle axial position unbalance force applied rotor therefore experimental tests rotor obtain unbalance response performed work aims comparison bayesian inference markov chain monte carlo method mcmc using delayed rejection adaptive metropolis algorithm dram stochastic collocation generalized polynomial chaos expansion method computational cost smaller mcmc methods used alternative method stochastic simulation bayesian inference mcmc dram based previous works however application mcmc high computational cost therefore stochastic collocation introduced likelihood function bayes theorem faster convergence rate low computational cost collocation evaluated results methods compared determine convergence precision collocation method â© springer nature switzerland ag
10.1016/j.geothermics.2018.09.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054256522&doi=10.1016%2fj.geothermics.2018.09.012&partnerID=40&md5=4799fe74db6938023cbfccb2ab79d6f9 0,evaluation low medium enthalpy geothermal resources island ireland interesting targets deep sedimentary basins northern ireland deepest rathlin basin permian triassic reservoir sediments known exist least depth two deep boreholes within basin provide evidence elevated temperatures depth atypical within ireland prompting geophysical exploration basin one component iretherm project magnetotelluric mt method selected investigative geophysical tool capable sensing defining electrically conductive porous sediments beneath overlying resistive strata case flood basalt sequences mt data acquired rectangular grid sites across almost half onshore basin investigate composition spatial variation basin formations one dimensional stochastic inverse modelling observed mt data reversible jump markov chain monte carlo inversion code resulting ensembles models site use model ensembles rather single models avoids pitfall reliant interpretation non unique resistivity models increasing robustness interpretation interpreted models compare favourably nearby deep borehole records interpolation complete set ensemble interpretations results conservative reservoir volume approx km combined permian triassic sandstones beneath mt survey based upon new high quality temperature data available ballinlea borehole approximate estimation thermal energy place function final reservoir temperature performed interpreted mt resistivity model volume final minimum temperature â°c temperature comparable estimates made adjacent geothermal prospects results minimum estimated indicated geothermal reserve igr ã— j beneath mt survey area modelling results suggest exploitation maximum volume sediments occur final temperature â‰ˆ â°c â© elsevier ltd
10.1016/j.physe.2018.08.028 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053436586&doi=10.1016%2fj.physe.2018.08.028&partnerID=40&md5=bd6ad2a8698e740b5803cb75db359998 0,markov model semiconductor nanolaser constructed order describe finely effects quantum fluctuations dynamics laser particular considering transition lasing nanolasers expected contain small number emitters whose semiconductor bands simulated using true carrier energy states model takes account carrier carrier interactions conduction valence bands result huge markov chain often demanding direct monte carlo simulation introduce technique split whole chain two subchains one referring thermalization events within bands laser photonic events interest model applied analysis laser transition enlightens coexistence pulse regime triggered quantum nature photon birth known coherent cw regime conclusion highlighted calculated time traces show ultrasmall scale nanolasers unable define perfectly threshold â© elsevier b v
10.1016/j.strusafe.2018.07.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050075353&doi=10.1016%2fj.strusafe.2018.07.001&partnerID=40&md5=e9d658c043af71e599553df6ca9ec24e 0,computation probability rare failure event common task structural reliability analysis applications numerical model defining rare event nonlinear resulting failure domain often multimodal one strategy estimating probability failure context importance sampling method efficiency importance sampling depends choice importance sampling density near optimal sampling density found application cross entropy method cross entropy method adaptive sampling approach determines sampling density minimizing kullback leibler divergence theoretically optimal importance sampling density chosen parametric family distributions paper investigate suitability multivariate normal distribution gaussian mixture model importance sampling densities within cross entropy method moreover compare performance cross entropy method sequential importance sampling another recently proposed adaptive sampling approach uses gaussian mixture distribution proposal distribution within markov chain monte carlo algorithm parameter updating gaussian mixture within cross entropy method propose modified version expectation maximization algorithm works weighted samples estimate number distributions mixture density based spatial clustering applications noise dbscan algorithm adapted use weighted samples compare performance different methods several examples including component reliability problems system reliability problems reliability varying dimensions results show cross entropy method using single gaussian outperforms cross entropy method using gaussian mixture distribution types suitable high dimensional reliability problems â© elsevier ltd
10.1016/j.envsoft.2018.09.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054236136&doi=10.1016%2fj.envsoft.2018.09.004&partnerID=40&md5=8078123e09bc38ffa176449632a09ede 0,dynamic global vegetation models dgvms crucial importance understanding predicting vegetation carbon nitrogen water dynamics ecosystems response climate change complexity however creates challenges model analysis data integration solution interface dgvms established statistical computing environments introduce rlpjguess r package couples widely used dgvm lpj guess r environment statistical computing making existing r packages functions readily available perform complex analyses model demonstrate advantages framework using rlpjguess perform several otherwise laborious tasks first set single simulations followed global local sensitivity analyses bayesian calibration markov chain monte carlo mcmc algorithm predictive simulation multiple climate scenarios example highlights opportunities interfacing existing models earth environmental sciences state art computing environments r â© elsevier ltd
10.1007/978-3-319-78187-7_3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049505586&doi=10.1007%2f978-3-319-78187-7_3&partnerID=40&md5=62718e2492dc7740fb08d286355baea2 0,reliable estimation regional ground motion plays critical role probabilistic seismic hazard analysis psha earthquake resistant design structures within region small spatial scale often based assumption relatively uniform form factors leads assumption station condition however small scale regions may case study propose new bayesian hierarchical model bhm peak ground acceleration pga records two small aperture icelandic strong motion arrays proposed bhm characterizes source effect local station effect source station effect error term represents measurement error unaccounted factors separately posterior inference based markov chain monte carlo algorithm uses metropolis algorithm uncertainty unknown parameters assessed joint posterior density analysis pga records based proposed bhm improve comprehensive understanding source effects localized station conditions wave propagation â© springer international publishing ag part springer nature
10.1007/978-3-319-78187-7_2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049538092&doi=10.1007%2f978-3-319-78187-7_2&partnerID=40&md5=1f70d90b99840e62867d8c0dbf8b0fbc 0,study probabilistic seismic hazard assessment psha north iceland explored terms sensitivity one key elements selected ground motion models gmms gmms previous psha studies iceland reviewed cases recalibrated icelandic dataset using markov chain monte carlo mcmc algorithm useful regions earthquake records scarce show ground motion model variability manifested psha uncertainties hazard maps standard deviation coefficient variation cv pga two hazard levels gmms recalibrating shown results indicate recalibrated models promising candidates applied future hazard studies iceland importantly show extent epistemic uncertainty gmms contribute patches heightened hazard uncertainties especially near far fault distances particular lack data â© springer international publishing ag part springer nature
10.1007/978-3-319-91086-4_1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053768966&doi=10.1007%2f978-3-319-91086-4_1&partnerID=40&md5=66daa9bca00d38e2856e20085ff045c7 0,simulated annealing sa one simplest best known metaheuristic method addressing difficult black box global optimization problems whose objective function explicitly given evaluated via costly computer simulation massively used real life applications main advantage sa simplicity sa based analogy physical annealing materials avoids drawback monte carlo approach trapped local minima thanks efficient metropolis acceptance criterion evaluation objective function results complex simulation processes manipulate large dimension state space involving much memory population based algorithms applicable sa right answer address issues chapter introduction subject presents principles local search optimization algorithms simulated annealing extension metropolis algorithm basic component sa basic sa algorithm optimization described together two theoretical properties fundamental sa statistical equilibrium inspired elementary statistical physics asymptotic convergence based markov chain theory chapter surveys following practical issues interest user wishes implement sa algorithm particular application finite time approximation theoretical sa polynomial time cooling markov chain length stopping criteria simulation based evaluations illustrate concepts chapter presents straightforward application sa two classical simple classical np hard combinatorial optimization problems knapsack problem traveling salesman problem overall sa methodology deployed detail real life application large scale aircraft trajectory planning problem involving nearly flights european continental scale exemplifies tackle nowadays complex problems using simple scheme sa exploiting particular features problem integrating astute computer implementation within algorithm setting user defined parameters empirically inspired sa basic theory presented chapter â© springer international publishing ag part springer nature
10.1016/j.ejor.2018.05.053 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049566717&doi=10.1016%2fj.ejor.2018.05.053&partnerID=40&md5=103d4ae053bb6dd15f9c39e0e57171a9 0,estimation banking efficiency productivity essential regulatory purposes testing various theories context banking quiet life hypothesis bad management hypothesis etc studies therefore important place restrictions possible functional forms subject global satisfaction theoretical properties relating monotonicity concavity paper propose alternative nonparametric segmented concave least squares use differentiable approximation arbitrary functional form based smoothly mixing cobb douglas anchor functions data space estimation based bayesian techniques organized around markov chain monte carlo approximation properties new functional form investigated monte carlo experiment true functional form symmetric generalized mcfadden new techniques applied large u banking data set well global banking data set â© elsevier b v
10.1016/j.agrformet.2018.09.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053793802&doi=10.1016%2fj.agrformet.2018.09.002&partnerID=40&md5=6ddf17121fa5ad08ce2005bb12ae5396 0,reliable data driven models designed accurately estimate cotton yield important agricultural commodity adopted farmers agricultural system modelling experts agricultural policy makers strategic decision making processes paper hybrid genetic programing model integrated markov chain monte carlo mcmc based copula technique developed incorporate climate based inputs predictors cotton yield selected study regions faisalabad â°n â°e multan â°n â°e nawabshah â°n â°e important cotton growing hubs developing nation pakistan several different types gp mcmc copula models developed well known copula families e gaussian student clayton gumble frank fischer hinzmann functions screen utilize optimal cotton yield forecast model present study region results gp mcmc based hybrid copula model evaluated standalone gp mcmc based copula model accordance statistical analysis predicted yield based correlation coefficient r willmott index wi nash sutcliffe coefficient nse root mean squared error rmse mean absolute error mae independent test phase performance preciseness evaluated akiake information criterion aic bayesian information criterion bic maximum likelihood maxl gp mcmc based copula well mcmc based copula model gp mcmc clayton copula model generated accurate result multan station optimal gp mcmc clayton copula model acquired model evaluation metrics multan lmâ‰ˆ rrmseâ‰ˆ rrmaeâ‰ˆ followed mcmc based gaussian copula model lmâ‰ˆ rrmseâ‰ˆ rrmaeâ‰ˆ standalone gp model lmâ‰ˆ rrmseâ‰ˆ rrmaeâ‰ˆ indicating superiority gp mcmc clayton copula model respect benchmark models performance gp mcmc based copula model also found superior case faisalabad nawabshah station confirmed aic bic maxl metrics including larger value legates mccabe lm index utilized conjunction relative percentage rrmse relative mean absolute error rmae accordingly averred developed gp mcmc copula model considered pertinent data intelligent tool used accurate prediction cotton yield utilizing readily available climate datasets agricultural regions relevance agricultural yield simulation sectoral decision making â© elsevier b v
10.1016/j.jcp.2018.08.049 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052906458&doi=10.1016%2fj.jcp.2018.08.049&partnerID=40&md5=de4a8254a06b0badc63008e03d087788 0,present systematic study nested sampling algorithm based example potts model model exhibits first order phase transition q gt exemplifies generic numerical challenge statistical physics evaluation partition function thermodynamic observables involve high dimensional sums sharply structured multi modal density functions poses major challenge standard numerical techniques markov chain monte carlo paper demonstrate nested sampling particularly suited problems couple advantages calculating partition function potts model n sites one run stops n moves takes n operations run b single run required compute partition function along assignment confidence intervals c confidence intervals logarithmic partition function decrease n single run allows compute quantities temperatures autocorrelation time small irrespective temperature thermodynamic expectation values observables completely determined bond configuration representation fortuin kasteleyn like helmholtz free energy internal energy well entropy heat capacity calculated single run needed partition function along confidence intervals contrast thermodynamic expectation values magnetic properties like magnetization magnetic susceptibility require sampling additional spin degree freedom results performance studied detail compared obtained multi canonical sampling eventually implications findings parallel implementation nested sampling outlined â© elsevier inc
10.1080/00949655.2018.1523410 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053520378&doi=10.1080%2f00949655.2018.1523410&partnerID=40&md5=172d648970a50091ee668008889e9b38 0,study discuss classical bayesian generalized inference reliability parameter rs k = pr least x x xk exceed = pr xkâˆ’s+ k gt k g system strength components x x xk subjected common stress whose probability densities independent two parameter general class exponentiated inverted exponential distributions statistical analyses carried based progressively type ii right censored data uniformly random removals squared error linex loss functions bayes estimates developed using lindley approximation markov chain monte carlo method due lack closed forms posterior distributions generalized inferences performed based generalized variable method simulation studies real world data analyses given illustrate proposed procedures size test adjusted unadjusted power test coverage probability expected confidence lengths confidence interval biases estimator also discussed comparison contrast among classical bayesian generalized inferences reliability parameter multicomponent stress strength model performed â© â© informa uk limited trading taylor francis group
10.1061/(ASCE)HE.1943-5584.0001720 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054990653&doi=10.1061%2f%28ASCE%29HE.1943-5584.0001720&partnerID=40&md5=427e01f4e2132246e2ff32475420d9a2 0,study presents probabilistic framework considers water quality improvement capability reliability alternative total maximum daily load tmdl pollutant allocations generalized likelihood uncertainty estimation markov chain monte carlo techniques used assess relative uncertainty reliability two alternative tmdl pollutant allocations developed address fecal coliform fc bacteria impairment rural watershed western virginia allocation alternatives developed using hydrological simulation program fortran specified differing levels fc bacteria reduction different sources allocations met applicable water quality criteria approved tmdl allocation called less reduction fc source produced greatest uncertainty cattle directly depositing feces stream suggesting less reliable alternative called greater reduction source approach presented paper illustrates method incorporate uncertainty assessment tmdl development thereby enabling stakeholders engage informed decision making â© asce
10.1016/j.csda.2018.07.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050977723&doi=10.1016%2fj.csda.2018.07.005&partnerID=40&md5=ace032cb65eabfeea1e9ec056ca5c70a 0,reversible jump markov chain monte carlo rjmcmc method offers across model simulation approach bayesian estimation model comparison exploring sampling space consists several models possibly varying dimensions naive implementation rjmcmc models like gibbs random fields suffers computational difficulties posterior distribution model termed doubly intractable since computation likelihood function rarely available consequently simply impossible simulate transition markov chain presence likelihood intractability variant rjmcmc presented called noisy rjmcmc underlying transition kernel replaced approximation based unbiased estimators based previous theoretical developments convergence guarantees noisy rjmcmc algorithm provided experiments show noisy rjmcmc algorithm much efficient exact methods provided estimator controlled monte carlo variance used fact agreement theoretical analysis â© elsevier b v
10.1016/j.compstruct.2018.08.074 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054027278&doi=10.1016%2fj.compstruct.2018.08.074&partnerID=40&md5=7bc260d8ab153584398632dba9a21d29 0,paper presents novel stochastic framework quantify knock strength plane wrinkles coupon level key innovation markov chain monte carlo algorithm rigorously derives stochastic distribution wrinkle defects directly informed image data defects approach significantly reduces uncertainty parameterization stochastic numerical studies effects defects demonstrate methodology present original stochastic study determine distribution strength corner bend samples random plane wrinkle defects defects parameterized stochastic random fields defined using karhunen loã©ve kl modes distribution kl coefficients inferred misalignment data extracted b scan data using modified version multiple field image analysis strength distribution estimated embedding wrinkles high fidelity fe simulations using high performance toolbox dune composites observe severe knockdowns structural strength probability supported literature results highlight strong correlation maximum misalignment knockdown coupon strength observation allows us define surrogate model providing fast assessment predicted strength informed stochastic simulations utilizing observed wrinkle data high fidelity finite element models â©
10.1016/j.ejor.2018.05.026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048809412&doi=10.1016%2fj.ejor.2018.05.026&partnerID=40&md5=620235a887587788e7cf7b1fdab89c61 0,method presented real time forecasting product returns remanufacturing determines quantity imminent returns quality features age distribution number past cycles required data real time include mean age stock scaled quantity population average reliably monitored even small size decentralized stock samples maximum minimum age return samples past volumes net demand sales characteristic parameters return distribution center axis spread updated real time method sequentially determines retention probability time period key random variable unties dynamic closed loop supply chain knot retention probability sequence used explicit expressions product return flow age distribution quality index based markov representation stock flows model allows arbitrarily random early loss non stationarities uncertain demand varying utilization reusable returns markov chain monte carlo simulation enables assessment efficacy forecasting method exploiting reliable current information method may provide improved estimates product returns compared linear models relate returns past levels sales returns utilize conventional regression recursive least squares adaptive identification methods forecasting efficiency higher measured mean integral absolute error particularly regarding peaks lows return flow results may useful enhanced acquisition returns reduced stock inventories efficient planning remanufacturing operations â© elsevier b v
10.1016/j.automatica.2018.07.024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053166670&doi=10.1016%2fj.automatica.2018.07.024&partnerID=40&md5=c2107a8e93805b393d87acead42a9022 1,previous work proposed particle gaussian mixture pgm filter nonlinear estimation pgm filter uses transition kernel state markov chain sample propagated prior constructs gaussian mixture representation propagated prior density clustering samples measurement data incorporated updating individual mixture modes using kalman measurement update however kalman measurement update inexact measurement function nonlinear leads restrictive assumption number modes remains fixed measurement update paper introduce alternate pgm ii filter employs parallelized markov chain monte carlo mcmc sampling perform measurement update pgm ii filter update asymptotically exact enforce assumptions number gaussian modes pgm ii filter employed estimation two test case systems results indicate pgm ii filter suitable handling nonlinear non gaussian measurement update â© elsevier ltd
10.1111/jiec.12698 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035207702&doi=10.1111%2fjiec.12698&partnerID=40&md5=36c92f2381757f9eb1abf30ed66072d9 0,material flow analysis mfa widely used study life cycles materials production use reuse recycling disposal order identify environmental impacts opportunities address however development type analysis often constrained limited data may uncertain contradictory missing aggregated article proposes bayesian approach uncertain knowledge material flows described probability distributions little data initially available model predictions rather vague new data acquired systematically incorporated reduce level uncertainty reviewing previous approaches uncertainty mfa bayesian approach introduced general recipe application material flow analysis developed applied map global production steel using markov chain monte carlo simulations well aiding analyst get started face incomplete data incremental approach mfa also supports efforts improve communication results transparently accounting uncertainty throughout â© authors journal industrial ecology published wiley periodicals inc behalf yale university
10.1186/s13634-017-0524-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040464639&doi=10.1186%2fs13634-017-0524-6&partnerID=40&md5=f4ca3fe2f14d18462d31663f7ba7d5ae 0,monte carlo methods become essential tools solve complex bayesian inference problems different fields computational statistics machine learning statistical signal processing work introduce novel class adaptive monte carlo methods called adaptive independent sticky markov chain monte carlo mcmc algorithms sample efficiently bounded target probability density function pdf new class algorithms employs adaptive non parametric proposal densities become closer closer target number iterations increases proposal pdf built using interpolation procedures based set support points constructed iteratively previously drawn samples algorithmâ€™s efficiency ensured test supervises evolution set support points extra stage controls computational cost convergence proposal density target part novel family algorithms discussed several examples specific methods provided although novel algorithms presented univariate target densities show easily extended multivariate context embedding within gibbs type sampler hit run algorithm ergodicity ensured discussed overview related works literature also provided emphasizing several well known existing methods like adaptive rejection metropolis sampling arms scheme encompassed new class algorithms proposed eight numerical examples including inference hyper parameters gaussian processes widely used machine learning signal processing applications illustrate efficiency sticky schemes stand alone methods sample complicated one dimensional pdfs within gibbs samplers order draw multi dimensional target distributions â© author
10.1093/gji/ggy362 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054749227&doi=10.1093%2fgji%2fggy362&partnerID=40&md5=da0ae1f330e434b6d25dcce8a7372cdf 0,seismic surfacewave tomography tried tested method reveal subsurface structure earth however conventional step scheme inverting first dmaps surface wave phase group velocity inverting spatial velocity structure preserves little information lateral spatial correlations introduces additional uncertainties errors result introduce step non linear surface wave tomography method removes effects inverting spatial structure directly frequencydependent traveltime measurements achieve using reversible jump markov chain monte carlo mcmc algorithm fully model parametrization synthetic tests show method estimates velocity model associated uncertainties significantly better conventional step mcmc method computational cost seems comparable step mcmc methods resulting uncertainties intuitively reasonable step method provide directly interpretable uncertainty volumetrics structures interest â© author published oxford university press behalf royal astronomical society
10.1016/j.cam.2018.04.028 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047254709&doi=10.1016%2fj.cam.2018.04.028&partnerID=40&md5=879e3f25bcd73b08721ae237459ccc6d 0,article consider problem estimation prediction unknown parameters lomax distribution lifetime data observed presence progressively type hybrid censoring scheme classical scenario expectationâ€“maximization em algorithm utilized derive maximum likelihood estimates mles unknown parameters associated confidence intervals bayesian framework point estimates unknown parameters respect different symmetric asymmetric balanced loss functions obtained using tierneyâ€“kadane approximation markov chain monte carlo mcmc technique also highest posterior density hpd credible intervals parameters reckoned using importance sampling procedure simulation experiments performed compare different proposed methods predictive estimates censored observations corresponding prediction intervals also provided one real life data example presented illustrate derived results â© elsevier b v
10.1016/j.jhydrol.2018.10.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055130504&doi=10.1016%2fj.jhydrol.2018.10.004&partnerID=40&md5=cb7c515255a30e9df0b062cf6476872e 0,fracture scale heterogeneity plays important role driving dispersion mixing heat transfer fractured rocks current approaches characterize fracture scale flow transport processes largely rely indirect information based interpretation tracer tests geophysical techniques used parallel tracer tests offer time lapse images indicative migration electrically conductive tracers away injection location study present methodology invert time lapse ground penetrating radar reflection monitoring data acquired push pull tracer test infer fracture scale transport patterns aperture distribution using probabilistic inversion based markov chain monte carlo algorithm demonstration synthetic dataset apply new inversion method field data main findings marginal distribution local fracture apertures well resolved field site characterized strong flow channeling consistent interpretations heat tracer tests injection fracture â© elsevier b v
10.1007/s00180-018-0801-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042227577&doi=10.1007%2fs00180-018-0801-3&partnerID=40&md5=c165d68bb145fc590c85a12458a3ff57 0,flexible bayesian periodic autoregressive model used prediction quarterly monthly time series data unknown autoregressive lag order occurrence structural breaks respective break dates common sources uncertainty treated random quantities within bayesian framework since analytical expressions corresponding marginal posterior predictive distributions exist markov chain monte carlo approach based data augmentation proposed performance demonstrated monte carlo experiments instead resorting model selection approach choosing particular candidate model prediction forecasting approach based bayesian model averaging used order account model uncertainty improve forecasting accuracy model diagnosis bayesian sign test introduced compare predictive accuracy different forecasting models terms statistical significance empirical application using monthly unemployment rates germany performance model averaging prediction approach compared model selected bayesian classical non periodic time series models â© springer verlag gmbh germany part springer nature
10.1016/j.cam.2018.05.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047760683&doi=10.1016%2fj.cam.2018.05.013&partnerID=40&md5=f967bf8753a1c82217d7cde96ad3222b 0,competing risks model based kumaraswamy distribution discussed progressive censoring latent lifetime model failure causes features different common parameters maximum likelihood estimates unknown parameters established existence uniqueness estimates provided approximate confidence intervals also constructed via observed fisher information matrix moreover bayes estimates associated highest posterior density credible intervals also obtained based monte carlo markov chain sampling methods addition test equivalence parameters competing risks likelihood ratio test also proposed finally simulation studies real life example presented illustration purpose â© elsevier b v
10.1038/s41598-018-24648-w https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045963174&doi=10.1038%2fs41598-018-24648-w&partnerID=40&md5=d5cab9a05fec2982b889a2535c1ee018 0,present framework simulate sir processes networks using weighted shortest paths framework maps sir dynamics weights assigned edges network done markovian non markovian processes alike weights represent propagation time adjacent nodes particular realization simulate dynamics constructing ensemble realizations done using markov chain monte carlo method direct sampling former provides runtime advantage realizations possible sources computed weighted shortest paths calculated efficiently apply framework three empirical networks analyze expected propagation time pairs nodes furthermore employed framework perform efficient source detection improve strategies time critical vaccination â© author
10.1016/j.sigpro.2018.07.028 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051832245&doi=10.1016%2fj.sigpro.2018.07.028&partnerID=40&md5=5299a027e20da3bb3c2e0f1071fab26b 0,reversible jump markov chain monte carlo rjmcmc bayesian model estimation method generally used trans dimensional sampling model order selection studies literature study draw attention unexplored potentials rjmcmc beyond trans dimensional sampling proposed usage call trans space rjmcmc exploits original formulation explore spaces different classes structures provides flexibility using different types candidate classes combined model space spaces linear nonlinear models various distribution families application looked special case trans space sampling namely trans distributional rjmcmc impulsive data modeling many areas seismology radar image using gaussian models common practice due analytical ease however many noise processes follow gaussian character generally exhibit events impulsive successfully described gaussian model test proposed usage rjmcmc choose various impulsive distribution families model synthetically generated noise processes real life measurements power line communications impulsive noises discrete wavelet transform coefficients â© elsevier b v
10.1016/j.jad.2018.07.044 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051484252&doi=10.1016%2fj.jad.2018.07.044&partnerID=40&md5=47a42fbf2aa5511d1f338abef7553324 0,background postpartum depression negatively affects whole family prevalence sweden ranges â€“ fathers â€“ mothers however mothers sweden currently routinely screened aim aim study determine postpartum depression screening fathers stockholm county cost effective methods national swedish databases used find registry data literature review undertaken identify model data inputs associated postpartum depression sweden generated evidence used build markov model treeage one way probabilistic sensitivity analyses performed account parameter uncertainties alternative scenario analyses undertaken test assumptions base case analysis results postpartum screening depression fathers cost effective base case alternative scenarios results indicate screening program associated lower costs higher health effects results sensitive variables quality adjusted life years depressed fathers probabilities remission treatment treatment groups start age productivity losses probabilistic sensitivity analysis resulted probability postnatal depression screening intervention cost effective limitations current study uses secondary data therefore future research assess cost effectiveness screening fathers depression conclusion postpartum screening intervention fathers cost effective compared screening future research replicate potential cost effectiveness screening fathers postpartum depression â©
10.1016/j.copbio.2018.01.023 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043587135&doi=10.1016%2fj.copbio.2018.01.023&partnerID=40&md5=34fbd2f28c735b3d6fed20c9991c4d98 0,organisms chromatin packed fulfil structural constraints functional requirements hierarchical model chromatin organization nuclear space encompasses different topologies diverse scale lengths chromosomes occupying distinct volumes organized compartments inside chromatin fibers fold large domains short range loops recent years combination chromosome conformation capture c techniques high throughput sequencing allowed probing chromatin spatial organization whole genome scale c based methods produce enormous amounts genomic data analyzed using ad hoc computational procedures review common pipelines methods analysis genome wide chromosome conformation capture data highlighting recent developments key steps identification chromatin structures â© elsevier ltd
10.1007/s00180-018-0799-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042223829&doi=10.1007%2fs00180-018-0799-6&partnerID=40&md5=2bf5ced10ab31aba590de2c15b5a6148 0,using recent developments econometrics computational statistics consider estimation fractional ornsteinâ€“uhlenbeck process flow sampling scheme address problem adopt throughout paper exact discretization approach flow sampling scheme arises example naturally modelling asset prices continuous time since time integral successive observations defines observable increments asset log prices exact discretization delivers arima model log prices fractional driving noise building resulting exact discretization formulae covariance function new markov chain monte carlo scheme proposed apply investigate properties time frequency domain likelihoods posteriors exact discrete model adopt general sampling interval length h allows us determine optimal choice h independent sample size illustrate methods ambition comprehensive data analysis use high frequency stock price data showing relevance aggregation time issues modelling asset prices â© springer verlag gmbh germany part springer nature
10.1007/s00180-018-0805-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043462586&doi=10.1007%2fs00180-018-0805-z&partnerID=40&md5=3c4ceb75009f99c54db7cb8ce9338813 0,paper describes package sppmix statistical environment r sppmix package implements classes methods modeling spatial point patterns using inhomogeneous poisson point processes intensity surface assumed multiple finite additive mixture normal components number components finite fixed random integer extensions marked inhomogeneous poisson point processes case also presented provide extensive suite r functions used simulate visualize model point patterns estimate parameters models assess convergence algorithms perform model selection checking proposed modeling context addition several approaches implemented order handle standard label switching issue arises modeling approach involving mixture models adapt hierarchical bayesian framework order model intensity surfaces implemented two major algorithms order estimate parameters mixture models involved data augmentation birthâ€“death markov chain monte carlo damcmc bdmcmc used c++ via rcpp package order implement computationally intensive algorithms â© springer verlag gmbh germany part springer nature
10.1016/j.dark.2018.09.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053439820&doi=10.1016%2fj.dark.2018.09.001&partnerID=40&md5=d07925af26c6936d70394c262dd44076 0,generalized chaplygin gas considered unified dark fluid model might describe past decelerating matter dominated era present time provides accelerating expansion universe paper employed planck cosmic microwave background anisotropy type ia supernovae observed hubble parameter data sets measure full parameter space generalized chaplygin gas unified dark matter dark energy model model parameters bs î± determine evolutional history unified dark fluid model influencing energy density ï�gcg=ï�gcg bs+ âˆ’bs aâˆ’ +î± âˆ• +î± assume pure adiabatic perturbation unified generalized chaplygin gas light markov chain monte carlo method found bs= âˆ’ âˆ’ + + î±= âˆ’ âˆ’ + + ïƒ level model parameter î± close zero nature gcg model similar cosmological standard model î›cdm â© elsevier b v
10.1186/s40649-018-0051-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050802342&doi=10.1186%2fs40649-018-0051-0&partnerID=40&md5=30680a990cd47c571159f063e81ea829 0,background framework network sampling random walk rw based estimation techniques provide many pragmatic solutions uncovering unknown network little possible despite several theoretical advances area rw based sampling techniques usually make strong assumption samples stationary regime hence impelled leave samples collected burn period methods work proposes two sampling schemes without burn time constraint estimate average arbitrary function defined network nodes example average age users social network central idea algorithms lies exploiting regeneration rws revisits aggregated super node set nodes strategies enhance frequency regenerations either contracting graph making hitting set larger first algorithm based reinforcement learning rl uses stochastic approximation derive estimator method seen intermediate purely stochastic markov chain monte carlo iterations deterministic relative value iterations second algorithm call ratio tours rt estimator modified form respondent driven sampling rds accommodates idea regeneration results study methods via simulations real networks observe trajectories rl estimator much stable standard random walk based estimation procedures error performance comparable respondent driven sampling rds smaller asymptotic variance many estimators simulation studies also show mean squared error rt estimator decays much faster rds time conclusion newly developed rw based estimators rl rt estimators allow avoid burn period provide better control stability along sample path overall reduce estimation time estimators applied social complex networks â© author
10.1016/j.neucom.2018.08.071 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053159085&doi=10.1016%2fj.neucom.2018.08.071&partnerID=40&md5=4255325c87b8122e813cde24e9b7475d 0,great number machine learning algorithms strongly depend underlying distance metric representing important correlations input data distance metric learning defined learning appropriate similarity distance metric input data pairs metric learning algorithms supervised unsupervised categories different deterministic probabilistic approaches one objectives unsupervised metric learning project data points new space way high clustering accuracy provided obtainable maximizing clusters separation exist deterministic metric learning methods serve purpose article probabilistic method unsupervised distance metric learning proposed aims maximize separability among different clusters projected space proposed method distance metric learning fuzzy c means clustering jointly formulated sense fcm provides clusters distance metric learning algorithm applies obtained clusters materialize maximum separability among moreover markov chain monte carlo mcmc algorithm applied infer latent variables proposed method obtain low dimensional projection specified number dimensions also learn proper number reduced dimensions dataset automated sense experimental results reveal performance method different real world datasets counterparts â© elsevier b v
10.1093/mnras/sty2144 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054062183&doi=10.1093%2fmnras%2fsty2144&partnerID=40&md5=0a9f3b9a61d47316811d5758c1be76a6 0,present day spectrum extragalactic background light ebl uv optical ir wavelengths integral result multiple astrophysical processes going throughout evolution universe relevant processes include star formation stellar evolution light absorption emission cosmic dust properties processes known uncertainties contribute ebl spectrum precision paper develop numerical model ebl spectrum maintaining explicit dependence astrophysical parameters involved constructed markov chain parameter space using likelihood function built date upper lower bounds ebl intensity posterior distributions built markov chain monte carlo method used determine allowed range individual parameters model consequently star formation rate multiplication factor constrained range lt csfr lt per cent c l method also results bounds lifetime radius dust particle density opacity molecular clouds large ambiguity otherwise shown reasonable agreement model intensity bounds astrophysical parameters best fitting model close estimates literature â© author published oxford university press behalf royal astronomical society
10.1093/mnras/sty2326 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054084560&doi=10.1093%2fmnras%2fsty2326&partnerID=40&md5=58387c5297ffe866017b5b0a3eba0afa 0,well known bayes theorem assumes posterior distribution probability distribution however posterior distribution may longer probability distribution improper prior distribution non probability measure unbounded uniform prior used improper priors often used astronomical literature reflect lack prior knowledge checking whether resulting posterior probability distribution sometimes neglected turns articles per cent published online two renowned astronomy journals apj mnras jan oct make use bayesian analyses without rigorously establishing posterior propriety disturbing aspect gibbs type markov chain monte carlo mcmc method produce seemingly reasonable posterior sample even posterior probability distribution hobert casella cases researchers may erroneously make probabilistic inferences without noticing mcmc sample non existing probability distribution review checking posterior propriety fundamental bayesian analyses discuss set scientifically motivated proper priors â© author published oxford university press behalf royal astronomical society
10.1108/MRR-11-2017-0377 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049564282&doi=10.1108%2fMRR-11-2017-0377&partnerID=40&md5=860426a8fba26f3c658200dd3acba248 0,purpose paper aims popularize bayesian methods among novice management researchers paper interprets results bayesian method confirmatory factor analysis cfa structural equation modelling sem mediation moderation analysis intention novice researchers apply method research paper made attempt discussing various complex mathematical concepts markov chain monte carlo bayes factor bayesian information criterion deviance information criterion dic etc lucid manner design methodology approach data collected pharmaceutical sales representatives used study help management researchers perform bayesian cfa bayesian sem bayesian moderation analysis bayesian mediation analysis using spss amos software findings interpretation results bayesian cfa bayesian sem bayesian mediation analysis discussed practical implications management scholars non statisticians much aware benefits offered bayesian methods hitherto management scholars use predominantly traditional sem validating models empirically study give exposure â€œbayesian statisticsâ€� practical advantages originality value one paper discusses following four concepts bayesian method cfa sem mediation moderation analysis â© emerald publishing limited
10.1080/02664763.2018.1435633 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042221260&doi=10.1080%2f02664763.2018.1435633&partnerID=40&md5=2a45803b1a9b5c4881b3f45110b83f77 0,word clouds constitute one popular statistical tools visual analysis text documents provide users quick intuitive understanding content despite popularity visualizing single documents word clouds appropriate compare different text documents independently generating word clouds document leads configurations word typically located widely different positions makes difficult compare two word clouds paper introduces cowords new stochastic algorithm create multiple word clouds including one document shared words multiple documents placed position clouds similar documents produce similar compact clouds making easier simultaneously compare interpret several word clouds algorithm based probability distribution probable configurations desirable visual aspect low value total distance words clouds algorithm output set word clouds randomly selected probability distribution selection procedure uses markov chain monte carlo simulation method present several examples illustrate performance visual results obtained algorithm â© â© informa uk limited trading taylor francis group
10.1016/j.atmosres.2018.07.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049460229&doi=10.1016%2fj.atmosres.2018.07.005&partnerID=40&md5=0a55d723e94ce9e6f61c1e6082983cdc 3,ameliorate agricultural impacts due persistent drought risks promoting sustainable utilization pre planning water resources accurate rainfall forecasting models addressing dynamic nature drought phenomenon crucial paper multi stage probabilistic machine learning model designed evaluated forecasting monthly rainfall multi stage hybrid mcmc cop bat os elm model utilizing online sequential extreme learning machines integrated markov chain monte carlo mcmc based bivariate copula bat algorithm employed incorporate significant antecedent rainfall tâ€“ model predictor training phase computing partial autocorrelation function pacf first stage twenty five mcmc based copulas e gaussian clayton gumble frank fischer hinzmann etc adopted determine dependence antecedent month rainfall current future rainfall second stage model design bat algorithm applied sort optimal mcmc copula model feature selection strategy third stage fourth stage pacf optimal mcmc copula model computed couple output os elm algorithm forecast future rainfall values independent test dataset benchmarking process standalone extreme learning machine elm random forest rf also integrated mcmc based copulas bat algorithm yielding hybrid mcmc cop bat elm mcmc cop bat rf models proposed multi stage hybrid model tested agricultural belt region faisalabad jhelum multan located pakistan testing performance three hybridized models according robust statistical error metrics satisfactory comparison standalone counterparts however multi stage hybridized mcmc cop bat os elm model found superior tool forecasting monthly rainfall multi stage probabilistic learning model explored pertinent decision support tool agricultural water resources management arid semi arid regions statistically significant relationship antecedent rainfall exists â© elsevier b v
10.1016/j.chemolab.2018.09.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054834438&doi=10.1016%2fj.chemolab.2018.09.004&partnerID=40&md5=2999a26a10726b0bc5eb68fbcd771f3a 0,tutorial user friendly program evaluating risks false decisions conformity assessment multicomponent material object due measurement uncertainty based bayesian approach presented developed program consists two separate ms excel spreadsheets allows calculation consumer producer risks concerning component material whose concentration tested â€˜particular risksâ€™ well concerning material whole â€˜total risksâ€™ according bayesian framework probability density functions actual â€˜trueâ€™ component concentrations prior pdfs likelihood functions likelihoods corresponding test results used model knowledge material object cases independent correlated variables actual concentrations test results treated present work spreadsheets provide estimate joint posterior pdf actual component concentrations normalized product multivariate prior pdf likelihood starting normal log normal prior pdfs normal likelihoods using markov chain monte carlo mcmc simulations metropolis hastings algorithm principles bayesian inference mcmc described users basic knowledge statistics necessary correct formulation task interpretation calculation results spreadsheet program validated comparison obtained results analytical results calculated r programming environment developed program allows estimation risks greater standard deviations estimates spreading depending risk value estimation characteristics satisfactory taking account known variability measurement uncertainty associated test results multicomponent materials â© elsevier b v
10.1080/0022250X.2017.1396985 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033672992&doi=10.1080%2f0022250X.2017.1396985&partnerID=40&md5=db7816f2ed11558a61fc26c3d299cc9d 0,generation deviates random graph models nontrivial edge dependence increasingly important problem introduce method allows perfect sampling random graph models exponential family form â€œexponential family random graphâ€� models using variant coupling past illustrate use method via application markov graphs family subject considerable research also show method applied variant biased net models exponentially parameterized â© taylor francis
10.1016/j.ecss.2018.07.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049775859&doi=10.1016%2fj.ecss.2018.07.012&partnerID=40&md5=98437a6722e149e68f908df2053808d6 0,differences species diversity ecosystems long often discussed interrogated ecological research two year study zooplankton diversity meghna river estuary bangladesh found diversity comparatively higher estuary river study examines whether biotic interactions species explain diversity difference two aquatic habitats study based several species diversity hypotheses related biotic interactions e low interspecific interactions comparatively higher disturbance higher species recruitments higher intransitivities cause higher species diversity first order markov chain model used estimate biotic interactions e species displacement ability disturbance colonization intransitivities monte carlo markov chain mcmc simulations performed estimate species interactions markov chain model results suggest low inter specific interactions comparatively higher disturbance rate higher species recruitment intransitivies meghna estuary caused higher zooplankton meghna riverine ecosystem addition evident negative association species colonization species displacement ability displacement risk also led comparatively higher diversity meghna estuary meghna river apparent zooplankton abundance data biotic interactions explain zooplankton species diversity difference meghna aquatic ecosystems bangladesh findings current study provides valuable insights zooplankton diversity differences tropical ecosystems â© elsevier ltd
10.1016/j.tecto.2018.09.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053936110&doi=10.1016%2fj.tecto.2018.09.005&partnerID=40&md5=c02e8901e0068c899204b44569e23cc1 0,monte carlo uncertainty estimation mcue emerging heuristic uncertainty propagation method designed provide reliable time cost efficient estimates geometrical uncertainties geological modeling mcue subtype bayesian monte carlo method similar geostatistical simulation methods described rely disturbance probability distributions parameterized best represent individual input uncertainty essentially disturbance distributions quantify error location x z orientation dip azimuth observed geological structures disturbance distributions sampled either independently via markov chain produce many plausible alternative datasets plausible datasets input geological modeling engine build series plausible alternative model realizations processing may applied series plausible models provide valuable decision aids probabilistic models reliability models uncertainty reduction hotspot maps paper complete comprehensive mcue procedure common drillhole path log uncertainty propagation proposed basic concepts drillhole uncertainty introduced applied markov chain scheme appropriate disturbance distributions different parts problem respective parameterization discussed method proposed demonstrated three separate proof concept case studies increasing complexity results demonstrate method able propagate path log uncertainty appropriately first order interpretation indicates path log uncertainty increase depth angle attack geological interfaces ignoring drillhole uncertainty found detrimental understanding modeled area likely due constraining effect brought â€œperfectâ€� drillholes third case study mansfield hints uncertainty better reduced drillholes intersect â€œtriple lineâ€� partitions three distinct lithologies cross sections triples lines appear triple points â© authors
10.1080/00949655.2018.1504944 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052104064&doi=10.1080%2f00949655.2018.1504944&partnerID=40&md5=31dbf81f6de0540882ee70165a110ae5 0,interval censored survival data arise often medical applications clinical trials wang l sun j tong x regression analyis case ii interval censored failure time data additive hazards model statistica sinica â€“ however existing interval censored survival analysis techniques suffer challenges heavy computational cost non proportionality hazard rates due complicated data structure wang l lin x bayesian approach analyzing case interval censored data semiparametric proportional odds model statistics probability letters â€“ banerjee chen h dey dk et al bayesian analysis generalized odds rate hazards models survival data lifetime data analysis â€“ address challenges paper introduce flexible bayesian non parametric procedure estimation odds interval censoring case ii use bernstein polynomials introduce prior modeling odds propose novel easy implement sampling manner based markov chain monte carlo algorithms study posterior distributions also give general results asymptotic properties posterior distributions simulated examples show proposed approach quite satisfactory cases considered use proposed method illustrated analyzing hemophilia study data mcmahan cs wang l package semiparametric regression analysis interval censored data http cran r project org package=icsurv â© â© informa uk limited trading taylor francis group
10.1080/13658816.2018.1504219 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052941492&doi=10.1080%2f13658816.2018.1504219&partnerID=40&md5=d4bec8c0ea992b2abb2b902e5ecd3496 0,research match web based activity diary data daily mobility information recorded gps trackers sample residents day survey beijing investigate activity satisfaction given complications arising irregular time intervals gps integrated diary data associated complex dependency structure direct application standard spatial panel data econometric approaches inappropriate study develops multi level temporal autoregressive modelling approach analyse data conceptualises time continuous examines sequential correlations via time space time weights matrix moreover manage simultaneously model individual heterogeneity inclusion individual random effects treated flexibly either independent dependent bayesian markov chain monte carlo mcmc algorithms developed model implementation positive sequential correlations individual heterogeneity effects found statistically significant geographical contextual characteristics sites activities take place significantly associated daily activity satisfaction controlling range situational characteristics individual socio demographic attributes apart conceivable urban planning development implications study demonstrate novel statistical methodology analysing semantic gps trajectory data general â© â© informa uk limited trading taylor francis group
10.1109/TIE.2018.2815941 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043763344&doi=10.1109%2fTIE.2018.2815941&partnerID=40&md5=7f95dbc7d0369259b3bb391d19cf26ac 0,new generation high efficiency video coding hevc standard recently developed joint collaborative team video coding provide significant improvement picture quality especially high resolution videos however one important challenges hevc high degree computational complexity problem addressed novel way considering skip detection coding unit termination two class decision making problems bayesian classifier used approaches prior class conditional probability values bayesian classifier known time encoding video frame therefore markov chain monte carlo model used experimental results show proposed method provides significant time reduction encoding reasonably low loss video quality â© ieee
10.3150/17-BEJ976 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046714336&doi=10.3150%2f17-BEJ976&partnerID=40&md5=9869ab53d5b63b9031ee46dd957bb8d8 1,purpose paper introduce new markov chain monte carlo method express effectiveness simulation high dimensional asymptotic theory key fact algorithm reversible proposal kernel designed heavy tailed invariant probability distribution high dimensional asymptotic theory studied class heavy tailed target probability distributions number dimensions state space passes infinity show algorithm much higher convergence rate pre conditioned crankâ€“nicolson pcn algorithm random walk metropolis algorithm â© isi bs
10.1016/j.dsp.2018.07.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051273711&doi=10.1016%2fj.dsp.2018.07.007&partnerID=40&md5=de27b7421f972ddaefde865c88b00943 1,bayesian methods implementations means sophisticated monte carlo techniques become popular signal processing last years importance sampling well known monte carlo technique approximates integrals involving posterior distribution means weighted samples work study assignation single weighted sample compresses information contained population weighted samples part theory present group importance sampling gis employed implicitly different works literature provided analysis yields several theoretical practical consequences instance discuss application gis sequential importance resampling framework show independent multiple try metropolis schemes interpreted standard metropolisâ€“hastings algorithm following gis approach also introduce two novel markov chain monte carlo mcmc techniques based gis first one named group metropolis sampling method produces markov chain sets weighted samples sets employed obtaining unique global estimator second one distributed particle metropolisâ€“hastings technique different parallel particle filters jointly used drive mcmc algorithm different resampled trajectories compared tested proper acceptance probability novel schemes tested different numerical experiments learning hyperparameters gaussian processes two localization problems wireless sensor network synthetic real data tracking vegetation parameters given satellite observations compared several benchmark monte carlo techniques three illustrative matlab demos also provided â© elsevier inc
10.1016/j.cageo.2018.07.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050894096&doi=10.1016%2fj.cageo.2018.07.004&partnerID=40&md5=56f4e3055094cc114e850be067e9814e 1,amorph utilizes new bayesian statistical approach interpreting x ray diffraction results samples crystalline amorphous components amorph fits x ray diffraction patterns mixture narrow wide components simultaneously inferring model parameters quantifying uncertainties program simulates background patterns previously applied manually providing reproducible results significantly reducing inter intra user biases approach allows quantification amorphous crystalline materials characterization amorphous component including properties centre mass width skewness nongaussianity amorphous component results demonstrate applicability program calculating amorphous contents volcanic materials independently modeling properties compositionally variable materials â© elsevier ltd
10.1016/j.jeconom.2018.08.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053813655&doi=10.1016%2fj.jeconom.2018.08.001&partnerID=40&md5=69cca64c3bc3a8b8c33f6a2ba880af26 0,two test statistics proposed determine model specification model estimated mcmc method first test mcmc version iosa test asymptotic null distribution normal second test motivated power enhancement technique fan et al combines component j tests null point hypothesis expanded model power enhancement component j obtained first test shown j converges zero null model correctly specified diverges null model misspecified also shown j asymptotically ï‡ distributed suggesting second test asymptotically pivotal null model correctly specified main feature first test alternative model needed second test several properties first size distortion small hence bootstrap methods avoided second easy compute mcmc output hence applicable wide range models including latent variable models frequentist methods difficult use third test statistic rejects null model j takes large value test suggests source misspecification finite sample performance investigated using simulated data method illustrated linear regression model linear state space model stochastic volatility model using real data â© elsevier b v
10.1016/j.autcon.2018.08.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052646219&doi=10.1016%2fj.autcon.2018.08.014&partnerID=40&md5=d202114b68ad92a5cdace1dae02895fa 0,crosshole ground penetrating radar gpr widely used measurement technique help inspect structural integrity man made underground structures previous paper introduced bayesian framework inversion crosshole gpr experiments help back defects concrete underground structures evaluate practical usefulness inversion framework application waveform data real world gpr survey diaphragm wall panel two embedded structure defects also use case study refine methodology introducing elements two stage inversion method help delineate exact location shape small structure defects herein low resolution inversion composed relatively inversion coefficients stage used determine roughly presence structure defects followed second inversion stage much enhanced spatial resolution areas classified anomalous suspicious permittivity values two stage inversion approach uses wisely cpu resources focusing primarily areas concrete structure classified anomalies investigate benefits two stage inversion scheme using synthetic real world case study involving waveform data diaphragm wall panel measured crosshole gpr results demonstrate proposed two stage inversion method recovers successfully location shape structure defects computational cost considerably lower original inversion framework â©
10.1016/j.mbs.2018.08.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053711844&doi=10.1016%2fj.mbs.2018.08.011&partnerID=40&md5=45ed9a7707f765dd2b23236e5e7d2a8d 0,background objectivebayesian state space models recent advancement stochastic modeling capture randomness hidden background process scrutinizing prior knowledge likelihood observed data article elucidate scope bayesian state space modeling predicting future expression values longitudinal micro array data methodsthe study conveniently makes use longitudinally collected clinical trial data gse ncbi gene expression omnibus geo data repository multiple testing methodology using test used selecting differentially expressed genes groups fitting model parameter values predictive model future expression levels estimated drawing samples posterior joint distribution using stochastic markov chain monte carlo mcmc algorithm relies gibbs sampling study also made attempt get estimates credible interval assumptions different covariance structures like variance components first order auto regressive unstructured varianceâ€“covariance structure showcase flexibility algorithm results distinct genes significantly different expression levels selected model fitting parameter estimates showed almost similar trends different covariance structure assumption cross tabulation gene frequencies minimum credible interval covariance structure study group showed significant p value conclusionspresent study reveals bayesian state space models effectively used explain predict complex data like gene expression data â© elsevier inc
10.1016/j.jhydrol.2018.08.047 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053828433&doi=10.1016%2fj.jhydrol.2018.08.047&partnerID=40&md5=42da371335dc597d1a67c8384507a876 0,carbon c measured groundwater half century remains widely used tool understanding groundwater flow systems ultimately usefulness c groundwater tracer relies ability distinguish changes concentration due various chemical physical processes e g chemical reactions solid carbonate material conditions water table changes due ageing along flow paths latter informative groundwater flow conditions end number correction methodologies developed account chemical modifications groundwater systems paper implement two different single sample correction models one closed one open system carbonate dissolution conjunction markov chain monte carlo mcmc approach two sites sedimentary port willunga formation aquifer south australia fractured rock aquifer hamersley basin northwest australia comparison include argon ar data taken wells sampled use mixing envelope constraint mcmc procedure found considering errors associated c correction resulted distribution values consider groundwater dating procedures accounting parameters associated single sample correction techniques associated error times greater analytical errors additionally inclusion ar data produced mixed results little improvement observed port willunga aquifer closed system correction significant improvement observed hamersley site open system likely due mixing caused long screens sensitivity open system correction model results highlight importance considering sources error groundwater dating studies â© elsevier b v
10.1002/for.2546 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053503795&doi=10.1002%2ffor.2546&partnerID=40&md5=d6bde55295833c0310822301a8c7b5db 0,paper examines method filtering volatility dynamics kospi index stochastic volatility model study applies particle filter algorithm sequential estimation volatility dynamics order improve estimation cross asset class approach adopted adding option price information model entire estimation procedure including derivation theoretical option price based bayesian markov chain monte carlo methods method presented paper applied diversified volatility models simulation study confirm method estimate unknown volatility dynamics correctly use additional option prices improves accuracy efficiency volatility filtering sequential one step ahead prediction distribution kospi index index option prices shows additional option price information also enhances prediction performance â© john wiley sons ltd
10.1002/wics.1441 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054701188&doi=10.1002%2fwics.1441&partnerID=40&md5=8c69703bb4d3bfcf51714b11a512157b 0,analysis small area health data often focus epidemiological research possible provide smoothed risk estimates disease maps often important consider underlying structure risk outcome suggested understanding etiology disease processes address complex problem important consider latent structure disease risk latent structure take variety forms basic random effects complex latent variables models paper review outline basic approaches problem latent structure spatio temporal health outcome data solutions bayesian modeling offer article categorized applications computational statistics computational climate change numerical weather forecasting statistical learning exploratory methods data sciences modeling methods statistical graphical methods data analysis bayesian methods theory statistical graphical methods data analysis markov chain monte carlo mcmc â© wiley periodicals inc
10.1115/1.4038475 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049388189&doi=10.1115%2f1.4038475&partnerID=40&md5=12249e70d09cd8a441c3e893ed3baa3a 1,paper present method determine quantitative stability level lean premixed combustor dynamic pressure data specifically make use autocorrelation function dynamic pressure signal acquired combustor turbulent flame acts thermoacoustic driver proposed approach unfiltered pressure signal including several modes analyzed algorithm based bayesian statistics purpose gibbs sampler used calculate parameters like damping rates eigenfrequencies form probability density functions pdf markov chain monte carlo mcmc method method provides robust solution algorithm fitting problems without requiring initial values advantage lies nature statistical approach since results assessed regarding quality means pdf standard deviation obtained parameters first simulation stochastically forced van der pol oscillator preset input values carried demonstrate accuracy robustness method context shown despite large amount uncorrelated background noise identified damping rates good agreement simulated parameters second technique applied measured pressure data combustor initially operated stable conditions thermal power gradually increased adjusting fuel mass flow rate limit cycle oscillation established found obtained damping rates qualitatively line amplitude levels observed operation combustor copyright â© asme
10.1016/j.nucengdes.2018.08.016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052301925&doi=10.1016%2fj.nucengdes.2018.08.016&partnerID=40&md5=8e87dd6358450b48dff7269955bb0f93 0,seismic risk assessment fragility curve used estimate reliability structures equipment seismic loads shape fragility curves usually approximated cumulative distribution function lognormal distribution estimation parameters fragility curves requires gathering different sources information quantifying uncertainties coming sources paper proposes methodology computation fragility curves nuclear power plant equipment based bayesian updating framework combines results numerical simulations damage data artificial neural network trained iteratively optimizing prediction uncertainties ground motion sample space used conduct numerical simulations results numerical simulations provide prior estimation seismic capacity equipment estimation uncertainty related equipment capacity taken literature damage data collected situ observation database seismic qualification utility group squg used construct likelihood function bayesian updating posterior equipment capacity evaluated markov chain monte carlo simulation posterior fragility curves obtained main contributions work proposal adaptive training algorithm artificial neural networks improve design experiments finite element simulations ii proposal two step transformation method construct likelihood function existing damage data squg database methodology applied compute fragility curves low voltage switchgear nuclear power plant within called karisma benchmark â© elsevier b v
10.1109/TASLP.2018.2852500 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049342264&doi=10.1109%2fTASLP.2018.2852500&partnerID=40&md5=40aedb01cdc2cd5cb8bfe875941e3223 0,develop parallelizable markov chain monte carlo sampler dirichlet process mixture mixtures model sampler jointly infers codebook clusters codebook global collection components clusters mixtures defined codebook combine nonergodic gibbs sampler two layers split merge samplers codebook mixture level form valid ergodic chain design additional switch sampler components supports convergence experimental results use case unsupervised subword modeling show method infers complex classes real speech feature vectors consistently show higher quality several evaluation metrics time infer fewer classes represent subword units consistently show longer durations compared standard dirichlet process mixture model sampler â© ieee
10.1007/s11128-018-2078-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053852552&doi=10.1007%2fs11128-018-2078-4&partnerID=40&md5=9a921e34330aacc0f6abf0f2fca5294a 0,investigate quantum parameter estimation circuit quantum electrodynamics via dispersive measurement based metropolisâ€“hastings algorithm markov chain monte carlo mcmc integration new algorithm proposed calculate fisher information stochastic master equation fisher information expressed form log likelihood functions approximated mcmc integration numerical results show evolution fisher information approach quantum fisher information short time interval results demonstrate effectiveness proposed algorithm finally based proposed algorithm consider effects measurement operator measurement efficiency fisher information â© springer science+business media llc part springer nature
10.1016/j.ejor.2017.10.059 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034420961&doi=10.1016%2fj.ejor.2017.10.059&partnerID=40&md5=962e5a6b7fcf4c55c29aa160e2171d33 0,shelf stock oos salient problem causes non trivial profit loss retailing tackle shelf oos plagues customers retailers suppliers develop decision support model managers aim fix recurring issue shelf oos data driven audits specifically propose point sale pos data analytics approach use consecutive zero sales observations pos data signals develop optimal audit policy proposed model considers relevant cost factors conditional probability shelf oos conditional expectation shelf oos duration analyze impact relevant cost factors stochastic transition non oos oos zero sale probability underlying demand managersâ€™ perceived oos likelihood even random fixes shelf oos optimal decisions also uncover interesting dynamics decisions costs probability estimates analyzing model behaviors perform extensive simulations validate economic utility proposed data driven audits cost efficient complement existing shelf inventory control outline implementation details sake model validation particularly use bayesian inference markov chain monte carlo develop estimation framework ensures model parameters empirically grounded conclude articulating practical theoretical implications data driven audit policy design retail managers â© elsevier b v
10.1016/j.ijpe.2018.09.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054827079&doi=10.1016%2fj.ijpe.2018.09.020&partnerID=40&md5=c00b302a4841162d4ef925b8fa816ead 0,national culture matters business affects managerial attitudes values behaviors efficacy organizations contributes understanding environmental management issues well previous studies investigating link national culture environmental performance mixed findings overlooked intervening mechanism twoâ€”firm environmental management practice emp adoption paper considers missing link lays complete theoretical framework empirically tests effects national culture firm emp adoption emp effectiveness analysis uses data collected th round global manufacturing research group gmrg survey hofstede cultural dimensions world bank database hierarchical linear models hlms using bayesian markov chain monte carlo mcmc approach employed examine cross level relationships framework study finds certain cultural traits significantly related corporate emp adoption effectively emps implemented adoption study provides meanings insights role national culture context environmental management â© elsevier b v
10.1016/j.infrared.2018.09.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053769640&doi=10.1016%2fj.infrared.2018.09.005&partnerID=40&md5=b9c40157dc22146d679a8f1acfa96933 0,micro doppler md effect weak vibration target obvious infrared laser detection provides foundation precise estimation micro motion parameters makes target classification recognition possible multi targets multi scattering points existing detecting field generate single channel multi component scmc signal laser detection similar micro motion parameters lead feature overlapping time frequency domain increase difficulty parameter estimation paper separate parameter estimator based maximum likelihood framework singular value decomposition proposed deal mixed signal first improved singular value ratio svr spectrum detailed period scanning presented locate vibration frequency amplitude ratio information component also extracted svr spectrum analytic expression maximum likelihood estimation mle micro motion parameters derived solve high nonlinear problem laser md signal new likelihood function lf designed derivation process robustness efficiency increased new lf markov chain monte carlo mcmc sampling employed implement mle finally simulation results verifies validity proposed method comparison cramer rao bound shows ability accurate estimation proposed method â© elsevier b v
10.1111/rssc.12280 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045730479&doi=10.1111%2frssc.12280&partnerID=40&md5=1bef3a1210e4d6c7e0feb96e10d7f901 0,identifying peptide basis scan mass spectrometer important yet highly challenging problem identify peptides present bayesian approach uses prior information average relative abundances bond cleavages prior probability particular amino acid sequence scoring function proposed composed two overall distance measures measure close observed spectrum theoretical scan peptide use scoring function approximates likelihood connections generalization presented bissiri co workers bayesian framework markov chain monte carlo algorithm employed simulate candidate choices posterior distribution peptide sequence true peptide estimated peptide largest posterior density â© royal statistical society
10.1007/s11222-017-9787-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033405542&doi=10.1007%2fs11222-017-9787-x&partnerID=40&md5=8c71ba05cf84ea2f142e2b7dc9bd4ae7 0,queueing networks describe complex stochastic systems theoretical practical interest provide means assess alterations diagnose poor performance evaluate robustness across sets interconnected resources present paper focus underlying continuous time markov chains induced networks present flexible method drawing parameter inference multi class markovian cases switching different service disciplines approach directed towards inferential problem missing data transition paths individual tasks among queues often unknown paper introduces slice sampling technique mappings measurable space task transitions service stations address time tractability issues computational procedures handle prior system knowledge overcome common restrictions service rates across existing inferential frameworks finally proposed algorithm validated synthetic data applied real data set obtained service delivery tasking tool implemented two university hospitals â© springer science+business media llc
10.1007/s11222-017-9786-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032711994&doi=10.1007%2fs11222-017-9786-y&partnerID=40&md5=9f686b689d296f8cea69335b09844301 1,cluster analysis interest lies probabilistically capturing partitions individuals items observations groups belonging group share similar attributes relational profiles bayesian posterior samples latent allocation variables effectively obtained wide range clustering models including finite mixtures infinite mixtures hidden markov models block models networks however due categorical nature clustering variables lack scalable algorithms summary tools interpret samples available adopt bayesian decision theoretical approach define optimality criterion clusterings propose fast context independent greedy algorithm find best allocations one important facet approach optimal number groups automatically selected thereby solving clustering model choice problems time consider several loss functions compare partitions show approach accommodate wide range cases finally illustrate approach artificial real datasets three different clustering models gaussian mixtures stochastic block models latent block models networks â© author
10.1016/j.insmatheco.2018.06.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053081962&doi=10.1016%2fj.insmatheco.2018.06.002&partnerID=40&md5=e23b1b3cdd5070891bdf9a3075c00472 0,standard regression models often insufficient describe complex relationships exist healthcare claims bayesian nonparametric regression approach presented flexible regression model relaxes assumption gaussianity details implementation presented bayesian nonparametric regression applied dataset claims episode treatment group etg specific focus prediction new observations shown predictive accuracy improves compared standard linear model assumptions flexible generalized beta regression different etgs nonparametric regression outperformed standard linear generalized beta regression studying conjunctivitis lung transplants specifically shown approach handle complex characteristics regression error distribution skewness thick tails outliers bimodality â© elsevier b v
10.1016/j.jpowsour.2018.09.091 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054415075&doi=10.1016%2fj.jpowsour.2018.09.091&partnerID=40&md5=1efe33aba84c9511d5b88bf2ba331f82 0,curve fitting important process analysis electrochemical impedance spectra evaluate ionic conductivity materials analyze impedance spectra gradient method steepest descent used far however parameter solution using gradient method often trapped local minima curve fitting strongly depends initial parameters study avoid local minima issue propose random walk metropolis hastings algorithm analyze impedance spectra provide unique solution impedance spectra example measured solid state oxide electrolyte la li tio la li tio la li nbo polycrystal uniquely identify respective lithium ion conductivity bulk grain boundary using random walk metropolis hastings algorithm present algorithm free choice initial values fitting parameters moreover estimated accuracy li ion conductivity better â© elsevier b v
10.3150/17-BEJ938 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045889269&doi=10.3150%2f17-BEJ938&partnerID=40&md5=b919720434a41b9ce7e94444dbec6183 0,perturbation theory markov chains addresses question small differences transition probabilities markov chains reflected differences distributions prove powerful flexible bounds distance nth step distributions two markov chains one satisfies wasserstein ergodicity condition work motivated recent interest approximate markov chain monte carlo mcmc methods analysis big data sets using approach based lyapunov functions provide estimates geometrically ergodic markov chains weak assumptions autoregressive model bounds improved general illustrate theory showing quantitative estimates approximate versions two prominent mcmc algorithms metropolisâ€“hastings stochastic langevin algorithms â© isi bs
10.1002/qre.2329 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053644777&doi=10.1002%2fqre.2329&partnerID=40&md5=32bedc5901d82cea7659d034e41772d1 1,recently new degradation process model named transformed gamma process proposed describe markovian degradation processes whose increments disjoint intervals independent degradation growth future time interval depend current age current state degradation level unit paper introduces bayesian estimation approach process based prior information physical characteristics observed degradation process several different prior distributions proposed reflecting different degrees knowledge analyst observed phenomenon monte carlo markov chain technique adopted estimate transformed gamma parameters functions thereof residual reliability unit well predict future degradation growth residual lifetime finally proposed approach applied real dataset consisting wear measures liners cylinder engine equips cargo ship â© john wiley sons ltd
10.1007/s11222-017-9789-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033456573&doi=10.1007%2fs11222-017-9789-8&partnerID=40&md5=d73c68a42fc8fd54350d1461cd36448e 1,fitting stochastic kinetic models represented markov jump processes within bayesian paradigm complicated intractability observed data likelihood therefore considerable attention given design pseudo marginal markov chain monte carlo algorithms models however methods typically computationally intensive often require careful tuning must restarted scratch upon receipt new observations sequential monte carlo smc methods hand aim efficiently reuse posterior samples time point despite appeal applying smc schemes scenarios dynamic states static parameters made difficult problem particle degeneracy principled approach overcoming problem move parameter particle metropolis hastings kernel leaves target invariant rejuvenation step key recently proposed smc algorithm seen pseudo marginal analogue idealised scheme known iterated batch importance sampling computing parameter weights smc requires running particle filter dynamic states unbiasedly estimate intractable observed data likelihood current time point paper propose use auxiliary particle filter inside smc scheme method uses two recently proposed constructs sampling conditioned jump processes find resulting inference schemes typically require fewer state particles using simple bootstrap filter using two applications compare performance proposed approach various competing methods including two global mcmc schemes â© author
10.1016/j.aap.2018.08.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054056389&doi=10.1016%2fj.aap.2018.08.021&partnerID=40&md5=2d491f15de24621d8f44252b1850c788 0,background fatality analysis reporting system fars provides important data studying role marijuana motor vehicle crashes however marijuana testing data available drivers fars represents major barrier use data methods developed multiple imputation mi procedure estimating marijuana positivity among drivers missing marijuana test results using bayesian multilevel model allows nonlinear association blood alcohol concentrations bacs accounts correlations among drivers states includes individual level state level covariates generated imputations missing marijuana testing data using markov chain monte carlo simulations estimated positivity rates marijuana nation state results drivers older age female using seatbelt time crash valid license operating median heavy trucks less likely test positive marijuana reverse u shaped association bacs positivity marijuana lower positivity bacs g dl â‰¥ g dl mi data estimated lower positivity rate marijuana nation state observed data national positivity rate ci versus using observed data conclusions mi procedure appears valid approach addressing missing marijuana data fars may help strengthen capacity fars monitoring epidemic drugged driving understanding role marijuana fatal motor vehicle crashes united states â© elsevier ltd
10.1016/j.ijrobp.2018.06.033 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053198037&doi=10.1016%2fj.ijrobp.2018.06.033&partnerID=40&md5=5b1aa408e7363443407b8db9bb7b206e 0,purpose priori identification small proportion radiation therapy patients prove severely radiosensitive long held goal radiation oncology number published studies indicate analysis dna damage response ex vivo irradiation peripheral blood lymphocytes using î³ h ax assay detect dna damage provides basis functional assay identification small proportion severely radiosensitive cancer patients undergoing radiotherapy methods materials introduce new rigorous integrated approach analysis radiation induced î³ h ax response using bayesian statistics results approach shows excellent discrimination radiosensitive non radiosensitive patient groups described previously reported data set conclusions bayesian statistical analysis provides appropriate reliable methodology future prospective studies â© elsevier inc
10.1007/s11222-017-9788-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032971018&doi=10.1007%2fs11222-017-9788-9&partnerID=40&md5=9793d1c32c0dcb93936d608f05be02cf 0,stochastic block model sbm widely used modelling network data assigning individuals nodes communities blocks probability edge existing individuals depending upon community membership paper introduce autoregressive extension sbm based continuous time markovian edge dynamics model appropriate networks evolving time allows edges turn moreover allow movement individuals communities effective reversible jump markov chain monte carlo algorithm introduced sampling jointly posterior distribution community parameters number location changes community membership algorithm successfully applied network mice â© springer science+business media llc
10.1002/env.2519 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050633642&doi=10.1002%2fenv.2519&partnerID=40&md5=7dd5b83f9dd349e48c1d3a85c9525e6b 1,new mobile monitoring technology revolutionized ability measure pollutant levels large regions statistical methods making inferences data collected mobile systems still developed introduce new captureâ€“recapture model answer key inferential questions data collected mobile monitoring systems apply new method characterize populations natural gas ng leaks urban areas using data collected atmospheric methane analyzers placed google street view cars leaks urban ng distribution systems correspond economic loss potential safety hazard climate altering ng primarily composed methane potent greenhouse gas new calibration captureâ€“recapture ccr model combines data controlled methane release experiments data collected mobile air monitors enable inference several ng leak population characteristics including number undetected leaks total methane output rate surveyed region methodology novel application captureâ€“recapture modeling ccr model addresses challenges associated using captureâ€“recapture model analyze data collected mobile monitoring system variable sampling effort develop markov chain monte carlo algorithm parameter estimation apply ccr model data collected two u cities ccr model provides new framework inferring total number leaks ng distribution systems offers critical insights informing intelligent infrastructure repair policy cost effective environmentally friendly â© john wiley sons ltd
10.1061/(ASCE)WW.1943-5460.0000472 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053062165&doi=10.1061%2f%28ASCE%29+WW.1943-5460.0000472&partnerID=40&md5=1039441538a174db6092381ac87d3586 0,bayesian inverse framework developed optimize skill predictive numerical model via interpolation bathymetric measurements provide probable bathymetric surface numerical model coupled wave flow model predicts wave hydrodynamic information e g significant wave height longshore velocity bayesian method coupled markov chain monte carlo mcmc optimization used find bathymetric field serves minimize residual errors measured data corresponding numerical model results using bayesian approach range probable model parameters inferred observed data monte carlo simulation also applied numerical model perform uncertainty analysis model output fields wave height flow velocity analysis performed taking random samples probability distribution function pdf inputs running model required desired precision â± significant wave height output fields achieved case study used analysis duck experiment conducted us army field research facility duck north carolina fall unknown model parameters hydrodynamic model involve controlling bathymetric resolution furthermore ability statistical model estimate observed data tested running forward model two sets input parameters estimated input parameters updated previously mentioned statistical model prior noninformative parameters using model parameters estimated bayesian analysis leads improved comparisons data using presented method relative errors model outputs observed data significant wave height nearshore gauges reduced â© american society civil engineers
10.1016/j.gsf.2017.10.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044648949&doi=10.1016%2fj.gsf.2017.10.014&partnerID=40&md5=4d6424ab2bacfbad6e111a66ff6373a3 2,determining soilâ€“water characteristic curve swcc site essential step implementing unsaturated soil mechanics geotechnical engineering practice measured directly various situ laboratory tests direct measurements however costly time consuming due high standards equipment procedural control limits testing apparatus result limited number data points e g volumetric water content vs matric suction swcc values matric suction obtained practice use limited number data points estimate site specific swcc quantify uncertainty degrees belief estimated swcc remains challenging task paper proposes bayesian approach determine site specific swcc based limited number test data prior knowledge e g engineering experience judgment proposed bayesian approach quantifies degrees belief estimated swcc according site specific test data prior knowledge simultaneously selects suitable swcc model number candidates based probability logic address computational issues involved bayesian analyses markov chain monte carlo simulation mcmcs specifically metropolis hastings h algorithm used solve posterior distribution swcc model parameters gaussian copula applied evaluating model evidence based mcmcs samples selecting probable swcc model pool candidates removes one key limitation h algorithm making feasible bayesian model selection problems proposed approach illustrated using real data unsaturated soil database unsoda developed u department agriculture shown proposed approach properly estimates swcc based limited number site specific test data prior knowledge reflects degrees belief estimated swcc rational quantitative manner â© china university geosciences beijing peking university
10.1038/s41437-018-0125-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052585483&doi=10.1038%2fs41437-018-0125-7&partnerID=40&md5=2fe3800e5edbd51d2c8bc4d5d115d333 0,fitness landscapes map relationship genotypes fitness however fitness landscape studies ignore genetic architecture imposed codon table thereby neglect potential role synonymous mutations quantify fitness effects synonymous mutations potential impact adaptation fitness landscape use new software based bayesian monte carlo markov chain methods estimate selection coefficients possible codon mutations across amino acid positions saccharomyces cerevisiae hsp across environments quantify distribution fitness effects synonymous mutations show dominated many mutations small effect mutations larger effect compare shape codon fitness landscape across amino acid positions environments quantify consideration synonymous fitness effects changes evolutionary dynamics fitness landscapes together results highlight possible role synonymous mutations adaptation indicate potential mis inference neglected fitness landscape studies â© genetics society
10.1080/02664763.2018.1431208 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041625565&doi=10.1080%2f02664763.2018.1431208&partnerID=40&md5=4f8e9d1a264080a935106df9c625b268 0,paper develop conditional model analyzing mixed bivariate continuous ordinal longitudinal responses propose quantile regression model random effects analyzing continuous responses purpose asymmetric laplace distribution ald allocated continuous response given random effects modeling ordinal responses cumulative logit model used via specifying latent variable model considering random effects therefore intra association continuous ordinal responses taken account using exclusive random effects inter association two mixed responses taken account adding continuous response term ordinal model use bayesian approach via markov chain monte carlo method analyzing proposed conditional model estimate unknown parameters gibbs sampler algorithm used moreover illustrate application proposed model using part british household panel survey data set results data analysis show gender age marital status educational level amount money spent leisure significant effects annual income also associated parameter significant using best fitting proposed conditional model thus employed rather analyzing separate models â© â© informa uk limited trading taylor francis group
10.1080/03610918.2017.1359289 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029436661&doi=10.1080%2f03610918.2017.1359289&partnerID=40&md5=fb6f7db0e9892084bf13680d2c30bdfd 0,article propose new distribution mixing normal pareto distributions new distribution provides unusual hazard function model mean variance covariates heterogeneity estimation parameters obtained bayesian method using markov chain monte carlo mcmc algorithms proposal distribution mcmc proposed defined working variable related observations simulation method shows dependable performance model demonstrate establishing model real dataset proposed model method suitable previous report â© â© taylor francis group llc
10.1080/03610918.2017.1359286 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033723707&doi=10.1080%2f03610918.2017.1359286&partnerID=40&md5=3af4e21c565affe0b208f2236b750a11 0,recently bayesian nonparametric approaches survival studies attract much attentions multimodality survival data mixture models common introduce bayesian nonparametric mixture model burr distribution burr type xii kernel since burr distribution shares good properties common distributions survival analysis flexibility distributions applying model simulated real failure time datasets show preference model compare dirichlet process mixture models different kernels markov chain monte carlo mcmc simulation methods calculate posterior distribution used â© â© taylor francis group llc
10.1016/j.physa.2018.05.064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047824118&doi=10.1016%2fj.physa.2018.05.064&partnerID=40&md5=2a13efd63cd79da85aad31fe06a57dfe 0,paper studies casual relationship oil major bilateral exchange rates us dollar via novel bayesian graph based approach approach shown quite effective dealing identification vector autoregression var model temporal causal structure represented graph sampled markov chain monte carlo mcmc method empirical evidence demonstrates oil price leads exchange market crisis period whereas vice versa crisis implying potential impact financial crisis causality two markets show general oil market specific shock affects dependence structure aggregate demand shock plays weaker role supply shock contributes least specifically three oil shocks take effect different periods thus capturing invisible information market evolutions â© elsevier b v
10.1016/j.scitotenv.2018.05.169 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047265427&doi=10.1016%2fj.scitotenv.2018.05.169&partnerID=40&md5=de894051dee701b7d91a0715cb33c6ce 0,knowledge global c cycle implications changes fire regime climate growing importance studies role fire regime combination climate change soil c pools lacking used bayesian modelling estimate soil total c ctot recalcitrant pyrogenic c rpc field samples collected using stratified sampling approach observations derived following scenarios three fire frequencies across three distinctive climate regions homogeneous dry sclerophyll forest south eastern australia four decades effects different fire intensity combinations successive wildfires found climate stronger effect fire frequency size estimated mineral soil c pool largest soil c pool estimated occur wet cold wc climate via presumed effects high precipitation adequate growing season temperature e resulting relatively high npp winter conditions sufficiently cold retard seasonal soil respiration rates smallest soil c pool estimated forests lower precipitation warmer mean annual temperature mat lower precipitation higher temperature likely retarded npp litter decomposition rates may little effect relative soil respiration small effects associated fire frequency found magnitude direction climate dependent increase soil c associated low intensity fire followed high intensity fire fire frequency intensity response rpc mirrored ctot e effectively constant across combinations climate fire regimes sampled â©
10.1002/eqe.3093 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050655385&doi=10.1002%2feqe.3093&partnerID=40&md5=fd60fee485dd38485b78b918dd28b2d3 0,two new algorithms presented efficiently selecting suites ground motions match target multivariate distribution conditional intensity measure target first algorithm markov chain monte carlo mcmc approach records sequentially added selected set joint probability density function pdf target distribution progressively approximated discrete distribution selected records second algorithm derives concept acceptance ratio within mcmc involve sampling first method takes advantage mcmc ability efficiently explore sampling distribution implementation traditional mcmc algorithm method shown enable good matches multivariate targets obtained numbers records selected relatively large weaker performance fewer records circumvented second method uses greedy optimisation impose additional constraints upon properties target distribution preselection approach based upon values multivariate pdf proposed enables near optimal record sets identified close match target methods applied number response analyses associated different sizes record sets rupture scenarios comparisons made throughout generalised conditional intensity measure gcim approach first method provides similar results gcim slightly worse performance small record sets second method outperforms method gcim considered cases â© john wiley sons ltd
10.3847/1538-4357/aadcf3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055161073&doi=10.3847%2f1538-4357%2faadcf3&partnerID=40&md5=c2c13bb1ff6275e5549bc05e58e5f03e 0,perform markov chain monte carlo analyses put constraints nonflat ï†cdm inflation model using planck cosmic microwave background cmb anisotropy data baryon acoustic oscillation distance measurements ï†cdm model consistent dynamical dark energy model currently accelerating cosmological expansion powered scalar field ï† slowly rolling inverse power law potential energy density also use physically consistent power spectrum energy density inhomogeneities nonflat model find like closed î›cdm closed xcdm models closed ï†cdm model provides better fit lower multipole region cmb temperature anisotropy data compared provided tilted flat î›cdm model also like closed models model reduces tension planck weak lensing ïƒ constraints however higher multipole region cmb temperature anisotropy data better fit tilted flat î› model closed models â© american astronomical society rights reserved
10.5194/bg-15-5801-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054855321&doi=10.5194%2fbg-15-5801-2018&partnerID=40&md5=3c158c7f908652bd0aa9a25856a43d73 0,data model integration plays critical role assessing improving capacity predict ecosystem dynamics similarly ability attach quantitative statements uncertainty around model forecasts crucial model assessment interpretation setting field research priorities bayesian methods provide rigorous data assimilation framework applications especially problems multiple data constraints however markov chain monte carlo mcmc techniques underlying bayesian calibration prohibitive computationally demanding models large datasets employ alternative method bayesian model emulation sufficient statistics approximate full joint posterior density amenable parallelization provides estimate parameter sensitivity analysis involved informative priors constructed meta analysis primary literature specification model data uncertainties introduced novel approaches autocorrelation corrections multiple data streams emulating sufficient statistics surface report integration method within ecological workflow management software predictive ecosystem analyzer pecan application validation two process based terrestrial ecosystem models sipnet ed test synthetic dataset emulator able retrieve true parameter values comparison emulator approach standard q mcmc involving multiple data constraints showed emulator method able constrain faster simpler sipnet model parameters comparable performance brute force approach reduced computation time orders magnitude emulator applied calibration ed model whose complexity precludes standard brute force bayesian data assimilation techniques models constrained assimilation observational data emulator method reducing uncertainty around predictions performance metrics showed increased agreement model predictions data study furthers efforts toward reducing model uncertainties showing emulator method makes possible efficiently calibrate complex models â© author
10.1080/02664763.2017.1421916 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041120642&doi=10.1080%2f02664763.2017.1421916&partnerID=40&md5=59aa41fc0d8a8b815481ef935421f2f3 0,paper presents new method reconciliation data described arbitrary continuous probability distributions focus nonlinear constraints main idea already applied linear constraints previous paper restrict joint prior probability distribution observed variables model constraints get joint posterior probability distribution general posterior probability density function calculated analytically shown decisive advantages sample posterior distribution markov chain monte carlo mcmc method resulting sample observed unobserved variables various characteristics posterior distribution estimated mean full covariance matrix marginal posterior densities well marginal moments quantiles hpd intervals procedure illustrated examples material flow analysis chemical engineering â© â© author published informa uk limited trading taylor francis group
10.1080/24725854.2018.1455117 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048165545&doi=10.1080%2f24725854.2018.1455117&partnerID=40&md5=05a94548d1c61e736d89fff12432b870 0,metrology data crucial quality control three dimensional printed parts low cost measurement systems often unreliable due low resolutions whereas high resolution measurement systems usually induce high measurement costs balance measurement cost accuracy new cost effective reliable measurement strategy proposed article jointly uses two resolution measurement systems specifically small sample base parts measured low high resolution measurement systems order save costs measurement accuracy parts low resolution metrology data improved effectively integrating high resolution metrology data base parts bayesian generative model parameterizes part independent bias variance pattern low resolution metrology data facilitates part data integration via efficient markov chain monte carlo sampling algorithm multi part two resolution metrology data integration highlights novelty contribution article compared existing one part data integration methods literature finally intensive experimental study involving laser scanner machine visual system validated effectiveness measurement strategy acquisition reliable metrology data printed parts â© copyright â© â€œiiseâ€�
10.1088/1742-6596/1087/2/022004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054904702&doi=10.1088%2f1742-6596%2f1087%2f2%2f022004&partnerID=40&md5=5b768dcf5eb8c63e9e47e94be4e4faaf 0,metropolis hastings algorithm keeps detailed balance basic element markov chain monte carlo sampling algorithms undermined markov processes reversible previous research shows nonreversible markov processes faster rate convergence reversible ones taking advantage lifting idea paper develops general framework designing metropolis hastings algorithms breaking detailed balance implements two new nonreversible metropolis hastings algorithms based gaussian proposal conditional probability langevin dynamics zero mass limit respectively numerical simulations one two dimensions demonstrate new nonreversible metropolis hastings algorithms speed convergence target stationary distributions supports theoretical finding design new algorithms â© published licence iop publishing ltd
10.1016/j.ress.2018.06.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049329553&doi=10.1016%2fj.ress.2018.06.005&partnerID=40&md5=ce07df8666645597ce93337c40abeffc 0,networked systems communication networks power grids graph separation node failures damage overall operation severely one important goals network attackers thus separate nodes sizes connected components become small work consider problem finding minimum î± separator partitions graph connected components sizes î±n n number nodes solve î± separator problem develop random walk algorithm based metropolis chain characterize conditions first passage time find optimal solution algorithm also find optimal cooling schedule random walk converges optimal solution almost surely furthermore generalize algorithm non uniform node weights show extensive simulations first passage time less n thereby validating analysis solution found algorithm allows us identify weakest points network need strengthened simulations real topologies show attacking dense area often efficient solution partitioning network small components â©
10.1107/S1600576718011597 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054101410&doi=10.1107%2fS1600576718011597&partnerID=40&md5=b2b8ba4edc4e414ff4f3ed705b361385 0,assemblies nanosheets often characterized extensive layer position disorder coupled often minute coherent scattering domain size relaxation nanosheet structure unambiguous interpretation x ray neutron scattering data materials non trivial work demonstrates general approach towards refinement layer disorder information atomic pair distribution function pdf data materials span gap turbostratism ordered stacking arrangements x ray total scattering data typical modern rapid acquisition pdf instrument simulated hypothetical graphene like structure using program diffax atomic pdfs extracted small ã— ã— supercell models representing stacking discrete layer types combined model continuous distribution layer position disorder models optimized using differential evolution algorithm demonstrate improved fit quality ã… single mean layer type model replaced constrained layertype model posterior distribution analyses using markov chainmonte carlo algorithm demonstrate influence layer disorder finite particle size correlated however refined mean stacking vectors match well generative parameter set â© international union crystallography
10.1016/j.ndteint.2018.02.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047862987&doi=10.1016%2fj.ndteint.2018.02.004&partnerID=40&md5=d479f21e25d6ad2bc518786d0e972038 0,flaw characterization eddy current testing usually requires solve non linear inverse problem due high computational cost markov chain monte carlo mcmc methods hardly employed since often needing many forward evaluations however good potential dealing complicated forward models reduce providing parameters sought introduce computationally cheap surrogate forward model mcmc algorithm eddy current flaw characterization due use database trained line benefit mcmc algorithm getting information suffer computational burden numerous experiments carried validate approach results include estimated parameters also standard deviations marginal densities correlation coefficients two parameters interest â© elsevier ltd
10.1016/j.ijthermalsci.2018.06.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049355475&doi=10.1016%2fj.ijthermalsci.2018.06.006&partnerID=40&md5=b2521d05cb65b4420bca11706570b77a 1,work deals solution inverse heat conduction problem aiming detection contact failures layered composites estimation contact conductance layers spatially varying contact conductance estimated using bayesian formulation problem markov chain monte carlo method infrared camera measurements transient temperature field surface body inverse analysis formulated using data compression scheme temperature measurements integral transformed respect spatial variable present approach evaluated using synthetic measurements experimental data controlled laboratory experiments shown transformed modes data required solving inverse problem thus providing substantial reduction computational time markov chain monte carlo method well regularization ill posed problem â© elsevier masson sas
10.1016/j.dsp.2018.07.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050687771&doi=10.1016%2fj.dsp.2018.07.001&partnerID=40&md5=9299ce9dae822c383f6e338007d9656b 0,many applications engineering one interested tracking dynamic system whose state evolves manifold solutions problems frequently must resort nonlinear filtering techniques many manifolds described equality restrictions higher dimensional embedding spaces propose paper new particle filtering pf method track states dynamic systems evolve according random walk unit sphere derive approximation intractable optimal importance function develop markov chain monte carlo mcmc method sample system state variable estimated via monte carlo approximation intrinsic mean sphere obtained karcher mean particle set verify via computer simulations proposed method shows improved performance compared previous constrained extended kalman filters bootstrap pf solutions â© elsevier inc
10.1016/j.jhydrol.2018.08.082 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053050730&doi=10.1016%2fj.jhydrol.2018.08.082&partnerID=40&md5=72a3896fe5c666fc470ebf3a5fdf169c 0,work conducted two laboratory column experiments undisturbed sandy soil first deals percolation drainage experiment whereas second deals infiltration constant water flux surface unsaturated soil bayesian assessment soil parameters performed experiments markov chain monte carlo mcmc method using measurements pressure head inside column cumulative outflow collected experiments results show experiments well reproduced mathematical model based richards equation van genchten mualem models furthermore inversion two laboratory experiments yields similar results terms mean estimated parameter values strong discrepancies occur confidence intervals used quantify uncertainty estimated parameters compared percolation drainage experiment infiltration experiment yields accurate parameters narrower uncertainty regions â© elsevier b v
10.1002/qre.2284 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053443606&doi=10.1002%2fqre.2284&partnerID=40&md5=d750300ced36abc9625e45c09c93909e 0,concept bayesian probability agreement recently introduced give posterior probabilities response surfaces two different groups within î´ one another example difference less î´ mean response fixed levels predictor variables might thought practically unimportant case say mean responses agreement posterior probability called bayesian probability agreement article quantify probability new response observations two groups within î´ continuous response probability two responses agree completely categorical cases logistic regression poisson regression call bayesian comparative predictive probabilities former predictive probability agreement use markov chain monte carlo simulation estimate posterior distribution model parameters predictive probability agreement illustrate use methodology three examples provide freely available r shiny app automates computation estimation associated methodology â© john wiley sons ltd
10.1016/j.compgeo.2017.11.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039913933&doi=10.1016%2fj.compgeo.2017.11.012&partnerID=40&md5=0383deff7332534377ba981f040956be 1,efficient probabilistic back estimation method characterization spatial variability proposed integration karhunenâ€“loã¨ve k l expansion method polynomial chaos expansion pce method markov chain monte carlo mcmc method reduce dimension back estimation spatially varied soil property simulated using k l expansion method basic random variables k l terms parameters estimated reduce computation load pce surrogate model constructed substitute original model proposed method applied example randomly heterogeneous soil slope subject surface infiltration pressure responses used estimate spatial variability saturated coefficient permeability results show spatial variability satisfactorily estimated coefficient variation estimation less â© elsevier ltd
10.1007/s10463-017-0615-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028894602&doi=10.1007%2fs10463-017-0615-z&partnerID=40&md5=45faa8480b603a2b8731e4a69ad6dcba 0,exact conditional goodness fit tests discrete exponential family models conducted via monte carlo estimation p values sampling conditional distribution multiway contingency tables two popular methods sampling markov chain monte carlo mcmc sequential importance sampling sis work consider various ways hybridize two schemes propose one standout strategy good general purpose method conducting inference proposed method runs many parallel chains initialized sis samples across fiber markov basis unavailable proposed scheme uses lattice basis intermittent sis proposals guarantee irreducibility asymptotic unbiasedness scheme alleviates many challenges faced mcmc sis schemes individually largely retaining strengths also provides diagnostics guide lend credibility procedure simulations demonstrate viability approach â© institute statistical mathematics tokyo
10.1007/s00477-018-1555-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047386843&doi=10.1007%2fs00477-018-1555-8&partnerID=40&md5=b998ed9cf79243aea75a88b2ab82533c 0,uncertainty propagation computer models relevance many disciplines including hydrology environmental engineering ecology climate change error propagation model results uncertainty prediction due uncertainties model inputs parameters common methods quantifying error propagation reviewed namely differential error analysis monte carlo simulation including underlying principles together discussion differences advantages disadvantages separate case uncertainty model calibration process different error propagation fixed model associated dynamic process iterative parameter adjustment compared context non linear regression bayesian approaches markov chain monte carlo simulation error propagation investigated soil model representing organic carbon depth profile also streamflow model using probabilistic simulation different sources error compared including uncertainty inputs parameters geometry results provided insights error propagation computation systems models general â© springer verlag gmbh germany part springer nature
10.1016/j.rse.2018.07.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050106933&doi=10.1016%2fj.rse.2018.07.017&partnerID=40&md5=c11383a12ca9e20958306e94432ea819 0,drought costliest hazard among natural disasters despite significant improvements drought modeling last decade accurate provisions drought conditions timely manner still major research challenge order improve current drought monitoring skills study presents land data assimilation system merging remotely sensed surface soil moisture model simulations use recently developed particle markov chain monte carlo pmcmc method cope computational complexity modular parallel particle filtering framework ppff developed allows large ensemble size pmcmc applications implementation proposed system demonstrated summer flash drought case study contiguous united states conus results synthetic real case studies suggest land data assimilation system improves soil moisture predictions drought monitoring skills compared u drought monitoring usdm land data assimilation better capture drought onset may drought severity june july study recommends proposed land data assimilation system based high performance computing hpc infrastructure better facilitate drought preparation response actions â© elsevier inc
10.1016/j.chemosphere.2018.06.118 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048968287&doi=10.1016%2fj.chemosphere.2018.06.118&partnerID=40&md5=64bfd5290b18eead60048e40670c3720 1,environmental factors may increase colon cancer cc risk suggested pesticides play significant role etiology malignancy agriculture one mainstays brazilian economy country become largest pesticides consumer worldwide cc burden also increasing brazil herein examined data brazilian federal government determine whether cc mortality pesticide consumption may associated database ministry health provided cc mortality data brazil pesticide usage accessed website brazilian institute environment renewable natural resources cc mortality brazilian states calculated standard mortality rates smr bayesian analysis performed using markov chain monte carlo method winbugs software observed cc mortality exhibited steady increase decade correlated amount sold pesticides country observations concentrated southern southeast regions brazil although ecological studies like methodological limitations current dataset suggests possibility pesticide exposure may risk factor cc warrants investigation â© elsevier ltd
10.1007/s00024-018-1881-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054696084&doi=10.1007%2fs00024-018-1881-2&partnerID=40&md5=0d925cef8a78522daa33001165ace8b1 0,ambient noise seismic tomography widely used study crustal upper mantle shear velocity structures studies however concentrate short period lt â surface wave ambient noise studies using long period surface wave ambient noise limited paper demonstrate feasibility using long period surface wave ambient noise study lithospheric structure continental scale use broadband rayleigh wave phase velocities obtain vs structures beneath contiguous united states period band â€“ â inversion shear wave velocity profile parameterized using b spline grid point inverted nonlinear markov chain monte carlo method shear velocity model constructed assembling shear velocity profiles model overall consistent existing models based multiple datasets data earthquakes model along post usarray models reveal lithosphere structures upper mantle consistent geological tectonic background e g craton root regional upwelling provinces model comparable resolution lithosphere structures compared many published results used future detailed regional continental studies analysis â© springer international publishing ag part springer nature
10.1016/j.ress.2018.05.016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048279401&doi=10.1016%2fj.ress.2018.05.016&partnerID=40&md5=425b305460b028b3ecc59c227178f42d 0,paper presents new modeling approach computational algorithm example application health monitoring learning line system health management shm hybrid dynamic bayesian network dbn introduced represent complex engineering systems underlying physics failure modeling theoretical empirical degradation model continuous variables methodology designed flexible intuitive scalable small localized functionality large complex dynamic systems markov chain monte carlo mcmc inference optimized using pre computation strategy dynamic programming line monitoring system health proposed monitoring anomaly detection algorithm uses pattern recognition improve failure detection estimation remaining useful life rul pre computation inference database enables efficient line learning maintenance decision making proposed methodology algorithm demonstrated unmanned aerial vehicle uav application â© elsevier ltd
10.1016/j.econlet.2018.08.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051537403&doi=10.1016%2fj.econlet.2018.08.004&partnerID=40&md5=aa13d5c2ca09e92ffdf8bbbd99b55419 0,propose poisson regression model controls three potential sources persistence panel count data dynamics latent heterogeneity serial correlation idiosyncratic errors also account initial conditions problem model estimation develop markov chain monte carlo algorithm proposed methodology illustrated real example number patents granted â© elsevier b v
10.1016/j.jeconom.2018.06.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049466754&doi=10.1016%2fj.jeconom.2018.06.006&partnerID=40&md5=4898979de2c0e84a814f6638bd0a5b33 0,ergodic theorem shows ergodic averages posterior draws converge probability posterior mean stationarity assumption literature also shows posterior distribution asymptotically normal sample size original data considered goes infinity best knowledge little discussion large sample behaviour posterior mean paper aim fill gap particular extend posterior mean idea conditional mean case conditioning given vector summary statistics original data establish new asymptotic theory conditional mean estimator case sample size original data concerned number markov chain monte carlo iterations go infinity simulation studies show conditional mean estimator good finite sample performance addition employ conditional mean estimator estimate garch model p stock returns find conditional mean estimator performs better quasi maximum likelihood estimation terms sample forecasting â© elsevier b v
10.1016/j.camwa.2018.07.027 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050686549&doi=10.1016%2fj.camwa.2018.07.027&partnerID=40&md5=cd9ae66d98e1c30ec9791dd94896ebf7 0,paper considers valuation cds credit default swap contract find accurate cds price work extended merton model assuming price reference asset follows regime switching blackâ€“scholes model moreover reference asset default time expiry time general pricing formula cds containing unknown default probability derived first subsequently shown default probability equivalent price binary option written reference asset simulating markov chain monte carlo technique obtain approximation formula binary option availability calculation cds price becomes straightforward finally numerical experiments conducted examine accuracy approximation approach well impacts introduction regime switching mechanics cds price â© elsevier ltd
10.5705/ss.202017.0016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054552439&doi=10.5705%2fss.202017.0016&partnerID=40&md5=d6583ef6e5b7bcd1bf95ea9f873a9908 0,nonresponse important practical problem epidemiological surveys clinical trials common methods dealing missing data rely untestable assumptions particular non ignorable modeling derives inference likelihood function based joint distribution variables missingness indicators sensitive misspecification distribution may also problems identifying parameters nonresponse two phase sampling nts contacts collects data subsample initial nonrespondents used reduce nonresponse bias additional data collected phase ii provide important information identifying parameters non ignorable models propose bayesian selection model utilizes additional data phase ii develop efficient markov chain monte carlo algorithm posterior computation illustrate proposed model simulation studies quality life qol dataset â© institute statistical science rights reserved
10.1111/jvp.12677 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050491648&doi=10.1111%2fjvp.12677&partnerID=40&md5=c6194877eb2a263e085aeea274aa17f5 0,bayesian population pharmacokinetic models florfenicol healthy pigs developed based retrospective data pigs either via intravenous v intramuscular administration following v administration disposition florfenicol best described two compartment open model typical values half life î± phase î± half life î² phase î² total body clearance cl volume distribution vd â â±â â â±â â hr â â±â â â±â â lâ kgâˆ’ respectively disposition florfenicol administration best described one compartment open model typical values maximum concentration drug serum cmax elimination half life kel cl volume v â â±â â î¼g ml â â±â â hr â â±â â lâ hrâˆ’ â kgâˆ’ â â±â â l kg respectively subject variabilities parameters administration â€“ florfenicol well absorbed administration according monte carlo simulation â mg kg adequate exert bactericidal effect actinobacillus pleuropneumoniae v administration â© john wiley sons ltd
10.1007/s10237-018-1036-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047664641&doi=10.1007%2fs10237-018-1036-5&partnerID=40&md5=e16d8c5c2626fc1233dccd3616242c0c 0,cell migration plays essential role cancer metastasis cancer invasion confined spaces cells must undergo extensive deformation capability related metastatic potentials simulate deformation cell nucleus invasion dense physiological microenvironment developing phenomenological computational model work cells attracted generic emitting source e g chemokine stiffness signal treated using greenâ€™s fundamental solutions use imex integration method linear parts nonlinear parts treated using euler backward scheme euler forward method respectively develop numerical model obstacle induced deformation considering uncertainty cell mobility stochastic processes incorporated uncertainties input variables evaluated using monte carlo simulations quantitative study aims estimating likelihood invasion length time interval cell invades tissue obstacle subsequently two dimensional cell deformation model applied simplified cancer metastasis processes serve model vivo vitro biomedical experiments â© author
10.1016/j.apenergy.2017.08.181 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028584694&doi=10.1016%2fj.apenergy.2017.08.181&partnerID=40&md5=aaffe48891cc56d1acf8715a6a3a6106 2,air conditioners ac usually consume electricity among auxiliary components electric bus battery power maximum board passengers carried electric bus important random heat sources obsessional disturbances cabin temperature control energy management ac system paper aims improve ac energy efficiency via passenger amount variation analysis forecast model predictive control mpc framework three forecasting approaches proposed realize passenger amount variation prediction real time namely stochastic prediction based monte carlo radial basis function neural network rbf nn prediction markov chain prediction sample passenger number database along typical bus line beijing built passenger variation pattern analysis forecast comparative study three prediction approaches different prediction lengths bus stops case conducted energy consumption temperature control perspectives predictive ac controller developed evaluated comparing dynamic programming dp commonly used rule based control strategy simulation results show three forecasting methods integrated within mpc framework able achieve stable temperature performance energy consumptions mpc markov chain prediction rbf nn forecast monte carlo prediction lower rule based control respectively beijing bus route studied paper â©
10.1109/TWC.2018.2861870 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051405233&doi=10.1109%2fTWC.2018.2861870&partnerID=40&md5=c2dafd4bdced2387385c7553b2f05fd6 0,distributed spatial modulation dsm protocol allows relays forward source data simultaneously allowing relays transmit data proposed narayanan et al paper introduce two new protocols enabling dsm consisting single antenna network nodes simultaneous wireless information power transfer capability power splitting based dsm ps dsm energy recycling based dsm er dsm specifically ps dsm relies power splitters relay nodes harvest energy transmitted source hand er dsm exploiting inactive cooperating relays dsm based protocols recycles part transmitted energy network without relying power splitters time switches relays harvest energy leads increase average harvested energy relays reduced hardware complexity ps dsm er dsm also retain original features dsm due particular operating principle specific advantages select er dsm candidate mathematical analysis specifically considering multi state battery model propose analytical framework based markov chain formulation modeling charging discharging behavior batteries relay nodes er dsm furthermore based derived markov chain model introduce mathematical framework computing error probability er dsm explicitly taking account effect finite sized batteries frameworks substantiated aid monte carlo simulations various system setups â© ieee
10.1016/j.expthermflusci.2018.04.026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047605965&doi=10.1016%2fj.expthermflusci.2018.04.026&partnerID=40&md5=5f484dc8eb5239b53120bf66cd07b32b 0,work inverse methodology developed estimating local heat transfer coefficients vertical plate embedded three discrete heat sources steady state natural convection temperatures measured adiabatic surface without disturbing fluid flow using simple conduction surrogate model bayesian inference liquid crystal thermography lct optical measurement method based colour temperature relationship thermochromic liquid crystal sheet tlc used determine temperature field adiabatic surface bayesian framework metropolis hastings markov chain monte carlo mh mcmc sampling method considered exploring posterior distribution estimate parameters terms point estimates like mean maximum posteriori map standard deviation parity plot simulated using retrieved parameters measured tlc temperatures shows good agreement â© elsevier inc
10.1007/s40273-018-0688-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050953934&doi=10.1007%2fs40273-018-0688-4&partnerID=40&md5=640957dcc135aa2bc172967e9bade493 0,background heart failure affects â million people germany contributes morbidity mortality high healthcare costs recent large randomized controlled trial compared novel compound sacubitril valsartan lcz angiotensin converting enzyme ace inhibitor enalapril found reduction mortalityâ hazard germany sacubitril valsartan launched beginning objective purpose study conduct postâ hoc analysis cost effectiveness budget impact disease burden reduction sacubitril valsartan compared ace inhibitors patients heart failure perspective german social health insurance shi based results trial methods markov cohort state transition model constructed simulate treatment remaining lifetime based markov model dynamic population model developed projects incidence prevalence mortality healthcare costs heart failure shi population population model follows prevalent incident cohorts time year new cohort added existing cohorts age â year die test sensitivity results monte carlo simulation run results based price negotiated manufacturer representatives shi base case incremental cost effectiveness ratio icer sacubitril valsartan versus ace inhibitors â‚¬ per life year gained euros price zero cost effectiveness ratio already â‚¬ per life year gained due high background costs heart failure annual budget impact reduction disease burden reach maximum â€“ â years launch â‚¬ million respectively base case conclusions icer sacubitril valsartan projected level accepted interventions treatment asymptomatic severe heart failure germany projected budget impact leads increase shi expenditures per year â© springer nature switzerland ag
10.1016/j.engstruct.2018.06.040 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048432351&doi=10.1016%2fj.engstruct.2018.06.040&partnerID=40&md5=e86978a0278e07b6daa7bf90068dfbde 0,work inverse analysis procedure adopting bayesian approach proposed numerical tool investigate causes led masonry arch bridge certain pathological condition within framework damaged condition investigation formulated parameter estimation problem nonlinear finite element model developed implementation plausible loading scenarios together possible initial undamaged configurations bridge carried computer model predictions subsequently compared real measured geometrical data aim identification problem obtain distribution likely values parameters mechanical model numerical predictions reproduce highest accuracy existing damage pattern posterior probability distributions unknown parameters estimated via use simulation techniques namely markov chain monte carlo mcmc method computational burden associated mcmc sampling procedure time consuming numerical model alleviated adoption gaussian process emulator feasibility practical implementation method tested real case study located kakodiki village island crete greece results indicate reasonable inferences original geometry bridge well possible damage loading scenarios made resulting nearly identical crack pattern respect present damaged state possibility exploiting posterior distributions model updating parameters subsequent structural assessment tasks also shown allowing probabilistic simulation outcomes reliable judgement actual bridge safety condition established application proposed methodology result better understanding underlying mechanisms triggering damage also providing useful guidelines decision making related planning adequate maintenance actions selection optimal strengthening measures â© elsevier ltd
10.1016/j.ijforecast.2018.04.008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050795529&doi=10.1016%2fj.ijforecast.2018.04.008&partnerID=40&md5=b18aaf752b9b4302e0e52e55d8c77229 0,paper analyzes drivers financial distress experienced small italian cooperative banks latest deep recession focusing mainly importance bank capital predictor bankruptcy italian nonprofit banks analysis aims build early warning model suitable type bank results reveal non monotonic effects bank capital probability failure contrast distress models profit banks non performing loans profitability liquidity management quality negligible predictive value findings also show unreserved impaired loans important impact probability bank distress moreover loanâ€“loss ratio provision substandard loans constitutes suitable antibody bank distress overall results robust terms methodology e frequentist bayesian approaches sample used e cooperative banks italy euro area countries â© international institute forecasters
10.1109/TNNLS.2017.2782711 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040636748&doi=10.1109%2fTNNLS.2017.2782711&partnerID=40&md5=9657de243ff6f87baa504f9b003faeb9 0,mixture gaussian processes gps capable learning general stochastic process based given set sample curves regression prediction problems however ineffective curve clustering prediction sample curves derived different stochastic processes independent sources linearly mixed together paper propose two layer mixture model gp functional regressions gpfrs describe mixture general stochastic processes independent sources especially curve clustering prediction specifically lower layer mixture gpfrs mgpfrs developed cluster class curves within input space higher layer mixture mgpfrs established divide curves clusters according components output space parameter estimation two layer mixture gpfrs develop monte carlo em algorithm based monte carlo markov chain mcmc method short mcmc em algorithm validate hierarchical mixture gpfrs mcmc em algorithm using synthetic real world data sets results show new model outperforms conventional mixture models curve clustering prediction â© ieee
10.1002/qre.2314 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053450633&doi=10.1002%2fqre.2314&partnerID=40&md5=7a1b06172fa0c4f3e634a345128763ba 0,two parameter shifted exponential distribution widely applied many areas reliability modeling analysis time failure protected guaranty period induces origin parameter exponential model despite large volume works inferential aspects two parameter exponential distribution studies done perspective process monitoring modern production process items come warranty often encounter shifted exponential time events consumers perspective therefore paper propose two cusum schemes joint monitoring origin scale parameters based maximum likelihood estimators study control behavior proposed procedures via markov chain approach well applying monte carlo provide detailed implementation strategies two schemes along follow procedures identify source shifts control signal obtained examine performance properties cusum schemes find two proposed schemes offer performance advantages shewhart type schemes especially monitoring small moderate shifts provide guidance choosing appropriate schemes study effect reference parameter k cusum schemes also investigate optimal design reference values known unknown shift cases finally two examples given illustrate implementation proposed approach â© john wiley sons ltd
10.1109/TGRS.2018.2825608 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046706999&doi=10.1109%2fTGRS.2018.2825608&partnerID=40&md5=e8077b926b8266915f09a040e47baa84 0,ages terrains planetary bodies chiefly determined using crater size frequency distributions however primary impacts generate numerous secondary craters affect crater population classifying impact craters primary secondary commonly done via time consuming manual inspection limits areas analyzed high resolution present parametric model characterizing small diameter impact craters model parameters implications describing physical processes involved formation modification infer parameters craters images captured high resolution imaging science experiment hirise camera onboard mars reconnaissance orbiter crater within appropriate size range algorithm creates surface parametrically modeled crater rendering using illumination metadata including emission phase solar incidence angles time image captured function describes likelihood set model parameters terms geometry craters given hirise image values optimized using metropolis hasting markov chain monte carlo sampler evaluated three different prior probability distributions parameter space two different likelihoods one digital terrain models images show applying distributed stochastic neighbor embedding sne inferred crater parameters sne able project multidimensional crater parameters space secondary craters cluster together separable primary craters â© ieee
10.1051/0004-6361/201833436 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055006385&doi=10.1051%2f0004-6361%2f201833436&partnerID=40&md5=2fbd22ebee6c5ba926a2cf565f6e80ef 0,context kepler object interest network koinet multi site network telescopes around globe organised follow transiting planet candidate kepler objects interest kois large transit timing variations ttvs main goal complete ttv curves kepler telescope longer observes original kepler field aims combining kepler new ground based transit data improve modelling systems end developed photodynamical model demonstrate performance using kepler system example methods comprehensive analysis combines numerical integration system dynamics time span observations along transit light curve model provides coherent description observations simultaneously model coupled markov chain monte carlo algorithm allowing exploration model parameter space results applied kepler long cadence data short cadence data new transit observations collected koinet years modelling provides well constrained predictions next transits system parameters determined densities planets kepler b c precise values ï�b = â± g cm ï�c = â± g cm analysis reveals kepler c stop transiting yr due strong dynamical interactions kepler b c near resonance leading periodic change inclination conclusions next years inclination kepler c b decrease increase slowly measurable substantial decrease increase transit duration soon years time observations contradict prediction might indicate presence additional objects system prediction turns accurate behaviour opens unique chance scan different latitudes star high latitudes planet c low latitudes planet b â© eso
10.1051/0004-6361/201832924 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054952645&doi=10.1051%2f0004-6361%2f201832924&partnerID=40&md5=1ab07bf31650ae8b1d5e7143003decb8 1,context evolutionary models widely used infer mass stars brown dwarfs giant planets predictions thought less reliable young ages lt myr low mass regime lt mâš™ gj ab twa ab two rare astrometric dwarf binaries respectively members ab doradus ab dor beta pictoris î² pic moving groups dynamical mass measured within years used calibrate evolutionary tracks set new constraints age young moving groups aims provide first dynamical mass measurement gj refined measurement total mass twa also characterize atmospheric properties individual components gj used inputs evolutionary models methods used naco sphere observations vlt archival keck nirc data complement astrometric monitoring binaries combined astrometry new harps radial velocities rvs feros rvs gj used markov chain monte carlo mcmc module estimate posteriors orbital parameters dynamical masses gj ab twa ab astrometry rvs complementary data obtained integral field spectrograph vlt sinfoni gathered extract individual near infrared î¼m medium resolution r âˆ¼ spectra gj b compared spectra known objects grids bt settl model spectra infer spectral type bolometric luminosities temperatures objects results find total mass â± mâš™ twa good agreement model predictions age î² pic moving group obtain total mass â± mâš™ gj estimate spectral type â± l lâš™ = â± dex teff = â± k gj b component â± dwarf l lâš™ = â± dex teff = â± k dynamical mass gj ab inconsistent recent models predictions bcah parsec ab dor age range myr ïƒ depending assumed age model predictions corresponding underestimation mâš™ coevality suggests young age system âˆ¼ myr according evolutionary models conclusions twa validates predictions recent evolutionary tracks âˆ¼ myr hand evidence ïƒ mismatch predicted observed mass gj ab slight departure may indicate one stars hosts tight companion alternatively confirm model tendency underestimate mass young low mass stars â© eso
10.1016/j.jmp.2018.08.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053770333&doi=10.1016%2fj.jmp.2018.08.005&partnerID=40&md5=20189e4ce54e289ec632f8683f05228d 0,measuring shared beliefs expert consensus details crime eyewitness testimony represents psychometric challenge expert interviews example correct responses representing expert consensus e answer key initially unknown experts may differ contribution consensus propose variable response model extension latent trait models model allows estimation answer key latent trait continuous categorical mixed responses describe minimal requirements addition new response formats model propose markov chain monte carlo algorithm estimate model parameters results simulation study demonstrate algorithm accurately recovers data generating parameters also present application variable response model empirical data geography test application parameter estimates correspond well true answer key â© elsevier inc
10.1093/molbev/msy147 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054892383&doi=10.1093%2fmolbev%2fmsy147&partnerID=40&md5=640c396b3d7408788342ee866b910fee 0,multispecies coalescent provides natural framework accommodating ancestral genetic polymorphism coalescent processes cause different genomic regions different genealogical histories bayesian program bpp includes full likelihood implementation multispecies coalescent using transmodel markov chain monte carlo calculate posterior probabilities different species trees bpp suitable analyzing multilocus sequence data sets accommodates heterogeneity gene trees topology branch lengths among loci gene tree uncertainties due limited phylogenetic information locus provide practical guide use bpp species tree estimation bpp command line program runs linux macosx windows protocol shows use bpp http abacus gene ucl ac uk software bpp https github com bpp
10.1093/cz/zox076 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047531305&doi=10.1093%2fcz%2fzox076&partnerID=40&md5=dcc55f6f47d9b95b1fb5d0d1b6351a8f 1,inbreeding negatively affects various life history traits inbred individuals typically lower fitness outbred individuals =inbreeding depression inbreeding depression often emphasized environmental stress underlying mechanisms potential long lasting consequences inbreeding environment interactions remain poorly understood hypothesize inbreeding environment interactions occur early life long term physiological effects particular adult oxidative balance applied unique experimental design manipulate early life conditions inbred outbred songbirds serinus canaria allowed us separate prenatal postnatal components early life conditions respective importance inbreeding environment interactions measured wide variety markers oxidative status adulthood resulting comprehensive account oxidative balance using bayesian approach markov chain monte carlo found clear sex specific effects also found females small yet significant long term effects inbreeding environment interactions adult oxidative balance postnatal components early life conditions persuasively reflected adult oxidative balance inbred females experienced disadvantageous postnatal conditions upregulating enzymatic antioxidants adulthood study provides evidence adult oxidative balance reflect inbreeding environment interactions early life given rather small effects limited females conclude oxidative stress might limited role asmechanism underlying inbreeding environment interactions â© author published oxford university press
10.1093/mnras/sty1835 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051545334&doi=10.1093%2fmnras%2fsty1835&partnerID=40&md5=e3cdd68dcedd3a3598bc8cf4447b0df9 3,study reionization two non flat n ary logical cdm inflation models best fit planck cosmic microwave background cmb anisotropy observations ignoring conjunction baryon acoustic oscillation distance measurements implement principal component analysis pca estimate uncertainties reionization history joint quasar cmb data set thorough markov chain monte carlo analysis done parameter space pcamodes non flat n ary logical cdminflationmodels aswell original planck tilted spatially flat n ary logical cdm inflation model although flat non flat models closely match low redshift z â‰² observations notice possible tension high redshift z lyman emitter data non flat models solely due fact closed models relatively higher reionization optical depth compared flat one turn demands high redshift ionizing sources favours extended reionization starting early z â‰ˆ conclude opposed flat cosmology non flat cosmology models escape fraction needs steep redshift evolution even unrealistically high values redshifts ii physical parameters require non monotonic redshift evolution especially apparent lyman emitter data included analysis â© author published oxford university press behalf royal astronomical society
10.1111/gean.12152 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055344331&doi=10.1111%2fgean.12152&partnerID=40&md5=2dbeab7f9813f4651bff0aaf72b4a9ad 0,extend heterogeneous coefficients spatial autoregressive panel model hsar aquaro bailey pesaran case heterogeneous coefficients matrix exponential spatial specification hmess hsar capable producing parameter estimates region sample follow spatial autoregressive process spatial autoregressive processes apply geometric decay influence higher order neighboring regions hmess takes similar approach hsar produce estimates region sample relies matrix exponential function apply exponential decay higher order neighbors mess introduced lesage pace case cross sectional spatial data samples potential computational advantages spatial autoregressive specification addition spatial dependence parameter mess ranges minus plus infinity allows use normal priors assigned parameter bayesian setting extend cross sectional mess case heterogeneous coefficients model describe bayesian markov chain monte carlo estimation illustrate hmess model panel wage curve relationship using quarterly unemployment wage rates counties centered bakken shale oil region north dakota montana â© ohio state university
10.1093/mnras/sty1820 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051458887&doi=10.1093%2fmnras%2fsty1820&partnerID=40&md5=046598d397de3f14714775b907a5a575 1,hubble frontier fields program gravitational lensing provided powerful way extend study ultraviolet luminosity function lf galaxies z unprecedented magnitude limits time significant discrepancies different studies found faint end lf attempt understand disagreements present comprehensive assessment uncertainties associated lensing models size distribution galaxies use end end simulations source plane final lf account lensing effects systematic uncertainties comparing several mass models addition size distribution choice lens model leads large differences magnitudes fainter muv = ab mag magnification factor becomes highly uncertain perform markov chain monte carlo mcmc simulations include uncertainties individual galaxy level compute final lf allowing particular crossover magnitude bins best lf fit using modified schechter function allows turnover faint magnitudes gives faint end slope î± = + curvature parameter î² = + turnover magnitude ofmt = + importantly procedure shows robust constraints lf magnitudes fainter muv = ab remain unrealistic per cent confidence interval accommodates turnover steep faint end slope accurate lens modeling future observations lensing clusters james webb space telescope reliably extend ultraviolet uv lf fainter magnitudes â© author published oxford university press behalf royal astronomical society
10.1016/j.neuroimage.2018.06.073 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049460748&doi=10.1016%2fj.neuroimage.2018.06.073&partnerID=40&md5=cc16f2650da95f6ff3ee9c9d2c75a51f 0,recently introduced hierarchical generative model unified inference effective connectivity individual subjects unsupervised identification subgroups defined connectivity patterns hierarchical unsupervised generative embedding huge approach combined hierarchical formulation dynamic causal modelling dcm fmri gaussian mixture models relied markov chain monte carlo mcmc sampling inference well suited inversion complex hierarchical models mcmc based sampling suffers computational burden prohibitive many applications address problem paper derives efficient variational bayesian vb inversion scheme huge simultaneously provides approximations posterior distribution model parameters log model evidence face validity vb scheme tested using two synthetic fmri datasets known ground truth additionally empirical fmri dataset stroke patients healthy controls used evaluate practical utility method application real world problems analyses demonstrate good performance vb scheme marked speed model inversion two orders magnitude compared mcmc maintaining similar level accuracy notably additional acceleration possible parallel computing techniques applied generally vb implementation huge fast enough support multi start procedures whole group analyses useful strategy ameliorate problems local extrema huge thus represents potentially useful practical solution important problem clinical neuromodeling computational psychiatry e unsupervised detection subgroups heterogeneous populations defined effective connectivity â© authors
10.3847/1538-4357/aadba5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054796521&doi=10.3847%2f1538-4357%2faadba5&partnerID=40&md5=f6586ee3bb7d63b30f4b6b4c640218b7 0,develop apply model quantify global efficiency radial orbit migration among stars milky way disk model parameterizes possible star formation enrichment histories radial birth profiles combines migration model relates present day orbital radii birth radii gaussian probability broadening age ï„ guided observations assume stars born initially tight age metallicity relation given radius becomes subsequently scrambled radial orbit migration thereby providing direct observational constraint radial orbit migration strength fit model markov chain monte carlo sampling observed age metallicity distribution low î± red clump stars galactocentric radii kpc apogee dr sidestepping complex spatial selection function accounting considerable age uncertainties simple model reproduces observed data well find global radius time radial orbit migration efficiency milky way = â± kpc marginalizing aspects model shows radial orbit migration milky way main disk indeed rather strong line theoretical expectations stars migrate half mass radius age disk model finds sun birth radius âˆ¼ kpc strong radial orbit migration typical mechanism indeed plays important role setting structural regularity disk galaxies â© american astronomical society rights reserved
10.1016/j.agee.2018.06.029 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049477360&doi=10.1016%2fj.agee.2018.06.029&partnerID=40&md5=591ed275f9755c1592e6c22524b15e8a 0,widely reported climate change felt throughout europe though effects likely vary dramatically across european regions areas expected experience elevated atmospheric co concentrations â†‘c higher temperatures â†‘t north east get considerably wetter â†‘w south much drier â†“w likely changes impact pastures consequently grazing livestock study aims evaluate expected changes pasture yield quality caused â†‘c â†‘t â†‘w â†“w across different european regions across different plant functional groups pfgs data collected studies giving total observations mixed models used estimate expected changes ground dry weight agdw nitrogen n concentrations implemented using markov chain monte carlo simulations results showed increase agdw â†‘c particularly shrubs + though likely accompanied reduction n concentrations âˆ’ â†‘t increase yields alpine northern areas + though regions experience little change else decreases â†‘t also reduce n concentrations especially shrubs âˆ’ forbs âˆ’ â†“w decrease agdw regions pfgs though increase n concentrations + â†‘w increase agdw need research get complete picture future pasture conditions analysis provides general overview expected changes thus help european farmers prepare adapt systems meet challenges presented changing climate â©
10.1371/journal.pone.0205889 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055071100&doi=10.1371%2fjournal.pone.0205889&partnerID=40&md5=0d5ac3a26d6cd52a671cc5ab706a81d0 0,japan experienced nationwide rubella epidemic mostly urban prefectures large population sizes present study aimed capture spatiotemporal patterns rubella using parsimonious metapopulation epidemic model examine potential usefulness spatial vaccination methodology principal findings metapopulation epidemic model discrete time space devised applied rubella notification data employing piecewise constant model linear growth rate six different time periods using particle markov chain monte carlo method effective reproduction numbers estimated cri cri tokyo osaka groups respectively growing phase epidemic rubella epidemic involved substantial uncertainties parameter estimates forecasts examined multiple scenarios spatial vaccination coverages japan distributed different combinations prefectures scenarios indicated vaccinating top six populous urban prefectures e tokyo kanagawa osaka aichi saitama chiba potentially effective random allocation however greater uncertainty introduced stochasticity initial conditions number infectious individuals fraction susceptibles conclusions forecast accompanied broad uncertainties narrower uncertainty bound parameters reliable forecast achieved greater rubella epidemic better capturing underlying epidemic dynamics spatial vaccination substantially outperform random vaccination â© saito et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.3847/1538-3881/aad45b https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054801851&doi=10.3847%2f1538-3881%2faad45b&partnerID=40&md5=61eca243aa576fc80de32e873b0a11e4 0,occultation radio galaxy + asteroid palma may observed using six antennas long baseline array vlba shadow palma crossed vlba station brewster washington owing wavelength used size distance asteroid diffraction pattern fraunhofer regime observed measurement retrieves amplitude phase diffracted electromagnetic wave first astronomical measurement phase shift caused diffraction maximum phase shift sensitive effective diameter asteroid bright spot shadow center called arago poisson spot clearly detected amplitude time series strength good indicator closest angular distance center asteroid radio source sample random shapes constructed using markov chain monte carlo algorithm suggests silhouette palma deviates perfect circle â± best fitting random shapes resemble suggest average approximates shape silhouette time occultation effective diameter obtained palma â± km excellent agreement recent estimates thermal modeling mid infrared photometry finally computations show high positional accuracy single radio interferometric occultation measurement reduce long term ephemeris uncertainty order magnitude â© american astronomical society rights reserved
10.1007/s10709-018-0027-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048376903&doi=10.1007%2fs10709-018-0027-x&partnerID=40&md5=f4c2dd2f99b9627a8f171d272527bd10 0,genomic prediction feasible estimating genomic breeding values dense genome wide markers credible statistical methods genomic best linear unbiased prediction gblup various bayesian methods compared gblup bayesian methods propose flexible assumptions distributions snp effects however bayesian methods performed based markov chain monte carlo mcmc algorithms leading computational efficiency challenges hence fast bayesian approaches fast bayesb fbayesb proposed speed calculation study proposed another fast bayesian method termed fast bayesc fbayesc prior distribution fbayesc assumes snp probability î³ non zero effect comes normal density common variance simulated data qtlmas xii workshop actual data large yellow croaker used compare predictive results fbayesb fbayesc mcmc based bayesc results showed î³ set small value simulated data actual data fbayesb fbayesc yielded lower prediction accuracies abilities bayesc actual data fbayesc yield similar predictive abilities bayesc î³ â‰¥ î³ = fbayesb also yield similar results fbayesc bayesc however fbayesb yield explicit result î³ â‰¥ similar situation observed fbayesc moreover computational speed fbayesc significantly faster bayesc making fbayesc promising method genomic prediction â© springer international publishing ag part springer nature
10.1088/1742-6596/1090/1/012014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054488552&doi=10.1088%2f1742-6596%2f1090%2f1%2f012014&partnerID=40&md5=0208f5a951e78b2dc49e838a1931f8dd 0,assessment comparison income inequality poverty supported estimating probability distribution income income distributions typically heavy tailed positively skewed estimated parametric nonparametric approach parametric approach finite mixtures distributions usefully implemented modelling income distributions multimodal characteristic markov chain monte carlo mcmc approach one estimation methods good performance estimating parameter bayesian finite mixture model convergence mcmc sampler posterior distribution typically assessed using standard diagnostics methods e gelman rubin method geweke method raftery lewis method heidelberger welch method methods give different results conclude mcmc convergence condition paper real sample income data indonesian family life survey ifls bidikmisi employed demonstrate performance diagnostics tools assess convergence mcmc algorithm estimating parameter bayesian finite mixture models â© published licence iop publishing ltd
10.1088/1742-6596/1090/1/012072 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054554265&doi=10.1088%2f1742-6596%2f1090%2f1%2f012072&partnerID=40&md5=13a6c899b6044b5f826b70b9eb1831a8 0,research purpose develop bernoulli mixture model bidikmisi data modelling using bayesian approach model development done considering specificity data acceptance bidikmisi scholarship prototype east java province bidikmisi acceptance status binary type coupled main criteria factor parent income number dependents family produces structure bernoulli mixture distribution two components characteristics component identified bernoulli mixture modelling involving covariates bidikmisi scholarship recipients estimating parameter performed using bayesian markov chain monte carlo mcmc couple gibbs sampling algorithm model applied data registrants bidikmisi districts cities province east java many students model shows smallest value deviance information criteria dic compared bayesian binary logistic regression â© published licence iop publishing ltd
10.1103/PhysRevD.98.063533 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054478048&doi=10.1103%2fPhysRevD.98.063533&partnerID=40&md5=f04aad4ea762b03e8ed1492848842a9e 0,work investigate holographic dark energy models slowly time varying model parameter defined based current hubble horizon length scale previous studies three popular holographic dark energy models defined based future event horizon ricci scale granda oliveros ir cutoffs showed models fit observational data akhlaghi malekjani basilakos h haghi mon r astron soc mnraa mnras sty work show holographic dark energy models time varying model parameter defined current hubble radius well favored observations using standard ï‡ minimization context markov chain monte carlo method compare ability holographic dark energy models time varying c parameter constructed current hubble length scale different sets observational data namely expansion data growth rate data expansion+growth rate data respectively based values akaike bayesian information criteria find types holographic dark energy models well fitted expansion growth rate observations equal î›cdm cosmology also put constraints cosmological parameters show transition epoch form early decelerated current accelerated expansion calculated holographic dark energy models time varying model parameter defined hubble length consistent observations â© american physical society
10.1515/jqas-2015-0076 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049726965&doi=10.1515%2fjqas-2015-0076&partnerID=40&md5=2f5da0d1b17daf63b62bd5376d31ee33 0,bayesian model used evaluate probability given skill performed specified area field lead predetermined outcome using discrete absorbing markov chains transient states markov process defined unique skill area combinations absorbing states markov process defined shot turnover bad turnover defining states manner allows probability transient state leading absorbing state derived non informative prior specification transition counts used permit data define posterior distribution web application created collect play play data division ncaa women soccer matches seasons prudent construction updated transition probabilities facilitates transformation monte carlo simulation obtain marginal probability estimates unique skill area combination leading absorbing state season marginal probability estimates given skills compared across within areas determine skills areas field advantageous â© walter de gruyter gmbh berlin boston
10.1515/jqas-2017-0066 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053147720&doi=10.1515%2fjqas-2017-0066&partnerID=40&md5=6c685d8ca8a5188eee0e454c62aa80a5 0,although consensus measure quantify individual performance sport less development area soccer major sports measurement defined modeling predictive purposes make sense use player ratings provided popular italian fantasy soccer game proxies players performance discuss merits flaws variety hierarchical bayesian models predicting ratings comparing models predictive accuracy hold data central goals explore accomplished simple freely available dataset comprising variables season top italian league serie focus small number interesting modeling prediction questions arise among highlight importance modeling missing observations propose two models designed task validate models graphical posterior predictive checks provide sample predictions second half season using first half training set use stan sample posterior distributions via markov chain monte carlo â© walter de gruyter gmbh berlin boston
10.1080/00949655.2018.1490418 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049088622&doi=10.1080%2f00949655.2018.1490418&partnerID=40&md5=aedac1c83e42d9480c98291f96a2a872 0,feature selection arises many areas modern science example genomic research want find genes used separate tissues different classes e g cancer normal one approach fit regression classification models certain penalization past decade hyper lasso penalization priors received increasing attention literature however fully bayesian methods use markov chain monte carlo mcmc regression classification hyper lasso priors still lack development paper introduce mcmc method learning multinomial logistic regression hyper lasso priors mcmc algorithm uses hamiltonian monte carlo restricted gibbs sampling framework used simulation studies real data demonstrate superior performance hyper lasso priors compared lasso investigate issues choosing heaviness scale hyper lasso priors â© â© informa uk limited trading taylor francis group
10.1080/00949655.2018.1487441 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048857826&doi=10.1080%2f00949655.2018.1487441&partnerID=40&md5=7feb6d01ca04785138c86dbb9b9c927c 0,inverted inverse distributions sometimes useful explore additional properties phenomenons non inverted distributions introduce new inverted model called inverted nadarajahâ€“haghighi distribution exhibits decreasing unimodal right skewed density hazard rate shapes decreasing upside bathtub main focus estimation frequentist bayesian points view unknown parameters along mathematical properties new model bayes estimators associated credible intervals obtained using markov chain monte carlo techniques squared error loss function gamma priors adopted scale shape parameters potentiality distribution analysed means two real data sets fact found superior ability sufficiently model data compared inverted weibull inverted rayleigh inverted exponential inverted gamma inverted lindley inverted power lindley models â© â© informa uk limited trading taylor francis group
10.1088/1757-899X/418/1/012089 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054205221&doi=10.1088%2f1757-899X%2f418%2f1%2f012089&partnerID=40&md5=cc115cd9c5c6b33f6e3da96dbffdad49 0,continual demand vehicle weight reduction improved fuel efficiency crashworthiness driven automotive industry increasingly fabricate automotive body parts advanced high strength steel ahss sheet dual phase dp transformation induced plasticity trip steels therefore essential carefully investigate forming behaviour sheet materials various forming conditions work quasi static tensile flow behaviour dp trip sheet specimens obtained three orientations rd dd td respect sheet rolling direction parameter voce hardening function fitted flow curve order determine true stress true strain based constant amount plastic work per unit volume calculate normalized yield stress well r value material orientation yoshida th order polynomial anisotropic yield function expressed function second third invariants deviatoric stress tensor j j respectively used predict mechanical response two sheet materials new optimization method based markov chain monte carlo mcmc metropolishastings mh algorithm employed calibrate anisotropic yield function determine anisotropic coefficients yield loci materials derived function also function j performance function evaluated validated comparing numerical predictions r value flow stress directionality experimental results effects j j predicting shape yield locus dp trip also discussed â© published licence iop publishing ltd
10.1093/mnras/sty1691 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051462796&doi=10.1093%2fmnras%2fsty1691&partnerID=40&md5=466e6dda9f07694db8abef9260fcb096 0,introduce phi fully bayesian markov chain monte carlo algorithm designed structural decomposition galaxy images phi uses triple layer approach effectively efficiently explore complex parameter space combining use priors prevent non physical models phi offers number significant advantages estimating surface brightness profile parameters traditional optimization algorithms apply phi sample synthetic galaxies sloan digital sky survey sdss like image properties investigate effect galaxy properties ability recover unbiased wellconstrained structural parameters two component bulge+disc galaxies find bulge structural parameters recovered less well disc particularly bulge contributes lower fraction luminosity barely resolved respect pixel scale point spread function psf systematic biases apart bulge+disc galaxies large bulge sã©rsic parameter n application sdss images find good agreement codes run images masks weights psf find bulge parameters difficult constrain robustly finally explore use bayesian information criterion method deciding whether galaxy one two components â© author published oxford university press behalf royal astronomical society
10.1103/PhysRevD.98.063011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054474767&doi=10.1103%2fPhysRevD.98.063011&partnerID=40&md5=ead5452224b4f384e726fb1a185b6d89 0,isolated nonaxisymmetric rotating neutron stars producing continuous gravitational wave signals may undergo occasional spin events known glitches unmodeled search glitches result continuous wave signals missed misidentified detector artifacts outline semicoherent glitch robust search method allows identification continuous wave signal candidates contain glitches inferences model parameters demonstrate applied follow candidates found wide parameter space searches find markov chain monte carlo method outperforms grid based method speed accuracy â© authors published american physical society
10.3847/1538-4357/aadadc https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053902151&doi=10.3847%2f1538-4357%2faadadc&partnerID=40&md5=64fe0c511fa02a663308e1bb2abac585 0,report individual dynamical masses brown dwarfs ïµ indi b c spectral types respectively measured astrometric orbit mapping measurements based joint analysis astrometric data carnegie astrometric planet search cerro tololo inter american observatory parallax investigation well archival high resolution imaging use markov chain monte carlo method find dynamical masses â± jup b component â± jup c component masses surprisingly high cool objects challenge understanding substellar structure evolution discuss several evolutionary scenarios proposed literature find none provide conclusive explanations high substellar masses evolutionary models incorporating lower atmospheric opacities come closer approximating results discuss details astrometric model algorithm implementation determine parameter values via markov chain monte carlo bayesian inference â© american astronomical society rights reserved
10.1103/PhysRevC.98.035802 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053849917&doi=10.1103%2fPhysRevC.98.035802&partnerID=40&md5=e07830bed5cb1678fd7470dc15b4cbe7 0,thermal evolution hot young neutron star supernova remnant hess j driven neutrino emission provides stringent constraint coupling light mass kev axion like particles neutrons using markov chain monte carlo find values axion neutron coupling gann ã— c l axion cooling bremsstrahlung reaction n+nâ†’n+n+a rapid account high observed surface temperature implies pecci quinn scale axion decay constant fa ã— gev ksvz axions fa ã— gev dfsz axions high temperature neutron star also allows us tighten constraints size nucleon pairing gaps â© american physical society
10.3847/1538-4357/aad95d https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053897152&doi=10.3847%2f1538-4357%2faad95d&partnerID=40&md5=b73d8e2759abad05b222619d779af308 0,interior characterization traditionally relies individual planetary properties ignoring correlations different planets system multiplanetary systems planetary data generally correlated differential masses radii better constrained absolute planetary masses radii explore correlations data specific multiplanetary system trappist study value understanding planet interiors furthermore demonstrate rocky interior planets multiplanetary system preferentially probed studying densest planet representing rocky interior analog methodology includes bayesian inference analysis uses markov chain monte carlo scheme interior estimates account anticipated variability compositions layer thicknesses core mantle water oceans ice layers well gas envelope results show interior estimates significantly depend available abundance proxies importance interdependent planetary data interior characterization comparable changes data precision interiors trappist planets find possible water mass fractions generally range lack clear trend water budgets orbital period planet mass challenges possible formation scenarios estimates change relatively little data precision critically depend data accuracy planetary masses varied within â± interiors consistent uniform âˆ¼ increasing water mass fractions orbital period âˆ¼ â© american astronomical society rights reserved
10.1186/s12936-018-2478-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053528747&doi=10.1186%2fs12936-018-2478-z&partnerID=40&md5=61ac5ba6e95fc308eab580bc15650dc9 0,background viet nam made tremendous progress towards reducing mortality morbidity associated malaria recent years despite success malaria control recent increase cases provinces order understand changing malaria dynamics viet nam measure progress towards elimination aim study describe quantify spatial temporal trends malaria species district level across country methods malaria case reports viet nam national institute malariology parasitology entomology reviewed period january december population district obtained population housing census multivariate insecticide treated mosquito nets itn indoor residual spraying irs maximum temperature zero inflated poisson regression model developed spatial spatiotemporal random effects modelled using conditional autoregressive prior structure posterior parameters estimated using bayesian markov chain monte carlo simulation gibbs sampling covariates included models coverage intervention itn irs maximum temperature results total plasmodium falciparum plasmodium vivax cases study period ratio p falciparum p vivax decreased p falciparum cases p falciparum cases coverage itn associated decreased p falciparum incidence credible interval cri decrease incidence increase itn coverage case p vivax case irs coverage maximum temperature associated increased incidence species cri cri increase p falciparum p vivax incidence temperature increase â°c respectively temporal trends p falciparum p vivax incidence significantly higher national average central central southern districts conclusion interventions itn distribution environmental factors increased temperature associated incidence p falciparum p vivax study period factors reviewed exhaustive however data suggest distribution resources targeted areas times increased malaria transmission additionally changing distribution two predominant malaria species viet nam require different programmatic approaches control elimination â© author
10.1088/1361-6382/aadc36 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053905352&doi=10.1088%2f1361-6382%2faadc36&partnerID=40&md5=0a81ca4a5a6cd15868f8578a4aaa102d 0,everpresent î› cosmological scenario observed cosmological constant î› fluctuates positive negative values vanishing mean magnitude comparable critical density epoch accord longstanding heuristic prediction causal set theory postulates î› stochastic function cosmic time vary one realization scenario another herein consider two models dark energy exhibit features via monte carlo markov chains explore space cosmological parameters set stochastic realizations models finding everpresent î› fit current cosmological observations well î›cdm model furthermore removes observational tensions î›cdm experiences relation low redshift measurements hubble constant baryonic acoustic oscillations bao lyman î± forest however help significantly early growth ultramassive black holes lithium problem big bang nucleosynthesis future measurements dark energy high redshifts test viability everpresent î› alternative î›cdm cosmology â© iop publishing ltd
10.1016/j.ejor.2018.02.037 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043503189&doi=10.1016%2fj.ejor.2018.02.037&partnerID=40&md5=ff034510540c01f8262a91f7e24d2cc7 0,propose novel multivariate approach dependence analysis energy market methodology based tree copulas garch type processes use study dependence structure among main factors affecting energy price perform portfolio risk evaluation temporal dynamic examined variables described via set garch type models joint distribution standardised residuals represented via suitable tree copula structures working bayesian framework perform qualitative quantitative learning posterior summaries quantities interest obtained via mcmc methods â© elsevier b v
10.1016/j.physa.2018.03.096 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046170598&doi=10.1016%2fj.physa.2018.03.096&partnerID=40&md5=29536f02103dff44cc68bea70d890b56 0,sampling complicated unknown distributions wide ranging applications standard monte carlo techniques designed known distributions difficult adapt distribution unknown markov chain monte carlo mcmc techniques designed unknown distributions underlying state space complex continuous application mcmc becomes challenging longer straightforward techniques proposed astronomically large redistricting application characterized extremely complex idiosyncratic state space explore theoretic applicability methods evaluate empirical performance â© elsevier b v
10.1080/03610918.2017.1341525 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025833700&doi=10.1080%2f03610918.2017.1341525&partnerID=40&md5=ea3cdf56436f0d95f633c1565fd41aa3 0,article reduce computational load performing bayesian variable selection used variant reversible jump markov chain monte carlo methods holmes held hh algorithm sample model index variables logistic mixed models involving large number explanatory variables furthermore proposed simple proposal distribution model index variables used simulation study real example compare performance hh algorithm proposed existing proposal distributions results show hh algorithm proposed proposal distribution computationally efficient reliable selection method â© â© taylor francis group llc
10.1186/s12859-018-2347-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053317941&doi=10.1186%2fs12859-018-2347-3&partnerID=40&md5=25b5bd81c4fd7efca86597266d1a9fd1 0,background conventional phylogenetic clustering approaches rely arbitrary cutpoints applied posteriori phylogenetic estimates although practice bayesian bootstrap based clustering tend lead similar estimates often produce conflicting measures confidence clusters current study proposes new bayesian phylogenetic clustering algorithm refer dm phyclus dirichlet multinomial phylogenetic clustering identifies sets sequences resulting quick transmission chains thus yielding easily interpretable clusters without using ad hoc distance confidence requirement results simulations reveal dm phyclus outperform conventional clustering methods well gap procedure pure distance based algorithm terms mean cluster recovery apply dm phyclus sample real hiv sequences producing set clusters whose inference line conclusions previous thorough analysis conclusions dm phyclus eliminating need cutpoints producing sensible inference cluster configurations facilitate transmission cluster detection future efforts reduce incidence infectious diseases like hiv need reliable estimates transmission clusters follows algorithms like dm phyclus serve better inform public health strategies â© author
10.3390/s18093057 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053662413&doi=10.3390%2fs18093057&partnerID=40&md5=c019f009c20d0b665bf5c5d8cb2edb62 0,focus bayesian inference framework finite element fe model updating long span cable stayed bridge using long term monitoring data collected wireless sensor network wsn robust bayesian inference method proposed marginalizes prediction error precisions applies transitional markov chain monte carlo tmcmc algorithm proposed marginalizing error precision compared two treatments prediction error precisions including constant error precisions updating error precisions theoretical analysis numerical investigation based bridge fe model tmcmc employed draw samples posterior probability density function pdf structural model parameters uncertain prediction error precision parameters required found proposed bayesian inference method prediction error precisions marginalized â€œnuisanceâ€� parameters produces fe model accurate posterior uncertainty quantification robust modal property prediction applying identified modal parameters acceleration data collected one year period large scale wsn bridge choose two candidate model classes using different parameter grouping based clustering results sensitivity analysis apply bayesâ€™ theorem model class level implementing tmcmc sampler posterior distributions structural model parameters plausibility two model classes characterized given real data computation posterior probabilities candidate model classes provides procedure bayesian model class assessment computation automatically implements bayesian ockham razor trades data fitting model complexity penalizes model classes â€œover fitâ€� data results fe model updating assessment based real data using proposed method show updated fe model successfully predict modal properties structural system high accuracy â© authors licensee mdpi basel switzerland
10.1109/RAM.2018.8463028 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054150819&doi=10.1109%2fRAM.2018.8463028&partnerID=40&md5=8e902fea2e0bb63fab3e724c3f3b33cb 0,paper deals selective maintenance multistate series system working time varying environmental operational conditions environmental conditions evolving dynamically mission influence degradation rate component whole system assume environmental conditions vary continuous time markov chain components maintained maintenance break two consecutive missions performing maintenance actions nothing imperfect perfect maintenance selective maintenance optimization problem used find optimal maintenance strategy order maximize expected system reliability next mission subjected maintenance time budget limitations monte carlo simulation used evaluate reliability system end next mission considering variable environmental operational conditions example provided demonstrate importance considering uncertainty environmental operational conditions â© ieee
10.1109/ICASSP.2018.8461412 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054275010&doi=10.1109%2fICASSP.2018.8461412&partnerID=40&md5=c7f9f45d0730ce01ba8f3a40c427130d 0,channel gain cartography relies sensor measurements construct maps providing attenuation profile arbitrary transmitter receiver locations existing approaches capitalize tomographic models shadowing weighted integral spatial loss field slf depending propagation environment currently slf learned via regularization methods tailored propagation environment however effectiveness existing approaches remains unclear especially propagation environment involves heterogeneous characteristics cope present work considers piecewise homogeneous slf hidden markov random field mrf model bayesian framework efficient field estimators obtained using samples markov chain monte carlo mcmc furthermore uncertainty sampling algorithm developed adaptively collect measurements real data tests demonstrate capabilities novel approach â© ieee
10.1109/ICASSP.2018.8462438 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054259859&doi=10.1109%2fICASSP.2018.8462438&partnerID=40&md5=0223f294b009094bffc20192611e04c0 0,work addresses problem segmentation time series data respect statistical parameter interest bayesian models common assume parameters distinct within segment many bayesian change point detection models exploit segment parameter patterns improve performance work proposes bayesian mean shift change point detection algorithm makes use repetition segment parameters introducing segment class labels utilise dirichlet process prior performance proposed approach assessed synthetic real world data highlighting enhanced performance using parameter labelling â© ieee
10.1109/ICASSP.2018.8462197 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054257655&doi=10.1109%2fICASSP.2018.8462197&partnerID=40&md5=f706bfe932e0d9c053755fc0e762d740 0,supervised classification spectral unmixing two methods extract information hyperspectral images however despite complementarity scarcely considered jointly paper presents new hierarchical bayesian model perform simultaneously analysis order ensure benefit linear mixture model proposed described pixel measurements clustering performed identify groups statistically similar abundance vectors markov random field mrf used prior corresponding cluster labels promotes spatial regularization potts markov potential also includes local potential induced classification finally classification exploits set possibly corrupted labeled data provided end user model parameters estimated thanks markov chain monte carlo mcmc algorithm interest proposed model illustrated synthetic real data â© ieee
10.1080/02664763.2017.1420147 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039854958&doi=10.1080%2f02664763.2017.1420147&partnerID=40&md5=ebf4fef11dbd2a4f7b928856efcc2f50 0,paper provide full bayesian analysis cox proportional hazards model different hazard rate shape assumptions end select modified weibull distribution family model failure rates novel markov chain monte carlo method allows one tackle exact right censored failure time data simulated real data used illustrate methods â© â© informa uk limited trading taylor francis group
10.1109/ICASSP.2018.8462457 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054267190&doi=10.1109%2fICASSP.2018.8462457&partnerID=40&md5=0062976ec02c788c542caca67bb55d3c 0,non homogeneous poisson process point process time varying intensity across domain use arises numerous areas signal processing machine learning however applications largely limited intractable likelihood function high computational cost existing inference schemes present sequential inference framework utilises generative poisson data sequential markov chain monte carlo smcmc algorithm enable online inference various applications proposed model compared competing methods synthetic datasets tested real world financial data â© ieee
10.23919/ICIF.2018.8455750 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054062058&doi=10.23919%2fICIF.2018.8455750&partnerID=40&md5=0d503b2b858041844bed0a32a80c0206 0,relying idea importance sampling substantiating bayesian filtering recursion particle filters may become prohibitively inefficient even moderate state dimensions likewise whenever signal noise ratio relatively high case nearly deterministic state dynamics random parameters markov chain monte carlo particle filters completely avoid importance sampling circumvent many deficiencies associated conventional particle filters methods may nevertheless suffer slow convergence rate inadequate computationally intractable proposal distributions used generating new candidate samples underlying markov chain work devise new markov chain monte carlo particle filter whose sampling mechanism employs jumping gaussian distributions technique enhances underlying sampling efficiency leads significant reduction computational cost newly derived filter shown outperform conventional regularised particle filter terms accuracy computational overhead particularly applied estimation systems low intensity noise relatively high state dimensions â© isif
10.23919/ICIF.2018.8455349 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054086524&doi=10.23919%2fICIF.2018.8455349&partnerID=40&md5=3c9b81101242e671299545ca296eea8d 0,particle filters powerful general tools performing nonlinear non gaussian filtering provide estimate distribution target state time last measurement however often desirable compute posterior distribution target path interval time given measurements received interval e smoothed estimate target path process computing distribution called smoothing paper presents markov chain monte carlo mcmc approach smoothing target motion given generalized random tour grt model non gaussian motion model model particularly appropriate maritime tracking situations often involve non linear measurements since filter non linear non gaussian one apply kalman smoother easy natural simulate target paths using grt model transition function closed analytic form result one use standard methods particle filter smoothing paper describe method performing mcmc smoothing grt particle filters demonstrate results using method examples â© isif
10.23919/ICIF.2018.8455307 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054082435&doi=10.23919%2fICIF.2018.8455307&partnerID=40&md5=5460ec357a0ceedb5cb5073165ae3d4f 0,previous work proposed particle gaussian mixture pgm filter nonlinear estimation pgm filter uses transition kernel state markov chain sample propagated prior constructs gaussian mixture representation propagated prior density clustering samples measurement data incorporated updating individual mixture modes using kalman measurement update however kalman measurement update inexact measurement function nonlinear leads restrictive assumption number modes remain fixed measurement update paper introduce alternate pgm ii filter employs parallelized markov chain monte carlo sampling perform measurement update pgm ii filter update asymptotically exact enforce assumptions number gaussian modes pgm ii filter employed estimation two test case systems results indicate pgm ii filter suitable handling nonlinear non gaussian measurement update â© isif
10.1016/j.vaccine.2018.07.053 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050650362&doi=10.1016%2fj.vaccine.2018.07.053&partnerID=40&md5=33b55b6f68987fd0991fa21c85417a3a 0,background norovirus thought responsible fifth acute gastroenteritis cases globally year population level transmission dynamics common virus still poorly understood part illness reported vaccines undergoing clinical trials growing need appropriate empirically grounded models predict likely impact vaccination methods developed dynamic age specific mathematical model norovirus transmission vaccination informed available data particularly age stratified time series case notification data introduce use self reporting markov model account variation age time statutory reporting norovirus germany estimated model using sequential monte carlo particle filter extended applied estimated model investigate potential impact range immunisation strategies performed sensitivity analyses mode vaccine action vaccine related parameters results find routine immunisation reduce incidence norovirus even vaccines provide complete protection disease furthermore find relative efficiency alternative strategies targeting different age groups dependant outcome consider sensitive assumptions mode vaccine action strategies target infants toddler efficient preventing infection targeting older adults preferable preventing severe outcomes conclusions model provides robust estimate dynamic transmission model norovirus population level vaccination may effective strategy preventing disease work required ascertain norovirus vaccine efficacy mode action estimate cost effectiveness immunisation norovirus â© authors
10.1021/acs.est.8b03217 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052400614&doi=10.1021%2facs.est.8b03217&partnerID=40&md5=b78b33026633cc6817ddd84f673ec52c 0,estimate postmeter methane ch emissions california residential natural gas ng system using measurements analysis sample homes appliances quiescent whole house emissions e pipe leaks pilot lights measured using mass balance method california homes ch co emission ratios measured steady operation individual combustion appliances separately transient operation three tankless water heaters measured quiescent whole house emissions typically lt g ch day though exhibit long tailed gamma distributions containing values gt g ch day operating appliances yield undetectable ch co enhancements steady operation lt gas consumed though storage water heaters stovetops exhibit long tailed gamma distributions containing high values âˆ¼ gas consumed transients observed tankless heaters extrapolating results state level using bayesian markov chain monte carlo sampling combined california housing statistics gas use information suggests quiescent house leakage confidence gg ch pilot lights contributing âˆ¼ emissions steady operation appliances pilots gg ch yr order magnitude larger current inventory estimates transients likely increasing appliance emissions together emissions residential ng gg ch yr equivalent âˆ¼ california ng ch emissions suggesting leak repair improvement combustion appliances adoption nonfossil energy heating sources help california meet climate goals â© american chemical society
10.1103/PhysRevLett.121.101101 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053313875&doi=10.1103%2fPhysRevLett.121.101101&partnerID=40&md5=d9876a023668069502fd55c340cece94 0,gravitational torques among objects orbiting supermassive black hole drive rapid reorientation orbital planes nuclear star clusters nscs process known vector resonant relaxation letter determine statistical equilibrium systems distribution masses semimajor axes eccentricities average interaction apsidal precession time construct monte carlo markov chain method sample microcanonical ensemble nsc examine case nscs formed episodes star formation globular cluster infall find massive stars stellar mass black holes form warped disk low mass stars resemble spherical distribution possible net rotation explains origin clockwise disk galactic center predicts population black holes bhs embedded within structure rate mergers among massive stars tidal disruption events massive stars bhs bh bh mergers highly increased disks first two may explain origin observed g g clouds latter may important gravitational wave detections ligo virgo generally black holes expected settle disks dense spherical stellar systems assembled mergers smaller systems including globular clusters â© american physical society
10.1088/1475-7516/2018/09/002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054524370&doi=10.1088%2f1475-7516%2f2018%2f09%2f002&partnerID=40&md5=378abdc1e78b2e6e412c8a914de092f4 0,future neutrino detectors obtain high statistics data nearby core collapse supernova study mixing ev mass sterile neutrinos supernova environment effects active neutrino fluxes detected hyper kamiokande icecube using markov chain monte carlo analysis make projections accurately experiments measure active sterile mixing angle î given substantial uncertainties expected luminosity spectrum active neutrinos galactic supernova burst find hyper kamiokande reconstruct sterile neutrino mixing mass many different situations provided neutrino luminosity supernova known precisely crucially identify degeneracy mixing angle overall neutrino luminosity supernova means possible determine luminosity presence sterile neutrinos î ruled independently discuss ways degeneracy may broken future â© iop publishing ltd sissa medialab
10.1088/1475-7516/2018/09/001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054470005&doi=10.1088%2f1475-7516%2f2018%2f09%2f001&partnerID=40&md5=d95c214d4035292ab45e6939fc7e28a5 0,well known fact galaxies biased tracers distribution matter universe galaxy bias usually factored function redshift scale approximated scale independent large linear scales cosmologies massive neutrinos galaxy bias defined respect total matter field cold dark matter baryons non relativistic neutrinos also depends sum neutrino masses mî½ becomes scale dependent even large scales effect usually neglected given sensitivity current surveys however becomes severe systematic future surveys aiming provide first detection non zero mî½ effect corrected defining bias respect density field cold dark matter baryons rather total matter field work provide simple prescription correctly mitigating neutrino induced scale dependent bias effect practical way clarify number subtleties regarding properly implement correction presence redshift space distortions non linear evolution perturbations perform markov chain monte carlo analysis simulated galaxy clustering data match expected sensitivity euclid survey find neutrino induced scale dependent bias lead important shifts inferred mean value mî½ well uncertainty provide analytical explanation magnitude shifts show shifts propagate inferred values cosmological parameters correlated mî½ cold dark matter physical density î©cdm h scalar spectral index ns conclusion find correctly accounting neutrino induced scale dependent bias crucial importance future galaxy clustering analyses encourage cosmology community correctly account effect using simple prescription present work tools necessary easily correct neutrino induced scale dependent bias made publicly available upcoming release boltzmann solver class â© iop publishing ltd sissa medialab
10.1080/15732479.2017.1402064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035124243&doi=10.1080%2f15732479.2017.1402064&partnerID=40&md5=1de0664775a85512bd7432f0e169c3e9 1,existing performance models developed interurban pavements applicable urban pavements due differences traffic demands deterioration trends objective study develop performance models management urban pavement networks markov chains monte carlo simulation applied account probabilistic nature pavements deterioration time using data collected field one advantages methodology used local agencies scarce technical resources historical data eight performance models developed successfully validated asphalt concrete pavements humid dry mediterranean climates different functional hierarchies resulting models evidence impact design traffic demand climate construction standards urban pavements performance predicted service life asphalt concrete pavements primary networks consistent design standards however pavements secondary local networks present shorter longer service life compared design life respectively climate relevant factor asphalt pavements higher deterioration observed compared expected opposite relevant differences design performance attributed climate concrete pavements â© â© informa uk limited trading taylor francis group
10.1080/03610926.2017.1367814 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032696075&doi=10.1080%2f03610926.2017.1367814&partnerID=40&md5=d10781c9fe2235bcff02409b2326cced 0,literature assuming independence random variables x statistical estimation stressâ€“strength parameter r = p x intensively investigated however real applications strength variable x highly dependent stress variable paper unlike common practice literature discuss estimation parameter r realistically x dependent random variables distributed bivariate rayleigh model derive bayes estimates highest posterior density credible intervals parameters using suitable priors parameters closed forms bayes estimates use approximation based laplace method markov chain monte carlo technique obtain bayes estimate r unknown parameters finally simulation studies conducted order evaluate performances proposed estimators analysis two data sets provided â© â© taylor francis group llc
10.1080/15732479.2017.1418009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039560400&doi=10.1080%2f15732479.2017.1418009&partnerID=40&md5=c8390c8b34e5729acfd650da96029415 0,main purpose study develop estimation procedure seismic design level setting reinforced concrete rc piers considering aftershock induced seismic hazards work develops assessment method seismic hazards induced aftershocks takes example chiâ€“chi earthquake taiwan number aftershocks assumed follow modified gutenbergâ€“richter law lower upper bounds analysing cumulative density function magnitude aftershock within specified post mainshock period earthquake additionally work considers spatial uncertainty hypocentres aftershocks assess aftershock induced seismic hazards fragility curves residual factors damaged rc piers used transition probability matrix markov chain model considering cumulative damage induced aftershocks incorporating uncertainty aftershock events well structural capacity residual factors corresponding specified damage state exceedance probabilities various damage states estimated using markov chain model monte carlo simulation finally case study proposed procedure used determine important factor preliminary seismic design typical rc piers chiâ€“chi earthquake taiwan â© â© informa uk limited trading taylor francis group
10.1109/TSIPN.2017.2756563 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051597888&doi=10.1109%2fTSIPN.2017.2756563&partnerID=40&md5=48bdf8563c6b119d8d24d45c0aca1b8e 0,measurements wireless sensor networks wsns often correlated space time paper focuses tracking multiple targets wsns taking consideration measurement correlations sequential markov chain monte carlo smcmc approach proposed metropolis within gibbs refinement step likelihood gradient proposal introduced smcmc filter applied case studies cellular network received signal strength data shadowing component correlations space time estimated efficiency smcmc approach compared particle filtering well gradient proposal compared basic prior proposal demonstrated numerical simulations accuracy improvement gradient based smcmc using low number particles thanks sequential nature proposed approach applied various wsn applications including traffic mobility monitoring prediction â© ieee
10.1016/j.matcom.2018.03.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046133836&doi=10.1016%2fj.matcom.2018.03.014&partnerID=40&md5=8bc51f6e77b4f8414d314b04fa37c385 0,improved prediction subsurface flows representation uncertainties geostatistical properties use framework bayesian statistical interface combination markov chain monte carlo mcmc method needs many fine scale simulations hence essential apply cheap screening stages coarse scale simulation remove irrelevant proposals generated markov chain reduce fine scale computational cost increase acceptance rate mcmc propose screening step examination subsurface characteristics around injection production wells aiming accurate breakthrough capturing well mentioned efficiency goals however short time simulation needs fine scale structure geological model around wells running fine scale model cheap necessary screening steps hand applying coarse scale model declines important data around wells causes inaccurate results particularly accurate breakthrough capturing important prediction applications therefore propose multi scale grid preserves fine scale model around wells well high permeable regions fractures coarsens rest field keeps efficiency accuracy screening well stage coarse scale simulation well discrete wavelet transform used powerful tool generate desired unstructured multi scale grid efficiently finally accepted proposal coarse scale models screening well stage coarse scale simulation assessed fine scale simulation accepted proposals saved prediction numerical results admit increment acceptance rate improvement breakthrough capturing significant reduction computational cost avoiding many forward simulations â© international association mathematics computers simulation imacs
10.1007/s11222-017-9780-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031117409&doi=10.1007%2fs11222-017-9780-4&partnerID=40&md5=102313459d872b362d9d939fa093197d 0,parallelizable markov chain monte carlo mcmc generates multiple proposals parallelizes evaluations likelihood function different cores mcmc iteration inspired calderhead proc natl acad sci â€“ introduce general â€˜waste recyclingâ€™ framework parallelizable mcmc show using weighted samples waste recycling preferable resampling terms statistical computational efficiencies also provide simple use criteria generalized effective sample size evaluating efficiencies parallelizable mcmc algorithms applies waste recycling vanilla versions moment estimator generalized effective sample size provided shown reasonably accurate simulations â© springer science+business media llc
10.1515/mcma-2018-0018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050857221&doi=10.1515%2fmcma-2018-0018&partnerID=40&md5=63592c7eeb036dcc3ae09321c0f435a8 0,consider problem sampling high dimensional likelihood functions large amounts non identifiabilities via markov chain monte carlo algorithms non identifiabilities problematic commonly used proposal densities leading low effective sample size address problem introduce regularization method using artificial prior restricts non identifiable parts likelihood function enables us sample posterior using common mcmc methods efficiently demonstrate three mcmc methods likelihood based complex high dimensional blood coagulation model single series measurements using approximation artificial prior non identifiable directions obtain sample quality criterion unlike sample quality criteria valid even short chain lengths use criterion compare following three mcmc variants random walk metropolis hastings adaptive metropolis hastings metropolis adjusted langevin algorithm â© walter de gruyter gmbh berlin boston
10.1037/met0000155 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035000253&doi=10.1037%2fmet0000155&partnerID=40&md5=214e88badc526432225f2a0e0eafd10b 0,starts stable trait autoregressive trait state model decomposes individual differences psychological measurement across time sources variation time invariant stable component time varying autoregressive component occasion specific state component previous simulation research applications starts model shown serious estimation problems nonconvergence inadmissible estimates e g negative variances frequently occur starts model parameters article introduces general approach estimating parameters starts model employing bayesian methods use markov chain monte carlo mcmc techniques specification appropriate prior distributions bayesian approach offers advantage model estimates within admissible range possible avoid estimation problems furthermore show bayesian methods used stabilize starts model estimates specifying weakly informative prior distributions model parameters simulation study statistical properties bias root mean square error coverage rate parameter estimates obtained bayesian approach compared maximum likelihood approach data example presented illustrate bayesian approach used estimate starts model finally extensions starts model discussed suggestions applied research made â© american psychological association
10.1007/s00180-017-0759-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027690095&doi=10.1007%2fs00180-017-0759-6&partnerID=40&md5=95fc68974263f87499fdd9cb227df977 0,bayesian analysis multidimensional scaling model mcmc algorithm encounter indeterminacy rotation reflection translation parameter matrix interest type indeterminacy may seen multivariate latent variable models well paper propose address indeterminacy problem novel offline post processing method easily implemented using easy use markov chain monte carlo mcmc software specifically propose post processing method based generalized extended procrustes analysis address problem proposed method compared four existing methods deal indeterminacy thorough analyses artificial well real datasets proposed method achieved least good performance best existing method benefit offline processing approach era easy use mcmc software discussed â© springer verlag gmbh germany
10.1007/s11222-017-9778-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030726080&doi=10.1007%2fs11222-017-9778-y&partnerID=40&md5=284bbf624068b87866c2ab1915004d74 1,integrated nested laplace approximation inla established widely used method approximate inference bayesian hierarchical models represented latent gaussian model lgm inla based producing accurate approximation posterior marginal distributions parameters model quantities interest using repeated approximations intermediate distributions integrals appear computation posterior marginals inla focuses models whose latent effects gaussian markov random field reason explored alternative ways expanding number possible models fitted using inla methodology paper present novel approach combines inla markov chain monte carlo mcmc aim consider wider range models fitted inla parameters model fixed show new values parameters drawn posterior using conditional models fitted inla standard mcmc algorithms metropolisâ€“hastings hence extend use inla fit models expressed conditional lgm also new approach used build simpler mcmc samplers complex models allows sampling limited number parameters model demonstrate approach extend class models benefit inla r inla package ease implementation go simple examples new approach discuss advanced applications datasets taken relevant literature particular inla within mcmc used fit models laplace priors bayesian lasso model imputation missing covariates linear models fitting spatial econometrics models complex nonlinear terms linear predictor classification data mixture models furthermore examples exploit inla within mcmc make joint inference ensemble model parameters â© springer science+business media llc
10.1016/j.envsoft.2018.05.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048199531&doi=10.1016%2fj.envsoft.2018.05.021&partnerID=40&md5=13172a6970e8dd0696b52e58bc04e7a9 0,human interventions optimise river functions often contentious disruptive expensive analyse expected impact intervention implementation decision makers rely computations complex physics based hydraulic models outcome models known sensitive uncertain input parameters long model runtimes render full probabilistic assessment infeasible standard computer resources paper propose alternative efficient method uncertainty quantification impact analysis significantly reduces required number model runs using subsample full monte carlo ensemble establish probabilistic relationship pre post intervention model outcome efficiency method depends number interventions initial monte carlo ensemble size desired level accuracy cases presented computational cost decreased â© elsevier ltd
10.1109/TPWRS.2018.2803044 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041508989&doi=10.1109%2fTPWRS.2018.2803044&partnerID=40&md5=937451885679c8766323729454675b09 0,concept virtual power plant vpp proposed manage distributed renewable energy sources packaging engage energy reserve planning contemporary generating portfolios context efficient tool needed support analysis generating flexibility conventional units combination vpps cooperatively counterbalance fluctuation net demand paper adaptive importance sampling method proposed intentionally efficiently evaluating specific indices capturing possibility severity rare inadequate spinning reserve events deployed unit comment schedule generating system incorporating vpps terms short term stochastic unit failures power fluctuation vpps proposed method based standard cross entropy ce method newly introduces mathematical transformation aiming diverting evaluations customized risk indices generic rare event probability estimation problem markov chain monte carlo method employed train proposal density efficiently gain best owing avoiding iterative parameter updating mechanism standard ce method efficacy proposed method tested modified rts generating system emulating portfolio conventional renewable generating sources modeled vpps â© ieee
10.1016/j.apm.2018.05.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047524319&doi=10.1016%2fj.apm.2018.05.004&partnerID=40&md5=bb15e1bab0f6b826caeabf3bd0f19d8c 0,present work associated bayesian finite element fe model updating using modal measurements based maximizing posterior probability instead sampling based approach bayesian updating framework usually employs normal distribution updating parameters although normal distribution usual statistical issues using non negative parameters issues proposed dealt incorporating lognormal distribution non negative parameters detailed formulations carried model updating uncertainty estimation probabilistic detection changes damages structural parameters using combined normal lognormal probability distribution bayesian framework normal lognormal distributions considered eigen system equation structural mass stiffness parameters respectively two distributions jointly considered likelihood function important advantages fe model updating e g utilization incomplete measured modal data non requirement mode matching also retained combined normal lognormal distribution based proposed fe model updating approach demonstrating efficiency proposed approach two dimensional truss structure considered multiple damage cases satisfactory performances observed model updating subsequent probabilistic estimations however level performances found weakened increasing levels damage scenario usual moreover performances proposed fe model updating approach compared typical normal distribution based updating approach damage cases demonstrating quite similar level performances proposed approach also demonstrates better computational efficiency achieving higher accuracy lesser computation time comparison two prominent markov chain monte carlo mcmc techniques viz metropolis hastings algorithm gibbs sampling â© elsevier inc
10.1002/wics.1435 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051442339&doi=10.1002%2fwics.1435&partnerID=40&md5=d1a49973fe87692a95cf12071408af5b 0,markov chain monte carlo algorithms used simulate complex statistical distributions way local exploration distributions local feature avoids heavy requests understanding nature target also potentially induces lengthy exploration target requirement number simulations grows dimension problem complexity data behind several techniques available toward accelerating convergence monte carlo algorithms either exploration level tempering hamiltonian monte carlo partly deterministic methods exploitation level raoâ€“blackwellization scalable methods article categorized statistical graphical methods data analysis markov chain monte carlo mcmc algorithms computational methods algorithms statistical graphical methods data analysis monte carlo methods â© authors wires computational statistics published wiley periodicals inc
10.1214/17-AOAS1132 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053352791&doi=10.1214%2f17-AOAS1132&partnerID=40&md5=d3ed3448fb96770ee26008aca06b1cf4 0,paper study data discrete labor market transitions austria particular follow careers workers experience job displacement due plant closure observeâ€”over period quartersâ€” whether workers manage return steady career path analyse discrete valued panel data apply new method bayesian markov chain clustering analysis based inhomogeneous first order markov transition processes time varying transition matrices addition mixture experts approach allows us model probability belonging certain cluster depending set covariates via multinomial logit model cluster analysis identifies five career patterns plant closure reveals workers cope quite easily job loss whereas others suffer large losses extended periods time â© institute mathematical statistics
10.1016/j.jmbbm.2018.05.037 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048805088&doi=10.1016%2fj.jmbbm.2018.05.037&partnerID=40&md5=23eabe1a6ee88f5ecea22e837265de91 0,results study comparing model calibration techniques ogden constitutive model describes hyperelastic behavior brain tissue presented one two term ogden models fit two different sets stress strain experimental data brain tissue using least squares optimization bayesian estimation bayesian estimation joint posterior distribution constitutive parameters calculated employing hamiltonian monte carlo hmc sampling type markov chain monte carlo method hmc method enriched work intrinsically enforce drucker stability criterion formulating nonlinear parameter constraint function ensures constitutive model produces physically meaningful results application nested sampling technique confidence bounds constitutive model parameters identified bounds propagated constitutive model produce resultant bounds stress strain response behavior model calibration procedures effect characteristics experimental data extensively evaluated demonstrated increasing model complexity e adding additional term ogden model improves accuracy best fit set parameters also increasing uncertainty via widening confidence bounds calibrated parameters despite similarity two data sets resulting distributions noticeably different highlighting sensitivity calibration procedures characteristics data example amount uncertainty reported experimental data plays essential role data points weighted calibration significantly affects parameters calibrated combining experimental data sets disparate sources â©
10.1016/j.jconhyd.2018.08.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052886023&doi=10.1016%2fj.jconhyd.2018.08.005&partnerID=40&md5=6ee26fd95d3cde70f07fe32182e6d4c8 0,groundwater reactive transport models consider coupling hydraulic biochemical processes vital tools predicting fate groundwater contaminants effective groundwater management models involve large number parameters whose specification greatly affects model performance thus model parameters calibration crucial successful application bayesian inference framework implemented markov chain monte carlo mcmc sampling provides comprehensive framework estimate model parameters however application hampered large computational requirements caused repeated evaluations model mcmc sampling study develops adaptive kriging based mcmc method overcome bottleneck bayesian inference replacing simulation model computationally inexpensive kriging surrogate model adaptive kriging based mcmc method instead constructing globally accurate surrogate simulation model sequentially build locally accurate surrogate iterative refinement high probability regions performance proposed method demonstrated using synthetic groundwater reactive transport model describing sequential kinetic degradation tetrachloroethene pce whose hydraulic biochemical parameters jointly estimated results suggest adaptive kriging based mcmc method able achieve accurate bayesian inference hundredfold reduction computational cost compared conventional mcmc method â©
10.3390/a11090142 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053777536&doi=10.3390%2fa11090142&partnerID=40&md5=338fa293ae7402f733aca6bdd83f5685 0,satisfiability modulo theories smt problem decide satisfiability logical formula respect given background theory work studies counting version smt respect linear integer arithmetic lia termed smt lia specifically purpose paper count number solutions volume smt lia formula many important applications computationally hard solve counting problem approximate method employs recent markov chain monte carlo mcmc sampling strategy called flat histogram proposed furthermore two refinement strategies proposed sampling process result two algorithms mcmc flat mcmc flat respectively mcmc flat pseudo sampling strategy introduced evaluate flatness histograms experimental results show mcmc flat method achieve good accuracy structured random instances mcmc flat scalable instances convex bodies variables â© authors
10.1016/j.matcom.2018.04.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046151927&doi=10.1016%2fj.matcom.2018.04.001&partnerID=40&md5=ab9a6c1afe18edc62724c9bb1baf103f 0,mathematical model heatâ€“moisture transfer within textiles corresponding inverse problem textile material design iptmd reformulated stability theorem forward problem given show wellposedness heatâ€“moisture transfer model bayesian inference approach presented solve iptmd based thermal comfort clothing triple parameters thickness thermal conductivity porosity textiles simultaneously determined sense statistical point estimation likelihood function bayesian techniques based markov chain monte carlo mcmc methods employed simultaneously determine three parameters iptmd metropolisâ€“hastings algorithm applied inversion process interpolated likelihood function reduces significantly computational cost associated implementation mcmc method without loss accuracy parameters estimation numerical experiments confirm bayesian inference method provide accurate solutions iptmd â© international association mathematics computers simulation imacs
10.1016/j.astropartphys.2018.04.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045421562&doi=10.1016%2fj.astropartphys.2018.04.002&partnerID=40&md5=10a8806f60bf133292e82f43233e5536 0,present flavor energy inference analysis going high energy astrophysical neutrino event observed icecube observatory six years data taking goal obtain first time estimate posterior probability distribution relevant properties neutrino energy flavor neutrino nucleon interactions producing shower track events icecube detector event main observables icecube detector deposited energy event topology showers tracks produced cherenkov light transit medium charged particles created neutrino interactions crucial reconstruct observables properties neutrino generated event describe achieve goal using bayesian inference markov chain monte carlo methods â© elsevier b v
10.1007/s12205-017-1727-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039839142&doi=10.1007%2fs12205-017-1727-y&partnerID=40&md5=f584cb47cbabd5148377514fcd4400af 0,traffic monitoring particularly maximum vehicle load important predicting remaining service time either long span short medium span bridges using weigh motion wim data nanxi yangtze river bridge novel maximum load estimation model vehicle load constructed novel model based extended burr xii eburr distribution includes weibull generalized pareto gpd log logistic distributions thus traditional gpd model special form proposed novel model correlation vehicle load extracted using peak threshold method markov chain monte carlo bayesian method applied estimate parameters proposed novel model compared traditional models th percentile load distribution considered evaluation point overloaded trucks addition vehicle loads collected highway station used verify novel modelâ€™s applicability results show eburr distribution suitable capture sparse extreme points traditional distributions according value sse closely r closely assessment reference period changes years deceased ration evaluation load weight eburr gpd nanxi yangtze river bridge eburr gpd bridge near la linhe highway station deceased ration evaluation load weight using eburr larger using gpd moreover deceased ration evaluation load weight using gpd la linhe highway station little change hence using eburr distribution model evaluation load correspond fact â© korean society civil engineers
10.1109/TCSVT.2017.2727963 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028875742&doi=10.1109%2fTCSVT.2017.2727963&partnerID=40&md5=74b2bb0c2ff08ae37e74816e79a6ad1a 0,semantic analysis activities events videos important capture spatio temporal relation among objects space paper present probabilistic method extracts trajectories objects videos captured monocular moving camera compared existing methods rely restrictive assumptions propose method extract trajectories much less restriction adopting new example based techniques compensate lack information estimate focal length camera based similar candidates use compute depths detected objects contrary trajectory extraction methods method able process videos taken stable camera well non calibrated moving camera without restrictions modify reversible jump markov chain monte carlo particle filtering suitable camera odometry without relying geometrical feature points moreover method decreases time consumption reducing number object detections keypoint matching finally evaluate method known data sets showing robustness system demonstrating efficiency dealing different kind videos â© ieee
10.1175/MWR-D-17-0366.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053609370&doi=10.1175%2fMWR-D-17-0366.1&partnerID=40&md5=68afbf48fb9ec0d0cba64c04e8c76673 0,probabilistic forecasting method predict thunderstorms european eastern alps developed statistical model links lightning occurrence ground based austrian lightning detection information system aldis detection network large set direct derived variables numerical weather prediction nwp system nwp system high resolution run hres european centre medium range weather forecasts ecmwf grid spacing km statistical model generalized additive model gam framework estimated markov chain monte carlo mcmc simulation gradient boosting stability selection serves tool selecting stable set potentially nonlinear terms three grids ã— ã— km five forecast horizons days day ahead investigated predict thunderstorms afternoons utc frequently selected covariates nonlinear terms variants convective precipitation convective potential available energy relative humidity temperature midlayers troposphere among others models even lead time days outperform forecast based climatology sample comparison example case illustrates coarse spatial patterns already successfully forecast days ahead â© american meteorological society
10.3390/rs10091400 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053633426&doi=10.3390%2frs10091400&partnerID=40&md5=2b8d13518db0cb9d9b972736d9599953 0,seismogenic fault geometry especially blind fault usually difficult derive based distribution aftershocks interference fringes interferometric synthetic aperture radar insar better constrain fault geometry jiuzhaigou mw earthquake first carried nonlinear inversion single fault source using multi peak particle swarm optimization mpso monte carlo mc markov chain monte carlo mcmc algorithms respectively constraints insar data multiple sar viewing geometries fault geometry models retrieved different methods highly consistent mutually verifiable showing blind faulting strike â° dip angle â° responsible jiuzhaigou earthquake based optimal fault geometry model fault slip distribution jointly inverted insar global positioning system gps data steepest descent method sdm mc method showed slip mainly concentrated depth km one slip center appeared depth km maximum slip different previous studies taking shear modulus î¼ = gpa seismic moment derived distributed slip model ã— nm equivalent mw slightly larger focal mechanism solutions fault spatial geometry slip distribution validated spatial patterns immediate aftershocks fault aftershocks magnitude gt within one year mainshock occurred stress positive stress change area coincided stress triggering theory static coulomb stress triggered mainshock significantly increased tazang fault northwest epicenter hidden north huya fault partial segments minjiang fault west epicenter â© authors
10.1177/0265813516688688 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041550024&doi=10.1177%2f0265813516688688&partnerID=40&md5=8a7c425f43cd4c4bbd78f3dbb1955f58 0,paper discusses project completion database socio economic indicators across european union years onward various spatial scales thus database consists various time series spatial component substantial amount data missing method imputation required complete database markov chain monte carlo approach opted describe markov chain monte carlo method detail furthermore explain achieved spatial coherence different time series observed estimated data points â© author
10.1016/j.buildenv.2018.06.045 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048999694&doi=10.1016%2fj.buildenv.2018.06.045&partnerID=40&md5=8b54cb03bfb1013d55a03cdcbeaac577 0,concept known â€˜nudgeâ€™ recently received attention many application domains implies influencing behavior decision making individuals making indirect suggestions presentation adequate information apply perspective improve value space measured number visitors predicted thermal sensation considered information offered potential visitors present study explain generate information required successful nudge information must specifically tailored towards personalized characteristics rather one fits approach study presents new data driven method predicting individuals thermal sensation formulating effect measured thermal non measured factors thermal sensation votes proposed model explicitly encoded based major premise â€œdifferent individuals different thermal sensation characteristics however individuals also common trend â€� inference model uses bayesian approach hierarchically structured represent dependencies across model parameters personalized characteristics individual level typical trend group level thermal sensations markov chain monte carlo approach used approximate posterior distribution draw inferences model parameters results based data collected outdoor spaces show proposed model provides accurate predictions personalized thermal sensation improves efficiency parameter estimates approach provides fresh insight statistical models predicting thermal sensation â© authors
10.1007/s10687-018-0330-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048681260&doi=10.1007%2fs10687-018-0330-z&partnerID=40&md5=9a7674004e86f61799697d6fb6717cae 1,paper concerns approach eva challenge aim predict extreme precipitation quantiles across several sites netherlands approach uses bayesian hierarchical structure combines gamma generalised pareto distributions impose spatio temporal structure model parameters via autoregressive prior estimates obtained using markov chain monte carlo techniques spatial interpolation approach successful context challenge providing reasonable improvements benchmark â© springer science+business media llc part springer nature
10.1111/anzs.12241 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052814743&doi=10.1111%2fanzs.12241&partnerID=40&md5=201df678a4f111dea75a5aefe500ffe3 0,demonstrate use r package gammslice bayesian fitting inference generalised additive mixed model analysis class models includes generalised linear mixed models generalised additive models special cases accurate bayesian inference achievable via sufficiently large markov chain monte carlo mcmc samples slice sampling key component mcmc scheme comparisons existing generalised additive mixed model software shows gammslice offers improved inferential accuracy albeit cost longer computational time â© australian statistical publishing association inc published john wiley sons australia pty ltd
10.1111/rssb.12269 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042587941&doi=10.1111%2frssb.12269&partnerID=40&md5=c0da2873f775845b886003c59560803a 0,introduce new family markov chain monte carlo samplers combine auxiliary variables gibbs sampling taylor expansions target density approach permits marginalization auxiliary variables yielding marginal samplers augmentation auxiliary variables yielding auxiliary samplers well known metropolis adjusted langevin algorithm mala preconditioned crankâ€“nicolsonâ€“langevin algorithm pcnl shown special cases prove marginal samplers superior terms asymptotic variance demonstrate cases slower computing time compared auxiliary samplers context latent gaussian models propose new auxiliary marginal samplers whose implementation requires single tuning parameter found automatically transient phase extensive experimentation shows increase efficiency measured effective sample size per unit computing time relative optimized implementations pcnl elliptical slice sampling mala ranges tenfold binary classification problems fold log gaussian cox processes fold gaussian process regression par riemann manifold hamiltonian monte carlo sampling example algorithm complexity aforementioned algorithms explain remarkable improvement terms way alternative samplers try approximate eigenvalues target introduce novel markov chain monte carlo sampling scheme hyperparameter learning builds auxiliary samplers matlab code reproducing experiments paper publicly available line supplement paper contains additional experiments implementation details â© royal statistical society
10.1007/s40995-016-0124-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051107074&doi=10.1007%2fs40995-016-0124-6&partnerID=40&md5=d2168fa3ec86bb15b0ad96347013ac4b 0,study deals analysis type ii hybrid censored data modified weibull distribution provide maximum likelihood estimates parameters reliability hazard rate functions along standard errors confidence intervals along widths also obtained assuming gamma jeffreyâ€™s invariant priors unknown parameters bayes estimates along posterior errors highest posterior density credible intervals obtained markov chain monte carlo technique used simulate draws complicated posterior densities parameters simulation study conducted compare performances classical bayesian methods estimation finally real data analysis performed illustrative purpose â© shiraz university
10.1111/1365-2435.13180 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050389546&doi=10.1111%2f1365-2435.13180&partnerID=40&md5=d46e175d1a7a6c430cd799432eeab565 0,characterising spatiotemporal variation animal behaviour elucidate way individuals interact environment allocate energy increasing sophistication tracking technologies paired novel analytical approaches allows characterisation movement dynamics even individual directly observable study high resolution movement data collected via global positioning system gps tracking three dimensions paired topographical information used bayesian state space model describe flight modes migrating golden eagles aquila chrysaetos eastern north america model identified five functional behavioural states two previously undescribed variations thermal soaring states comprised gliding perching orographic soaring states discriminated movement features horizontal step length turning angle vertical change altitude planes association ridgelines promoting wind deflection tracked eagles spent daytime directed thermal soaring gliding convoluted thermal soaring perching orographic soaring respectively analysis relative occurrence flight modes highlighted yearly seasonal age individual sex differences flight strategy performance particularly less energy efficient orographic soaring frequent autumn thermals less available adult birds also better optimising energy efficiency subadults approach represents first example state space model bird flight mode using altitude data conjunction horizontal locations applicable flying organisms similar data available ability describe animal movements three dimensional habitat critical advance understanding functional processes driving animalsâ€™ decisions plain language summary available article â© authors functional ecology â© british ecological society
10.1214/17-AOAS1129 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053334214&doi=10.1214%2f17-AOAS1129&partnerID=40&md5=1509a700574bcdd4675258971fbceb8f 1,gene expression largely controlled transcription factors tfs collaborative manner therefore understanding tf collaboration crucial elucidation gene regulation co activation tfs represented networks networks dynamic diverse biological conditions heterogeneous across genome within biological condition existing methods construction tf networks lack solid statistical models analyze biological condition separately enforce single network genomic locations within one biological condition resulting low statistical power misleading spurious associations paper present novel bayesian nonparametric dynamic poisson graphical model inference tf networks approach automatically teases genome heterogeneity borrows information across conditions improve signal detection replicates thus offering valid efficient measure tf co activations develop efficient parallel markov chain monte carlo algorithm posterior computation proposed approach applied study tf associations encode cell lines provides novel findings â© institute mathematical statistics
10.7845/kjm.2018.8044 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054685305&doi=10.7845%2fkjm.2018.8044&partnerID=40&md5=8e98fa94fd084e65758130dd77ed7b0e 0,avian influenza recently damaged poultry industry suffered huge economic loss reaching billions u dollars south korea transmission routes pathogens help plan control limit spread devastating biological tragedy phylogenetic analyses pathogen dna sequences sketch transmission trees relating hosts directed edges last decade seen methodological development inferring transmission trees using epidemiological well genetic data reanalyzed dna sequence data originated highly pathogenic avian influenza h n outbreak south korea h n viruses spread geographically contiguously origin outbreak jeonbuk jeonbuk origin viruses known spread four provinces neighboring jeonbuk estimated transmission tree host domestic migratory wild birds combining multiple runs markov chain monte carlo using bayesian method inferring transmission trees estimated transmission tree albeit rather large uncertainty directed edges showed viruses spread jeonbuk chungnam gyeonggi domestic birds breeder broiler ducks estimated appear terminal nodes transmission tree observation confirmed migratory wild birds played important role one main infection mediators avian influenza h n outbreak south korea â© microbiological society korea ìµœê·¼ ì–‘ê³„ì—…ì—� ë§‰ëœ€í•œ í”¼í•´ë¥¼ ë�¼ì¹˜ëš” ì¡°ë¥˜ë�…ê°�ì�€ í•œêµ­ì—�ì„œ ìˆ˜ì²œì–µì›�ì�˜ ê±°ëœ€í•œ ê²½ì œì � ì†�ì‹¤ì�„ ì´ˆëž˜í•˜ì˜€ë‹¤ ë³‘ì›�ê· ì�˜ ì „ì—¼ ê²½ë¡œë¥¼ íœœì•…í• ìˆ˜ ìžˆë‹¤ë©´ ë§‰ëœ€í•œ ì†�í•´ë¥¼ ë�¼ì¹˜ëš” ìƒ�ë¬¼í•™ì � í”¼ í•´ì�˜ í™•ì‚°ì�„ ë§‰ê³ ì�¼ë¶€ ì§€ì—­ìœ¼ë¡œ ì œí•œí•˜ëš”ë�° í�° ë�„ì›€ì�´ ë� ê²ƒ ì�´ë‹¤ ë³‘ì›�ê· dna ì„œì—´ì�˜ ê³„í†µí•™ì �ì� ë¶„ì„�ì�„ í†µí•˜ì—¬ ê°�ì—¼ë�œ ìˆ™ì ¼ë“¤ì�„ ë°©í–¥ì„±ì�´ ìžˆëš” ì—°ê²°ì„ ìœ¼ë¡œ ì—°ê´€ì§“ëš” ì „ì—¼ ê³„í†µìˆ˜ë¥¼ ì–»ì�„ ìˆ˜ ìžˆë‹¤ ì§€ë‚œ ì—¬ë…„ê°„ ìœ ì „ì � ë�°ì�´í„°ë¿�ë§œ ì•„ë‹ˆë�¼ ì—­í•™ ë�°ì�´í„°ë¥¼ ì�´ìš©í•œ ì „ì—¼ ê³„í†µìˆ˜ ì¶”ë¡ ì�˜ ë°©ë²•ë¡ ì � ë°œì „ì�´ ì�´ë ¨ì–´ ì¡œë‹¤ ì�´ì—� ë³ ì—°êµ¬ì—�ì„œëš” ì „ì—¼ ê³„í†µìˆ˜ ì¶”ë¡ ë°©ë²•ì�„ ì�´ìš©í•˜ì—¬ ì§€ë‚œ ë…„ í•œêµ­ì—� ë°œë³‘í•œ ê³ ë³‘ì›�ì„± ì¡°ë¥˜ë�…ê°� h n ì—�ì„œ ìœ ëž˜í•œ dna ì„œì—´ì�„ ìž¬ë¶„ì„�í•˜ì˜€ë‹¤ ë‹¹ì‹œ h n ë°”ì�´ëÿ¬ìš¤ëš” ì „ ë�¼ë¶�ë�„ì—�ì„œ ì‹œìž‘í•˜ì—¬ ì§€ì—­ì �ìœ¼ë¡œ ì ‘í•´ìžˆëš” ê°œì�˜ ì§€ì—­ìœ¼ë¡œ í™•ì‚°ë�˜ì–´ ë‚˜ê°”ë�˜ ê²ƒìœ¼ë¡œ ì•œë ¤ì ìžˆë‹¤ ì „ì—¼ ê³„í†µìˆ˜ë¥¼ ì¶”ë¡ í•˜ ëš” ë² ì�´ì§€ì– í†µê³„ ë°©ë²•ì� markov chain monte carloë¥¼ ë°˜ë³µì � ìœ¼ë¡œ ì‹œí–‰í•˜ê³ ì�´ë¥¼ ì¢…í•©í•˜ì—¬ ì² ìƒˆ ì™ ëž˜ì¢…ê³¼ êµ­ë‚´ì¢… ì¡°ë¥˜ ìˆ™ ì ¼ë“¤ì�˜ ì „ì—¼ ê³„í†µìˆ˜ë¥¼ ì¶”ì •í•˜ì˜€ë‹¤ ë¹„ë¡� ì—°ê²°ì„ ì�˜ ë¶ˆí™•ì‹¤ì„±ì�€ ë†’ì•˜ìœ¼ë‚˜ ì¶”ì •ë�œ ì „ì—¼ ê³„í†µìˆ˜ë¥¼ í†µí•˜ì—¬ ë‹¹ì‹œ h n ë°”ì�´ëÿ¬ìš¤ ëš” ì „ë�¼ë¶�ë�„ì—�ì„œ ì‹œìž‘í•˜ê³ ì¶©ì²­ë‚¨ë�„ë¥¼ ê±°ì³� ê²½ê °ë�„ë¡œ í�¼ì ë‚˜ ê°„ ê²ƒì�„ í™•ì� í• ìˆ˜ ìžˆì—ˆë‹¤ ì‚¬ìœ¡í•˜ëš” ì˜¤ë¦¬ì™€ ê°™ì�€ êµ­ë‚´ì¢… ì¡°ë¥˜ ëš” ì „ì—¼ ê³„í†µìˆ˜ì�˜ ë§�ë‹¨ ë… ë“œì—� ìœ„ì¹˜í•˜ëš” ê²ƒìœ¼ë¡œ ì¶”ì •ë�˜ì—ˆë‹¤ ì�´ëÿ¬í•œ ê²°ê³¼ë¥¼ í†µí•˜ì—¬ ì•¼ìƒ� ì² ìƒˆì¢…ì�´ ë…„ í•œêµ­ì�˜ h n ì¡° ë¥˜ë�…ê°�ì�˜ ê°�ì—¼ ë§¤ê°œìž�ë¡œ ì ¼ë�œ ì—­í• ì�„ í•˜ì˜€ë‹¤ëš” ê²ƒì�„ ìž¬í™•ì� í•˜ ì˜€ë‹¤
10.1002/gepi.22133 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052931521&doi=10.1002%2fgepi.22133&partnerID=40&md5=cbc001b95470abdd1d9f7dfaaf660234 0,multipoint linkage analysis important approach localizing disease associated loci pedigrees linkage analysis however sensitive misspecification marker allele frequencies pedigrees recently admixed populations particularly susceptible problem challenge accurately accounting population structure therefore increasing emphasis use multiethnic samples genetic studies requires reevaluation best practices given data currently available typical strategies compute allele frequencies sample use marker allele frequencies determined admixture proportions averaged entire sample however admixture proportions vary among pedigrees throughout genome family specific manner evaluate several approaches model admixture linkage analysis providing different levels detail ancestral origin perform evaluations specification marker allele frequencies used data caribbean hispanic admixed families alzheimer disease sequencing project results show choice admixture model effect linkage analysis results variant specific admixture proportions computed individual families provide detailed regional admixture estimates appropriate allele frequencies linkage analysis likely decreases number false positive results straightforward implement â© wiley periodicals inc
10.1111/sjos.12312 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042183382&doi=10.1111%2fsjos.12312&partnerID=40&md5=581b0aed6fdab8d5569f79d6a5e17c98 1,bayesian hierarchical formulations utilized u bureau labor statistics bls respondent level data missing item imputation formulations readily parameterized capture correlation structures bls collects survey data informative sampling designs assign probabilities inclusion correlated response sampling weighted pseudo posterior distributions estimated asymptotically unbiased inference population model parameters computation expensive support bls production schedules propose new method scale computation divides data smaller subsets estimates sampling weighted pseudo posterior distribution parallel every subset combines pseudo posterior parameter samples subsets mean wasserstein space order construct conditions class sampling designs posterior consistency proposed method achieved demonstrate synthetic data application current employment statistics survey method produces results similar accuracy usual approach offering substantially faster computation published article u government work public domain usa
10.1214/18-AOAS1139 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053347780&doi=10.1214%2f18-AOAS1139&partnerID=40&md5=c9842d19bb57d41e9a69f81477efeab3 1,randomized response technique rrt classical effective method used mitigate distortion arising dishonest answers traditional rrt usually focuses case single sensitive attribute discussion case multiple sensitive attributes limited study business case identify individual organizational determinants driving information systems resource misuse workplace people actually engage resource misuse probably willing provide honest answers given sensitivity topic yet develop causal relationship resource misuse determinants version rrt multivariate analysis required implement rrt multiple sensitive attributes propose bayesian approach estimating covariance matrices incomplete information sulting randomization procedure rrt case proposed approach accommodates positive definite condition intrinsic parameter constraints posterior improve statistical precision ii incorporates bayesian shrinkage estimation covariance matrices despite incomplete information iii adopts quasi likelihood method achieve bayesian semiparametric inference enhancing flexibility show effectiveness proposed method simulation study also apply bayesian rrt method structural equation modeling identify causal relationship resource misuse determinants â© institute mathematical statistics
10.1007/s11336-017-9594-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034215692&doi=10.1007%2fs11336-017-9594-5&partnerID=40&md5=3172c076cf16db538d58f720d82e69ba 0,piecewise growth mixture models flexible useful class methods analyzing segmented trends individual growth trajectory time individuals come mixture two latent classes models allow segment overall developmental process within class different functional form examples include two linear phases growth quadratic phase followed linear phase changepoint knot time transition one developmental phase segment another inferring location changepoint often practical interest along inference model parameters random changepoint allows individual differences transition time within class primary objectives study follows develop pgmm using bayesian inference approach allows estimation multiple random changepoints within class develop procedure empirically detect number random changepoints within class empirically investigate bias precision estimation model parameters including random changepoints via simulation study developed user friendly package bayesianpgmm r facilitate adoption methodology practice available https github com lockef bayesianpgmm describe application mouse tracking data visual recognition task â© psychometric society
10.1214/17-AOAS1123 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053344866&doi=10.1214%2f17-AOAS1123&partnerID=40&md5=d0812ea52c9feba86e50f92db10f4162 1,tumors heterogeneous tumor sample usually consists set subclones distinct transcriptional profiles potentially different degrees aggressiveness responses drugs understanding tumor heterogeneity therefore critical precise cancer prognosis treatment paper introduce baycountâ€”a bayesian decomposition method infer tumor heterogeneity highly dispersed rna sequencing count data using negative binomial factor analysis baycount takes account sample gene specific random effects raw counts sequencing reads mapped gene posterior inference develop efficient compound poisson based blocked gibbs sampler simulation studies show baycount able accurately estimate subclonal inference including number subclones proportions subclones tumor sample gene expression profiles subclone real world data examples apply baycount cancer genome atlas lung cancer kidney cancer rna sequencing count data obtain biologically interpretable results method represents first effort characterizing tumor heterogeneity using rna sequencing count data simultaneously removes need normalizing counts achieves statistical robustness obtains biologically clinically meaningful insights r package baycount implementing model algorithm available download â© institute mathematical statistics
10.1016/j.insmatheco.2018.06.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049729846&doi=10.1016%2fj.insmatheco.2018.06.010&partnerID=40&md5=e28d9c4784fffaa6e65a9a6005921975 0,presence systematic risk mortality forecasts known longevity risk called introduction longevity instruments market development management longevity risk ongoing issue insurance companies pension funds offer products payout depending lifetime policyholders one major difficulties pricing longevity instruments determination longevity risk premium problem arises fact longevity market illiquid considered incomplete paper provide insight study several pricing approaches longevity instruments proposed literature account parameter uncertainty mortality forecasts longevity instruments pricing analysis hinges bayesian state space mortality model sampling based bayesian approach allows us obtain distribution longevity risk premium thus providing alternative perspective analyzing pricing methods also discussed advantages disadvantages considered pricing approaches â© elsevier b v
10.1016/j.jneumeth.2018.04.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049610929&doi=10.1016%2fj.jneumeth.2018.04.006&partnerID=40&md5=6b8bb25efbc4e042f91d71cfd96a3ee0 0,background study learning populations subjects provide insights changes occur brain aging drug intervention psychiatric disease new method introduce separable two dimensional random field rf model analyzing binary response data acquired learning object reward associations across multiple days method quantify variability performance within day across days capture abrupt changes learning results apply method data young aged macaque monkeys performing reversal learning task method provides estimate performance within day age group learning rate across days monkey find group older monkeys require trials learn object discriminations young monkeys cognitive flexibility younger group higher also use model estimates performance features clustering monkeys two groups clustering results two groups part coincide formed age groups simulation studies suggest clustering captures inter individual differences performance levels comparison existing method comparison generalized linear models method better able capture inherent two dimensional nature data find group differences conclusions applied binary response data groups individuals performing multi day behavioral experiments model discriminates group differences identifies subgroups â© authors
10.1016/j.resconrec.2018.04.026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046996755&doi=10.1016%2fj.resconrec.2018.04.026&partnerID=40&md5=9a91a607fce78ef49303e067371cac75 0,apart technical improvements inducing green citizen behavior also key way reduce carbon emissions various studies tried identify determinants green behavior hitherto lacks quantitative analysis directed effects factor outbreak green behavior final adopted fraction fill gap paper propose heterogeneous green behavior spreading hgbs model explore impacts negative information diffusion green behavior effects spreading green behavior simulations performed top two layer multiplex networks individuals involved two processes information diffusion information layer green behavior spreading physical contact layer based microscopic markov chain approach mmca monte carlo mc simulations find slight impact information layer make green behavior harder break reduce adopted fraction moreover diversity information diffusion ways makes worse suggests control negative information diffusion helpful contributing low carbon city another effective way encourage individuals neighbours real world behave pro environmentally since adopted fraction increased small degree individuals physical contact layer essential consider heterogeneity spreading activity one wants model green behavior spreading â© elsevier b v
10.1002/wics.1438 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051429298&doi=10.1002%2fwics.1438&partnerID=40&md5=43f55b175c1c968d9bac426ca857b47c 0,paper present overview state art kalman filtering dynamic bayesian linear nonlinear models present basic results including derivation kalman filtering equations well recent advances kalman filter models extensions including non gaussian state space models take bayesian perspective discuss parameter learning state space models typically involves markov chain monte carlo sequential monte carlo methods present particle filtering bayesian particle learning techniques state space models discuss recent advances article categorized applications computational statistics signal image processing coding statistical models bayesian models statistical models time series models statistical graphical methods data analysis markov chain monte carlo mcmc â© wiley periodicals inc
10.1061/JPEODX.0000055 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047721312&doi=10.1061%2fJPEODX.0000055&partnerID=40&md5=0867bad67019cb7351766f08ad61e67b 0,study applied markov chain mc model uses transition matrix transmit probability monitored pavement markings one service life state changing another service life state time interval service life prediction mc models compared linear models testing clear advantages using one model terms predicting longevity marking retroreflectivity retroreflectivity data collected monitoring coefficient dry retroreflective luminance years using handheld retroreflectometer using mc model study found pavement marking retroreflectivity pmr degradation follows exponential curve trend whereby degradation rates decrease time increases significant differences found deterioration markings based colors white yellow line type center lane line edge line white thermoplastic edge lines two lane roadways found better performance low deterioration rates compared lines four lane highways based transition probability matrix tpm observed retroreflectivity excellent good state short period time probability fair poor state longer time probability suggesting trend higher degradation rate beginning lower rate near failure state keeping minimum failure states mcd=m =lx white yellow markings respectively service life white markings found approximately years months found years months yellow markings mc model findings compared obtained linear regression showed white thermoplastic pavement markings take approximately years months deteriorate failure state level yellow thermoplastics take years months study concluded clear difference prediction using mc models compared linear models withmcmodels cost effective terms maintenance replacement scheduling due longer life prediction â© american society civil engineers
10.1785/0220180074 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052601419&doi=10.1785%2f0220180074&partnerID=40&md5=55240001ef9b49d039d24d3575072e9e 1,albuquerque belen socorro basins reside central rio grande rift partially overlie midcrustal socorro magma body smb inflation contributes ongoing seismicity localized uplift region rayleigh wave dispersion measurements extracted ambient noise cross correlation seismic data collected âˆ¼ station sevilleta seismic array southern albuquerque northern socorro basins inverted obtain rayleigh wave phasevelocity maps tomography results indicate large â± lateral variations rayleigh wave phase velocities period range rayleigh wave velocities inverted utilizing nonlinear monte carlo markov chain method obtain wave velocity uppermost km crust shallow depths km wave velocity models show lowvelocity km=s anomalies rio grande rift axis mainly due cenozoic rift sediments relatively higher km=s velocities local mountain ranges due older volcanic rocks kmdepth relationship inverted higher wave velocities km=s generally present beneath rift axis beneath surrounding ranges suggest elevated wave velocities km=s related large km km granitic pluton found sediment cover consortium continental reflection profiling cocorp reflection profiles abo pass survey line low wave velocities related structural changes moderate high grade metamorphism midcrustal rocks upper crustal extension ongoing uplift northern part midcrustal smb copyright â© geo science world
10.1016/j.bspc.2018.07.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049988398&doi=10.1016%2fj.bspc.2018.07.001&partnerID=40&md5=393e2a704ddd6701cf8d9cb2221f54cc 0,present quantitative study performance two automatic methods early detection ovarian cancer exploit longitudinal measurements multiple biomarkers study carried subset data collected uk collaborative trial ovarian cancer screening ukctocs use statistical analysis techniques area receiver operating characteristic roc curve evaluating performance two techniques aim classification subjects either healthy suffering disease using time series multiple biomarkers inputs first method relies bayesian hierarchical model establishes connections within set clinically interpretable parameters second technique purely discriminative method employs recurrent neural network rnn binary classification inputs available dataset performance two detection schemes similar area roc curve combination three biomarkers bayesian approach advantage outputs parameters estimates uncertainty analysed clinical expert â©
10.1007/s10559-018-0072-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053832410&doi=10.1007%2fs10559-018-0072-6&partnerID=40&md5=13b98dd8dcc29e23f25bb5a57c35056d 0,paper considers model network nodes one server queueing systems non stationary poisson flows traffic flows input flows queueing systems statistical simulation algorithm proposed identifies weak points network allows formulating heuristic flow control algorithm reduces total waiting time algorithm illustrated example flow network intersections â© springer science+business media llc part springer nature
10.1007/s00181-017-1278-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021754101&doi=10.1007%2fs00181-017-1278-6&partnerID=40&md5=6777bbb32c3412825e96c89db74a5651 0,paper proposes latent dynamic factor model high dimensional realized covariance matrices stock returns approach based matrix logarithm combines common latent factors driven har processes idiosyncratic autoregressive dynamics model accounts positive definiteness covariance matrices without imposing parametric restrictions simulated bayesian parameter estimates obtained using basic markov chain monte carlo methods empirical application dimensional dimensional realized covariance matrices shows remarkably good forecasting results sample sample â© springer verlag gmbh germany
10.1016/j.cognition.2018.04.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048716477&doi=10.1016%2fj.cognition.2018.04.017&partnerID=40&md5=6fb86d26fb4d301cd5e6e9a889adff98 0,bayesian models cognition assume people compute probability distributions hypotheses however required computations frequently intractable prohibitively expensive since people often encounter many closely related distributions selective reuse computations amortized inference computationally efficient use brain limited resources present three experiments provide evidence amortization human probabilistic reasoning sequentially answering two related queries natural scenes participantsâ€™ responses second query systematically depend structure first query influence sensitive content queries appearing queries related using cognitive load manipulation find evidence people amortize summary statistics previous inferences rather storing entire distribution findings support view brain trades accuracy computational cost make efficient use limited cognitive resources approximate probabilistic inference â© elsevier b v
10.1109/TCST.2017.2723877 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028944370&doi=10.1109%2fTCST.2017.2723877&partnerID=40&md5=185a6be5de9488e9c6ef4617fe45fa16 0,wireless networked control systems wncss control loops closed wireless network prevailing days however due uncertainties random accessing delays possible packet drops stability analysis wncs challenging task previous studies communication network analysis either relied monte carlo simulation followed multistate markov chain framework paper main contribution propose formal method based stability analysis communication system modeled probabilistic timed automaton underlying communication protocol analyzed probabilistic model checking particular stability condition wncs expressed probabilistic temporal logic formula quality service requirement checked satisfaction specification equivalent stability guarantee wncs study impact different media access control mac parameters satisfaction specification furthermore specification satisfied initially propose systematic way tune mac parameters redesign controller specification met paper presents attempt new angle communication control system codesign problem â© ieee
10.1007/s13253-018-0327-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048015494&doi=10.1007%2fs13253-018-0327-8&partnerID=40&md5=1075efc026e91918abab4e6091aa327e 0,distinction overlap species daily activity patterns proximate co occurrence species location time due behavioral attraction avoidance critical addressing question species co occurrence use data dense grid camera traps forest central north carolina inform proximate co occurrence camera trigger times recorded animals pass front cameraâ€™s field vision view data point pattern time species model intensities driving patterns species specific intensities modeled jointly linear time preserve notion co occurrence show multivariate log gaussian cox process incorporating circular linear time provides preferred choice modeling occurrence forest mammals based daily activity rhythms model inference obtained hierarchical bayesian framework efficient markov chain monte carlo sampling algorithm model fitting account imperfect detection individuals camera traps incorporating species specific detection probabilities adjust estimates occurrence co occurrence obtain rich inference including assessment probability presence one species particular time interval given presence another species adjacent interval enabling probabilities proximate co occurrence results describe ecology interactions four common mammals within suburban forest including daily rhythms responses temperature rainfall effects presence predator species supplementary materials accompanying paper appear online â© international biometric society
10.1016/j.resuscitation.2018.05.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047089935&doi=10.1016%2fj.resuscitation.2018.05.005&partnerID=40&md5=bad679445d0635c98566392d0698f335 1,aim compare relative efficacy safety mechanical compression devices autopulse lucas manual compression patients cardiac arrest undergoing cardiopulmonary resuscitation cpr methods bayesian network meta analysis seven randomized controlled trials rcts selected using pubmed medline embase central inception october outcomes median estimate odds ratio posterior distribution corresponding credible interval cr calculated markov chain monte carlo mcmc modeling used estimate relative ranking probability intervention based surface cumulative ranking curve sucra results analysis patients cardiac arrest autopulse patients lucas patients manual compression patients manual compression improved survival days hospital discharge cr â€“ neurological recovery cr â€“ compared autopulse differences lucas autopulse regards survival hospital admission neurological recovery return spontaneous circulation rosc manual compression reduced risk pneumothorax cr â€“ manual compression cr â€“ lucas cr â€“ reduced risk hematoma formation compared autopulse probability analysis ranked manual compression effective treatment improving survival days hospital discharge sucra conclusions manual compression effective autopulse comparable lucas improving survival days hospital discharge neurological recovery manual compression lesser risk pneumothorax hematoma formation compared autopulse â© elsevier b v
10.1016/j.chaos.2018.07.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049991308&doi=10.1016%2fj.chaos.2018.07.010&partnerID=40&md5=c789f19967c10c31e7936857dad28dff 0,substantial evidence supports financial returns time series exhibit abnormal properties including leptokurtosis volatility clustering well intermittent jumps leverage effects returns volatility processes paper studies heavy tailed stochastic volatility sv model jumps components leverage effects student distribution employed describe error innovations svjlt since existence high dimensionality latent variables special structure hessian matrix stochastic volatility density develop efficient markov chain monte carlo mcmc posterior simulator exploiting adaptive importance sampling technique based band sparse matrix routine rather conventional kalman filter estimate new model precision sampler exploited due band structure inverse covariance matrix state variables model comparisons returns volatility conducted utilizing observed data based deviance information criterion dic cross entropy ce based marginal likelihood estimation effectiveness proposed model methodology illustrated applications stock returns volatility forecast employing several loss functions evaluation empirical studies suggest strong evidence heavy tailed distributions jumps features leverage effects simultaneously â© elsevier ltd
10.1002/nau.23559 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045101075&doi=10.1002%2fnau.23559&partnerID=40&md5=68692dcdbabef07b01b04b041b1e575c 0,aims investigate long term cost utility artificial urinary sphincter aus compared transobturator retroluminal sling advance treatment patients severe post prostatectomy stress urinary incontinence ppsui canadian provincial health perspective methods markov model monte carlo simulation developed cycle length year time horizon years estimate incremental cost per quality adjusted life years qalys patients assigned treatment either aus advance sling transition probabilities efficacy data utility indices derived published literature expert opinion cost data obtained provincial health care system hospital data canadian dollars primary outcome cost per quality adjusted life year standard discount rate applied annually probabilistic one way deterministic sensitivity analyses performed results aus implantation year mean total cost sd â± qalys advance sling mean total cost sd â± qalys incremental cost savings aus years âˆ’ added effectiveness qalys willingness pay threshold aus remained cost effective option limitation analysis lack direct long term comparisons scenarios along standard success definition conclusions aus implantation appears economical treatment strategy severe ppsui compared advance sling publicly funded health care system year time horizon â© wiley periodicals inc
10.1016/j.neuroimage.2018.04.077 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048510824&doi=10.1016%2fj.neuroimage.2018.04.077&partnerID=40&md5=2748bc81c499c51f8e38f6e4e2a5f02d 0,bayesian model sparse hierarchical inver covariance estimation presented applied multi subject functional connectivity estimation human brain enables simultaneous inference strength connectivity brain regions subject population level applicable fmri meg eeg data two versions model encourage sparse connectivity either using continuous priors suppress irrelevant connections using explicit description network structure estimate connection probability pair regions large evaluation model thirteen methods represent state art inverse covariance modelling conducted using simulated resting state functional imaging datasets novel bayesian approach similar performance best extant alternative ng et al sparse group gaussian graphical model algorithm also based hierarchical structure using data human connectome project show hierarchical models able reduce measurement error meg beta band functional networks producing concomitant increases estimates genetic influence functional connectivity â©
10.1371/journal.pone.0204359 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053672610&doi=10.1371%2fjournal.pone.0204359&partnerID=40&md5=b55c4bb3d1bbac484d36bb0b3cf12702 0,coxsackievirus cv emerged important etiological agent hand foot mouth disease herpangina pathogen spectrum high global prevalence present study investigated evolutionary dynamics cv circulating china analyzed total entire vp sequences cv including sequences generated present study sequences collected genbank database phylogenetic analysis based entire vp nucleotide sequences confirmed persistent circulation predominant genotype mainland china since cluster analysis grouped sequences two distinct clusters clusters grouped cluster cluster gradually replaced cluster results bayesian markov chain monte carlo analysis suggested multiple lineages genotype transmitted mainland china estimated evolutionary rate ã— âˆ’ substitutions per site per year consistent global evolutionary rate cv ã— âˆ’ substitutions per site per year continuous transmission evolution cv resulted genetic polymorphism â© yang et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1002/jmv.25220 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049781987&doi=10.1002%2fjmv.25220&partnerID=40&md5=277c2879260776c7469132cb0b44cf58 0,despite significantâ decrease acute hepatitis last decades italy outbreaks observed occurring mostly southern italy study bayesian phylogenetic analysis used analyze origin epidemics aim different data sets hepatitis virus sequences built perform genotyping neighbor joining method estimate evolutionary rates using bayesian markov chain monte carlo approach investigate demographic history independent markov chain monte carlo runs enforcing strict relaxed clock estimated mean value evolutionary rate representing ia ib strains ã— âˆ’ ã— âˆ’ substitutions site year respectively bayesian maximum clade credibility tree hepatitis virus hav ia ib strains showed italian sequences mostly formed separate clusters root time recent common ancestor tmrca hav ia ib strains dated back respectively showing cases different epidemic entrances phylodynamic analysis showed genotype ia increased apulia epidemic started suffered bottleneck probably consequent vaccination herd immunity followed new increase virus population years â consequent epidemic caused ingestion mixed frozen berries similar trend without evident bottleneck observed also case genotype ib conclusion bayesian phylogenetic analysis represents good tool measure effectiveness public health plans used hav control â© wiley periodicals inc
10.1007/s40484-018-0149-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053228281&doi=10.1007%2fs40484-018-0149-2&partnerID=40&md5=c70045fb74caa4e83cdad51d52661984 0,background recently emerged technology methylated rna immunoprecipitation sequencing merip seq sheds light study rna epigenetics new bioinformatics question calls effective robust peaking calling algorithms detect mrna methylation sites merip seq data methods propose bayesian hierarchical model detect methylation sites merip seq data modeling approach includes several important characteristics first models zero inflated dispersed counts deploying zero inflated negative binomial model second incorporates hidden markov model hmm account spatial dependency neighboring read enrichment third bayesian inference allows proposed model borrow strength parameter estimation greatly improves model stability dealing merip seq data small number replicates use markov chain monte carlo mcmc algorithms simultaneously infer model parameters de novo fashion r shiny demo available https qiwei shinyapps io bayseqpeak r c ++ code available https github com liqiwei bayseqpeak results simulation studies proposed method outperformed competing methods exomepeak metpeak especially excess zeros present data real merip seq data analysis proposed method identified methylation sites consistent biological knowledge better spatial resolution compared methods conclusions study develop bayesian hierarchical model identify methylation peaks merip seq data proposed method competitive edge existing methods terms accuracy robustness spatial resolution figure available see fulltext â© higher education press springer verlag gmbh germany part springer nature
10.1016/j.ijthermalsci.2018.03.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047393262&doi=10.1016%2fj.ijthermalsci.2018.03.009&partnerID=40&md5=f6a5a32cdc90b2270c6caf510e3c06c5 0,work novel experimental technique developed estimate spatially varying heat transfer coefficients flat plate flush mounted discrete heat sources using bayesian inference temperature measurements liquid crystal thermography lct adiabatic surface plate without disturbing fluid flow steady state laminar forced convection experiments done flat bakelite plate three identical embedded discrete aluminium heat sources dimensions ã— ã— l ã— w ã— variation local convective heat transfer coefficient obtained form nusselt number correlation nu=areb x l c correlation first developed limited numerical simulations two dimensional conjugate convection correlation computationally less complex problem conjugate conduction flat plate also known forward model repeatedly solved various values â€˜aâ€™ â€˜bâ€™ â€˜câ€™ obtain temperature distributions select points adiabatic surface using comsol surrogate model obtained artificial neural networks ann built upon data simulations replaces forward model surrogate model used drive markov chain monte carlo based metropolis hastings algorithm generate samples forward model solve inverse problem getting â€˜aâ€™ â€˜bâ€™ â€˜câ€™ temperature measurements adiabatic surface bayesian framework adopted compare experimental simulated temperatures generate posteriors mean maximum posteriori standard deviation parameters â€˜aâ€™ â€˜bâ€™ â€˜câ€™ estimated effect number samples temperature points performance estimation process reported finally retrieved values â€˜aâ€™ â€˜bâ€™ â€˜câ€™ temperature distributions obtained solving conduction problem compared actually measured tlc â© elsevier masson sas
10.1007/s00362-016-0810-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979985979&doi=10.1007%2fs00362-016-0810-7&partnerID=40&md5=9bcd6d9155e5cbcae84af675f77b0fd5 1,kâ â g system consists k components functions least components functions paper consider kâ â g system system exposed common random stress underlying distributions belong family inverse exponentiated distributions estimates sytem reliability investigated using classical bayesian approaches uniformly minimum variance unbiased exact bayes estimates reliability system obtained analytically common second parameter known bayes estimates reliability system developed using lindleyâ€™s approximation markov chain monte carlo method due lack explicit forms parameters unknown asymptotic confidence interval coverage probabilities derived based fisherâ€™s information matrix highest probability density credible interval constructed using markov chain monte carlo method comparison derived estimates carried using monte carlo simulations real data set also analysed illustration findings â© springer verlag berlin heidelberg
10.1214/17-BA1077 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047837602&doi=10.1214%2f17-BA1077&partnerID=40&md5=ed2b46bd060863adfcad4b308f2904ae 1,propose new scheme selecting pool states embedded hidden markov model hmm markov chain monte carlo mcmc method new scheme allows embedded hmm method used efficient sampling state space models state high dimensional previously embedded hmm methods applicable low dimensional state space models demonstrate using proposed pool state selection scheme embedded hmm sampler similar performance well tuned sampler uses combination particle gibbs backward sampling pgbs metropolis updates scaling higher dimensions made possible selecting pool states locally near current value state sequence proposed pool state selection scheme also allows iteration embedded hmm sampler take time linear number pool states opposed quadratic original embedded hmm sampler â© international society bayesian analysis
10.1111/jedm.12184 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052605958&doi=10.1111%2fjedm.12184&partnerID=40&md5=792399a24789947429d8ab2e7a6e743f 0,bayesian methods incorporate model parameter information prior data collection eliciting information content experts option seen little implementation bayesian item response theory irt modeling study aims use ethical reasoning content experts elicit prior information incorporate information markov chain monte carlo mcmc estimation six step elicitation approach followed relevant details stage two irt items parameters difficulty guessing results indicate using content experts preferred approach rather noninformative priors parameter types use noninformative prior small samples provided dramatically different results compared results content expertâ€“elicited priors wambs worry avoid misuse bayesian statistics checklist used aid comparisons â© national council measurement education
10.1016/j.jkss.2018.03.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045297978&doi=10.1016%2fj.jkss.2018.03.003&partnerID=40&md5=bec688158aa1213f096c374336881f22 0,paper propose bayesian variable selection method linear regression models high order interactions method automatically enforces heredity constraint higher order interaction term exist model parent terms model based stochastic search variable selection george mcculloch propose novel hierarchical prior fully considers heredity constraint controls degree sparsity simultaneously develop markov chain monte carlo mcmc algorithm explore model space efficiently accounting heredity constraint modifying shotgun stochastic search algorithm hans et al performance new model demonstrated comparisons methods numerical studies real data analysis simulations show new method tends find relevant variable effectively higher order interaction terms considered â© korean statistical society
10.1111/sjos.12310 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045190421&doi=10.1111%2fsjos.12310&partnerID=40&md5=446ea324adf30135f7335d6c8de33807 1,gaussian errors inappropriate multivariate linear regression setting often assumed errors iid distribution scale mixture multivariate normals combining robust regression model default prior unknown parameters results highly intractable posterior density fortunately simple data augmentation da algorithm corresponding haar px da algorithm used explore posterior paper provides conditions mixing density geometric ergodicity markov chains underlying markov chain monte carlo algorithms letting denote dimension response main result shows da haar px da markov chains geometrically ergodic whenever mixing density generalized inverse gaussian log normal inverted gamma shape parameter larger frã©chet shape parameter larger results also apply certain subsets gamma f weibull families â© board foundation scandinavian journal statistics
10.1214/17-AOAS1116 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052688774&doi=10.1214%2f17-AOAS1116&partnerID=40&md5=93d163459b067973ac480b5fdbab764c 2,medical imaging studies collected high dimensional imaging data identify imaging biomarkers diagnosis screening prognosis among many others imaging data often represented form multi dimensional array called tensor aim paper develop tensor partition regression modeling tprm framework establish relationship low dimensional clinical outcomes e g diagnosis high dimensional tensor covariates tprm hierarchical model efficiently integrates four components partition model ii canonical polyadic decomposition model iii principal components model iv generalized linear model sparse inducing normal mixture prior framework reduces ultra high dimensionality manageable level resulting efficient estimation also optimizes prediction accuracy search informative sub tensors posterior computation proceeds via efficient markov chain monte carlo algorithm simulation shows tprm outperforms several competing methods apply tprm predict disease status alzheimer versus control using structural magnetic resonance imaging data obtained alzheimerâ€™s disease neuroimaging initiative adni study â© institute mathematical statistics
10.1140/epjc/s10052-018-6190-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052832337&doi=10.1140%2fepjc%2fs10052-018-6190-5&partnerID=40&md5=34d0ea2510a8f32aac3f8ae186fec8c1 0,among various possibilities probe theory behind recent accelerated expansion universe energy conditions ecs particular interest since possible confront constrain different theories gravity observational data context use ecs probe alternative theory gravity whose extra term acts cosmological constant purpose apply model independent approach reconstruct recent expansion universe using type ia supernova baryon acoustic oscillations cosmic chronometer data perform markov chain monte carlo analysis put constraints effective cosmological constant î©eff addition find posterior distribution incompatible cosmological constant showing method potentially rule mechanism accelerated expansion also study consequence constraints two particular formulations massive gravity scenario theories mimic general relativity cosmological constant using î©eff observational bounds along upper bounds graviton mass obtain constraints parameter spaces theories â© author
10.1029/2018JB015490 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053705985&doi=10.1029%2f2018JB015490&partnerID=40&md5=6e63ae3b8dc831e10d65cf0c8830bc4c 0,present high resolution shear wave velocity model greenland lithosphere regional teleseismic rayleigh waves recorded greenland ice sheet monitoring network supplemented observations several temporary seismic deployments construct rayleigh wave group velocity maps integrated signals regional teleseismic earthquakes several years ambient seismic noise used dispersion constrain crustal upper mantle seismic shear wave velocity structure specifically used markov chain monte carlo technique estimate shear wave velocities beneath greenland depth â km model reveals four prominent anomalies deep high velocity feature extending southwestern northwestern greenland may signature thick cratonic keel corridor relatively low upper mantle velocity across central greenland associated lithospheric modification passage iceland plume beneath greenland interpreted tectonic boundary cratonic blocks upper crustal southwest northeast trending boundary separating greenland two regions contrasting tectonic crustal properties midcrustal low velocity anomaly beneath northeastern greenland nature midcrustal anomaly particular interest given underlies onset northeast greenland ice stream raises interesting questions regarding deeper processes may impact ice stream dynamics evolution greenland ice sheet â© american geophysical union rights reserved
10.1016/j.jmva.2018.05.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047878733&doi=10.1016%2fj.jmva.2018.05.003&partnerID=40&md5=86498826d3ae5ad99e76658b901cf337 0,multidimensional item response theory mirt models quite useful analyze datasets involving multiple skills latent traits occur many applications however works consider usual multivariate symmetric normal distribution model latent traits deal multiple group framework also general works consider limited number model fit assessment tools investigate measurement instrument dimensionality detailed way assumption normality latent traits distributions hold misleading results conclusions obtained goal propose mirt multiple group model multivariate skew normal distributions centered parameterization model distribution latent traits group presenting simple feasible conditions model identification approach flexible usual multivariate symmetric normal one addition full bayesian approach parameter estimation structural selection model comparison determination dimensionality measurement instrument model fit assessment developed markov chain monte carlo algorithms proposed tools illustrated analysis real dataset related first stage university campinas admission exam â© elsevier inc
10.1093/mnras/sty1377 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051526000&doi=10.1093%2fmnras%2fsty1377&partnerID=40&md5=cd65908297e66f131b622c13c30654ec 0,weak gravitational lensing depends integrated mass along line sight baryons contribute mass distribution galaxy clusters resulting mass estimates lensing analysis use cosmo owls suite hydrodynamic simulations investigate impact baryonic processes bias scatter weak lensing mass estimates clusters estimates obtained fitting nfw profiles mock data using markov chain monte carlo techniques particular examine difference estimates dark matter runs including various prescriptions baryonic physics find significant difference themass bias baryonic physics included though overall mass estimates suppressed feedback active galactic nucleus included lowest mass systems reliable mass obtained â‰ˆ ã— mâš™ find bias â‰ˆ per cent magnitude bias tends decrease higher mass clusters consistent bias massive clusters masses comparable found clash hff samples lowest mass clusters mass bias particularly sensitive fit radii limits placed concentration prior rendering reliable mass estimates difficult scatter mass estimates dark matter various baryonic runs less different projections individual clusters highlighting importance triaxiality â© author published oxford university press behalf royal astronomical society
10.1016/j.jand.2018.05.019 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051965255&doi=10.1016%2fj.jand.2018.05.019&partnerID=40&md5=d2d2140ff6a7eaee743e734e4a9df537 3,background healthy eating index hei diet quality index measures alignment dietary guidelines americans updated dietary guidelines americans objective design evaluate psychometric properties hei eight questions examined five relevant construct validity two related reliability one assess criterion validity data sources three data sources used exemplary menus n= national health nutrition examination survey n= national institutes health aarp formally known american association retired persons diet health study n= statistical analyses exemplary menus scores calculated using population ratio method national health nutrition examination survey means standard errors estimated using markov chain monte carlo approach analyses stratified compare groups tests analysis variance principal components analysis examined number dimensions pearson correlations estimated components energy cronbach coefficient alpha national institutes health aarp diet health study adjusted cox proportional hazards models used examine scores mortality outcomes results construct validity hei yielded high scores exemplary menus four menus received high scores mean score national health nutrition examination survey first th percentile respectively supporting sufficient variation among smokers mean score significantly lower among nonsmokers respectively p demonstrating differentiation groups correlation diet quality diet quantity low supporting elements independent components demonstrated multidimensionality examined scree plot least four dimensions reliability intercorrelations among components low moderate exceptions standardized cronbach alpha criterion validity highest vs lowest quintile hei scores associated decreased risk cause cancer cardiovascular disease mortality conclusions results demonstrated evidence supportive construct validity reliability criterion validity hei used examine diet quality relative dietary guidelines americans â© academy nutrition dietetics
10.1140/epjc/s10052-018-6233-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054193991&doi=10.1140%2fepjc%2fs10052-018-6233-y&partnerID=40&md5=b96dd5e8812025cf658caca8ececc2d9 0,dark energy models î›cdm limit future observations constrain universe close î›cdm bayesian arguments evidence fine tuning employed discriminate models assuming baseline î›cdm model investigate number quintessence phantom dark energy models study perform compared observational data expansion rate angular distance growth rate measurements upcoming dark energy spectroscopic instrument desi survey sample posterior likelihood surfaces dark energy models monte carlo markov chains using central values consistent planck î›cdm universe covariance matrices estimated fisher information matrix techniques find setup bayes factor provides substantial evidence favor î›cdm model alternatives also investigated well cpl parametrization approximates various scalar field dark energy models identified location dark energy model cpl parameter space â© author
10.3390/sym10090372 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054357052&doi=10.3390%2fsym10090372&partnerID=40&md5=a4de248341dc1e3f007d4a5963b2c5fe 0,decaying dark energy models modify background evolution common observables hubble function luminosity distance cosmic microwave background temperature redshift scaling relation use recent observationally determined datasets including supernovae type ia gamma ray bursts data along h z cosmic microwave background temperature versus z data reduced cosmic microwave background parameters improve previous constraints models perform monte carlo markov chain analysis constrain parameter space basis two distinct methods view first method hubble constant matter density left vary freely case results compatible previous analyses associated decaying dark energy models well recent description cosmological background view second method set hubble constant matter density best fit values obtained planck satellite reducing parameter space two dimensions improving existent constraints model parameters results suggest accelerated expansion universe well described cosmological constant argue forthcoming observations play determinant role constrain rule decaying dark energy â© authors
10.1109/ACCESS.2018.2867744 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052797220&doi=10.1109%2fACCESS.2018.2867744&partnerID=40&md5=ddbf28e9a5500226a2021d7ff2eb072c 0,existing approaches heterogeneous redundancy allocation problem rap prone getting trapped local optimal modes optimization mainly due rugged combinatoric landscapes recently optimization sampling paradigm based stochastic approximation monte carlo samc sampling shown superior performance solving heterogeneous rap multi state systems msss however one drawback method global move markov chain relying uniform distribution typically hard hit low energy regions due uninformative proposal leading insufficient global exploration sampling address problem sample efficient optimization heterogeneous rap introduce rejection free monte carlo method sample target distribution combinatorial space specifically model based proposal learning algorithm derived guide global exploration towards promising regions descrete state space experimental evaluations set benchmark instances show superiority proposed approach compared several state arts terms solution quality computational efficiency â© ieee
10.1109/SSP.2018.8450801 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053831839&doi=10.1109%2fSSP.2018.8450801&partnerID=40&md5=206542a704298c88124d7edb61a726a1 0,imaging technologies coherent fibred bundle optical microscopy fbom operate irregularly spaced sparse subsamples field view paper address problem data deconvolution applications observed irregularly distributed samples considered result convolution operator acting original samples corrupted additive observation noise propose hierarchical bayesian model suitable prior distributions assigned unknown model parameters compare two estimation strategies including markov chain monte carlo mcmc variational bayes vb used perform bayesian inference using posterior distribution simulations conducted synthetic real datasets illustrate benefits proposed methods terms quality deconvolution sparse samples â© ieee
10.1109/SSP.2018.8450740 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053847768&doi=10.1109%2fSSP.2018.8450740&partnerID=40&md5=308c06f360154bb797dbaaded1f53dcc 0,motivated challenges computational statistics penalized maximum likelihood inference statistical models intractable likelihoods analyze convergence stochastic perturbation fast iterative shrinkage thresholding algorithm fista stochastic approximation relies biased monte carlo estimation happens points drawn markov chain monte carlo mcmc sampler first motivate general framework show convergence result perturbed fista algorithm discuss convergence rate algorithm computational cost monte carlo approximation reach given precision finally numerical example explore new directions better understanding proximal gradient based stochastic optimization algorithms â© ieee
10.1109/SSP.2018.8450772 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053838247&doi=10.1109%2fSSP.2018.8450772&partnerID=40&md5=a12f46755eeb3446dc5869c33f5a6a0d 0,sequential mcmc smcmc methods useful alternative particle filters performing sequential inference bayesian framework nonlinear non gaussian state space models weight degeneracy phenomenon impacts performance even advanced particle filters higher dimensions avoided paper explore applicability discrete bouncy particle sampler based constructing guided random walk performing delayed rejection perform effective sampling within smcmc perform numerical simulations examine proposed method offers advantages compared state art smcmc techniques â© ieee
10.1109/SSP.2018.8450720 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053838430&doi=10.1109%2fSSP.2018.8450720&partnerID=40&md5=43dfd09a5241dfa38ef18c345bbe0362 0,paper considers identification point like source groundwater pollution ill posed character problem recently led introduction regularization approach combines source parametrization penalization undesirable solutions based prior information source parameters thereby ending parametric bayesian estimation framework framework stochastic type markov chain monte carlo mcmc method introduced approximate computation tool posterior mean estimate source parameters variance assumed homogeneous observation noise general case inhomogeneous noise main goal propose deterministic type computation method based variational bayesian approach simulation results suggest proposed scheme provide comparable estimation accuracy mcmc requiring less computational time â© ieee
10.1109/SSP.2018.8450787 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053841848&doi=10.1109%2fSSP.2018.8450787&partnerID=40&md5=0aae6fee46060612d0054bbe0fddd80e 0,present model point processes gamma distributed increments assume piecewise constant latent process controlling shape scale distribution discrete number states latent process use non parametric assumption utilizing chinese restaurant process crp inference inhomogeneous gamma processes unbounded number states bayesian inference using markov chain monte carlo finally apply inference algorithm simulated point processes empirical spike train recordings inherently possess non stationary non poissonian behavior â© ieee
586.2616297315036 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052489405&partnerID=40&md5=73a078f6c4319938ba4e649ab692fd0b 0,paper burr x distribution type hybrid censored data considered e bayesian estimation expectation bayesian estimate corresponding maximum likelihood bayesian estimation methods discussed distribution parameter reliability function bayesian e bayesian estimates derived using linex squared error loss sel functions applying markov chain monte carlo mcmc techniques bayesian e bayesian estimates obtained illustrative examples type hybrid censored samples real data set presented finally comparison among proposed estimation methods conducted â© international association engineers
10.1109/IWCMC.2018.8450271 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053935457&doi=10.1109%2fIWCMC.2018.8450271&partnerID=40&md5=61e45a1c9216bcb9de7feb6fca101381 0,paper presents decisive threshold termed buffer threshold control selection probability source relay sr relay destination rd links buffer aided cooperative wireless networks weights links reassigned using buffer threshold link maximum weight activated proposed scheme termed buffer threshold based relay selection scheme btrs relations outage probability op average delay calculated markov modelling buffers theoretical results analyzed different cases buffer threshold validated monte carlo simulations performance evaluation btrs compared max link relay selection mlrs scheme max weight relay selection mwrs scheme outperforms counterparts terms average delay â© ieee
10.1109/ACCESS.2018.2867687 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052625977&doi=10.1109%2fACCESS.2018.2867687&partnerID=40&md5=75c351e7c01c3475910e29a41cb8c451 0,paper proposes bayesian framework localization multiple sources event accidental hazardous contaminant release framework assimilates sensor measurements contaminant concentration integrated multizone computational fluid dynamics multizone cfd based contaminant fate transport model ensure online tractability build deep gaussian process based emulators approximating multizone cfd model effectively represent transient response multizone cfd model deep gaussian processes extended matrix variate architecture adopting kronecker products output covariance gp layer resultant deep matrix variate gaussian process emulators used define likelihood bayesian framework markov chain monte carlo approach used sample posterior distribution proposed method evaluated single multiple contaminant sources localization tasks modeled contam simulator single story building zones demonstrating proposed approach accurately perform inference locations contaminant sources moreover proposed model shows outstanding regression performance speed training â© ieee
10.1088/1475-7516/2018/08/042 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053125653&doi=10.1088%2f1475-7516%2f2018%2f08%2f042&partnerID=40&md5=19a28613c979535b6ed9195641459bea 0,taking neutrino oscillation data consideration dimensionless parameter î” = +m adopted parameterize three neutrino mass eigenstates normal positive î” inverted negative î” mass hierarchies three typical cosmological models using currently available cosmic observational data several markov chain monte carlo chains obtained uniform priors free parameters first applying importance sampling results compared three new priors e logarithmic prior î” linear logarithmic priors î mî½ turns three new priors increase upper limits neutrino mass change tendency towards different model preference different hierarchies e normal hierarchy tends favored î›cdm wcdm however disappears w wacdm model addition almost symmetrical contours w î” w î” wa î” planes indicate normal inverted hierarchy strong degeneracy finally perform bayesian model comparison analysis finding flat linear prior î” w wacdm preferred prior model respectively â© iop publishing ltd sissa medialab
10.1088/1751-8121/aad6fa https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053133854&doi=10.1088%2f1751-8121%2faad6fa&partnerID=40&md5=c1b38a6c5912894365642ca9513ca333 0,investigate randomized benchmarking rb general setting quantum gates form representation necessarily irreducible one finite group derive estimate average fidelity experimental data may calibrated furthermore establish rb achieved sole implementation quantum gates generate group well one additional arbitrary group element case need assume noise close covariant yields practical approach rb moreover show rb stable respect approximate haar sampling sequences gates opens possibility using markov chain monte carlo methods obtain random sequences gates efficiently demonstrate results numerically using well studied example clifford group well group monomial unitary matrices latter focus subgroup nonzero entries consisting nth roots unity contains gates â© iop publishing ltd
10.1109/CCECE.2018.8447816 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053628272&doi=10.1109%2fCCECE.2018.8447816&partnerID=40&md5=493ffd2e9f395584fd8fdab19d2d8f1f 0,propose fully bayesian learning approach using reversible jump markov chain monte carlo rjmcmc asymmetric gaussian mixtures agm compared classic gaussian mixture model agm imply target data symmetric brings flexibility better fitting results paper also introduces rjmcmc learning implementation based metropolis hastings mh within gibbs sampling method improvement traditional sampling based mcmc learning rjmcmc assumption concerning number components therefore agm model transferred iterations better evaluating models different mixture components numbers model selection achieved calculating integrated likelihood using laplace approximation figure best fit components number selected synthetic challenging spam filtering dataset show merits proposed model â© ieee
10.3390/e20090642 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053691374&doi=10.3390%2fe20090642&partnerID=40&md5=559e42fa903a9d4a955a2424686fafea 0,paper study performance bayesian computational methods estimate parameters bivariate survival model based ali mikhail haq copula marginal distributions given byweibull distributions estimation procedure based monte carlo markov chain mcmc algorithms present three version metropolis hastings algorithm independent metropolis hastings imh randomwalk metropolis rwm metropolis hastings natural candidate generating density mh since creation good candidate generating density imh rwm may difficult also describe update parameter interest using slice sampling ss method simulation study carried compare performances imh rwm ss comparison made using sample root mean square error indicator performance results obtained simulations show ss algorithm effective alternative imh rwm methods simulating values posterior distribution especially small sample sizes also applied methods real data set â© authors
10.1109/SPAWC.2018.8445994 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053481823&doi=10.1109%2fSPAWC.2018.8445994&partnerID=40&md5=9e8e837e9620aabedee30e3c95cf72e4 0,identification useful temporal dependence structure discrete time series data important component algorithms applied many tasks statistical inference machine learning used wide variety problems across spectrum biological studies early statistical approaches ineffective practice amount data required reliable modelling grew exponentially memory length hand many modern methodological approaches make use flexible parsimonious models result algorithms scale well computationally ineffective larger data sets paper describe class novel methodological tools effective bayesian inference general discrete time series motivated primarily questions regarding data originating studies genetics neuroscience starting point development rich class bayesian hierarchical models variable memory markov chains particular prior structure adopt makes possible design effective linear time algorithms compute important features relevant posterior predictive distributions without resorting markov chain monte carlo simulation origin algorithms traced family context tree weighting ctw algorithms developed data compression since mid used resulting methodological tools numerous application specific tasks including prediction segmentation classification anomaly detection entropy estimation causality testing data different areas application results obtained compare quite favourably obtained using earlier approaches probabilistic suffix trees pst variable length markov chains vlmc class markov transition distributions mtd â© ieee
10.1109/ICCSEC.2017.8446846 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053889436&doi=10.1109%2fICCSEC.2017.8446846&partnerID=40&md5=5d31675102b8e80b3242a53bb46ecdea 0,paper particle filter designed deal class nonlinear systems measurements undergo multi step random delay due limited transmission capability data link first discrete time variable governed markov chain defined describe measurement random delay considering target maneuver multi model method adopted another discrete time variable introduced model system jump markov system second two newly defined variables used augment original state vector hybrid system containing two kinds discrete time components obtained finally hybrid system estimated particle filtering framework simulation results show proposed filter effectively deal systems target maneuver measurement delay occur simultaneously â© ieee
10.1063/1.5030531 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049309835&doi=10.1063%2f1.5030531&partnerID=40&md5=c57b3369ab6d9274b2787c3d51dff654 0,configurational sampling algorithm based nested layerings markov chains layered nested markov chain monte carlo l nmcmc presented simulations systems characterized rugged free energy landscapes layerings generated using set auxiliary potential energy surfaces implementation method demonstrated context rugged two dimensional potential energy surface versatility algorithm next demonstrated simple many body system namely canonical lennard jones fluid liquid state example different layering schemes auxiliary potentials used including variable cutoff distances excluded volume tempering addition calculating variety properties system also shown l nmcmc combined free energy perturbation formalism provides straightforward means construct approximate free energy surfaces additional computational cost using sampling distributions auxiliary markov chain proposed l nmcmc scheme general complementary number methods rely sampling target distribution methods exploit hierarchy time scales length scales decomposition potential energy â© author
10.1063/1.5027001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051503769&doi=10.1063%2f1.5027001&partnerID=40&md5=e65ac7071dc6a9a1f231096f1b2bc884 0,markov state model msm become popular approach study conformational dynamics complex biological systems recent years built upon large number short molecular dynamics simulation trajectories msm able predict long time scale dynamics complex systems however achieve markovianity msm often contains hundreds thousands states microstates hindering human interpretation underlying system mechanism one way reduce number states lump kinetically similar states together thus coarse grain microstates macrostates work introduce probabilistic lumping algorithm gibbs lumping algorithm assign probability given kinetic lumping using bayesian inference algorithm transitions among kinetically distinct macrostates modeled poisson processes well reflect separation time scales underlying free energy landscape biomolecules furthermore facilitate search optimal kinetic lumping e lumped model highest probability gibbs sampling algorithm introduced demonstrate power new method apply three systems potential alanine dipeptide ww protein domain comparison six popular lumping algorithms show method persistently produce lumped macrostate model highest probability well largest metastability anticipate gibbs lumping algorithm holds great promise widely applied investigate conformational changes biological macromolecules â© author
10.1109/ISEMA.2018.8442313 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053493575&doi=10.1109%2fISEMA.2018.8442313&partnerID=40&md5=4547fe1dab8057d15046dfb55d88e07b 0,non contact measurement heterogeneous moisture content constrained inconsistencies probing signal first step new approach using non diffracting probing signal derive robust markov chain monte carlo formulation determine antenna patch signals generate microwave bessel beam show solutions provide set robust driving signals well collimated beam high snr region easily sufficient proximal sensing moisture content â© ieee
10.1109/TVCG.2018.2866436 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052653479&doi=10.1109%2fTVCG.2018.2866436&partnerID=40&md5=73543f481087dee17f6476c26255458c 0,arrangement objects layout challenging non experts affirmed existence interior design professionals recent research automation task yielded methods synthesize layouts objects respecting aesthetic functional constraints non linear competing methods usually adopt stochastic optimization scheme samples different layout configurations process slow inefficient introduce physics motivated continuous layout synthesis technique results significant gain speed readily scalable demonstrate method variety examples show achieves results similar conventional layout synthesis based markov chain monte carlo mcmc state search faster least order magnitude handle layouts unprecedented size well tightly packed layouts overwhelm mcmc ieee
10.3847/1538-4357/aad236 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052396012&doi=10.3847%2f1538-4357%2faad236&partnerID=40&md5=f874d56b365efccf23dff1fe4331a619 0,investigate dark matter density profile massive elliptical galaxy ngc constructing spherically symmetric jeans models field star globular cluster systems two major challenges models degeneracy stellar mass dark matter halo profiles degeneracy orbital anisotropy tracer population total mass causing observed motions address first issue using new measurements mass light ratio profile stellar population constraints include radially varying initial mass function mitigate mass anisotropy degeneracy make use multiple kinematic tracers including two subpopulations globular clusters addition galaxys field stars create hierarchical bayesian model addresses several often neglected systematic uncertainties statistical weight given various data sets adopted distance sampling posterior probability distribution markov chain monte carlo method find evidence central cusp log slope î³ = + stat sys quantified systematic uncertainty dominated choice anisotropy profile lower expected dark matter halos undergone adiabatic contraction supporting inferences gravitational lensing process suppressed steepening halos massive galaxies also confirm radially biased orbits metal rich globular clusters tangentially biased orbits metal poor globular clusters remains puzzling finding accretion dominated halo â© american astronomical society rights reserved
10.1080/08912963.2017.1336620 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020696626&doi=10.1080%2f08912963.2017.1336620&partnerID=40&md5=c8cb812a3dfdb7324498769d38ca3cbd 0,faunal skeletal profiles archaeological assemblages long analysed regarding differential transport carcasses infer hunting preferences human mobility even dietary stress however existence several possible accumulating agents together effect bone attrition known introduce potential bias thus hindering possibilities meaningful concussions order overcome problem several methods proposed late early â€™s although consensus reached mainly different approaches based certain initial hypothesis significantly affected output building previous experience new methodological framework proposed compared moving rather deterministic techniques bayesian alternative approach based monte carlo markov chain sampling presented applied several ethnographic pleistocene key sites new method makes use available information constrain possible degrees attrition carcass processing strategies leading easily comparable results â© â© informa uk limited trading taylor francis group
10.1109/PMAPS.2018.8440277 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053155645&doi=10.1109%2fPMAPS.2018.8440277&partnerID=40&md5=beedfd3ba8241c72dcfcf9a3e6145fe0 0,recent years studies natural inflow energy nie synthetic scenario simulations resulted new methodological proposals developments often assume gaussianity residues thus making possible transform data parametric distribution noticed real cases brazilian electric sector noise treated thus since presents intrinsically skewed tail behaviors challenging national interconnected system operational planning reproduce thus work proposes nonparametric approach simulate sample nie series residues using markov chain monte carlo technique kernel density estimation hence possible simulate synthetic nie scenarios presented results show proposed methodology good alternative current model â© ieee
10.1109/PMAPS.2018.8440564 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053122548&doi=10.1109%2fPMAPS.2018.8440564&partnerID=40&md5=ea3dcfd10ba485107882ddb6e75cc4f6 0,great deal literature examines economic dispatch perspective grid operator assuming full knowledge generating unit costs constraints network topology line capacities etc others without access complete data intensive model may also wish predict unit dispatch various scenarios paper develops bayesian approach predicting future economic dispatch relies historical dispatch observations well general assumptions operating costs approach uses markov chain monte carlo method create ensemble network free models capture fundamental properties economic dispatch like merit order marginal generator behavior particular regimes grid operation particular range load set congested lines set committed units etc uses bayesian averaging many simple models create ensemble model approximates economic dispatch general operating conditions case study using data new york used verify ensemble model â© ieee
10.1109/PMAPS.2018.8440239 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053110910&doi=10.1109%2fPMAPS.2018.8440239&partnerID=40&md5=7f2d0d1e4e70b0b2e599f9aab0810932 0,paper presents algorithm employs sequential monte carlo simulation smcs estimate operational states components connected grid use accelerated quantum particle swarm optimization aqpso algorithm determines optimum size location static var compensators svcs approach maximizes level reliability smart grid subject voltage regulation specific contribution paper presents impact integration svc system reliability leads comprehensive composite system adequacy evaluation smart grid environment â© ieee
10.1109/TSP.2018.2847660 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048639281&doi=10.1109%2fTSP.2018.2847660&partnerID=40&md5=b9faf3b8c74831635bfbd7343a10adbd 0,missing values impediment designing applying classifiers missing values common biomedical studies due various reasons including missing tests complex profiling technologies different omics measurements modern biomedicine many procedures proposed impute values missing paper considers missing feature values context optimal bayesian classification selects classifier minimizes expected error respect posterior distribution governing uncertainty class feature label distributions missing value problem fits neatly overall framework optimal bayesian classification marginalizing missing value process feature label distribution updating prior distribution class conditional parameters posterior distributions using new observations generally optimal bayesian classifier defined via effective class conditional densities averages parameterized feature label distributions uncertainty class relative posterior distribution hence posterior distribution incorporating missing value process found optimal bayesian classifier pertaining features missing values derived corresponding effective class conditional densities paper presents general theory derives closed form decision rule optimal bayesian classifier gaussian model independent features utilizes hamiltonian monte carlo gaussian model arbitrary covariance matrices superior performance demonstrated compared linear discriminant analysis quadratic discriminant analysis support vector machines conjunction gibbs sampling imputation using synthetic real world omics data â© ieee
10.1016/j.nucengdes.2018.06.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048431095&doi=10.1016%2fj.nucengdes.2018.06.003&partnerID=40&md5=45745f7a17d54ade332589af2680937b 4,inverse uncertainty quantification uq process quantify uncertainties random input parameters achieving consistency code simulations physical observations paper performed inverse uq using improved modular bayesian approach based gaussian process gp trace physical model parameters using bwr full size fine mesh bundle tests bfbt benchmark steady state void fraction data model discrepancy described gp emulator numerical tests demonstrated treatment model discrepancy avoid fitting furthermore constructed fast running accurate gp emulator replace trace full model markov chain monte carlo mcmc sampling computational cost demonstrated reduced several orders magnitude sequential approach also developed efficient test source allocation tsa inverse uq validation sequential tsa methodology first selects experimental tests validation full coverage test domain avoid extrapolation model discrepancy term evaluated input setting tests inverse uq selects tests tend reside unfilled zones test domain inverse uq one extract information posterior probability distributions calibration parameters using relatively small number tests research addresses â€œlack input uncertainty informationâ€� issue trace physical input parameters usually ignored described using expert opinion user self assessment previous work resulting posterior probability distributions trace parameters used future uncertainty sensitivity validation studies trace code nuclear reactor system design safety analysis â© elsevier b v
10.1103/PhysRevD.98.043008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052642162&doi=10.1103%2fPhysRevD.98.043008&partnerID=40&md5=19df0ff8a1a4d9c8afa4123850179f13 0,mhz gravitational wave band galactic ultracompact binaries ucbs continuous sources emitting near constant frequency signals many galactic binaries sufficiently strong detectable laser interferometer space antenna lisa âˆ¼o week observing addition astrophysical value ucbs used monitor data quality observatory paper demonstrates capabilities galactic ucbs used calibration sources lisa demanding signal coherence adjacent week long data segments separated gap time priori unknown duration parameter gap duration added ucb waveform model used markov chain monte carlo algorithm simultaneously fitting astrophysical source parameters results measurements several ucbs combined produce joint posterior gap duration measurement accuracy dependence much known ucbs prior observing seasonal variations due lisa orbital motion quantified duration data gaps two week segment data constrained within âˆ¼ using ucbs one month observing timing accuracy ucbs improves year mission operations results robust within factor âˆ¼ taking account seasonal variations â© us published american physical society
10.1063/1.5029566 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051468466&doi=10.1063%2f1.5029566&partnerID=40&md5=1cebb97e13b72a6f2b86fd30f2501b88 0,pruned enriched rosenbluth method perm popular powerful monte carlo technique sampling flexible chain polymers substantial length original form however method applied markov chain monte carlo schemes rendered perm unsuited systems consist many chains current work builds configurational bias monte carlo cbmc method growth large set trial configurations move governed simultaneous pruning enrichment events tend replace configurations low statistical weight clones stronger configurations simulations dense brushes flexible chains gain efficiency least three orders magnitude observed respect cbmc one order magnitude respect recoil growth approaches moreover meaningful statistics collected trial configurations called â€œwaste recyclingâ€� monte carlo scheme â© author
10.1063/1.5036638 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051441946&doi=10.1063%2f1.5036638&partnerID=40&md5=4aac423736d03d1a4c3a1f2b07d44420 0,apply irreversible event chain monte carlo ecmc algorithm simulation dense atom systems long range coulomb interactions ecmc event driven exactly samples boltzmann distribution neither uses time step approximations spatial cutoffs range interaction potentials importantly need evaluate total coulomb potential thus circumvents major computational bottleneck traditional approaches requires derivatives two particle coulomb potential discuss mutually consistent choices ecmc breaks total interaction potential factors particle systems made neutral dipolar molecules demonstrate superior performance dipole dipole factors decompose coulomb potential beyond two molecule level demonstrate long range factors nevertheless lead local lifting schemes subsequently moved particles mostly close simple point charge water model flexible molecules spc fw combines long ranged intermolecular coulomb potential hydrogen oxygen bond length vibrations flexible hydrogen oxygen hydrogen bond angle lennard jones oxygen oxygen potentials break potential factors containing two six particles atom liquid water model demonstrate computational complexity ecmc scales well system size achieved pure particle particle framework without interpolating mesh required efficient implementation modern coulomb algorithms finally discuss prospects challenges ecmc outline several future applications â© author
10.1109/TITS.2018.2852493 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051645543&doi=10.1109%2fTITS.2018.2852493&partnerID=40&md5=2da811460e143d9a994336c64eb3f179 0,context public transport modeling simulation address problem mismatch simulated transit trips observed ones point weakness current travel demand modeling process trips generates overly optimistic reflect real passenger choices explain deviation simulated trips observed trips introduce notion mini activities travelers trips propose mine smart card data identify characteristics help detect mini activities develop technique integrate generated trips learn integration two available sources trip history trip planner recommendations input travel demand build markov chain trip collection apply monte carlo markov chain algorithm integrate mini activities way trip characteristics converge target distributions test method trip data set collected nancy france evaluation results demonstrate important reduction trip generation error good capacity cope new simulation scenarios ieee
10.1080/00949655.2018.1462813 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045629427&doi=10.1080%2f00949655.2018.1462813&partnerID=40&md5=1948a185006668e13fe04dfee0046264 0,existing studies spatial dynamic panel data model sdpdm mainly focus normality assumption response variables random effects assumption may inappropriate applications paper proposes new sdpdm assuming response variables random effects follow multivariate skew normal distribution markov chain monte carlo algorithm developed evaluate bayesian estimates unknown parameters random effects skew normal sdpdm combining gibbs sampler metropolisâ€“hastings algorithm bayesian local influence analysis method developed simultaneously assess effect minor perturbations data priors sampling distributions simulation studies conducted investigate finite sample performance proposed methodologies example illustrated proposed methodologies â© informa uk limited trading taylor francis group
10.1108/IJLM-02-2017-0047 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048364490&doi=10.1108%2fIJLM-02-2017-0047&partnerID=40&md5=7260aef16ed21ae621f597454bc1372a 1,purpose study proposes use cumulative prospect theory cpt predict estimation risks counteractive adjustment cold chain context particular purpose paper address importance socio demographic characteristics individual influencing risk attitude analysis measurable risk probability design methodology approach study uses cpt basis develop decision analysis model two functions value editing probability weighting nonlinear adequately determine flexible risk attitudes individuals well prospects numerous outcomes different probabilities experiment conducted obtain empirical predictions efficient markov chain monte carlo algorithm applied overcome nonlinearity dimensionality process parameter estimation findings respondents overweigh minor cold chain risks small probabilities behave risk averse manner underweighting major events larger ones thereby leading risk seeking behavior judgment distortion regarding probability observed risk decision low probability high impact moreover findings indicate factors gender job familiarity confidentiality significantly influence risk attitudes subjective probability weighting respondents research limitations implications findings fit framework cpt extend theory deal human risk attitudes subjective bias cold chains particular study enhances literature providing analysis cold chain risk human decision making managerial perspectives moreover research determined importance socio demographic characteristics individual explain variability risk attitudes responses practical implications managers must consider issues flexible risk attitude subjective judgment making choices risk mitigation strategies given focus counteractive adjustment estimated risk firms evaluate cold chain risk accurately thereby enhance resilience risky events reducing variability performance originality value current study first materialize phenomena estimation cold chain risks well emphasize different characteristics loss aversion judgment distortion individual level â© emerald publishing limited
10.1080/00949655.2018.1458310 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045029793&doi=10.1080%2f00949655.2018.1458310&partnerID=40&md5=aa35aeb9c4295f5827f6db633d7205ad 0,paper consider marshallâ€“olkin extended exponential moee distribution capable modelling various shapes failure rates aging criteria purpose paper three fold first derive maximum likelihood estimators unknown parameters observed fisher information matrix progressively type ii censored data next bayes estimates evaluated applying lindleyâ€™s approximation method markov chain monte carlo method squared error loss function performed simulation study order compare proposed bayes estimators maximum likelihood estimators also compute asymptotic confidence interval symmetric credible interval along coverage probability third consider one sample two sample prediction problems based observed sample provide appropriate predictive intervals classical well bayesian framework finally analyse real data set illustrate results derived â© informa uk limited trading taylor francis group
10.5194/amt-11-4627-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051359687&doi=10.5194%2famt-11-4627-2018&partnerID=40&md5=ebf06c07909a78fbb27f98113f07ac90 0,neural network based method quantile regression neural networks qrnns proposed novel approach estimating posteriori distribution bayesian remote sensing retrievals advantage qrnns conventional neural network retrievals learn predict single retrieval value also associated case specific uncertainties study retrieval performance qrnns characterized compared state art retrieval methods synthetic retrieval scenario presented used validation case application qrnns bayesian retrieval problems qrnn retrieval performance evaluated markov chain monte carlo simulation another bayesian method based monte carlo integration retrieval database scenario also used investigate different hyperparameter configurations training set sizes affect retrieval performance second part study qrnns applied retrieval cloud top pressure observations moderate resolution imaging spectroradiometer modis shown qrnns capable achieving similar accuracy standard neural network retrievals also provide statistically consistent uncertainty estimates non gaussian retrieval errors results presented work show qrnns able combine flexibility computational efficiency machine learning approach theoretically sound handling uncertainties bayesian framework together article python implementation qrnns released public repository make method available scientific community â© author
10.1109/TNNLS.2018.2855699 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051401712&doi=10.1109%2fTNNLS.2018.2855699&partnerID=40&md5=2889450a8e5335ab88799501226c8e28 0,learning hidden markov model hmm typically based computation likelihood intractable due summation possible combinations states mixture components estimation often tackled maximization strategy known baum welch algorithm however drawbacks approach led consideration bayesian methods add prior parameters order work posterior probability marginal likelihood approaches lead good models cost extremely long computations e g markov chain monte carlo recently variational bayesian frameworks proposed bayesian alternative keeps computation tractable approximation tight relies introduction prior parameters learned approximation true posterior distribution proving good standing case finite mixture models discrete gaussian hmms propose derive equations variational learning dirichlet mixture based hmm extend generalized dirichlet latter case presents several properties make estimation accurate prove validity approach within context unusual event detection public areas using university california san diego data sets hmms trained normal video sequences using typical baum welch approach versus variational one variational learning leads accurate models detection localization anomaly general hmm approach shown versatile enough handle detection various synthetically generated tampering events ieee
10.1080/00223131.2018.1445564 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043691744&doi=10.1080%2f00223131.2018.1445564&partnerID=40&md5=9afd27062a1683529fcd82fc524f1c3b 0,probabilistic risk assessment pra event tree et methodology widely used quantify accident scenarios result core damage fission products release however current approach using et methodology applicable evaluate dynamic characteristics accident progression accident progression time dependent headings et inter dependency events thus dynamic approach accident scenario quantification necessary evaluate realistic pra research addressed need developing dynamic scenario quantification method level pra coupling continuous markov chain monte carlo cmmc method plant thermalâ€“hydraulic analysis code sodium cooled fast reactor sfr cmmc method applied protected loss heat sink plohs accident sfr analyze dynamic scenario quantifications coupling method requires heavy computational cost makes difficult quantify whole accident scenarios comparing results existing plant state analysis codes thus meta analysis coupling method proposed obtain dynamic scenario quantifications reasonable computational cost also categorizing method used depict analytical results transparent manner â© â© atomic energy society japan rights reserved
10.1088/1757-899X/392/6/062107 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052389620&doi=10.1088%2f1757-899X%2f392%2f6%2f062107&partnerID=40&md5=6e1f172984b893bd0f136f94f4940a6c 0,calculation flood quantiles uncertainty estimation important subjects hydraulic engineering planning water resources management study bayesian theory used implement frequency analysis uncertainty assessment annual maximum flood series generalized extreme value gev distribution considered flood frequency distribution line type markov chain monte carlo mcmc method based metropolis hastings algorithm used evaluate gev distribution parameters posterior distributions flood flow quantiles used calculate point estimations interval estimations flood design values different return periods results show fitting effect bayesian mcmc method maximum likelihood estimation mle bayesian mcmc superior uncertainties considered compared traditional methods flood frequency analysis proposed bayesian mcmc method provides design flood estimated values also confidence intervals estimated values addition lengths upper confidence limits estimated values greater lower confidence limits estimated values asymmetry realistic traditional methods delta method thus improve reliability flood frequency analysis â© published licence iop publishing ltd
10.1109/TITS.2018.2852726 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051049472&doi=10.1109%2fTITS.2018.2852726&partnerID=40&md5=9d76fe9fd4d295c78b0b10bcb779ddcb 0,public transport planners predict passenger loads levels service applying prior knowledge transit network using transit assignment models individual travel history data available automated fare collection afc systems bring opportunity understanding individual travel behavior necessary develop transit assignment model combining prior knowledge transit network afc data transit assignment model calibrated paper proposes bayesian hierarchical model estimate attributes travel time components calibrate transit assignment model model route choices represented multinomial logit model coefficients estimated via markov chain monte carlo method proposed model specified two ways order consider travel time variability assumed travel time links follows gamma distribution first specification route choice variables parameters transit modes bus train ferry second specification mode specific route choice variables parameters defined order assess model fitness root mean square error rmse posterior estimate actual observation computed lowest x rmse belongs third model specification x indicates high predictive power ieee
10.1016/j.media.2018.05.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047641088&doi=10.1016%2fj.media.2018.05.007&partnerID=40&md5=9219cf229d482bbee975a51c58fb21ce 0,model personalization requires estimation patient specific tissue properties form model parameters indirect sparse measurement data moreover low dimensional representation parameter space needed often limited ability reveal underlying tissue heterogeneity result significant uncertainty associated estimated values model parameters left unquantified lead unknown variability model outputs hinder reliable clinical adoption probabilistic estimation model parameters however remains unresolved challenge direct markov chain monte carlo mcmc sampling posterior distribution function pdf parameters infeasible involves repeated evaluations computationally expensive simulation model accelerate inference one popular approach construct computationally efficient surrogate sample approximation however sampling approximation efficiency gained expense sampling accuracy paper address issue integrating surrogate modeling posterior pdf accelerating metropolis hastings mh sampling exact posterior pdf achieved two main components construction gaussian process gp surrogate exact posterior pdf actively selecting training points allow good global approximation accuracy focus regions high posterior probability use gp surrogate improve proposal distribution mh sampling order improve acceptance rate presented framework evaluated estimation local tissue excitability cardiac electrophysiological model synthetic data experiments real data experiments addition obtained posterior distributions model parameters interpreted relation factors contributing parameter uncertainty including different low dimensional representations parameter space parameter non identifiability parameter correlations â© elsevier b v
10.3150/16-BEJ914 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041896923&doi=10.3150%2f16-BEJ914&partnerID=40&md5=c30aa9fe91fe6030097fbc5e05feb869 0,markov chain monte carlo mcmc algorithms used estimate features interest distribution monte carlo error estimation asymptotic normal distribution whose multivariate nature far ignored mcmc community present class multivariate spectral variance estimators asymptotic covariance matrix markov chain central limit theorem provide conditions strong consistency examine finite sample properties multivariate spectral variance estimators eigenvalues context vector autoregressive process order â© isi bs
10.1007/s00024-018-1870-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051455477&doi=10.1007%2fs00024-018-1870-5&partnerID=40&md5=cc3d58310f57efb9cb97f43d3848f9bf 0,present first inversion magnetotelluric mt data using hamiltonian monte carlo algorithm inversion mt data underdetermined problem leads ensemble feasible models given dataset standard approach mt inversion perform deterministic search single solution maximally smooth given data fit threshold alternative approach use markov chain monte carlo mcmc methods used mt inversion explore entire solution space produce suite likely models approach advantage assigning confidence resistivity models leading better geological interpretations recent advances mcmc techniques include u turns sampler nuts efficient rapidly converging method based hamiltonian monte carlo implemented mt inversion uses nuts algorithm model includes fixed number layers variable thickness resistivity well probabilistic smoothing constraints allow sharp smooth transitions present results synthetic study show accuracy technique well fast convergence independence starting models sampling efficiency finally test technique mt data collected site boulia queensland australia show utility geological interpretation ability provide probabilistic estimates features depth basement â© springer international publishing ag part springer nature
10.1007/s00477-018-1571-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048805419&doi=10.1007%2fs00477-018-1571-8&partnerID=40&md5=599bd336377d8e09c276050a2d34d2d2 0,study focus hydrogeological inverse problem specifically targeting monitoring soil moisture variations using tomographic ground penetrating radar gpr travel time data technical challenges exist inversion gpr tomographic data handling non uniqueness nonlinearity high dimensionality unknowns developed new method estimating soil moisture fields crosshole gpr data uses pilot point method provide low dimensional representation relative dielectric permittivity field soil primary object inference field converted soil moisture using petrophysical model integrate multi chain markov chain monte carlo mcmc â€“bayesian inversion framework pilot point concept curved ray gpr travel time model sequential gaussian simulation algorithm estimating dielectric permittivity pilot point locations distributed within tomogram well corresponding geostatistical parameters e spatial correlation range infer dielectric permittivity probability density function thus capturing uncertainty inference multi chain mcmc enables addressing high dimensional inverse problems required inversion setup method scalable terms number chains processors useful computationally demanding bayesian model calibration scientific engineering problems proposed inversion approach successfully approximate posterior density distributions pilot points capture true values computational efficiency accuracy convergence behaviors inversion approach also systematically evaluated comparing inversion results obtained different levels noises observations increased observational data well increased number pilot points â© author
10.1016/j.petrol.2018.04.029 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045686572&doi=10.1016%2fj.petrol.2018.04.029&partnerID=40&md5=2c7f0be35c85f2f7516d8982be24af54 0,history matching crucial step reservoir simulation decision making process field development uncertainty history matching task well known technically computationally challenging several algorithms studied decade assist history matching one algorithms used markov chain monte carlo mcmc capable providing accurate posterior probability density ppd history matched realizations several researchers applied studied mcmc assisted history matching ahm many conventional reservoirs studies performed unconventional reservoirs since difference physics two reservoir types important worthwhile investigating performance ahm unconventional reservoirs purpose apply ahm workflow using proxy based mcmc shale oil well vaca muerta formation demonstrate application workflow highlight lessons learnt direct mcmc also performed field case compare accuracy efficiency first method study design experiment doe used selecting influential uncertain parameters performing either two mcmc methods found direct mcmc find enough solutions construct statistically meaningful ppd efficient manner contrast proxy based mcmc less computationally demanding direct mcmc efficient enough construct ppd tested workflow used probabilistically forecast cumulative oil water production well oil recovery factor vaca muerta well â© elsevier b v
10.4230/LIPIcs.APPROX-RANDOM.2018.36 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052436490&doi=10.4230%2fLIPIcs.APPROX-RANDOM.2018.36&partnerID=40&md5=d9af2f50420dce1ad57f1fc9dde239b6 0,consider well studied problem uniformly sampling bipartite graphs given degree sequence equivalently uniform sampling binary matrices fixed row column sums particular focus markov chain monte carlo mcmc approaches proceed making small changes preserve degree sequence given graph markov chains converge uniform distribution challenge show quickly e rapidly mixing standard example markov chain approach sampling bipartite graphs switch algorithm proceeds locally switching two edges preserving degree sequence curveball algorithm variation approach essentially multiple switches trades performed simultaneously goal speeding switch based algorithms even though curveball algorithm expected mix faster switch based algorithms many degree sequences nothing currently known mixing time hand switch algorithm proven rapidly mixing several classes degree sequences work present first results regarding mixing time curveball algorithm give theoretical comparison switch curveball algorithms terms underlying markov chains main result show curveball chain rapidly mixing whenever switch based chain rapidly mixing using novel state space graph decomposition switch chain johnson graphs decomposition independent interest â© aditya bhaskara srivatsan kumar
10.1109/TVT.2018.2822943 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051649424&doi=10.1109%2fTVT.2018.2822943&partnerID=40&md5=7672989592bc0600dd9ee7bd66c70435 0,paper low complexity soft decision detectors orthogonal frequency division multiplexing index modulation ofdm im single two level coded modulation systems studied single level coded ofdm im bitwise markov chain monte carlo b mcmc detector overcome drawback conventional symbolwise mcmc detector signal vectors obtained gibbs sampling trapped activation pattern ap initial vector integrating randomized step alleviate stalling problem randomized b mcmc detector proposed two level coded ofdm im framework iterative multistage decoding imsd two component detectors ap symbol information respectively employed reduce complexity imsd efficient processing multiplicative interference component detectors proposed finally effectiveness proposed detectors verified computer simulations â© ieee
10.1145/3186327 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053426775&doi=10.1145%2f3186327&partnerID=40&md5=a6fa11dd07be269012ec2e6f78690df8 0,article addresses statistical output analysis transient simulations parallel computing environment fixed computing time using parallel computing commonly used unbiased estimators based output sequence compromise rectify issue article proposes estimation procedure bayesian framework proposed procedure particularly useful computing time depends output value simulation replication effectiveness method demonstrated studies queuing simulation control chart simulation â© acm
10.4230/LIPIcs.APPROX-RANDOM.2018.57 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052449379&doi=10.4230%2fLIPIcs.APPROX-RANDOM.2018.57&partnerID=40&md5=6c5d8ada57056bf57fa73e1c76212b26 0,consider problem sampling proper k coloring graph maximal degree î” uniformly random describe new markov chain sampling colorings show mixes rapidly graphs logarithmically bounded pathwidth îº â‰¥ + ïµ î” ïµ using hybrid paths argument â© aditya bhaskara srivatsan kumar
10.3150/16-BEJ911 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041908437&doi=10.3150%2f16-BEJ911&partnerID=40&md5=40e4a2f4cf0852ff7b1e8bed52f53b85 1,provide general methodology unbiased estimation intractable stochastic models consider situations target distribution written appropriate limit distributions conventional approaches require truncation representation leading systematic bias example target distribution might representable l limit basis expansion suitable hilbert space alternatively distribution interest might representable weak limit sequence random variables mcmc main motivation comes infinite dimensional models parameterised terms series expansion basis functions given karhunen loeve expansion introduce analyse schemes direct unbiased estimation along expansion however substantial component paper devoted study mcmc schemes due infinite dimensionality directly implemented effectively estimated unbiasedly methods give theory justify numerical stability robust monte carlo implementation cases illustrate using simulations interestingly computational efficiency methods usually comparable simpler methods biased crucial effectiveness proposed methodology construction appropriate couplings many resonate strongly monte carlo constructions used coupling past algorithm â© isi bs
10.1016/j.csda.2018.02.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044112773&doi=10.1016%2fj.csda.2018.02.009&partnerID=40&md5=7434355e1e0ef0c394608ae14b61f50d 0,likelihood free methods approximate bayesian computation powerful tools practical inference problems intractable likelihood functions markov chain monte carlo sequential monte carlo variants approximate bayesian computation effective techniques sampling posterior distributions approximate bayesian computation setting however without careful consideration convergence criteria selection proposal kernels methods lead biased inference computationally inefficient sampling contrast rejection sampling approximate bayesian computation despite computationally intensive results independent identically distributed samples approximated posterior alternative method proposed acceleration likelihood free bayesian inference applies multilevel monte carlo variance reduction techniques directly rejection sampling resulting method retains accuracy advantages rejection sampling significantly improving computational efficiency â© elsevier b v
10.1016/j.scitotenv.2018.02.302 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043333827&doi=10.1016%2fj.scitotenv.2018.02.302&partnerID=40&md5=eb222a8d2078722f09981e45031f3c5c 0,spatial modelling environmental data commonly considers spatial variability single source uncertainty reality however measurement errors also accounted recent years infrared spectroscopy shown offer low cost yet invaluable information needed digital soil mapping meaningful spatial scales land management however spectrally inferred soil carbon data known less accurate compared laboratory analysed measurements study establishes methodology filter measurement error variability incorporating measurement error variance spatial covariance structure model study carried lower hunter valley new south wales australia combination laboratory measured vis nir mir inferred topsoil subsoil soil carbon data available investigated applicability residual maximum likelihood reml markov chain monte carlo mcmc simulation methods generate parameters matã©rn covariance function directly data presence measurement error results revealed measurement error effectively filtered proposed technique measurement error filtered data prediction variance almost halved ultimately yielded greater certainty spatial predictions soil carbon mcmc technique successfully used define posterior distribution measurement error important outcome mcmc technique used estimate measurement error explicitly quantified although study dealt soil carbon data method amenable filtering measurement error kind continuous spatial environmental data â© elsevier b v
10.1007/s00158-018-1911-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042094124&doi=10.1007%2fs00158-018-1911-9&partnerID=40&md5=20ae92005f9e1383b32885d74a1cd69e 0,structural reliability analysis time consuming performance functions innovative design experiment doe strategy kriging model proposed named stepwise accuracy improvement strategy epistemic randomness performance value point provided kriging model used derive accuracy measure kriging model basic idea proposed strategy enhance accuracy kriging model best next point largest improvement regard accuracy measure optimization problem developed define best next point objective function expectation quantifies much untried point enhance accuracy kriging model markov chain monte carlo sampling gaussâ€“hermite quadrature employed make several approximations solve optimization problem get best next point structural reliability analysis method also constructed based proposed strategy accuracy measure employed several examples studied results validate advantages proposed doe strategy â© springer verlag gmbh germany part springer nature
10.1016/j.ress.2018.04.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045273076&doi=10.1016%2fj.ress.2018.04.001&partnerID=40&md5=2bf9f67ad24a2dd8a644123b0519d0ba 0,hydraulic reliability sensitivity analysis large scale water distribution systems presence uncertainty considered work assessment network reliability sensitivity performed efficient markov chain monte carlo method namely subset simulation prescribed nodal heads storage tanks nodal demands pipe roughness coefficients modeled uncertain parameters described probabilistic manner failure assumed occur minimum nodal head network lower minimum allowable value efficiency proposed method demonstrated analysis real water distribution network consisting large number nodes pipes order thousands corresponding reliability problem represents high dimensional problem approach gives important insight performance reliability sensitivity class complex utility networks â© elsevier ltd
10.1016/j.ast.2018.05.050 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048742215&doi=10.1016%2fj.ast.2018.05.050&partnerID=40&md5=0642b09382ae7c1cfef7157cbe76562b 0,failure probability based global sensitivity measure detect effect input variables structural failure probability provide useful information reliability based design paper new efficient simulation method proposed estimate failure probability based global sensitivity measure proposed method based bayesâ€™ theorem importance sampling markov chain simulation bayesâ€™ theorem used provide single loop simulation method importance sampling markov chain simulation used reduce computational cost compared traditional double loop monte carlo simulation method proposed method requires single set samples estimate failure probability based global sensitivity measure computational cost depend dimensionality input variables finally one numerical example two engineering examples presented illustrate accuracy efficiency proposed method â© elsevier masson sas
10.3150/17-BEJ932 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041895827&doi=10.3150%2f17-BEJ932&partnerID=40&md5=11dda07b0e1d23a47b5e7d861a3f6f12 0,paper defines approximation scheme solution poisson equation geometrically ergodic metropolis hastings chain scheme based idea weak approximation gives rise natural sequence control variates ergodic average sk f = k k i= f f force function poisson equation main results show sequence asymptotic variances clts control variate estimators converges zero give rate convergence numerical examples case double well potential discussed â© isi bs
10.1016/j.compgeo.2018.04.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045747493&doi=10.1016%2fj.compgeo.2018.04.006&partnerID=40&md5=01b1e7333818da9ed63c05b862d863cf 0,late various constitutive models proposed literature purpose capturing various complex physical mechanisms governing creep behavior soft soil however complex model greater number associated uncertain parameters less robustness study bayesian model class selection approach applied select plausible suitable model describing creep behavior soft soil using laboratory measurements total one elastic plastic ep model eight elastic viscoplastic evp models investigated assess performance different models prediction creep behavior soft soils bayesian model class selection respectively performed using oedometer test data intact samples vanttila clay reconstituted samples hong kong marine clay collected literature unknown model parameters identified simultaneously adopting transitional markov chain monte carlo tmcmc method uncertainty quantified obtained posterior probability density functions pdfs result shows proposed method excellent candidate identifying plausible model associated parameters different kinds soft soils approach also provides uncertainty evaluation model prediction based given data â©
10.1007/s11356-018-2409-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047956574&doi=10.1007%2fs11356-018-2409-0&partnerID=40&md5=e4c561a8e2e1d076bc9732a7b2234585 0,drought main abiotic stress seriously influencing wheat production information inheritance drought tolerance necessary determine appropriate strategy develop tolerant cultivars populations study generation means analysis identify genetic effects controlling grain yield inheritance water deficit normal conditions considered model selection problem bayesian framework stochastic search variable selection ssvs applied identify important genetic effects best fitted models using different generations obtained two crosses applying two water regimes two growing seasons ssvs used evaluate effect variable dependent variable via posterior variable inclusion probabilities model highest posterior probability selected best model study grain yield controlled main effects additive non additive effects epistatic results demonstrate breeding methods recurrent selection subsequent pedigree method hybrid production useful improve grain yield â© springer verlag gmbh germany part springer nature
10.1002/env.2460 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026457410&doi=10.1002%2fenv.2460&partnerID=40&md5=10ef42f49c67e0e8c190dfd814e29ada 0,future behavior west antarctic ice sheet wais may major impact future climate instance ice sheet melt may contribute significantly global sea level rise understanding current state wais therefore great interest wais drained fast flowing glaciers major contributors ice loss hence understanding stability dynamics glaciers critical predicting future ice sheet glacier dynamics driven interplay topography temperature basal conditions beneath ice glacier dynamics model describes interactions processes develop hierarchical bayesian model integrates multiple ice sheet surface data sets glacier dynamics model approach allows us infer important parameters describing glacier dynamics b learn ice sheet thickness c account errors observations model relatively dense accurate ice thickness data thwaites glacier west antarctica use data validate proposed approach long term goal work general model may used study multiple glaciers antarctic copyright â© john wiley sons ltd
10.1016/j.csda.2018.03.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044919583&doi=10.1016%2fj.csda.2018.03.007&partnerID=40&md5=49a172b065c5684c445200c78f53d566 0,recent advances overfitting bayesian mixture models provide solid straightforward approach inferring underlying number clusters model parameters heterogeneous datasets applicability framework clustering correlated high dimensional data demonstrated purpose overfitting mixture factor analyzers introduced assuming number factors fixed markov chain monte carlo mcmc sampler combined prior parallel tempering scheme used estimate posterior distribution model parameters optimal number factors estimated using information criteria identifiability issues related label switching problem dealt post processing simulated mcmc sample relabeling algorithms method benchmarked state art software maximum likelihood estimation mixtures factor analyzers using extensive simulation study finally applicability method illustrated publicly available data â© elsevier b v
10.1111/rssc.12259 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050252151&doi=10.1111%2frssc.12259&partnerID=40&md5=3ea9d8d3577ff90a8162bfe1db63f846 0,many data sets especially surveys made available users weights derivation weights known information often incorporated user substantive model model interest derivation unknown established procedure carry weighted analysis however non trivial proportions missing data inefficient may biased data missing random bayesian approaches provide natural approach imputation missing data unclear handle weights propose weighted bootstrap markov chain monte carlo algorithm estimation inference simulation study shows good inferential properties illustrate utility analysis data millennium cohort study â© royal statistical society
10.1214/17-AAP1365 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052710300&doi=10.1214%2f17-AAP1365&partnerID=40&md5=45bf1684e049084390a4ec6a3231a231 0,introduce markov chain sampling uniform distribution riemannian manifold call geodesic walk prove mixing time walk manifold positive sectional curvature cx u v bounded lt â‰¤ cx u v â‰¤ lt âˆž oâˆ— particular bound mixing time depend explicitly dimension manifold special case boundary convex body give explicit computationally tractable algorithm approximating exact geodesic walk consequence obtain algorithm sampling uniformly surface convex body running time bounded solely terms curvature body â© institute mathematical statistics
10.1214/17-AAP1358 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052684601&doi=10.1214%2f17-AAP1358&partnerID=40&md5=4cfd12752c33e9870a85a42bfd087e88 0,show class l functions ergodic averages reversible markov chain finite asymptotic variance determined class l functions ergodic averages associated jump chain finite asymptotic variance allows us characterize completely ergodic averages finite asymptotic variance markov chain independence sampler practical perspective important result identifies simple sufficient condition ergodic averages l functions primary variable pseudo marginal markov chain finite asymptotic variance â© institute mathematical statistics
10.3390/e20080569 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052203710&doi=10.3390%2fe20080569&partnerID=40&md5=eed5ca09b01341c81711d26ccbab13f1 0,parameter estimation one key technologies system identification bayesian parameter estimation algorithms important identifying stochastic systems paper random finite set based algorithm proposed overcome disadvantages existing bayesian parameter estimation algorithms estimate unknown parameters stochastic system consists varying number constituent elements using measurements disturbed false detections missed detections noises models used parameter estimation constructed using random finite set based proposed system model measurement model key principles formula derivation proposed algorithm detailed implementation algorithm presented using sequential monte carlo based probability hypothesis density phd filter simulated tempering based importance sampling finally experiments systematic errors estimation multiple sensors provided prove main advantages proposed algorithm sensitivity analysis carried study mechanism algorithm experimental results verify superiority proposed algorithm â© authors
10.1029/2017JB015418 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051217570&doi=10.1029%2f2017JB015418&partnerID=40&md5=7c13cc6218251400a9ee4fb6e847c717 3,paper shows imaging interior solid bodies fully nonlinear physics highly beneficial compared imaging equivalent linearized tomographic methods true variety different types physics including full nonlinearity provides interpretable uncertainties far greater depth image penetration unknown targets earth subsurface use adaptively parameterized monte carlo method invert electrical resistivity data conductivity structure earth demonstrate method two field data sets key results include observation directly interpretable uncertainty loops define possible geometrical variations edges isolated anomalies hence quantifying spatial resolution boundaries topologies uncertainties similar observed performing fully nonlinear seismic traveltime tomography shows loop like uncertainty topologies expected solutions wide variety tomographic problems using variety data types hence laws physics laplace equation previous work eikonal ray equations also show depth construct tomographic image using electrical data extended factor using nonlinear methods compared linearized inversion using common standard linearized programs advantages come cost significantly increased computation results illustrated synthetic real data examples â© american geophysical union rights reserved
10.1177/0962280216682284 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049881536&doi=10.1177%2f0962280216682284&partnerID=40&md5=430737b9632ee128488a6728708c66ad 0,population based cancer screening often asked hardly addressed question â€œhow many rounds screening required identifying cancer interest staying pre clinical detectable phase pcdp â€� also similar one related number screens required stopping screening low risk group answered using longitudinal follow data repeated rounds screen namely periodic screen kind data rather complicated fraught intractable statistical properties including correlated multistate outcomes unobserved incomplete censoring truncation information imperfect measurements therefore developed negative binomial family based discrete time stochastic process taking sensitivity specificity account accommodate thorny issues estimation parameters implemented bayesian markov chain monte carlo method demonstrated apply proposed negative binomial family based model empirical data similar finnish breast cancer screening program â© author
779.9413399734049 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052928611&partnerID=40&md5=48e5e17754ea9290edc04ab6adc95226 0,modeling continuous time physiological processes manifest patientâ€™s evolving clinical states key step approaching many problems healthcare paper develop hidden absorbing semi markov model hasmm versatile probabilistic model capable capturing modern electronic health record ehr data unlike existing models hasmm accommodates irregularly sampled temporally correlated informatively censored physiological data describe non stationary clinical state transitions learning hasmm parameters ehr data achieved via novel forward filtering backward sampling monte carlo em algorithm exploits knowledge end point clinical outcomes informative censoring ehr data implements e step sequentially sampling patientsâ€™ clinical states reverse time direction conditioning future states real time inferences drawn via forward filtering algorithm operates virtually constructed discrete time embedded markov chain mirrors patientâ€™s continuous time state trajectory demonstrate prognostic utility hasmm critical care prognosis setting using real world dataset patients admitted ronald reagan ucla medical center particular show using hasmms patientâ€™s clinical deterioration predicted hours prior intensive care unit admission auc gain compared rothman index state art critical care risk scoring technology â© ahmed alaa mihaela van der schaar
10.1145/3161569 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053402202&doi=10.1145%2f3161569&partnerID=40&md5=f08fbaf92c8b886f06ad53cc45b6a991 0,introduce path zva efficient simulation technique estimating probability reaching rare goal state regeneration state discrete time markov chain standard monte carlo simulation techniques work well rare events use importance sampling e change probability measure governing markov chain transitions towards goal state become likely need idea distance goal state level knowledge markov chain required article use graph analysis obtain knowledge particular focus knowledge shortest paths terms rare transitions goal state show subset possibly huge state space needs considered effective high dependability system primarily due high component reliability less due high redundancies several models compare results well known importance sampling methods literature demonstrate large potential gains method â© acm
10.1007/s00181-017-1409-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040019823&doi=10.1007%2fs00181-017-1409-0&partnerID=40&md5=7915ebb47b11ffc12f0f7b093f043b42 0,paper proposes generalized spatial panel data probit model spatial autocorrelation dependent variable time invariant individual shocks remainder disturbances proposes estimation bayesian markov chain monte carlo procedure simulation results show proposed estimation method performs well small medium sized samples method applied analysis export market participation chinese firms prefecture level city wenzhou province zhejiang empirical results show two three forms hypothesized spatial autocorrelation significant namely spatial lag dependent variable time invariant firm specific shocks time variant shocks ignoring significant spatial effects lead misspecification â© springer verlag gmbh germany part springer nature
10.1016/j.pnucene.2018.04.015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046168452&doi=10.1016%2fj.pnucene.2018.04.015&partnerID=40&md5=601413cb4cb72271d480ab680ffe8606 0,mcnpx general purpose monte carlo radiation transport code designed track many particle types broad ranges energies potential deal accelerator driven system ads problems neutronics design analysis ads using mcnpx code significantly complex mainly constructing three dimensional geometry model especially additional spallation target coupled subcritical reactor constructed abundant nested repeated structures several levels modeling process long recognized time consuming tedious error prone task hard master novice users therefore imperative build code system translate cad models ads native language mcnpx code context demand code system named cad psmc freecad based parsing script mcnpx code developed solve ads modeling conversion problems framework code hierarchical tree based basic geometry classes boolean affine operations established mapping relationship mcnpx code additionally ray casting technology markov chain based iteration method proposed solve problem spline surfaces complex geometries finally applicability accuracy cad psmc code demonstrated comparing various reference models numerical calculation results â© elsevier ltd
10.5588/ijtld.17.0869 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049746027&doi=10.5588%2fijtld.17.0869&partnerID=40&md5=c9ef228bacfbbecad2b30e4e05fe5b94 1,b c k g r u n adverse drug reactions adrs common standard long course treatment multidrug resistant rifampicin resistant tuberculosis mdr rr tb particular second line injectables slis associated permanent hearing loss acute renal injury electrolyte imbalance adapted established markov model ambulatory treatment estimate impact toxicity profile incremental cost effectiveness ratio icer proposed mdr rr tb regimen replacing sli bedaquiline bdq e h treatment effectiveness evaluated disability adjusted life years dalys clinical outcomes ingredient costs provider perspective derived south african public sector treatment program extracted literature costs effectiveness discounted per year years r e u l bdq based mdr rr tb regimen compared sli regimen mean icer us per daly averted using standard markov model costs regimens increased effectiveness decreased sli regimen adjusted toxicity resulting icer bdq based regimen cost saving us patient effective dalys averted adjusting adrs c n c l u n decision analysis models treatment mdr rr tb including new drug regimens consider costs managing adrs sequelae â© union
10.1016/j.csda.2018.02.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044477732&doi=10.1016%2fj.csda.2018.02.007&partnerID=40&md5=f3e54f179f0dee5609e060fbb5f3163a 1,bayesian methods flexible time event models usually rely theory markov chain monte carlo mcmc sample posterior distributions perform statistical inference techniques often plagued several potential issues high posterior correlation parameters slow chain convergence foremost strong computational cost novel methodology proposed overcome inconvenient facets intrinsic mcmc sampling major advantage posterior distributions latent variables rapidly approximated high level accuracy achieved exploiting synergy laplace method posterior approximations p splines flexible tool nonparametric modeling methodology developed class cure survival models useful extension standard time event models assumed unknown proportion unidentified cured units never experience monitored event attractive feature new approach point estimators credible intervals straightforwardly constructed even complex functionals latent model variables properties proposed methodology evaluated using simulations illustrated two real datasets fast computational speed accurate results suggest combination p splines laplace approximations considered serious competitor mcmc make inference semi parametric models illustrated survival models cure fraction â© elsevier b v
10.1007/s11769-018-0975-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049948815&doi=10.1007%2fs11769-018-0975-1&partnerID=40&md5=2ab8e857658621c42881d265ac07d4ea 0,article propose novel multilevel dynamic factor model determine endogenously clustered regions investigation regional clustering synchronization provincial business fluctuations china parameter identification model estimation conducted using markov chain monte carlo method conducted empirical study provincial business fluctuations china chinese provinces considered except hong kong macau taiwan due data unavailability sampled january december results indicated provinces clustered four regions leading coincident lagging overshooting comparison traditional geographical divisions novel clustering four regions enabled regional business cycle synchronization accurately captured within four regional clusters possible identify substantial heterogeneities among regional business cycle fluctuations especially periods financial crisis â€˜four trillion economic stimulus planâ€™ â© science press northeast institute geography agricultural ecology cas springer verlag gmbh germany part springer nature
10.1016/j.taap.2018.05.033 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048476414&doi=10.1016%2fj.taap.2018.05.033&partnerID=40&md5=bcd189c8f6023060f13c7edd73a7b1ca 0,background perchloroethylene perc induced target organ toxicity associated tissue specific metabolic pathways previous physiologically based pharmacokinetic pbpk modeling perc accurately predicted oxidative metabolites suggested need better characterize glutathione gsh conjugation well toxicokinetic uncertainty variability objectives updated previously published â€œharmonizedâ€� perc pbpk model mice better characterize gsh conjugation metabolism well uncertainty variability perc toxicokinetics methods updated pbpk model includes expanded models perc oxidative metabolite trichloroacetic acid tca physiologically based sub models conjugative metabolites previously compiled mouse kinetic data b c f swiss webster mice augmented include data recent study male c bl j mice measured perc metabolites serum multiple tissues hierarchical bayesian population analysis using markov chain monte carlo conducted characterize uncertainty inter strain variability perc metabolism results updated model fit data well better previously published â€œharmonizedâ€� pbpk model tissue dosimetry oxidative conjugative metabolites successfully predicted across three strains mice estimated residuals errors fold majority data inter strain variability across three strains evident oxidative metabolism gsh conjugation data available one strain conclusions updated pbpk model fills critical data gap quantitative risk assessment predicting internal dosimetry perc oxidative gsh conjugation metabolites lays groundwork future studies better characterize toxicokinetic variability â© elsevier inc
10.1007/s10450-018-9958-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050796380&doi=10.1007%2fs10450-018-9958-x&partnerID=40&md5=eeb81a34c2dec015b4c01d215435a461 0,paper reports results international interlaboratory study led national institute standards technology nist measurement high pressure surface excess carbon dioxide adsorption isotherms nist reference material rm ammonium zsm zeolite â k â â°c â kpa â mpa eleven laboratories participated exercise first time high pressure adsorption reference data reported using reference material empirical reference equation nex=d +exp ln p +a b c nex surface excess uptake mmol g p equilibrium pressure mpa = âˆ’ b = c = = along uncertainty interval uk = = â mmol g determined reference isotherm using bayesian markov chain monte carlo method together zeolitic reference material associated adsorption data provide means laboratories test validate high pressure adsorption equipment measurements recommendations provided measuring reliable high pressure adsorption isotherms using material including activation procedures data processing methods determine surface excess uptake appropriate equation state used â© author
10.1016/j.jhydrol.2018.06.043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049305594&doi=10.1016%2fj.jhydrol.2018.06.043&partnerID=40&md5=e7fe7becb7b0df3a015d92fcd1ed7438 0,statistical calibration flow transport models unsaturated porous media often carried markov chain monte carlo mcmc methods however practicality methods limited computational requirement particularly large prior intervals assigned model parameters work new operational strategy investigated alleviate computational burden mcmc samplers using results preliminary calibration performed first order approximation foa method new strategy posterior distribution approximated using high order polynomial chaos expansion pce surrogate model constructed reduced parameter ranges latter obtained foa confidence intervals two challenging test cases investigated assess efficiency accuracy new strategy first test case considers estimation flow pesticide transport parameters synthetic infiltration experiment second test case deals assessment unsaturated hydraulic soil parameters real word laboratory drainage experiment results proposed strategy compared foa standard mcmc method improved mcmc method sampler preconditioned draws foa posterior distribution test cases new strategy provides accurate mean estimated parameter values uncertainty regions much efficient mcmc methods times efficient standard mcmc method â© elsevier b v
10.1007/s11239-018-1694-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048586866&doi=10.1007%2fs11239-018-1694-2&partnerID=40&md5=78ba45ce705d26579044c041c09b1d95 0,abstract available
10.1093/GJI/GGY163 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052529694&doi=10.1093%2fGJI%2fGGY163&partnerID=40&md5=8858b87d389a0b4eb17cd14d1e07f819 0,introduce new bayesian inversion method estimates spatial distribution geological facies attributes seismic data showing usual probabilistic inverse problem solved using optimization framework still providing full probabilistic results mathematical model consists seismic attributes observed data assumed generated geological facies method infers post inversion posterior probability density facies plus unknown model parameters seismic attributes geological prior information previous research domain based localized likelihoods assumption whereby seismic attributes location assumed depend facies location assumption unrealistic imperfect seismic data acquisition processing fundamental limitations seismic imaging methods paper relax assumption allow probabilistic dependence seismic attributes location facies neighbourhood location spatial filter term likelihoods quasilocalized exact bayesian inference impractical requires normalization posterior distribution intractable large models must approximated stochastic sampling e g using markov chain monte carlo commonly used approximate inference method computationally expensive detection convergence often subjective unreliable use variational bayes method efficient alternative offers reliable detection convergence achieves replacing intractable posterior distribution tractable approximation inference performed using approximate distribution optimization framework thus circumventing need sampling still providing probabilistic results show noisy synthetic example new method recovered coefficients spatial filter reasonable accuracy recovered correct facies distribution also show method robust weak prior information non localized likelihoods outperforms previous methods require likelihoods localized method computationally efficient expected applicable models realistic size modern computers without incurring significant computational limitations â© authors
10.1016/j.jeconom.2018.01.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047229242&doi=10.1016%2fj.jeconom.2018.01.009&partnerID=40&md5=e7bfc3a46c7bb2527cb57457eaba20d8 0,draw inference serial extremal dependence within heavy tailed markov chains drees et al proposed nonparametric estimators spectral tail process methodology extended general setting stationary regularly varying time series large sample distribution estimators derived via empirical process theory cluster functionals finite sample performance estimators evaluated via monte carlo simulations moreover two different bootstrap schemes employed yield confidence intervals pre asymptotic spectral tail process stationary bootstrap multiplier block bootstrap estimators applied stock price data study persistence positive negative shocks â©
10.1016/j.electstud.2018.05.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047256789&doi=10.1016%2fj.electstud.2018.05.002&partnerID=40&md5=31cd4b52237dd27bb212f00053f66739 0,poll based methods used forecast elections various countries settings common factor models inclusion time dependent variable model evolution public support party cause time typically variable modeled random walk problematic underlying assumptions random walk restrictive hold empirically propose flexible alternative time dependent variable modeled using ideas time series analysis approach embedded generic model allows inclusion various covariates rely bayesian estimation techniques using markov chain monte carlo algorithms credible intervals obtained straightforward include uncertainty estimated parameters forecasts application model german federal election indicates benefits new approach â© elsevier ltd
10.1016/j.spl.2018.02.059 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045920064&doi=10.1016%2fj.spl.2018.02.059&partnerID=40&md5=9214ae04434538e3627294bda850a1d9 0,paper concerns generalized regime switching garch model capture dynamic behavior volatility financial market four state markov chain regime switching adopted white noise stationary integrated explosive states consider time dependent transition probabilities markov chain derive time dependent probability state assumption conditional normality noise garch model multi step ahead volatility formulated cumulative impulse response function measure persistence volatility discussed monte carlo experiment shows dynamics volatilities time dependent probabilities well behaviors cumulative impulse response functions â© elsevier b v
10.1007/s40300-018-0141-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050038469&doi=10.1007%2fs40300-018-0141-7&partnerID=40&md5=cf519fb04f19c485d42ee2c28bc05ba9 0,paper presents bayesian approach using differential evolution markov chain method estimate parameters failure time distribution percentiles based grouped non grouped degradation data observed failure times modeled linear degradation path model random degradation rates follow log logistic distribution two monte carlo simulation studies conducted first one devoted assess performance proposed method respect mean squared error mse different values scale shape parameters degradation model using small moderate large sample sizes proposed method performs better applied non grouped data compared grouped data second simulation study conducted compare proposed log logistic model weibull degradation model importantly log logistic model outperforms weibull model proposed methods demonstrated modeling real life times laser devices â© sapienza universitã di roma
49.66214358451326 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052970495&partnerID=40&md5=a062dfe8b127bd750d71e5e4a9001f5b 0,graphical models change points computationally challenging fit particularly cases number observation points number nodes graph large focusing gaussian graphical models introduce approximate majorize minimize mm algorithm useful computing change points large graphical models proposed algorithm order magnitude faster brute force search regularity conditions data generating process show high probability algorithm converges value within statistical error true change point fast implementation algorithm using markov chain monte carlo also introduced performances proposed algorithms evaluated synthetic data sets algorithm also used analyze structural changes p period â© leland bybee yves atchadã©
10.3847/1538-4357/aaccfa https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051560186&doi=10.3847%2f1538-4357%2faaccfa&partnerID=40&md5=2be1da393007b3d9d7118d88967c80e0 1,paper uses multi epoch astrometry wide field infrared survey explorer wise demonstrate method measure proper motions trigonometric parallaxes precisions âˆ¼ mas yr âˆ¼ mas respectively low mass stars brown dwarfs method relies wise single exposures level b frames markov chain monte carlo method limitations gaia observing low mass stars brown dwarfs discussed shown wise able measure astrometry past completeness limit magnitude limit gaia l dwarfs fainter g â‰ˆ g = respectively method applied wise data nearby â‰² pc dwarfs spectral types previously measured trigonometric parallaxes also provided wise astrometric measurements additional low mass dwarfs spectral types estimated photometric distances lt pc nine objects contain parallaxes within gaia data release â© american astronomical society
10.1002/env.2478 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031098823&doi=10.1002%2fenv.2478&partnerID=40&md5=01283d3abfb037b1b72dbeed81c67e2e 0,environmental health disease mapping studies often concerned evaluation combined effect various sociodemographic behavioral factors environmental exposures time event outcomes interest death individuals organisms plants studies estimation hazard function often interest addition known explanatory variables hazard function may subject spatial geographical variations proximally located regions may experience hazards similar regions distantly located popular approach handling type spatially correlated time event data cox proportional hazards regression model spatial frailties however proportional hazards assumption poses major practical challenge entails effects various explanatory variables remain constant time assumption often unrealistic instance studies long follow ups effects exposures hazard may vary drastically time goal paper offer flexible semiparametric additive hazards model spatial frailties proposed model allows frailties regression coefficients time varying thus relaxing proportionality assumption estimation framework bayesian powered carefully tailored posterior sampling strategies via markov chain monte carlo techniques apply model dataâ set prostate cancer survival u state louisiana illustrate advantages copyright â© john wiley sons ltd
10.1007/s11069-018-3291-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044580749&doi=10.1007%2fs11069-018-3291-2&partnerID=40&md5=39b176a03e26eef4b7a2289ed03a42b2 1,context climate change essential quantify uncertainty effective design risk management practices present study accessed climate model flood return level uncertainties river basin six high resolution global climate models gcms two representative concentration pathways rcps used project future climate change impact streamflow wainganga river basin uncertainty associated use high resolution multiple gcm treated reliability ensemble average rea followed bias correction bias corrected weighted outputs used input variable infiltration capacity vic model physically based hydrological model calibration validation carried hydrological model parameters vic fixed trial error method uncertainty flood return level associated future projected flows dealt bayesian analysis modelled markov chain monte carlo mcmc simulation technique using metropolisâ€“hastings algorithm non informative prior distribution study provides robust framework help effective decision making adaptation strategies river basin â© springer science+business media b v part springer nature
10.1029/2018JE005574 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053378606&doi=10.1029%2f2018JE005574&partnerID=40&md5=97220ba36889ce2ce3f387ef1f06b502 0,mars lost large fraction water space h component loss thought occur mainly result thermal jeans escape upper atmosphere constraints h loss historically made using hydrogen lyman alpha â nm light scattered planet extended upper atmosphere corona employ observations mars atmosphere volatile evolution maven mission imaging ultraviolet spectrograph iuvs constrain h escape december august maven observed dayside corona low latitude obtain adequate fits address systematic sources uncertainty including instrument calibration fit exobase number density escape rate instead density temperature employing markov chain monte carlo techniques produces better model fits data previous analyses assume single population h atoms obtain h temperatures inconsistent expected trends shape mismatch observed modeled profiles similar previous studies introducing either second population h distinct temperature density adding deuterium corona allows essentially perfect fits despite model ambiguity derived loss rates periods within factor four â€“ ã— cmâˆ’ december lsâˆ¼ â€“ ã— cmâˆ’ august lsâˆ¼ rates similar found prior studies confirm known seasonal trendâ€”doing incorporating substantial uncertainty absolute calibration insufficiently explored previous studies â© american geophysical union rights reserved
10.1371/journal.pone.0201892 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052837063&doi=10.1371%2fjournal.pone.0201892&partnerID=40&md5=f067a8ec3ad677efcb4acdd10b469fd3 0,measurements energy balance components energy intake energy expenditure changes energy stores often plagued measurement error doubly labeled water measure energy intake ei negligible error expensive cumbersome alternative approach gaining popularity use energy balance principle measuring energy expenditure ee change energy stores es back calculate ei gold standard methods ee es exist known give accurate measurements albeit high cost propose joint statistical model assess measurement error cheaper non intrusive measures ee es let unknown true ee es individuals latent variables model using bivariate distribution try bivariate normal well dirichlet process mixture model compare results via simulation approach first account dependencies exist individualsâ€™ daily ee es employ semiparametric regression free knot splines measurements error linear components error free covariates adopt bayesian approach estimation inference use reversible jump markov chain monte carlo generate draws posterior distribution based semipar ameteric regression develop calibration equation adjusts cheaper less reliable estimate closer true value along calibrated value method also gives credible intervals assess uncertainty simulation study shows calibration helps produce accurate estimate approach compares favorably terms prediction commonly used models open access article free copyright may freely reproduced distributed transmitted modified built upon otherwise used anyone lawful purpose work made available creative commons cc public domain dedication
10.1214/17-AOS1597 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048035074&doi=10.1214%2f17-AOS1597&partnerID=40&md5=b57509473af27c881c0a8a16074e5bd8 2,consider bayesian situation observe âˆ¼ pî î âˆˆ family î½h h âˆˆ h potential prior distributions let g real valued function î let ig h posterior expectation g î prior î½h interested two problems selecting particular value h ii estimating family posterior expectations ig h h âˆˆ h let h marginal likelihood hyperparameter h h = pî î½h dî empirical bayes estimate h definition value h maximizes h turns typically possible use markov chain monte carlo form point estimates h ig h individual h continuum also confidence intervals h ig h valid pointwise however interested forming estimates confidence statements entire families integrals h h âˆˆ h ig h h âˆˆ h need estimates first family order carry empirical bayes inference need estimates second family order bayesian sensitivity analysis establish strong consistency functional central limit theorems estimates families using tools empirical process theory give two applications one latent dirichlet allocation used topic modeling model bayesian variable selection linear regression â© institute mathematical statistics
10.1371/journal.pone.0201209 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053513036&doi=10.1371%2fjournal.pone.0201209&partnerID=40&md5=061a49fa6b3dd64062c456b19c1154d7 0,japanese encephalitis je important cause human encephalitis throughout asia pacific although je vector borne disease demonstrated experimentally transmission pigs occur direct contact whether pig pig transmission plays role natural epidemiological cycle je remains unknown assess whether direct transmission pigs may occur field conditions built two mathematical models je transmission incorporating vector borne transmission alone combination vector borne direct transmission used markov chain monte carlo mcmc techniques estimate parameters models fitted models two serological datasets collected longitudinally two pig cohorts c c two periods four months farm outskirts phnom penh cambodia ii cross sectional cs serological survey dataset collected swine coming eight different provinces cambodia cases model incorporating vector borne direct transmission better explained data computed value basic reproduction number r c c cs well vector borne reproduction number rpv direct transmission reproduction number rpp determined contribution direct transmission r c c cs according results existence pig pig transmission consistent swine serological data thus direct transmission may contribute epidemiological cycle je cambodia results need confirmed eco climatic settings particular temperate areas pig pig transmission may facilitate persistence je virus jev cold seasons mosquitoes â© diallo et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.3997/1873-0604.2017065 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053739015&doi=10.3997%2f1873-0604.2017065&partnerID=40&md5=0aaf166c7b6cf341c810f7934dc5c4c3 2,induced polarization phenomenon time domain frequency domain often parameterised using empirical cole cole model improve resolution model parameters decrease parameter correlations inversion process induced polarization data suggest three parameterisations cole cole model namely maximum phase angle cole cole model maximum imaginary conductivity cole cole model minimum imaginary resistivity cole cole model maximum phase angle cole cole model uses maximum phase ï†max inverse phase peak frequency ï„ï† instead intrinsic charge ability time constant adopted classic cole cole model maximum imaginary conductivity cole cole model uses maximum imaginary conductivity ïƒmax â€³ instead time constant ï„ïƒ cole cole model conductivity form minimum imaginary resistivity cole cole model uses minimum imaginary resistivity ï�min â€³ instead time constant ï„ï� cole cole model resistivity form effects three parameterisations tested synthetic timedomain frequency domain data using markov chain monte carlo inversion method allows easy quantification parameter uncertainty field data using gradient based inversion comparison classic cole cole model found three parameterisations model parameters less correlated consequently better resolved time domain frequency domain data increase model resolution particularly significant models poorly resolved using classic cole cole parameterisation instance low values frequency exponent low signal noise ratio general leads significantly deeper depth investigation ï†max ïƒmax â€³ ï�min â€³ parameters compared classic parameter shown field example believe use reparameterisations inverting field data contribute narrow gap induced polarization theory laboratory findings field applications â© eage publishing bv rights reserved
10.1371/journal.pone.0201872 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052061614&doi=10.1371%2fjournal.pone.0201872&partnerID=40&md5=f0548f78f574a6ad868e23343a1ee7fe 0,paper propose novel object tracking algorithm using high dimensional particle filter combined features firstly refined two dimensional principal component analysis tendency combined represent object secondly present framework using high order monte carlo markov chain considers information performs discriminative efficient moving objects traditional first order particle filtering finally advanced sequential importance resampling applied estimate posterior density obtains high quality particles gain better samples k means clustering used select typical particles reduces computational cost qualitative quantitative evaluations challenging image sequences demonstrate performance proposed algorithm superior state art methods â© liu et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1140/epjc/s10052-018-6101-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051739518&doi=10.1140%2fepjc%2fs10052-018-6101-9&partnerID=40&md5=6270e083f06048d3581f1630e0597d03 0,approximate dual representation non abelian lattice gauge theories terms new set dynamical variables plaquette occupation numbers pons natural numbers discussed expansion indices local series expansion boltzmann factors every plaquette yangâ€“mills action studying constraints due gauge symmetry su gauge theory solved using monte carlo simulations pons configuration weight factor given haar measure integrals links whose integrands products powers plaquettes herein updates limited changes pon plaquette pons coordinate plane markov chain transition probabilities computed employing truncated maximal trees metropolis algorithm algorithm performance investigated different types updates plaquette mean value large range î²s using lattice good agreement conventional heath bath algorithm found strong weak coupling limits deviations latter lt î² lt mass lightest jpc= + + glueball evaluated reproduces results found literature â© author
10.1109/COGSIMA.2018.8423984 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051469526&doi=10.1109%2fCOGSIMA.2018.8423984&partnerID=40&md5=3808e008e779fe834817b8ed74715ba7 0,distributed detection problem consideration correlated sensor observations np hard problem paper heuristic markov chain monte carlo algorithm consists methods slice sampling simulated annealing investigated solve problem based criterion minimizing probability error sub optimal solutions including fusion rules sensor decisions acquired performance algorithm studied analysis experimental results â© ieee
300.4986610550691 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051542690&partnerID=40&md5=aaa97121b0a00d4b0f5059fde0bfb4f2 0,proceedings contain papers topics discussed include automating behaviour tree generation simulating troop movements situations information evidence situation granularity automatic identification maritime incidents unstructured articles adaptive situational leadership framework high clutter close range wi fi imaging probabilistic learning classifier empirically identified gaps situation awareness model human machine coordination probabilistic time reversal theorem method identify relevant information sufficient answer situation dependent queries situations simulations initial appraisal virtual leadership complex multiorganizational research development programs modelling complex system systems creating situation awareness observer effect act r modeling intelligence analysts perception information improve situational understanding artificial swarms find social optima tactical decision support uav deployment mum helicopter missions distributed detection correlated signal using markov chain monte carlo cognitive support promote shared mental models safety critical situations cardiac surgery interactive decision support framework improve diagnostic processes cancerous diseases using bayesian networks
10.1016/j.ecoenv.2018.03.044 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044612933&doi=10.1016%2fj.ecoenv.2018.03.044&partnerID=40&md5=20a39538f6f3de35b14b86cd95244b70 0,developed analytical means estimating population level effects endocrine disruptors daphnia magna approach based fact endocrine disrupting juvenile hormone analogs induce production male neonates exposed analogs particular period prenatal development method also assumed abnormal production male neonates sake production female neonates reduces population growth constructed linear toxicodynamics model elucidate period magna neonates sensitive exposure analog also probability individual neonate changing sex specific exposure concentrations proposed model applied magna reproduction test data obtained time varying exposure pyriproxyfen derive maximum likelihood estimates posterior distributions model parameters quantitatively assess ecological risk population level conducted population dynamics simulation two time varying exposure scenarios e constant pulsed exposure using age structured population model change sex ratio based time weighted average concentration period sensitivity change sex ratio caused approximately equivalent population level effects reproductive inhibition e reduction total number neonates per female parent regardless exposure scenario contrast change sex ratio based maximum concentration sensitive period change sex ratio caused half population level effects reproductive inhibition constant exposure whereas caused much larger population level effect reproductive inhibition pulsed exposure â© elsevier inc
10.1080/02664763.2017.1391754 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032347757&doi=10.1080%2f02664763.2017.1391754&partnerID=40&md5=ce35f80bc5025486d6999c7f8043f31f 0,choice model framework regression setting depends nature data focus study changepoint data exhibiting three phases incoming outgoing linear joined curved transition bent cable regression appealing statistical tool characterize trajectories quantifying nature transition two linear phases modeling transition quadratic phase unknown width demonstrate quadratic function may appropriate adequately describe many changepoint data propose generalization bent cable model relaxing assumption quadratic bend properties generalized model discussed bayesian approach inference proposed generalized model demonstrated applications three data sets taken environmental science economics also consider comparison among quadratic bent cable generalized bent cable piecewise linear models terms goodness fit analyzing real world simulated data study suggests proposed generalization bent cable model valuable adequately describing changepoint data exhibit either abrupt gradual transition time â© â© informa uk limited trading taylor francis group
10.5194/gmd-11-3027-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050933372&doi=10.5194%2fgmd-11-3027-2018&partnerID=40&md5=989db67c3561d233273c16efe4ff4d1e 1,soil organic carbon soc significant effect carbon emissions climate change however current soc prediction accuracy models low evaluation studies indicate prediction error mainly comes parameter uncertainties improved parameter calibration data assimilation techniques successfully employed parameter calibration soc models however data assimilation algorithms sampling based bayesian markov chain monte carlo mcmc generally high computation costs appropriate complex global land models study proposes new parameter calibration method based surrogate optimization techniques improve prediction accuracy soc experiments three types soil carbon cycle models including community land model carnegie ames stanford approach biogeochemistry submodel clm casa two microbial models show surrogate based optimization method effective efficient terms accuracy cost compared predictions using tuned parameter values bayesian mcmc root mean squared errors rmses predictions using calibrated parameter values surrogate base optimization observations reduced different soc models meanwhile corresponding computational cost lower global optimization algorithms â© author
10.1080/02664763.2017.1401049 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034269172&doi=10.1080%2f02664763.2017.1401049&partnerID=40&md5=14492004de7a71eead0b160a9e294f6e 0,present bayesian approach problem estimating density matrices quantum state tomography general framework presented based suitable mathematical formulation study convergence monte carlo markov chain algorithm given including comparison estimation methods maximum likelihood estimation linear inversion analysis indicates approach recovers underlying parameters quite properly also produces physically acceptable punctual interval estimates prior sensitive study conducted indicating useful prior information available incorporated accurate results obtained general framework based reparameterization model allows easier choice prior proposal distributions metropolisâ€“hastings algorithm â© â© informa uk limited trading taylor amp francis group
10.1515/jtse-2017-0011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050800927&doi=10.1515%2fjtse-2017-0011&partnerID=40&md5=1559f6dd179739fd351181c5bfba9151 0,numerical standard error nse estimate standard deviation simulation result simulation experiment repeated many times review standard methods computing nse perform monte carlo experiments compare performance case high extreme autocorrelation particular propose application risk management assess precision value risk measure underlying risk model estimated simulation based methods overall heteroscedasticity autocorrelation estimators prewhitening perform best presence large extreme autocorrelation â© walter de gruyter gmbh berlin boston
10.1109/TSG.2018.2860783 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050760353&doi=10.1109%2fTSG.2018.2860783&partnerID=40&md5=f37473da59c73aa27e70eeb4c3417d91 0,fast charging stations critical infrastructures enable high penetration plug electric vehicles pevs future distribution networks need carefully planned ensure meeting charging demand well economic benefits accurate estimation pev charging demand prerequisite planning non trivial task paper addresses sizing number chargers waiting spaces problem fast charging stations presents optimal planning solution based explicit temporal soc characterization pev fast charging demand characteristics pev charging demand derived vehicle travel behavior analysis using available statistics pev dynamics charging stations modelled markov chain queuing theory result optimal number chargers waiting spaces fast charging stations jointly determined maximize expected operator profits considering profit charging service penalty waiting rejection well maintenance cost idle facilities proposed solution validated case study mathematical justifications numerical results simulation ieee
10.1093/mnras/sty1079 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048472826&doi=10.1093%2fmnras%2fsty1079&partnerID=40&md5=931afe090d48d7e074f88b805a8ff882 0,extreme mass ratio inspiral observations future space based gravitational wave detectors lisa enable strong field tests general relativity unprecedented precision prohibitive computational cost existing statistical techniques used one test currently employed ligo black hole binary mergers generic deviations relativity represented n deformation parameters generalized waveform model bayesian evidence n combinatorial submodels combined posterior odds ratio modified gravity relativity null hypothesis test adapt apply test generalized model extreme mass ratio inspirals constructed deformed black hole spacetimes focus investigation computational efficiency increased evidence free method model selection method akin algorithm known product space markov chain monte carlo uses nested sampling improved error estimates rethreading technique perform benchmarking robustness checks method find order magnitude computational gains regular nested sampling case synthetic data generated null model â© author published oxford university press behalf royal astronomical society
10.1109/VTCSpring.2018.8417572 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050967387&doi=10.1109%2fVTCSpring.2018.8417572&partnerID=40&md5=6118f60a14ed5aefcb8b73a62a6e4a88 0,meet goal tenfold increase spectral efficiency interference cancellation multiuser detection expected important tasks fifth generation g radio access systems tasks realized joint detection algorithms however joint detection algorithms maximum likelihood ml detection high computational complexity previous works shown joint detectors based markov chain monte carlo mcmc methods achieve similar results compared ml detection large reduction computational complexity systems large number streams users purpose work present mimo joint detector based mcmc methods evaluate within constraints lte advanced lte namely using transmit antennas qam modulation evaluation done separately channel decoder moreover complexity presented algorithm compared one ml detector results show proposed mimo detector offers similar detection error rate compared ml detector furthermore observed complexity reduction significant systems six transmit antennas â© ieee
10.1109/VTCSpring.2018.8417493 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050983442&doi=10.1109%2fVTCSpring.2018.8417493&partnerID=40&md5=c6ab97e032e357aac4d1ee9dc4a60bfd 0,load modulated arrays lmas getting recent research attention attractive multiantenna transmission architecture wireless communications lmas use single power amplifier drive entire transmit antenna array implement multidimensional signaling constellation analog domain paper consider lmas multiuser setting uplink setting multiple user terminals using lma e g antenna elements communicate base station bs multiple tens hundreds receive antennas system consider problem low complexity signal detection bs receiver specifically propose markov chain monte carlo mcmc sampling based detection algorithm evaluate bit error rate performance algorithm via numerical simulations simulation results show proposed detection achieves good performance also scaling well complexity â© ieee
10.1002/sim.7649 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044430956&doi=10.1002%2fsim.7649&partnerID=40&md5=06ee383a9c61bbde4db6c5c6fb916305 0,hierarchical models extensively used pharmacokinetics longitudinal studies estimation performed bayesian approach model comparison often based deviance information criterion dic hierarchical models latent variables several versions statistic conditional dic cdic incorporates latent variables focus analysis marginalized dic mdic integrates regardless asymptotic coherency difficulties cdic alternative usually used markov chain monte carlo mcmc methods hierarchical models practical convenience mdic criterion appropriate cases requires integration likelihood computationally demanding implemented bayesian software therefore consider method compute mdic generating replicate samples latent variables need integrated alternative easily conducted mcmc output bayesian packages widely applicable hierarchical models general additionally propose approximations order reduce computational complexity large sample situations method illustrated simulated data sets medical studies evidencing cdic may misleading whilst mdic appears pertinent copyright â© john wiley sons ltd
10.3390/s18072363 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050639620&doi=10.3390%2fs18072363&partnerID=40&md5=58c6abd80b7c926e3c96f5fd7d2c66e3 0,multi object tracking mot especially using moving monocular camera challenging task field visual object tracking tackle problem traditional tracking detection based method heavily dependent detection results occlusion mis detections often lead tracklets drifting paper tasks mot camera motion estimation formulated finding maximum posteriori map solution joint probability synchronously solved unified framework improve performance incorporate three dimensional relative motion model sequential bayesian framework track multiple objects cameraâ€™s ego motion estimation relative motion model describes spatial relations among objects exploited predicting object states robustly recovering objects occlusion mis detections occur reversible jump markov chain monte carlo rjmcmc particle filtering applied solve posteriori estimation problem quantitative qualitative experiments benchmark datasets video collected campus conducted confirms proposed method outperformed many evaluation metrics â© authors licensee mdpi basel switzerland
10.15961/j.jsuese.201700538 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053727990&doi=10.15961%2fj.jsuese.201700538&partnerID=40&md5=f905006d73b27e0ca7906afc9d01a42c 0,rerouting important strategy deal bad weather military activities traffic flow control emergency situations process flight operation improved rerouting algorithm based mining features historical radar data proposed firstly rerouting constraints established taking economy security route features impact traffic flow capacity consideration rough process made select optimal rerouting zone possible key point sequences meet constraints rerouting routes historical flight operations analyzed positions historical flights combining flights whose plan path contain given route utilization representation proposed select preferred key point optimal key point sequence obtained analyzing utilization historical radar data taking velocity vector modeling object machine learning algorithm used mine flight pattern route segment gaussian mixture model applied model distribution velocity markov chain monte carlo used predict velocity sequence rerouting finally whole rerouting path planned kinematics equation constant acceleration rules application large scale traffic management system demonstrates high practicability proposed algorithm considering actual operating conditions flight proposed approach also predict trajectory rerouting flights provides data support air traffic flow management rerouting path areas therefore rerouting issue flight solved reasonably efficiently â© advanced engineering sciences right reserved
10.1109/VTCSpring.2018.8417682 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050973984&doi=10.1109%2fVTCSpring.2018.8417682&partnerID=40&md5=2f421b6ff1b74c8951a49d761819aef7 0,paper focuses handover probability result random rotation user equipment ue hybrid light fidelity lifi radio frequency rf networks received signal strength indicator rssi based handover algorithm considered study using rssi user association rule guarantee randomly oriented ue always associated nearest access point ap cases depending orientation ue received signal powers lifi aps weak unreliable therefore vertical handover lifi ap rf ap required maintain user quality service hence essential study handover probability due change orientation theoretical analysis handover probability based markov chain model provided analytical results confirmed monte carlo simulation effects parameters threshold hysteresis level trade frequency delay handover presented paper â© ieee
10.3847/1538-4357/aacc6c https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050742089&doi=10.3847%2f1538-4357%2faacc6c&partnerID=40&md5=db4c5d12306128196b019f67084db549 0,present near infrared k band r â‰ƒ keck spectrum n class protostar serpens molecular cloud spectrum shows red continuum co absorption bands weak nonexistent atomic metal absorptions h emission lines near ir h emission consistent excitation shocks x rays uv radiation model absorption component stellar photosphere plus circumstellar continuum emission wavelength dependent extinction markov chain monte carlo analysis shows likely model parameters consistent low temperature low gravity photosphere significant extinction modest continuum veiling eff â‰ƒ k effective temperature similar older evolved pre main sequence stars surface gravity log g â‰ƒ cm approximately dex lower implies radius protostar factor âˆ¼ larger year old tauri stars low veiling consistent circumstellar disk intrinsic near ir emission less equal evolved class protostars along high extinction suggests circumstellar material cold envelope expected class protostar first known detection analysis class protostar absorption spectrum â© american astronomical society
10.3889/oamjms.2018.296 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051417765&doi=10.3889%2foamjms.2018.296&partnerID=40&md5=fe97da51a35bfad63f86829ea3564d0e 0,aim verification bias one major problems encountered diagnostic accuracy studies occurs standard test performed non representative subsample subjects undergone diagnostic test study extend bayesian model correct bias methods study population patients undergone least two repeated failed ivf icsi vitro fertilization intra cytoplasmic sperm injection cycles patients screened using ultrasonography polyps recommended hysteroscopy bayesian modeling applied mechanism missing data using informative prior disease prevalence parameters model estimated markov chain monte carlo methods results total patients screened polyps polyps strongly recommended undergo hysteroscopy decide hysteroscopy polyps confirmed none patients polyps detected ultrasonography underwent hysteroscopy model using bayesian approach applied informative prior polyp prevalence false true negatives estimated bayesian framework false negative obtained true negatives obtained sensitivity specificity estimated easily estimating missing data sensitivity specificity equal respectively conclusion bayesian analyses informative prior seem powerful tools simulation experimental space â© abdollah hajivandi hamid reza ghafarian shirazi seyed hassan saadat mohammad chehrazi
10.3847/1538-4357/aacaf1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050765614&doi=10.3847%2f1538-4357%2faacaf1&partnerID=40&md5=7085f30a177b796d2fe39c07231aea6e 0,second paper series studying galaxy galaxy lensing signals using sloan digital sky survey data release sdss dr present measurement modeling lensing signals around groups galaxies divide groups four halo mass bins measure signals around four different halo center tracers brightest central galaxies bcgs luminosity weighted centers number weighted centers x ray peak positions groups cross identified x ray sdss dr split groups low high x ray emission subsamples assigned two halo center tracers bcgs x ray peak positions galaxy galaxy lensing signals show bcgs among four candidates best halo center tracers model lensing signals using combination four contributions center nfw host halo profile subhalo contribution stellar contribution projected two halo term sample posterior five parameters e halo mass concentration centering distance subhalo mass fraction subhalos via monte carlo markov chain mcmc package using galaxy galaxy lensing signals taking account sampling effects e g eddington bias found best fit halo masses obtained lensing signals quite consistent obtained group catalog based abundance matching method except lowest mass bin â© american astronomical society rights reserved
10.1109/DSN.2018.00040 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051075476&doi=10.1109%2fDSN.2018.00040&partnerID=40&md5=230ec7c7d995e30d0ed6abb3f469eec6 0,real world systems rare events often characterize critical situations like probability system fails within time bound used model potentially harmful scenarios dependability safety critical systems probabilistic model checking used verify dependability properties various types systems limited state space explosion problem alternative recourse statistical model checking smc relies monte carlo simulations provides estimates within predefined error confidence bounds however rare properties require large number simulations occurring least tackle problem importance sampling rare event simulation technique proposed smc different types probabilistic systems importance sampling requires full knowledge probabilistic measure system e g markov chains practice however often models uncertainty e g interval markov chains work propose method apply importance sampling interval markov chains show promising results applying method multiple case studies â© ieee
10.1109/TAC.2018.2857760 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050400972&doi=10.1109%2fTAC.2018.2857760&partnerID=40&md5=70936457d42fd67a0391dc841a76db75 0,work consider using multiple noisy binary sensors track target moves markov chain finite discrete environment symmetric probability false alarm missed detection study two policies firstly show greedy policy whereby sensors placed likely target locations one step optimal maximizes expected maximum posteriori map estimate secondly show policy sensors placed second formula tex m+ st tex formula likely target locations achieves equal slightly worse expected map performance leads significantly decreased variance map estimate result proven = monte carlo simulations give evidence formula tex x e tex formula policies closed loop index based active sensing strategies computationally trivial implement approach focuses one step optimality apparent intractability computing optimal policy via dynamic programming belief space however monte carlo simulations suggest policies perform well arbitrary horizons ieee
10.3389/fgene.2018.00254 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050266890&doi=10.3389%2ffgene.2018.00254&partnerID=40&md5=38e75c7170e3efe738a3a2c9bb1d4103 0,large scale tumor genome sequencing projects revealed complex landscape genomic mutations multiple cancer types major goal projects characterize somatic mutations discover cancer drivers thereby providing important clues uncover diagnostic therapeutic targets clinical treatment however distinguishing somatic mutations majority passenger mutations still major challenge facing biological community fortunately combining functional features mutations predict cancer driver genes effective approach solve problem protein lysine modifications important functional feature regulates development cancer therefore work systematically analyzed somatic mutations seven protein lysine modifications identified several important drivers responsible tumorigenesis published literature first collected lysine modification sites analysis another million non synonymous single nucleotide variants snvs downloaded tcga mapped collected lysine modification sites identify driver proteins significantly altered lysine modifications developed hierarchical bayesian model applied markov chain monte carlo mcmc method testing strikingly coding sequences proteins found carry higher mutation rate lysine modification sites compared background regions hypergeometric tests also revealed gene products enriched known cancer drivers functional analysis suggested mutations within lysine modification regions possessed higher evolutionary conservation deleteriousness furthermore pathway enrichment showed mutations lysine modification sites mainly affected cancer related processes cell cycle rna transport moreover clinical studies also suggested driver proteins significantly associated patient survival implying opportunity use lysine modifications molecular markers cancer diagnosis treatment searching within protein protein interaction networks using random walk restart rwr algorithm identified series potential treatment agents therapeutic targets cancer related lysine modifications collectively study reveals functional importance lysine modifications cancer development may benefit discovery novel mechanisms cancer treatment â© chen miao liu zeng gao peng hu li zheng xue zuo xie ren
10.1109/ICSTW.2018.00052 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050985329&doi=10.1109%2fICSTW.2018.00052&partnerID=40&md5=922749fa99a4c598fbfc7bd2b4db940a 0,temporal logic falsification promising approach model based testing cyber physical systems starts formalized system requirement specified metric temporal logic mtl property subsequently test input signals generated order stimulate system produce output signal finally output signals system test compared prescribed property falsify property means counterexample find counterexample markov chain monte carlo mcmc methods used construct optimization problem steer test input generations input areas maximize probability falsifying property paper identify two practical issues mentioned falsification process firstly fixed time domain input signal space assumed process restricts frequency content generated input signals secondly existing process allows input selection steered distribution single input variable address issues firstly considering multiple time domains input signal space subsequently input signal space optimization problem formally defined implemented taliro+ extension taliro existing implementation solving mtl falsification problem secondly propose decoupled scheme considers distribution input variable independently applicability proposed solutions experimentally evaluated well known benchmark problems â© ieee
10.1016/j.ejor.2018.01.016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042451249&doi=10.1016%2fj.ejor.2018.01.016&partnerID=40&md5=b5ae966cb3164a03957f2325298cef81 0,paper presents novel model measuring technical inefficiency based notion higher efficiency requires certain cost first apply â€œrational inefficiency hypothesisâ€� bogetoft hougaard fail find rationalizes data set large u banks multiple inputs outputs consequence adopt novel model profit maximization explicitly incorporates cost technical inefficiency cost inefficiency treated unknown parametrized function inputs outputs decision making unit specific fixed effects importantly showing model equivalent one inefficiency arbitrary function inputs outputs inefficiency cost able determine optimal directions input output space reduce inefficiency bayesian techniques organized around markov chain monte carlo used perform computations provide statistical inferences well useful policy measures reduce inefficiencies u banking sector examination different realistic scenarios â© elsevier b v
10.1080/00036846.2018.1430338 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041537436&doi=10.1080%2f00036846.2018.1430338&partnerID=40&md5=1f9fabe0290e4a3c662da6708b59712c 0,based general time varying parameter vector autoregressive model data mining technology study proposes new extension mixed innovation time varying parameter stochastic volatility vector autoregressive model investigates time varying characteristics efficiencies different shock effects chinaâ€™s monetary policy towards inflation gdp using sample monthly data â€“ utilize typical time points illustrate mechanisms different economic variables via markov chain monte carlo method impulse response function empirical results show monetary transmission mechanism china effective real economy delay efficiency leakage average delay maximum efficiency measured mi model capture accurate information economic variables effectively improving precision macroeconomic regulation control meanwhile difference impacts different channels obvious impact interest rates significant impact stock market significant action mechanism gdp inflation rate undergoes gradual structural change evidently displaying time varying characteristics gradually weakening impact time â© informa uk limited trading taylor francis group
10.1103/PhysRevD.98.023510 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051133881&doi=10.1103%2fPhysRevD.98.023510&partnerID=40&md5=67951e3648f108d80bd260894f68ef52 0,studies dark energy advanced gravitational wave gw interferometers normally focus dark energy equation state wde z however modified gravity theories predict nontrivial dark energy equation state generically also predict deviations general relativity propagation gws across cosmological distances even theories speed gravity equal c find generic modified gravity models effect modified gw propagation dominates wde z making modified gw propagation crucial observable dark energy studies standard sirens present convenient parametrization effect terms two parameters îž n analogue w wa parametrization dark energy equation state give limit ligo virgo measurement h neutron star binary gw perform markov chain monte carlo analysis estimate sensitivity einstein telescope et cosmological parameters including îž n using standard sirens combining cosmological data sets particular hubble parameter measured accuracy better already using standard sirens combining et current cmb+bao+sne data îž measured discuss predictions modified gw propagation specific nonlocal modification gravity recently developed group show within reach et modified gw propagation also affects gw transfer function therefore tensor contribution isw effect â© american physical society
10.1142/S0219455419400121 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049777430&doi=10.1142%2fS0219455419400121&partnerID=40&md5=e2d2e2ee72cff3e74b70ab4bee7a986e 0,paper reports step step procedures full scale ambient vibration test corresponding modal identification bayesian structural model updating coupled building building characterized combination main part complementary part connected together corridors compared main part volume complementary part much smaller therefore influence dynamic properties complementary part counterpart expected capture dynamic properties coupled building setup ambient vibration test designed cover degrees freedom dofs interest modal parameters setup identified following frequency domain decomposition fdd method partial mode shapes different setups assembled following least squares method determine stiffness linkage two parts coupled building simulated two linked shear buildings updated utilizing markov chain monte carlo mcmc based bayesian model updating method identified modal parameters revealed interesting features coupled effects main part complementary part discussed detail good match model predicted identified modal parameters verified validity proposed shear building model study provides valuable experience area structural model updating structural health monitoring â© world scientific publishing company
10.1080/02664763.2018.1495701 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049802210&doi=10.1080%2f02664763.2018.1495701&partnerID=40&md5=aee277e4762711438c01d6a71447e787 0,modeling analysis lifetime data main endpoints times event interest occurs great interest medical studies studies common two lifetimes associated unit times deterioration levels times reaction treatment pairs organs like lungs kidneys eyes ears medical applications also possible cure rate present needed modeled lifetime data long term survivors paper presented comparative study bayesian approach among existing continuous discrete bivariate distributions bivariate exponential distributions bivariate geometric distributions presence cure rate censored data covariates presence lifetimes related cured patients assumed standard mixture cure rate models data analysis posterior summaries interest obtained using markov chain monte carlo methods illustrate proposed methodology two real medical data sets considered â© informa uk limited trading taylor francis group
10.1088/1475-7516/2018/07/025 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051699540&doi=10.1088%2f1475-7516%2f2018%2f07%2f025&partnerID=40&md5=cf30734ac58bcb8de2bcea89a0abdf75 0,flux extra terrestrial neutrinos energies â‰¥ ev potential serve cosmological probe high energy universe well tests fundamental particle interactions cosmogenic neutrinos produced interactions ultra high energy cosmic rays uhecrs cosmic photon backgrounds regarded guaranteed flux however expected neutrino flux depends composition uhecrs highest energies heavier nuclei result lower neutrino fluxes compared lighter nuclei protons objective study estimate range cosmogenic neutrino spectra consistent recent cosmic ray spectral compositional data using fully inferential bayesian approach study assumes range source distributions consistent astrophysical sources flux composition cosmic rays detector systematic uncertainties technique applied study use affine invariant markov chain monte carlo effective bayesian inference tool characterizing multi dimensional parameter spaces correlations â© iop publishing ltd sissa medialab
10.1007/s10237-018-1049-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049809513&doi=10.1007%2fs10237-018-1049-0&partnerID=40&md5=f0736152e31d966eb8fe5a39d314e42d 0,propose reduced ode model mechanical activation cardiac myofilaments based explicit spatial representation nearest neighbour interactions model derived cooperative markov chain model washio et al cell mol bioeng â€“ assumption conditional independence specific sets events physically motivated assumption allows drastically reduce number degrees freedom thus resulting significantly large computational saving indeed original markov chain model involves huge number degrees freedom order formula presented solved means monte carlo method notoriously reaches statistical convergence slow fashion reduced model instead numerical simulations carried solving system odes reducing computational time times moreover reduced model accurate respect original markov chain model show reduced model capable reproducing physiological steady state forceâ€“calcium forceâ€“length relationships observed asymmetry apparent cooperativity near calcium level producing half activation finally also report good qualitative quantitative agreement experimental measurements dynamic conditions â© springer verlag gmbh germany part springer nature
10.1021/acs.iecr.8b00293 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048734247&doi=10.1021%2facs.iecr.8b00293&partnerID=40&md5=246d948f24ccea42d8e57460f2b8d0f6 0,approximate bayesian expectation maximization abem methodology laplace approximation bayesian lab methodology developed estimating parameters nonlinear stochastic differential equation sde models chemical processes new methodologies powerful previous maximum likelihood methodologies sdes enable modelers account prior information unknown parameters initial conditions abem methodology suitable situations modeler assume measurement noise variances well known whereas lab includes measurement noise variances among parameters require estimation techniques estimate magnitude stochastic terms included differential equations account model mismatch unknown process disturbances proposed abem lab methodologies illustrated using nonlinear continuous stirred tank reactor cstr case study simulated data sets generated using variety scenarios abem lab objective functions used case study result improved estimates model parameters noise parameters compared previous maximum likelihood objective functions especially situations data available parameter estimation sparse proposed abem lab methodologies rely b spline basis functions rather markov chain monte carlo techniques straightforward implement using available optimizers modeling software require modest computational effort â© copyright american chemical society
10.1080/01621459.2018.1448827 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049997626&doi=10.1080%2f01621459.2018.1448827&partnerID=40&md5=8cf998a5b92a31a63994ee925200e964 1,propose subsampling markov chain monte carlo mcmc mcmc framework likelihood function n observations estimated random subset observations introduce highly efficient unbiased estimator log likelihood based control variates computing cost much smaller full log likelihood standard mcmc likelihood estimate bias corrected used two dependent pseudo marginal algorithms sample perturbed posterior derive asymptotic error respect n respectively propose practical estimator error show error negligible even small applications demonstrate subsampling mcmc substantially efficient standard mcmc terms sampling efficiency given computational budget outperforms subsampling methods mcmc proposed literature supplementary materials article available online â© authors published license taylor francis
10.1016/j.ecolmodel.2018.03.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046140758&doi=10.1016%2fj.ecolmodel.2018.03.013&partnerID=40&md5=2152eca4a60306f293856702129cde97 0,process based ecosystem models increasingly used estimate carbon water exchanges ecosystems atmosphere models inevitably suffer deficiencies uncertainties thoroughly examined better understand processes governing ecosystem dynamics paper systematically explored uncertainties model predictions changbaishan cbs broad leaved korean pine mixed forest using simplified photosynthesis evapo transpiration sipnet model eddy flux meteorological data first screened key parameters model parameters using morris global sensitivity analysis method estimated probability distributions markov chain monte carlo technique two optimization set ups e using observed net ecosystem exchange co nee using observed nee evapotranspiration et simultaneously conducted detect different constraints different observations model parameters four parameters well constrained using observed nee including photosynthesis respiration related parameters seven parameters well constrained using measured nee et simultaneously four water related parameters obviously information derived simultaneous optimization since additional process information water flux observation modeled et nee et optimization set much better fit measured values nee optimization set r = vs r = although modeled nee two set ups good fit observations r = vs r = implied assimilating carbon water fluxes simultaneously improve parameterization overall performance model quantified uncertainties model predictions using monte carlo simulation trace specific parameter parameter interactions sobolâ€™ variance decomposition method uncertainties five outputs interest cbs site nee gross primary productivity gpp ecosystem respiration et transpiration respectively uncertainty predicted nee much larger since nee small difference two large fluxes e gpp maximum net co assimilation rate amax carbon content leaves slw classified highly sensitive parameters outputs interest cbs site contributing uncertainties outputs except nee importance two parameters holds one subtropical evergreen coniferous plantation one subtropical evergreen broad leaved forest therefore two parameters underlying processes focus future model research plant trait data collection field measurement least sites study help connect model simulation research field data collection making mutually informative â© elsevier b v
10.1021/acs.jctc.7b01245 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047606645&doi=10.1021%2facs.jctc.7b01245&partnerID=40&md5=d23d564475932a5336cc2f1b81237a6a 0,knowledge structure dynamics biomolecules essential elucidating underlying mechanisms biological processes given stochastic nature many biological processes like protein unfolding almost impossible two independent simulations generate exact sequence events makes direct analysis simulations difficult statistical models like markov chains transition networks etc help shedding light mechanistic nature processes predicting long time dynamics systems short simulations however methods fall short analyzing trajectories partial temporal information example replica exchange molecular dynamics monte carlo simulations work propose probabilistic algorithm borrowing concepts graph theory machine learning extract reactive pathways molecular trajectories absence temporal data suitable vector representation chosen represent frame macromolecular trajectory series interaction conformational energies dimensionality reduction performed using principal component analysis pca trajectory clustered using density based clustering algorithm cluster represents metastable state potential energy surface pes biomolecule study graph created clusters nodes edges learned using iterative expectation maximization algorithm reactive path conceived widest path along graph tested method rna hairpin unfolding trajectory aqueous urea solution method makes understanding mechanism unfolding rna hairpin molecule tractable method rely temporal data used analyze trajectories monte carlo sampling techniques replica exchange molecular dynamics remd copyright â© american chemical society
10.1080/01621459.2018.1423984 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049785007&doi=10.1080%2f01621459.2018.1423984&partnerID=40&md5=8465d50664c7836f07553f9b237c4f5d 0,malware computer software either designed modified malicious intent hundreds thousands new malware threats appear internet day made possible reuse known exploits computer systems fully eradicated existing pieces malware trivially modified combined create new malware unknown anti virus programs finding new software similarities known malware therefore important goal cyber security dynamic instruction trace piece software sequence machine language instructions generates executed statistical analysis dynamic instruction trace help reverse engineers infer purpose origin software generated instruction traces successfully modeled simple markov chains empirically change points structure traces recurring regimes transition patterns reversible jump markov chain monte carlo change point detection extended incorporate regime switching allowing regimes inferred malware instruction traces similarity measure malware programs based regime matching used infer originating families leading compelling performance results â© american statistical association
10.1080/01621459.2018.1458618 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049786049&doi=10.1080%2f01621459.2018.1458618&partnerID=40&md5=b92e26b0d00c9df12f96ae54af30aa01 0,fundamental problem network analysis clustering nodes groups share similar connectivity pattern existing algorithms community detection assume knowledge number clusters estimate priori using various selection criteria subsequently estimate community structure ignoring uncertainty first stage may lead erroneous clustering particularly community structure vague instead propose coherent probabilistic framework simultaneous estimation number communities community structure adapting recently developed bayesian nonparametric techniques network models efficient markov chain monte carlo mcmc algorithm proposed obviates need perform reversible jump mcmc number clusters methodology shown outperform recently developed community detection algorithms variety synthetic data examples benchmark real datasets using appropriate metric space configurations develop nonasymptotic bayes risk bounds even number clusters unknown enroute develop concentration properties nonlinear functions bernoulli random variables may independent interest analysis related models supplementary materials article available online â© american statistical association
10.1109/ACCESS.2018.2853998 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049692319&doi=10.1109%2fACCESS.2018.2853998&partnerID=40&md5=c5f4ea8a8ff734772fb94cc4557d124f 0,article develops sequential bayesian learning method estimate parameters recover state variables generalized autoregressive conditional heteroscedasticity garch models commonly used financial time series analysis simulation based method combines particle filtering technology markov chain monte carlo algorithm model non linear number observed variables relatively sparse compare performance sequential bayesian learning approach numerical maximum likelihood estimation nmle estimating models based sp return rates research concludes sequential parameter learning approach performs robustly accurately nmle taking account uncertainty model also carry simulation studies confirm sequential bayesian learning method extremely reliable garch models â© ieee
10.1007/s00477-018-1580-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049586094&doi=10.1007%2fs00477-018-1580-7&partnerID=40&md5=c938031c06217758f3af14bfb6c921d0 0,benchmark dose bmd approach exposure limit risk assessment cancer non cancer endpoints well established often based doseâ€“response modeling critical sensitive outcome however neither critical endpoint sensitive endpoint may necessarily representative overall toxic effects whole picture preferable express responses different endpoints equivalent severity levels integrate one analysis framework paper derive bmd case multivariate ordered categorical responses none mild adverse severe based structural equation models sems first ordered categorical responses obtain latent continuous variable based fictitious cutoffs standard normal distribution second use sems integrate multiple continuous variables single latent continuous variable derive corresponding bmd employed bayesian statistical approach using markov chain monte carlo simulations obtain parameter estimates latent variables sems corresponding bmd illustrate proposed procedure simulation studies analysis experimental study acrylamide exposure mice multivariate endpoints different severity levels â© springer verlag gmbh germany part springer nature
10.3390/w10070900 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049660376&doi=10.3390%2fw10070900&partnerID=40&md5=a99e68d613c88bfacc60729c009ae4ca 0,recent years several bayesian markov chain monte carlo mcmc methods proposed extreme value analysis eva assessing flood risk certain location study hamiltonian monte carlo hmc method employed obtain approximations posterior marginal distribution generalized extreme value gev model using annual maximum discharges two major river basins bangladesh comparison well known metropolis hasting mh algorithm also applied converge well yielded skewness values opposite hmc statistical characteristic data sets discharge records ganges brahmaputra rivers bangladesh past years analyzed estimate flood risk return level confidence intervals ci also calculated results show shape parameter station greater zero describes heavy tailed frã©chet cases gev distributions one station bahadurabad brahmaputra river basin estimated â·s ci range year return level year return level â·s ci station hardinge bridge ganges basin estimated â·s ci year return level year return level â·s ci bangladesh flood prone country approach bayesian hmc eva help policy makers plan initiatives result preventing damage lives assets â© authors
10.1080/01621459.2017.1415908 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049655648&doi=10.1080%2f01621459.2017.1415908&partnerID=40&md5=c2e2a5c9277daa5eb85f9358a9860694 0,article introduces nonparametric approach multivariate time varying power spectrum analysis procedure adaptively partitions time series unknown number approximately stationary segments spectral components may remain unchanged across segments allowing components evolve differently time local spectra within segments fit whittle likelihood based penalized spline models modified cholesky components provide flexible nonparametric estimates preserve positive definite structures spectral matrices approach formulated bayesian framework number location partitions random relies reversible jump markov chain hamiltonian monte carlo methods adapt unknown number segments parameters averaging distribution partitions approach approximate abrupt slowly varying changes spectral matrices empirical performance evaluated simulation studies illustrated analyses electroencephalography sleep el niã±o southern oscillation supplementary materials article available online â© american statistical association
10.1080/02664763.2018.1492527 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049597530&doi=10.1080%2f02664763.2018.1492527&partnerID=40&md5=d35b538b53c27ff4e3a54a9890811a71 0,work assume sequence recording whether ozone exceedance environmental threshold occurred given day ruled non homogeneous markov chain order one order account possible presence cycles empirical transition probabilities parametric form incorporating seasonal components considered results show even though covariates namely relative humidity temperature included explicitly model influence captured behavior transition probabilities parameters estimated using bayesian point view via markov chain monte carlo algorithms model applied ozone data obtained monitoring network mexico city mexico analysis methodology used aid decision making also given â© informa uk limited trading taylor francis group
10.1142/S021945541940011X https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049348700&doi=10.1142%2fS021945541940011X&partnerID=40&md5=d7e91453cb609e6b5c3297fe7bb62542 1,paper presents probabilistic damage identification methodology tailor made periodically supported structures finite length free wave motion general periodically supported structure single disorder analyzed characteristic receptance approach corresponding frequency characteristic equation developed addition concept nondimensional frequency introduced sensitivity matrix nondimensional frequencies respect changes stiffness periodic cells obtained solving frequency characteristic equation utilizing sensitivity analysis technique following sensitivity based identification equation nondimensional frequency information probabilistic methodology identifying damage occurring periodically supported structures developed implementing bayesian approach markov chain monte carlo mcmc simulation metropolisâ€“hasting sampling algorithm validity proposed methodology demonstrated numerical simulations periodically supported flanged pipeline example experimental case studies conducted multi span aluminum beam model endowed bolted connections laboratory â© world scientific publishing company
10.1088/1757-899X/383/1/012018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050468093&doi=10.1088%2f1757-899X%2f383%2f1%2f012018&partnerID=40&md5=505ae44d8edaa1d189fef653516f17ac 0,study proposes online offline learning framework argizero based three components generative adversarial network online auction market offline simulated agents digital twins buyers farmers natures markets generative time series digital twins massively generated manner monte carlo extremely efficient algorithms goal generator produce time series statistically indistinguishable records auction market goal discriminator develop triangulation method based semi modeless assimilation separate generated actual time series farmers believe agriculture impossible planned uncertainty crowding crisis risk foreseen accommodated agrizero framework alleviates challenges techniques bayesian deep learning data assimilation well mega power gpu computation thanks bayesian hierarchical estimation akin deep learning sophisticate longer history able estimate human behaviour agents buyers farmers natural disaster agents natures price fluctuations agents markets framework validated large amount records vegetable auctions taiwan usa hierarchical bayesian estimation monte carlo markov chain particle filters used hidden markov model appreciated massive construction probable digital twins feature space mapping wavelet time series bayesian deep learning recurrent neural network kernel induced hamiltonian dynamics abc hybrid sde kernel based forecasting time series analysis embodies particle generator gan structure also apply time series clustering rnn bagging boosting semi modeless assimilation assist performance triangulated discriminator â© published licence iop publishing ltd
10.1080/13647830.2017.1370557 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047045189&doi=10.1080%2f13647830.2017.1370557&partnerID=40&md5=aa771dda5b9d585b016cc2b318fa86c5 1,investigation tackles probabilistic parameter estimation problem involving arrhenius parameters rate coefficient chain branching reaction h + â†’ oh + achieved bayesian inference framework uses indirect data literature form summary statistics approximating maximum entropy solution aid approximate bayesian computation summary statistics include nominal values uncertainty factors rate coefficient obtained shock tube experiments performed various initial temperatures bayesian framework allows incorporation uncertainty rate coefficient secondary reaction namely oh + h â†’ h + h resulting consistent joint probability density arrhenius parameters two rate coefficients also allows uncertainty quantification numerical ignition predictions conforming published summary statistics method relies probabilistic reconstruction unreported data oh concentration profiles shock tube experiments along unknown arrhenius parameters data inference performed using markov chain monte carlo sampling procedure relies efficient adaptive quadrature estimating relevant integrals needed data likelihood evaluations efficiency gains local padã©â€“legendre approximants used surrogates time histories oh concentration alleviating need auto ignition simulations reconstructed realisations missing data used provide consensus joint posterior probability density unknown arrhenius parameters via probabilistic pooling uncertainty quantification analysis performed stoichiometric hydrogenâ€“air auto ignition computations explore impact uncertain parameter correlations range quantities interest â© work authored part contributor official duties employee united states government therefore work united states government accordance usc copyright protection available works us law
10.1088/1742-6596/1047/1/012014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050476726&doi=10.1088%2f1742-6596%2f1047%2f1%2f012014&partnerID=40&md5=852d9c6e48e0f1fb8a90dba5ee2ba135 0,estimating properties using maximum likelihood mle gives point values rough idea uncertainty parameters distributions approximately normal accurate results require monte carlo approach often using markov chain monte carlo mcmc method complex models unrealistic computational expense variational bayes approach gives results comparable mcmc evaluation model model imprecise expensive evaluate gaussian processes provide one means analyzing noise determine uncertainties â© published licence iop publishing ltd
10.1080/10543406.2017.1372768 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030570997&doi=10.1080%2f10543406.2017.1372768&partnerID=40&md5=5c70dd99ee4cce95c0aa822de25db432 0,receiver operating characteristic roc curve well established analysis method evaluate biomarkerâ€™s discrimination accuracy binary outcomes endpoint interest time event outcome time cancer recurrence biomarkerâ€™s time varying discriminatory performance often assessed time dependent roc analysis practice biomarkers often imprecisely measured due limitation assay sensitivity values limit detection detectable ignorance data characteristic may lead inaccurate estimation markerâ€™s potential discriminatory power objective article extend time dependent roc method censored biomarker data using parameter estimates cox regression model accommodates censored biomarker measurements simulation study proposed methods shown outperform simple substitution method conventionally adopted handling censored data application data also given illustrate methods â© â© taylor amp francis
10.1080/02664763.2017.1386771 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031781964&doi=10.1080%2f02664763.2017.1386771&partnerID=40&md5=8f502f674eda65cbfba5f9b2915fe003 0,spatial hidden markov model shmm introduced analyse distribution species atlas taking account false observations false non detections species occur survey blurring true map presence absence species reconstruction true map tackled restoration degraded pixel image true map autologistic model hidden behind observed map whose normalizing constant efficiently computed simulating auxiliary map distribution species explained bayesian paradigm markov chain monte carlo mcmc algorithms developed interested spatial distribution bird species greywing francolin south africa many climatic land use explanatory variables also available included shmm subset selected mutation operators within mcmc algorithm â© informa uk limited trading taylor francis group
10.1080/09637486.2017.1402868 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034810057&doi=10.1080%2f09637486.2017.1402868&partnerID=40&md5=b28a1845f24f53a3197555a9f108810b 0,aim meta analysis conducted estimate cardiovascular benefits indiscriminate supplementation omega capsules results expressed terms quality adjusted life years qaly intuitively understood general public basis personal decision whether take omega supplements methods results meta analysis eight double blind placebo controlled clinical trials expressed terms qaly using markov model monte carlo simulations results omega supplementation results decrease risk cardiac death unless patients treated statins results indicate omega supplementation may prolong qaly month old people gain less whereas dm patients people history cv events gain discussion analysis yielded algorithm estimating benefit omega supplementation based age individual risk cv events patient â© â© informa uk limited trading taylor francis group
10.1080/07350015.2018.1469998 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049803072&doi=10.1080%2f07350015.2018.1469998&partnerID=40&md5=4eaa542dd629ad8beee901fb1b4b20ce 0,article extends literature copulas discrete continuous marginals case marginals mixture discrete continuous components carefully defining likelihood density observations respect mixed measure treatment quite general although focus mixtures gaussian archimedean copulas inference bayesian estimation carried markov chain monte carlo illustrate methodology algorithms applying estimate multivariate income dynamics model supplementary materials article available online xa american statistical association
10.1080/10589759.2018.1449841 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044526731&doi=10.1080%2f10589759.2018.1449841&partnerID=40&md5=9d0d85bbc97396adf02746c0158a0856 0,current evaluation ancient stone monuments ultrasonic tomography widely used detection result however deviation location shape since ultrasonic velocity voids cracks area change much drastic healthy parts base homogeneous material assumption contour node representation therefore proposed fitting best defect shape location contour node representation quick ray tracing method proposed inverse problem solved bayesian framework use markov chain monte carlo search global optimal result applying prior knowledge model quick ray tracing model computational cost inverse process highly reduced compared ultrasonic tomography result proposed method accurate location shape inspection finally laboratory experiment also tests ability proposed method â© â© informa uk limited trading taylor francis group
10.1109/MECBME.2018.8402432 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050036964&doi=10.1109%2fMECBME.2018.8402432&partnerID=40&md5=3860121426861aa7a52b04ddf0549750 0,paper presents sparse bayesian regularization technique image restoration parallel magnetic resonance imaging pmri technique based hierarchical bayesian model solves inverse problem pmri reconstruction promoting sparsity using bernoulli laplace mixture prior markov chain monte carlo mcmc sampling technique used numerically approximate target posterior model allows handling complex valued data promising results obtained synthetic data demonstrate performance proposed sparse bayesian restoration model provide accurate estimation target images â© ieee
10.1080/01621459.2018.1448824 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054626424&doi=10.1080%2f01621459.2018.1448824&partnerID=40&md5=1fc233efa72e231831a888717213d089 0,models intractable normalizing functions arise frequently statistics common examples models include exponential random graph models social networks markov point processes ecology disease modeling inference models complicated normalizing functions probability distributions include parameters interest bayesian analysis result called doubly intractable posterior distributions pose significant computational challenges several monte carlo methods emerged recent years address bayesian inference models provide framework understanding algorithms elucidate connections among multiple simulated real data examples compare contrast computational statistical efficiency algorithms discuss theoretical bases study provides practical recommendations practitioners along directions future research markov chain monte carlo mcmc methodologists supplementary materials article available online â© â© american statistical association
10.1080/01621459.2017.1409122 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049121069&doi=10.1080%2f01621459.2017.1409122&partnerID=40&md5=4e3cd9f2dcfe5b3e6b7bea89aadcad4a 0,recent advances high throughput biotechnologies provided unprecedented opportunity biomarker discovery statistical point view cast variable selection problem problem challenging due high dimensional nonlinear nature omics data general suffers three difficulties unknown functional form nonlinear system ii variable selection consistency iii high demanding computation circumvent first difficulty employ feed forward neural network approximate unknown nonlinear function motivated universal approximation ability circumvent second difficulty conduct structure selection neural network induces variable selection choosing appropriate prior distributions lead consistency variable selection circumvent third difficulty implement population stochastic approximation monte carlo algorithm parallel adaptive markov chain monte carlo algorithm openmp platform provides linear speedup simulation number cores computer numerical results indicate proposed method work well identification relevant variables high dimensional nonlinear systems proposed method successfully applied identification genes associated anticancer drug sensitivities based data collected cancer cell line encyclopedia study supplementary materials article available online â© â© american statistical association
10.1080/10618600.2017.1395343 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048132059&doi=10.1080%2f10618600.2017.1395343&partnerID=40&md5=22be4b3ffd0c6de0cde4183f227f2f31 0,normal distribution classical tools building random effects regression models used specification either conditional response distribution random effects distribution however underlying assumption symmetry questionable many applications therefore propose regression models skew normal skew distribution considered response random effects specification embed models framework distributional regression regression predictors specified distributional parameters distributional regression framework also allows us consider multivariate versions skew normal skew distribution bayesian inference adapt iteratively weighted least square proposals within markov chain monte carlo simulations also facilitate inclusion nonnormal random effects specifications model choice based watanabeâ€“akaike information criterion particular differentiate skew nonskew distributional specifications number simulation studies finally illustrate practical applicability developed models applied study cholesterol levels originating framingham heart study dataset demographic health surveys undernutrition among children nigeria supplementary material article available online â© â© american statistical association institute mathematical statistics interface foundation north america
10.1007/s10955-018-2103-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049568453&doi=10.1007%2fs10955-018-2103-0&partnerID=40&md5=5170229183eb062216c6697df59cf9c5 0,study models weighted exponential random graphs large network limit models recently proposed model weighted network data arising host applications including socio econometric data migration flows neuroscience analogous fundamental results derived standard unweighted exponential random graph models work chatterjee diaconis derive limiting results structure models number nodes goes infinity results applicable wide variety base measures including measures unbounded support also derive sufficient conditions continuity functionals specification model including conditions nodal covariates finally include number open problems spur understanding model especially context applications â© springer science+business media llc part springer nature
10.1080/10618600.2017.1415911 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047312427&doi=10.1080%2f10618600.2017.1415911&partnerID=40&md5=a891fe8109a1c433e4aee29bb5192362 1,although metropolis algorithm simple implement often difficulties exploring multimodal distributions propose repellingâ€“attracting metropolis ram algorithm maintains simple implement nature metropolis algorithm likely jump modes ram algorithm metropolis hastings algorithm proposal consists downhill move density aims make local modes repelling followed uphill move density aims make local modes attracting downhill move achieved via reciprocal metropolis ratio algorithm prefers downward movement uphill move opposite using standard metropolis ratio prefers upward movement movement density increases probability proposed move different mode acceptance probability proposal involves ratio intractable integrals introduce auxiliary variable creates term acceptance probability cancels intractable ratio using several examples demonstrate potential ram algorithm explore multimodal distribution efficiently metropolis algorithm less tuning commonly required tempering based methods supplementary materials available online â© â© american statistical association institute mathematical statistics interface foundation north america
10.1080/10485252.2018.1470241 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046892481&doi=10.1080%2f10485252.2018.1470241&partnerID=40&md5=4aeaa13770e64660066d949b2b8f0f98 0,last years lot achievements made study posterior contraction rates nonparametric bayesian methods plenty involve sieve priors mainly specific models sieves provide posterior contraction theorem general parametric sieve priors theorem weaker simpler conditions compared existing results indicates sieve prior rate adaptive apply general theorem density estimations nonparametric regression jumps also provided reversible jump mcmc markov chain monte carlo algorithm sieve prior â© â© american statistical association taylor francis
10.1080/15598608.2018.1431575 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042232719&doi=10.1080%2f15598608.2018.1431575&partnerID=40&md5=fa325eac4befa8653cfa5edfdcf0190e 1,article deals problem estimating parameters modified weibull distribution mwd using progressively type ii censored sample constant stress partially accelerated life test model maximum likelihood bayes parametric bootstrap methods obtained point estimations distribution parameters acceleration factor furthermore approximate confidence intervals acis bootstrap confidence intervals credible intervals estimators obtained results bayes estimators computed squared error loss sel function using markov chain monte carlo mcmc method gibbs sampling within metropolisâ€“hasting algorithm applied generate mcmc samples posterior density functions analysis simulated data set presented illustrative purposes finally monte carlo simulation study carried investigate precision bayes estimates maximum likelihood estimates two bootstrap estimates also compare performance different corresponding confidence intervals considered â© â© grace scientific publishing llc
10.1080/10618600.2017.1407325 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053593442&doi=10.1080%2f10618600.2017.1407325&partnerID=40&md5=41725e69f4aecafe6dff3b5ce2f3f229 3,bayesian analysis provides convenient setting estimation complex generalized additive regression models gams since computational power tremendously increased past decade possible tackle complicated inferential problems example markov chain monte carlo simulation virtually modern computer one reasons bayesian methods become increasingly popular leading number highly specialized optimized estimation engines attention shifting conditional mean models probabilistic distributional models capturing location scale shape aspects response distribution embed many different approaches suggested literature software unified modeling architecture distributional gams established exploits distributions estimation techniques posterior mode posterior mean model terms fixed random smooth spatial â€¦ shown within framework implementing algorithms complex regression problems well integration already existing software relatively straightforward usefulness emphasized two complex computationally demanding application case studies large daily precipitation climatology well cox model continuous time space time interactions supplementary material article available online â© â© author published license taylor francis group llc â© â© nikolaus umlauf nadja klein achim zeileis
10.1080/01621459.2017.1379402 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049145270&doi=10.1080%2f01621459.2017.1379402&partnerID=40&md5=fa9826d97967319c528a5efa10fb3843 0,many researchers biology medicine focused trying understand biological rhythms potential impact disease common biological rhythm circadian cycle repeats every hours however disturbance circadian pattern may indicative future disease article develop new statistical methodology assessing degree disturbance irregularity circadian pattern count sequences observed time population individuals develop latent variable poisson modeling approach circadian stochastic short term trend autoregressive latent process components allow individual variation degree component parameterization proposed modeling covariate dependence proportion two model components across individuals addition incorporate covariate dependence overall mean magnitude trend phase shift circadian pattern innovative markov chain monte carlo sampling used carry bayesian posterior computation several variations proposed models considered compared using deviance information criterion illustrate methodology longitudinal physical activity count data measured longitudinal cohort adolescents â© public domain
10.5194/hess-22-3561-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049389989&doi=10.5194%2fhess-22-3561-2018&partnerID=40&md5=2d22e64d7edcf1f0cabd7c1fcd6dea90 0,fluid flow charged porous medium generates electric potentials called streaming potential sp sp signal related hydraulic electrical properties soil work global sensitivity analysis gsa parameter estimation procedures performed assess influence hydraulic geophysical parameters sp signals investigate identifiability parameters sp measurements procedures applied synthetic column experiment involving falling head infiltration phase followed drainage phase gsa used variance based sensitivity indices calculated using sparse polynomial chaos expansion pce allow high pce orders use efficient sparse pce algorithm selects best sparse pce given data set using kashyap information criterion kic parameter identifiability performed using two approaches bayesian approach based markov chain monte carlo mcmc method first order approximation foa approach based levenberg marquardt algorithm comparison approaches allows us check whether foa provide reliable estimation parameters associated uncertainties highly nonlinear hydrogeophysical problem investigated gsa results show short time periods saturated hydraulic conductivity ks voltage coupling coefficient saturation csat influential parameters whereas long time periods residual water content î mualem van genuchten parameter n archie saturation exponent na become influential strong interactions mualem van genuchten parameter î± weak influence sp signals whole experiment results parameter estimation show although studied problem highly nonlinear several sp data collected different altitudes inside column used calibrate model hydraulic ks î î± n geophysical parameters na csat reasonably estimated sp measurements case foa approach provides accurate estimations mean parameter values uncertainty regions conversely number sp measurements used calibration strongly reduced foa approach yields accurate mean parameter values agreement mcmc results inaccurate even unphysical confidence intervals parameters large uncertainty regions â© author
10.1190/geo2016-0594.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048483218&doi=10.1190%2fgeo2016-0594.1&partnerID=40&md5=08e288b0773610ebe2aeba60fcd6d52e 0,applied transdimensional stochastic inversion algorithm reversible jump markov chain monte carlo rjmcmc angle stack seismic inversion characterization reservoir acoustic shear impedance uncertainty quantification rjmcmc able infer number parameters model well parameter values case number parameters depends number model layers given data set also use method uncertainty quantification transdimensional sampling helps prevent underparameterization strong overparameterization ensemble models proper parameterization improve parameter estimation uncertainty quantification new results uncertainty analysis indicate uncertainty seismic inversion including uncertainty earth properties locations related discontinuity property across interface trade property uncertainty location uncertainty stronger discontinuity induce property uncertainty less location uncertainty discontinuity interface therefore use inversion uncertainty novel seismic attribute assist delineation subsurface discontinuity interfaces quantify magnitude discontinuities facilitates quantitative interpretation stratigraphic interpretation â© society exploration geophysicists
10.1016/j.petrol.2018.03.062 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044755051&doi=10.1016%2fj.petrol.2018.03.062&partnerID=40&md5=b3efbc2d267eac271862024056c95854 0,present probabilistic approach integrating multiple data types subsurface flow models approach based bayesian framework whereby exhaustively sample multi dimensional posterior distribution define pareto front represents trade multiple objectives history matching objectives matching water cut gor bhp time lapse seismic data field applications objectives necessarily move tandem measurement errors also interpretative nature seismic data proposed method built differential evolution markov chain monte carlo demc algorithm multiple markov chains run parallel first dominance relationship established amongst multiple models followed construction posterior distribution based hypervolume measure unique aspect method parameter proposal generation based random walk two arbitrarily selected chains promotes effective mixing chains resulting improved convergence illustrate algorithm using nine spot waterflood model whereby use water cut bottomhole flowing pressure data calibrate permeability field permeability field parameterized using previously proposed grid connectivity transform gct model order reduction technique defined based decomposition grid laplacian compression power gct allows us reconstruct permeability field parameters thus significantly improving computational efficiency mcmc approach next applied method brugge benchmark case involving water injectors producers cases algorithm provides ensemble models constrained history data defines probabilistic pareto front objective space several experimental runs conducted compare effectiveness algorithm non dominated sorting genetic algorithms nsga ii higher hypervolume constantly measured using algorithm indicates optimal solutions sampled method provides novel approach subsurface model calibration uncertainty quantification using mcmc communication parallel markov chains enhances adequate mixing significantly improves convergence without loss sampling quality â© elsevier b v
10.1016/j.ijepes.2018.01.008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044635599&doi=10.1016%2fj.ijepes.2018.01.008&partnerID=40&md5=efc0722348eab6ade191d15ff17c7560 2,penetration electric vehicles evs increases patterns use need well understood future system planning operating purposes using high resolution data accurate driving patterns generated markov chain monte carlo mcmc simulation simulated driving patterns used undertake uncertainty analysis network impact due ev charging case studies workplace domestic uncontrolled charging investigated confidence interval adopted represent associated uncertainty following grid operational metrics network voltage profile line thermal performance home charging example impact evs network compared weekday weekend cases different ev penetration levels â© elsevier ltd
10.1177/0962280217747054 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047953488&doi=10.1177%2f0962280217747054&partnerID=40&md5=6c1cdb8fa20cc476729ebe2af056bb20 1,simple mechanistic epidemic models widely used forecasting parameter estimation infectious diseases based noisy case reporting data despite widespread application models emerging infectious diseases know little comparative performance standard computational statistical frameworks contexts build simple stochastic discrete time discrete state epidemic model process observation error use characterize effectiveness different flavours bayesian markov chain monte carlo mcmc techniques use fits simulated data parameters future behaviour known explore limitations different platforms quantify parameter estimation accuracy forecasting accuracy computational efficiency across combinations modeling decisions e g discrete vs continuous latent states levels stochasticity computational platforms jags nimble stan â© â© author
10.1029/2018WR022658 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050928412&doi=10.1029%2f2018WR022658&partnerID=40&md5=80ae85e4dade4e8759eda64ef8e66cdb 0,markov chain monte carlo mcmc simulation methods widely used assess parametric uncertainties hydrologic models conditioned measurements observable state variables however model cpu intensive high dimensional computational cost mcmc simulation prohibitive situation cpu efficient less accurate low fidelity model e g numerical model coarser discretization data driven surrogate usually adopted nowadays multifidelity simulation methods take advantage efficiency low fidelity model accuracy high fidelity model gaining popularity mcmc simulation posterior distribution unknown model parameters region interest wise distribute computational budget e high fidelity model evaluations therein based idea paper propose adaptive multifidelity mcmc algorithm efficient inverse modeling hydrologic systems method evaluate high fidelity model mainly posterior region iteratively running mcmc based gaussian process system adaptively constructed multifidelity simulation error gaussian process system rigorously considered mcmc simulation gradually reduced negligible level posterior region thus proposed method obtain accurate estimate posterior distribution small number high fidelity model evaluations performance proposed method demonstrated three numerical case studies inverse modeling hydrologic systems â© american geophysical union rights reserved
10.5004/dwt.2018.22381 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054851138&doi=10.5004%2fdwt.2018.22381&partnerID=40&md5=a2680318edfbbd4482f293460cb95173 0,soil water characteristic curve swcc important property unsaturated soils essential unsaturated soil engineering analysis significant uncertainty swcc obtained experiment due complicated unmodelled influencing factors swcc paper regarding fitting parameters fredlund xing fx model van genuchten vg model gardner model random vectors uncertainty swcc fitting parameters evaluated using bayesian framework framework demonstrated using sandy experimental data records unsoda posterior distributions fitting parameters obtained markov chain monte carlo simulation different levels confidence intervals fitting parameters fx vg gardner models obtained intuitively proposed bayesian framework found confidence interval vg model narrowest uncertainty lowest different levels confidence intervals swcc vg model applied one dimensional vertical soil water filtration results demonstrated uncertainty swcc significant effects soil water infiltration â© desalination publications rights reserved
10.1016/j.forsciint.2018.04.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046170124&doi=10.1016%2fj.forsciint.2018.04.003&partnerID=40&md5=7cb9039f2ca15c2ebcb7571780264076 0,closed circuit tv cctv systems often record vehicle motion prior incidents footage estimate average speed vehicle two frames calculated forensic investigation estimate average speed needed also estimation measurement error earlier papers approach explained estimate average speed corresponding uncertainty terms confidence interval practice confidence intervals often wrongly interpreted probability intervals paper show use markov chain monte carlo approach derive probability intervals instead confidence intervals show robustness markov chain monte carlo approach numerical differences approaches casework difference confidence intervals probability intervals turns limited consequence impact confusion confidence probability intervals also expected limited â© elsevier b v
10.3847/1538-4365/aaca30 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051164086&doi=10.3847%2f1538-4365%2faaca30&partnerID=40&md5=8c57d0fcd882b37c18ef12d09e364256 0,employing monte carlo random sampling traditional binary population synthesis bps offers substantial improvement efficiency brute force grid based studies even bps models typically require large number simulation realizations computationally expensive endeavor generate statistically robust results recent advances statistical methods led us revisit traditional approach bps work describe publicly available code dart board combines rapid binary evolution codes typically used traditional bps modern markov chain monte carlo methods dart board takes novel approach treats initial binary parameters supernova kick vector model parameters formulation several advantages including ability model either populations systems individual binaries natural inclusion observational uncertainties flexible addition new constraints problematic include using traditional bps testing code mock systems demonstrate flexibility dart board applying three examples generic population high mass x ray binaries hmxbs ii population hmxbs large magellanic cloud lmc spatially resolved star formation history used prior iii one particular hmxb lmc swift j include observations system component masses orbital period although work focuses hmxbs dart board applied variety stellar binaries including recent detections gravitational wave observatories merging compact object binaries â© american astronomical society rights reserved
10.1016/j.jmva.2018.03.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045195363&doi=10.1016%2fj.jmva.2018.03.012&partnerID=40&md5=a13cf46ad5e0179b35788e73fde47730 1,let ï€ denote intractable posterior density results likelihood multivariate linear regression model errors scale mixture normals combined standard non informative prior simple data augmentation algorithm based latent data mixing density used explore ï€ let h denote mixing density dimension regression model respectively hobert et al recently shown h converges origin appropriate rate âˆ« âˆžudâˆ• h u du lt âˆž markov chains underlying data augmentation da algorithm alternative haar parameter expanded da px da algorithm geometrically ergodic results established using probabilistic techniques based drift minorization conditions paper spectral analytic techniques used establish something much stronger geometric ergodicity often holds particular shown simple conditions h markov operators defined da haar px da markov chains trace class e compact summable eigenvalues many standard mixing densities satisfy conditions developed paper indeed new results imply da haar px da markov operators trace class whenever mixing density generalized inverse gaussian log normal frã©chet shape parameter larger dâˆ• inverted gamma shape parameter larger dâˆ• â© elsevier inc
10.1029/2017WR021176 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050936752&doi=10.1029%2f2017WR021176&partnerID=40&md5=c28f45ce8a557569e00e3fc7ac275293 0,dam breach models commonly used predict outflow hydrographs potentially failing dams key ingredients evaluating flood risk paper new dam breach modeling framework introduced shall improve reliability hydrograph predictions homogeneous earthen embankment dams striving small number parameters simplified physics based model describes processes failing embankment dams breach enlargement driven progressive surface erosion therein erosion rate dam material modeled empirical sediment transport formulations embedding model bayesian multilevel framework allows quantitative analysis different categories uncertainties end data available literature observed peak discharge final breach width historical dam failures used perform model inversion applying markov chain monte carlo simulation prior knowledge mainly based noninformative distribution functions resulting posterior distribution shows main source uncertainty correlated subset parameters consisting residual error term epistemic term quantifying breach erosion rate prediction intervals peak discharge final breach width congruent values known literature finally predict outflow hydrograph real case applications alternative residual model formulated assumes perfect data perfect model fully probabilistic fashion hydrograph prediction potential improve adequate risk management downstream flooding â© american geophysical union rights reserved
10.1029/2017WR022185 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050334686&doi=10.1029%2f2017WR022185&partnerID=40&md5=479935f9ac6ca08f37743015663b7348 0,develop bayesian model predict maximum thickness seasonally frozen ground mtsfg using historical air temperature precipitation observations use stefan solution meteorological data stations estimate mtsfg changes yellow river source region northwestern china employ antecedent precipitation index model estimate changes liquid soil water content marginal posterior probability distributions antecedent precipitation index parameters estimated using markov chain monte carlo sampling methods compare results stochastic method obtained traditional deterministic method find consistent general stochastic approach effective estimating historical changes frozen ground depth root mean square errorsâ =â â€“ â provides information model uncertainty regarding soil moisture variations additionally simulation shows mtsfg decreased â cm per year last â years northeastern qinghai tibet plateau decrease frost depth accelerated considering lack data seasonally frozen soil monitoring bayesian method provides pragmatic approach statistically model frozen ground changes using available meteorological data â© american geophysical union rights reserved
10.1109/TNNLS.2017.2688499 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022088337&doi=10.1109%2fTNNLS.2017.2688499&partnerID=40&md5=020bb10f7333c1289339806995d58232 0,deep generative models dgms often organized hierarchical manner provide principled framework capturing underlying causal factors data recent work dgms focussed development efficient scalable variational inference methods learn single model mean field parameterization assumptions however little work done extending markov chain monte carlo mcmc methods bayesian dgms enjoy many advantages compared variational methods present doubly stochastic gradient mcmc simple generic method approximate bayesian inference dgms collapsed continuous parameter space mcmc sampling step algorithm randomly draws mini batch data samples estimate gradient log posterior estimates intractable expectation hidden variables via neural adaptive importance sampler proposal distribution parameterized deep neural network learnt jointly along sampling process demonstrate effectiveness learning various dgms wide range tasks including density estimation data generation missing data imputation method outperforms many state art competitors â© ieee
10.1098/rsif.2018.0318 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051432422&doi=10.1098%2frsif.2018.0318&partnerID=40&md5=026990aefe4c8efa471a3b784b3626f8 0,systems approaches development biological models become mature attention increasingly focusing problem inferring parameter values within models experimental data however particularly nonlinear models obvious either inspection model experimental data inverse problem parameter fitting unique solution even non unique solution constrains parameters lie within plausible physiological range parameters constrained termed unidentifiable focus gaining insight causes unidentifiability using inference based methods compare recently developed measure theoretic approach inverse sensitivity analysis popular markov chain monte carlo approximate bayesian computation techniques bayesian inference three approaches map uncertainty quantities interest output space probability sets parameters input space geometry sets demonstrates unidentifiability caused parameter compensation provides intuitive approach inference based experimental design â© author published royal society rights reserved
10.1016/j.trc.2018.05.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047600880&doi=10.1016%2fj.trc.2018.05.017&partnerID=40&md5=2a3e9e9a94d543dce0c008a4bb3d001d 1,driving behavior general considered leading cause intersection related traffic crashes however due unavailability real world driving data intersection safety performance evaluations largely reactive state art methods applied analyze historical crash data regard emerging connected vehicles technology provides promising opportunity investigating intersection safety proactive perspective driving volatility captures extent variations instantaneous driving decisions vehicle driven study develops fundamental understanding microscopic driving volatility relates unsafe outcomes intersections using high resolution driving data real world connected vehicle testbed safety pilot model deployment ann arbor michigan methodology presented quantify driving volatility intersections analyzing million real world basic safety messages proactive intersection safety evaluation large scale connected vehicle data linked detailed intersection data containing crashes traffic exposure geometric features using vehicular speed acceleration deceleration vehicular jerk based eight different volatility measures descriptive analysis performed spot differences driving volatility signalized un signalized intersections depth statistical analysis conducted separately intersections signalized un signalized signalized intersections importantly factors may influence crash frequency observed data unobserved factors included model correlations driving volatility crash frequency change e g relationship become statistically insignificant given important methodological concerns unobserved heterogeneity potential omitted variable bias hierarchical fixed random parameter poisson poisson log normal models estimated full bayesian estimation via markov chain monte carlo mcmc based gibbs sampling performed providing efficient results intersections controlling traffic exposure geometrics unobserved factors one percent increase intersection level volatility calculated two standard deviations threshold acceleration deceleration passing level volatility captured coefficient variation speed mean absolute deviance vehicular jerk results increase crash frequencies respectively however relationships intersection specific volatility crash frequencies different signalized intersections several exogenous factors found normally distributed random parameters suggesting effects variables vary across different intersections implications findings proactive safety management discussed â©
10.1177/0954405416673109 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053472090&doi=10.1177%2f0954405416673109&partnerID=40&md5=78d5fdd8a449202a481985b643e6ea02 0,hazard rate curve numerical control machine tool bathtub curve change point early failure period random failure period curve difficult obtain small data sample thus bayesian method proposed method build prior distributions weibull parameters developed integrates multi source prior information target numerical control machine tool reference numerical control machine tool markov chain monte carlo method adopted calculate estimators weibull parameters corresponding failure solves problem absence analytical solution total working time numerical control machine tool estimator shape parameter equal estimated taking estimator shape parameter function time result change point early failure period obtained comparison result shows result obtained existing change point solving method large dataset close result generated proposed method small dataset change point early failure period obtained proposed method used guide early failure test design rational maintenance strategy vital engineering significance â© imeche
10.1016/j.jngse.2018.04.031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047250044&doi=10.1016%2fj.jngse.2018.04.031&partnerID=40&md5=db1172499bc2128d6ed160e750bd7aa6 1,petrophysical parameters great importance evaluation characterization reservoirs especially unconventional reservoirs complex properties geophysical inversion efficient economic method obtain petrophysical parameters paper bayesian inversion method presented predict petrophysical model conventional well logs statistical analysis results accepted markov chain monte carlo mcmc samples used study uncertainty forecasted parameters since mcmc powerful approach obtain adequate samples obeying posterior distribution bayesian inversion proposed method applied reservoirs xiashihezi formation typical tight sandstone layers ordos basin model prediction corresponding uncertainty analysis presented detail specific depth interactive effects multiple petrophysical parameters investigated correlation coefficients accuracy reliability predicted model validated forward log responses core data whole depth interval according results discussions concluded reasonable prior information model parameters simplify inversion problem provides much conveniences statistical analysis mcmc samples weak correlation two petrophysical parameters indicates reasonable feasible disregard dependence parameters synthetic logs calculated predicted model good agreement observed well logs implies precision credibility bayesian inversion predicted porosity permeability minerals content consistent core data verifying effectiveness reliability proposed method inversion results advantage bayesian inversion locate probable reservoirs extreme value â© elsevier b v
10.1002/eco.1957 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044731353&doi=10.1002%2feco.1957&partnerID=40&md5=2daa0d5536cc415319ce434db4fb74f9 0,evapotranspiration et net ecosystem exchange nee driven high slow frequency scalar fluxes quantifying variation two processes different timescales remains challenge bridging knowledge gap crucial order improve insights impact biotic abiotic factors modulating fluxes well accurate estimation gross primary productivity gpp ecosystem respiration issue addressed using modelâ€“data fusion approach within bayesian framework running model et nee observations three different time steps subdaily â min daily â day intermediate â days model tested eddy covariance data collected month period june july sagebrush steppe ecosystem united states credible interval ci fast processes transpiration photosynthesis reduced compared priori range model run min time step reduction ci parameters varied model run day time step ci slow process root respiration reduced model run day min time step respectively found strong confidence predicting et nee subdaily timescale whereas uncertainty increased increase temporal resolution gpp varied strongly system transitioned traditionally wet june dry july month copyright â© john wiley sons ltd
10.1093/sysbio/syy008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050917016&doi=10.1093%2fsysbio%2fsyy008&partnerID=40&md5=e2d10c3706d5160b3f61fe99d51c4a0f 0,bayesian phylogenetic inference relies use markov chain monte carlo mcmc provide numerical approximations high dimensional integrals estimate posterior probabilities however mcmc performs poorly posteriors rugged e regions high posterior density separated regions low posterior density one technique become popular improving numerical estimates mcmc distributions rugged metropolis coupling mc inmc additional chains employed sample flattened transformations posterior improve mixing highlight several underappreciated behaviors mc notably estimated posterior probabilities may incorrect appear converge individual chains mixwell despite different chains sampling trees relevant areas tree space counter intuitively behavior difficult diagnose increased numbers chains illustrate surprising behaviors mc using simple non phylogenetic example phylogenetic examples involving constrained unconstrained analyses detect mitigate effects behaviors recommend increasing number independent analyses varying temperature hottest chain current versions bayesian phylogenetic software convergence diagnostics based behavior hottest chain may also help detect behaviors form useful addition future software releases â© author
10.1145/3182392 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052597871&doi=10.1145%2f3182392&partnerID=40&md5=55ce0fcdfb2f0041f7d0c9b5aeb1a260 0,counting subgraphs fundamental analysis task online social networks osns given sheer size restricted access osn efficient computation subgraph counts highly challenging although number algorithms proposed estimate relative counts subgraphs osns restricted access works try solve general problem e counting subgraph frequencies article propose efficient random walk based framework estimate subgraph counts framework generates samples leveraging consecutive steps random walk well observing neighbors visited nodes using importance sampling technique derive unbiased estimators subgraph counts make better use degree information visited nodes also design improved estimators increases accuracy estimation additional cost conduct extensive experimental evaluation real world osns confirm theoretical claims experiment results show estimators unbiased accurate efficient better state art algorithms weibo graph million nodes method produces estimate triangle count error less using sampled nodes detailed comparison state art methods demonstrates algorithm times accurate â© acm
10.1016/j.csda.2018.01.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042913559&doi=10.1016%2fj.csda.2018.01.017&partnerID=40&md5=ff907ac217d738e889e00dda704a04ed 0,cox regression one commonly used methods analysis interval censored failure time data many practical studies covariate effects failure time may constant time time varying coefficients therefore great interest due flexibility capturing temporal covariate effects analyze spatially correlated interval censored time event data time varying covariate effects bayesian approach dynamic cox regression model proposed coefficient estimated piecewise constant function number jump points estimated data conditional autoregressive distribution employed model spatial dependency posterior summaries obtained via efficient reversible jump markov chain monte carlo algorithm properties method illustrated simulation studies well application smoking cessation data southeast minnesota â© elsevier b v
10.1007/s11042-017-5195-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030089456&doi=10.1007%2fs11042-017-5195-7&partnerID=40&md5=ba94d169d0edbb75d0ff67e63c713b65 0,paper addresses problem estimating camera motion non calibrated monocular camera compared existing methods rely restrictive assumptions propose method estimate camera motion much less restrictions adopting new example based techniques compensating lack information specifically estimate focal length camera referring visually similar training images focal lengths associated one step camera estimation refer stationary points landmark points whose depths estimated based rgb candidates addition landmark points moving objects also used information source estimate camera motion therefore method simultaneously estimates camera motion video trajectories objects video using reversible jump markov chain monte carlo rj mcmc particle filtering method evaluated challenging datasets demonstrating effectiveness efficiency â© springer science+business media llc
10.1121/1.5044423 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050114517&doi=10.1121%2f1.5044423&partnerID=40&md5=170c809b67a59e9537b2f0fbc5c0675c 0,purpose paper present method ultrasonic characterization air saturated porous media solving inverse problem using reflected waves first interface infer porosity tortuosity viscous thermal characteristic lengths solution inverse problem relies use different reflected pressure signals obtained multiple obliquely incident waves time domain paper authors propose solve inverse problem numerically first level bayesian inference method summarizing authors knowledge inferred parameters form posterior probability densities exploring densities using markov chain monte carlo approach despite low sensitivity reflection coefficient still possible extract knowledge viscous thermal characteristic lengths allowing simultaneous determination physical parameters involved expression reflection operator constrain problem guide inference knowledge particular incident angle used one advantage order precisely define thermal length effectively yielding statistical relationship tortuosity characteristic length ratio â© acoustical society america
10.1002/pst.1851 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049791472&doi=10.1002%2fpst.1851&partnerID=40&md5=8777fa873f5f14676a73e6946e507bbd 2,recent advancement many therapeutic areas quest better enhanced treatment options ever increasing â€œefficacyâ€� metric plays important role development emphasis important clinical factors less intensive side effects lower toxicity ease delivery less debilitating factors may result selection treatment options may beat current established treatment option terms efficacy yet prove desirable subgroups patients resultant clinical trial means one establishes slightly less efficacious treatment known noninferiority ni trial noninferiority trials often involve active established comparator arm along placebo experimental treatment arm resulting arm trial past developments arm ni trial consider defining prespecified fraction unknown effect size reference drug e without directly specifying fixed ni margin however recent developments direct approach considered prespecified fixed margin albeit frequentist setup article consider bayesian implementation trial primary outcome interest binary bayesian paradigm important provides path integrate historical trials current trial information via sequential learning use several approximation based exact fully bayesian methods evaluate feasibility proposed approach finally clinical trial example reanalyzed demonstrate benefit proposed approach copyright â© john wiley sons ltd
10.1016/j.compedu.2018.04.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045216062&doi=10.1016%2fj.compedu.2018.04.002&partnerID=40&md5=35149cb6a99689e65fadcd8ad371bb7f 0,paper assesses integration ict education affected mathematics test scores italian students measured programme international student assessment data problem endogeneity affects survey data area addressed applying bayesian additive regression trees bart methodology cabras tena horrillo bart methodology needs prior likelihood functions using markov chain monte carlo mcmc algorithm obtain posterior distribution controlling socio economic demographic school factors predicted posterior distribution implies increase average points test scores result indicates use ict school positive strong impact mathematic test scores â©
10.1007/s11222-017-9764-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023207113&doi=10.1007%2fs11222-017-9764-4&partnerID=40&md5=5944003a4a12bfaa55da4fc8e201a948 0,approximate bayesian computation abc methods permit approximate inference intractable likelihoods possible simulate model however perform poorly high dimensional data practice must usually used conjunction dimension reduction methods resulting loss accuracy hard quantify control propose new abc method high dimensional data based rare event methods refer abc uses latent variable representation model given parameter value estimate probability rare event latent variables correspond data roughly consistent observations performed using sequential monte carlo slice sampling systematically search space latent variables contrast standard abc viewed using naive monte carlo estimate use rare event probability estimator likelihood estimate within pseudo marginal metropolisâ€“hastings algorithm parameter inference provide asymptotics showing abc lower computational cost high dimensional data standard abc methods also illustrate approach empirically gaussian distribution application infectious disease modelling â© author
10.1007/s11222-017-9763-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022186020&doi=10.1007%2fs11222-017-9763-5&partnerID=40&md5=d4f1356e05bf47413c3729bed9b0b4f3 0,riemann manifold hamiltonian monte carlo rmhmc potential produce high quality markov chain monte carlo output even challenging target distributions end symmetric positive definite scaling matrix rmhmc proposed scaling matrix obtained applying modified cholesky factorization potentially indefinite negative hessian target log density methodology able exploit sparsity hessian stemming conditional independence modeling assumptions thus admit fast implementation rmhmc even high dimensional target distributions moreover methodology exploit log concave conditional target densities often encountered bayesian hierarchical models faster sampling straightforward tuning proposed methodology compared alternatives challenging targets illustrated applying state space model real data â© springer science+business media llc
10.1007/s00168-017-0859-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040054841&doi=10.1007%2fs00168-017-0859-9&partnerID=40&md5=1627194379bba174f0cac0c2e66b13c2 0,spatial effects recognized play important role transitional dynamics regional incomes detection evaluation spatial heterogeneity spatial dependence discrete markov chain models widely applied study regional income distribution dynamics convergence vital explored issues indeed spatiotemporal setting spatial effects take much complex forms pure cross sectional setting paper address two test frameworks first conditional spatial markov chains test framework used detect spatial heterogeneity temporally lagged spatial dependence second joint spatial markov chains test framework tests contemporaneous spatial dependence series monte carlo experiments designed examine size power robustness properties tests range sample sizes spatial ã— temporal dimensions different levels discretization granularity different number regimes results indicate tests display good size property except sample size fairly small tests spatial dependence similar almost aspectsâ€”size power robustness conditional spatial markov tests spatial heterogeneity highest power detecting spatial heterogeneity granularity discretization major impact size properties tests sample size fairly small â© springer verlag gmbh germany part springer nature
10.1002/asmb.2258 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021160713&doi=10.1002%2fasmb.2258&partnerID=40&md5=944fef376d0b651cf6e6a90f294b3909 0,work investigate sequential bayesian estimation inference stochastic volatility variance gamma svvg jumps returns develop estimation algorithm combines sequential learning auxiliary particle filter particle learning filter simulation evidence empirical estimation results indicate approach able filter latent variances identify latent jumps returns provide sequential learning static parameters svvg demonstrate comparative performance sequential algorithm line markov chain monte carlo synthetic real data applications copyright â© john wiley sons ltd
10.1016/j.jval.2017.10.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035360231&doi=10.1016%2fj.jval.2017.10.021&partnerID=40&md5=cc8df1c25c1caa47547a93df73210dee 0,objectives conduct cost effectiveness analysis two planning strategies second generation direct acting antiviral interferon free regimens treatment chronic hepatitis c virus infection methods lifetime multicohort model comprised real life patients enrolled piter italian platform study viral hepatitis registry implemented iss istituto superiore di sanitã two treatment planning strategies compared policy â€”treat patients regardless stage fibrosis f â€“f second generation direct acting antivirals policy â€”treat patients f f stage prioritized scientific guidelines first remaining patients reach f stage clinical outcomes costs evaluated using lifetime horizon markov model adopting third party payer perspective health outcomes expressed terms quality adjusted life years qalys sensitivity analysis run explore first second order uncertainty heterogeneity expected value perfect information analysis also conducted results policy exhibits incremental cost effectiveness ratio â‚¬ qaly gained remains less â‚¬ qaly realizations produced monte carlo simulation proportion increases adopting threshold â‚¬ qaly gained conclusions moving urgency criterion evidence based escalating strategies prioritizing access new antiâ€“hepatitis c virus treatments good investment health whose affordability explored context specific budget impact analyses â© international society pharmacoeconomics outcomes research ispor
10.1016/j.jclinepi.2018.03.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044948118&doi=10.1016%2fj.jclinepi.2018.03.005&partnerID=40&md5=0a5e636484ba98300a09acbec3554d55 0,objectives network meta analyses nma extensively used compare effectiveness multiple interventions health care policy decision making however methods evaluating performance multiple diagnostic tests less established decision making context often interested comparing ranking performance multiple diagnostic tests varying levels test thresholds one simultaneous analysis study design setting motivated example cognitive impairment diagnosis following stroke synthesized data studies assessing efficiency two diagnostic tests mini mental state examination mmse montreal cognitive assessment moca two test thresholds mmse moca using markov chain monte carlo mcmc methods fitted bivariate network meta analysis model incorporating constraints increasing test threshold accounting correlations multiple test accuracy measures study results developed successfully fitted model comparing multiple tests threshold combinations imposing threshold constraints using model found moca threshold appeared best true positive rate whereas mmse threshold appeared best true negative rate conclusion combined analysis multiple tests multiple thresholds allowed rigorous comparisons competing diagnostics tests decision making â© authors
10.1093/gji/ggy146 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047840156&doi=10.1093%2fgji%2fggy146&partnerID=40&md5=63bae0c79c254ae0cb5d0985b6da077f 0,despite surface displacements observed geodesy linear combinations slip faults elastic medium determining spatial distribution fault slip remains ill posed inverse problem widely used approach circumvent illness inversion add regularization constraints terms smoothing damping linear system becomes invertible however choice regularization parameters often arbitrary sometimes leads significantly different results furthermore resolution analysis usually empirical made independently regularization stochastic approach inverse problems provides rigorous framework priori information searched parameters combined observations order derive posterior probabilities unkown parameters investigate approach prior probability density function pdf multivariate gaussian function single truncation impose positivity slip double truncation impose positivity upper bounds slip interseismic modelling show joint posterior pdf similar linear untruncated gaussian case expressed truncated multivariate normal tmvn distribution tmvn form used obtain semi analytical formulae single n marginal pdf semi analytical formula involves product gaussian integral term evaluated using recent developments tmvn probabilities calculations posterior mean covariance also efficiently derived show maximum posterior map obtained using non negative least squares algorithm single truncated case using bounded variable least squares algorithm double truncated case show case independent uniform priors approximated using tmvn numerical equivalence bayesian inversions using monte carlo markov chain mcmc sampling shown synthetic example real case interseismic modelling central peru tmvn method overcomes several limitations bayesian approach using mcmc sampling first need computer power largely reduced second unlike bayesian mcmc based approach marginal pdf mean variance covariance obtained independently one third probability cumulative density functions obtained density points finally determining map extremely fast â© author published oxford university press behalf royal astronomical society
10.1145/3186586 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052573954&doi=10.1145%2f3186586&partnerID=40&md5=9c36ec309ef95ce4d087f0441d0db8f7 0,counting graphlets well studied problem graph mining social network analysis recently several papers explored simple natural algorithms based monte carlo sampling markov chains mc reported encouraging results show perhaps surprisingly algorithms outperformed color coding cc sophisticated algorithmic technique extend case graphlet sampling prove strong statistical guarantees computational experiments graphs millions nodes show cc accurate mc furthermore formally show mixing time mc approach high general even input graph high conductance comes price however mc efficient terms space cc memory requirements become demanding size input graph graphlets grow yet experiments show cc push limits state art terms size input graph graphlets â© acm
10.3969/j.issn.1000-7229.2018.07.016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054599093&doi=10.3969%2fj.issn.1000-7229.2018.07.016&partnerID=40&md5=bd0d7e578bb36721841a781aa2da3033 0,view uncertainty electric vehicle charging behavior models electric vehicle travel battery electricity change based trip chain theory established analysis method charging behavior electric vehicles introducing markov decision processes mdp proposed method takes user charging behavior markov decision set constructs state transfer matrix according transfer probability various regions user satisfaction index set reward function decision process optimal charging decision electric vehicle users every decision point obtained solving finite stage total reward criterion example simulated extracting characteristic data electric vehicles results show time space distribution electric vehicle charging load compared traditional monte carlo method proposed mdp method simulate user charging behavior accurately reflect temporal spatial distribution characteristics charging demand time different charging behavior electric vehicles different areas different parking hours analyzed provide support planning construction electric vehicle charging piles â© state power economic research institute rights reserved
10.1029/2018GC007585 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051075759&doi=10.1029%2f2018GC007585&partnerID=40&md5=fa3cfb739a961d59eab5744f9e517e07 1,new satellite missions e g european space agency sentinel constellation advances data downlinking rapid product generation provide us ability access space geodetic data within hours acquisition truly take advantage opportunity need able interpret geodetic data prompt robust manner present bayesian approach inversion multiple geodetic data sets allows rapid characterization posterior probability density functions pdfs source model parameters inversion algorithm efficiently samples posterior pdfs markov chain monte carlo method incorporating metropolis hastings algorithm automatic step size selection apply approach synthetic geodetic data simulating deformation magmatic origin demonstrate ability retrieve known source parameters also apply inversion algorithm interferometric synthetic aperture radar data measuring co seismic displacements thrust faulting earthquake mw pishan earthquake china retrieve optimal source parameters associated uncertainties given robustness rapidity estimating deformation source parameters uncertainties bayesian framework capable taking advantage real time geodetic measurements thus approach applied geodetic data study magmatic tectonic geophysical processes especially rapid response operational settings e g volcano observatories algorithm fully implemented matlabâ® based software package geodetic bayesian inversion software make freely available scientific community â© authors
10.1051/0004-6361/201732547 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051949735&doi=10.1051%2f0004-6361%2f201732547&partnerID=40&md5=4eb2b0c56ecd50cc9dd25475ef1929c2 1,galaxies follow tight radial acceleration relation rar acceleration observed every radius correlates expected distribution baryons use markov chain monte carlo method fit mean rar individual galaxies sparc database marginalizing stellar mass light ratio î³ âˆ— galaxy distance disk inclination acceptable fits astrophysically reasonable parameters found vast majority galaxies residuals around fits rms scatter dex agreement predictions modified newtonian dynamics mond consider generalized version rar unlike mond permits galaxy galaxy variation critical acceleration scale fits improved additional freedom credible indication variation critical acceleration scale data consistent action single effective force law apparent universality acceleration scale small residual scatter key understanding galaxies â© eso
10.1371/journal.pcbi.1006202 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050992207&doi=10.1371%2fjournal.pcbi.1006202&partnerID=40&md5=39e182e9247768081db272327f4ddadb 1,event new infectious disease outbreak mathematical simulation models commonly used inform policy evaluating control strategies minimize impact epidemic early stages outbreaks substantial parameter uncertainty may limit ability models provide accurate predictions policymakers luxury waiting data alleviate state uncertainty policymakers however selection optimal control intervention face uncertainty rather accuracy model predictions measure success counts simulate process real time decision making fitting epidemic model observed spatially explicit infection data weekly intervals throughout two historical outbreaks foot mouth disease uk miyazaki japan compare forward simulations impact switching alternative control intervention time point question compared policy recommendations generated hindsight using data entire outbreak thereby comparing best done time best done retrospect results show control policy chosen using data also identified early stage outbreak using available data despite high variability projections epidemic size critically find improved understanding locations infected farms rather improved estimates transmission parameters drives improved prediction relative performance control interventions however ability estimate undetected infectious premises function uncertainty transmission parameters demonstrate need real time model fitting generating projections evaluate alternative control interventions throughout outbreak results highlight use using models outbreak onset inform policy importance state dependent interventions adapt response additional information throughout outbreak â© public library science rights reserved
10.29220/CSAM.2018.25.4.355 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054033525&doi=10.29220%2fCSAM.2018.25.4.355&partnerID=40&md5=3ae05abf407c32b6bb7c4aa12d78e9fd 0,two parameter negative exponential distribution many practical applications queuing theory service times agents system time takes next telephone call time radioactive practical decays distance mutations dna strand extreme values annual snowfall rainfall consequently many applications reliability systems paper considers estimation problem stress strength model two parameter negative parameter exponential distribution introduce maximum penalized likelihood method bayes estimator using lindley approximation estimate stress strength model compare proposed estimators regular maximum likelihood estimator complete data also introduce maximum penalized likelihood method bayes estimator using markov chain mote carlo technique incomplete data monte carlo simulation study performed compare stress strength model estimates real data used practical application proposed model â© korean statistical society korean international statistical society
10.1007/s00601-018-1384-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046291102&doi=10.1007%2fs00601-018-1384-9&partnerID=40&md5=5d0120d488ec5a6a67c8d8c635af6632 0,method presented ensures different polarization observables describing one reaction channel consistent using connection observables underlying reaction amplitudes constrained estimate observables carried using markov chain monte carlo method initial results indicate new estimates guaranteed physical remove need artificial fudge factors processed data used subsequent fits â© author
10.1007/s11222-017-9774-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028543383&doi=10.1007%2fs11222-017-9774-2&partnerID=40&md5=15aff8bdc73f59f0db24394f644d8ac5 1,label switching well known fundamental problem bayesian estimation finite mixture models arises exploring complex posterior distributions markov chain monte carlo mcmc algorithms likelihood model invariant relabelling mixture components mcmc sampler randomly switches labels unsuitable exploring posterior distributions component related parameters paper new procedure based post mcmc relabelling chains proposed main idea method perform clustering technique similarity matrix obtained mcmc sample whose elements probabilities two units observed sample drawn component although generalized situation may handy many applications simplicity low computational burden â© springer science+business media llc
10.18576/amis/120413 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053404661&doi=10.18576%2famis%2f120413&partnerID=40&md5=fe556e85885b8f9e658d414a6a615f27 0,article considers problem estimating unknown parameters compound rayleigh distribution progressive first failure censoring scheme step stress partially accelerated life tests alt progressive first failure censoring accelerated life testing performed decrease duration testing lower test expenses maximum likelihood estimators mles bayes estimates bes distribution parameters acceleration factor obtained optimal time stress change determined furthermore approximate bootstrap credible confidence intervals cis parameters derived methods markov chain monte carlo mcmc used obtain bayes estimates finally accuracy mles bes model parameters investigated simulation studies â© nsp
10.1142/S0218271818440078 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045930412&doi=10.1142%2fS0218271818440078&partnerID=40&md5=3072d9a07e735aa1908015e301eea2ce 0,discovery high energy gamma ray emission flat spectrum radio quasars fsrqs ground based cherenkov telescopes hess magic veritas provides new view blazar emission processes available data multiwavelength observations fsrqs allow us constrain size possibly also location emitting region magnetic field electron energy distribution etc crucial understanding jet properties investigate origin emission fsrqs pks pks + c modeling broadband spectral energy distribution quiescent flaring states using estimation parameter space describes underlying particle distribution responsible emission markov chain monte carlo mcmc technique â© world scientific publishing company
10.1007/s11222-017-9770-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026771351&doi=10.1007%2fs11222-017-9770-6&partnerID=40&md5=f91b033290896e2e9641f0bb054828b3 0,statistical model assuming preferential attachment network generated adding nodes sequentially according simple rules usually describes real life networks better model assuming example bernoulli random graph two nodes probability connected therefore study propagation â€œinfectionâ€� across social network propose network epidemic model combining stochastic epidemic model preferential attachment model simulation study based subsequent markov chain monte carlo algorithm reveals identifiability issue model parameters finally network epidemic model applied set online commissioning data â© author
10.1002/asna.201813491 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053525313&doi=10.1002%2fasna.201813491&partnerID=40&md5=a023688c347cd278478528644890d93d 0,photometric observation one important means understand fundamental properties asteroids photometric data obtained expanding effectively number samples spin states asteroids become important research topic obtain preliminary solution spin state without statistical discrepancy photometric observations derived handful apparitions moderate complexity shape model consisting eight adjacent octants different semiaxes namely cellinoid ellipsoid adopted using model employing markov chain monte carlo mcmc method spin states four asteroids discussed based existing photometric data â© wiley vch verlag gmbh co kgaa weinheim
10.15446/rce.v41n2.69621 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050977672&doi=10.15446%2frce.v41n2.69621&partnerID=40&md5=65788f57cfb111c72694d9ddc965cde5 0,paper study reliability multicomponent stress strength model assuming components follow power lindley model maximum likelihood estimate reliability parameter asymptotic confidence interval obtained applying parametric bootstrap technique interval estimation reliability presented also bayes estimate highest posterior density credible interval reliability parameter derived using suitable priors parameters closed form bayes estimate use markov chain monte carlo method obtain approximate bayes estimate reliability evaluate performances different procedures simulation studies conducted example real data sets provided â© universidad nacional de colombia rights reserved
10.1007/s11222-017-9773-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028765412&doi=10.1007%2fs11222-017-9773-3&partnerID=40&md5=4797d850d23af43745291276de877620 2,synthetic likelihood attractive approach likelihood free inference approximately gaussian summary statistic data informative inference parameters available synthetic likelihood method derives approximate likelihood function plug normal density estimate summary statistic plug mean covariance matrix obtained monte carlo simulation model article develop alternatives markov chain monte carlo implementations bayesian synthetic likelihoods reduced computational overheads approach uses stochastic gradient variational inference methods posterior approximation synthetic likelihood context employing unbiased estimates log likelihood compare new method related likelihood free variational inference technique literature time improving implementation approach number ways new algorithms feasible implement situations challenging conventional approximate bayesian computation methods terms dimensionality parameter summary statistic â© springer science+business media llc
10.1590/0001-3765201820171040 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054562013&doi=10.1590%2f0001-3765201820171040&partnerID=40&md5=b00e7888ed6e5cde8f025c63f671ba19 0,paper takes account estimation unknown parameters gompertz distribution frequentist bayesian view points using objective subjective prior distributions first derive non informative priors using formal rules jefreys prior maximal data information prior mdip based fisher information entropy respectively also propose prior distribution incorporate expertâ€™s knowledge issue study regard assume two independent gamma distributions parameters gompertz distribution employed elicitation process based predictive prior distribution using laplace approximation integrals suppose expert summarize knowledge reliability item statements percentiles also present set priors proposed singpurwala assuming truncated normal prior distribution median distribution gamma prior scale parameter next investigate effects priors posterior estimates parameters gompertz distribution bayes estimates computed using markov chain monte carlo mcmc algorithm extensive numerical simulation carried evaluate performance maximum likelihood estimates bayes estimates based bias mean squared error coverage probabilities finally real data set analyzed illustrative purposes â© academia brasileira de ciencias rights reserved
10.3847/1538-4357/aac77d https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050117249&doi=10.3847%2f1538-4357%2faac77d&partnerID=40&md5=946e45f8e51ac5aa7fb7dae863e38b96 0,spectral type mrk changed type returned back period years investigated physical mechanisms responsible spectral change mrk analyzing archival spectral imaging data two kinematically distinct broad line components blueshifted redshifted components found spectral decomposition velocity offset curve broad line function time shows characteristic pattern oscillating recoiled supermassive black hole rsmbh scenario proposed explain observed velocity offset broad emission lines bayesian markov chain monte carlo simulation performed derive best fit orbital parameters find rsmbh highly eccentric orbit period âˆ¼ years active galactic nucleus agn activity traced variation broad hî² emission lines found increase decrease rapidly start end cycle peaks twice start near end cycle extinction start end cycle spectral type type found increase due increased covering factor perturbations accretion disk caused pericentric passage reasonably explain agn activity spectral change mrk currently spectral type mrk type know repeat similar pattern spectral change future spectral type turn type around mid â© american astronomical society rights reserved
10.1177/1060028018786954 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049899625&doi=10.1177%2f1060028018786954&partnerID=40&md5=18ac7e1045098a1ad9bba7ae27eac813 0,background comparative effects droxidopa midodrine standing systolic blood pressure ssbp risk supine hypertension patients neurogenic orthostatic hypotension noh unknown objective perform bayesian mixed treatment comparison meta analysis droxidopa midodrine treatment noh methods pubmed central embase databases searched november study selection consisted randomized trials comparing droxidopa midodrine placebo reporting changes ssbp supine hypertension events data pooled perform comparison among interventions bayesian fixed effects model using vague priors markov chain monte carlo simulation gibbs sampling calculating pooled mean changes ssbp risk ratios rrs supine hypertension associated credible intervals cris results six studies administering droxidopa administering midodrine enrolling total patients included analysis mean change baseline ssbp significantly greater drugs compared placebo droxidopa mm hg cri = midodrine mm hg cri = comparative analysis revealed significant credible difference droxidopa midodrine rr supine hypertension significantly greater midodrine droxidopa compared placebo droxidopa rr = cri = midodrine rr = cri = conclusion relevance patients noh droxidopa midodrine significantly increase ssbp latter greater extent however midodrine droxidopa significantly increases risk supine hypertension â© author
10.1002/uog.19073 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047825136&doi=10.1002%2fuog.19073&partnerID=40&md5=03d7f53cffe300f3d424aa09dceda3d9 3,objective develop fetal neonatal population weight charts rationale reference ranges estimated fetal weight efw representative whole population traditional approach deriving birth weight bw charts misleading large proportion babies born preterm arise pathological pregnancy propose reference population bw charts case efw charts comprise babies given gestational age including still utero methods two sources data used study inclusion criteria singleton pregnancy dating fetal crownâ€“rump length + + weeks gestation availability ultrasonographic measurements fetal head circumference hc abdominal circumference ac femur length fl live birth phenotypically normal neonate dataset comprised sample paired measurements efw bw ultrasound examinations carried â€“ weeks gestation birth occurred within days ultrasound examination efw derived hc ac fl measurements using formula reported hadlock et al dataset comprised sample pregnancies efw obtained routine ultrasonographic fetal biometry + + weeks gestation nâ = + + weeks nâ = + + weeks nâ = purpose study included data one three visits per pregnancy development reference ranges efw bw according gestational age following assumptions made first efw bw common median dependent gestational age second deviations median occur efw bw deviations correlated different levels spread efw bw dependent gestational age adopted bayesian approach inference combining information two datasets using markov chain monte carlo sampling fitted model assumed mean log transformed measurements efw bw related gestational age according cubic equation deviations mean follow bivariate gaussian distribution results case efw dataset good distribution values lt rd lt th lt th gt th gt th gt th percentiles reference range efw according gestational age throughout gestational age range + + â weeks case bw good distribution values cases delivered gt weeks gestation preterm births particularly â€“ weeks bw rd th th percentiles high proportion cases particularly cases iatrogenic birth incidence small gestational age fetuses neonates respective efw bw charts higher women black white racial origin conclusion established bw chart babies given gestational age including still utero thereby overcoming problem underestimation growth restriction preterm birth bw efw charts common median differ levels spread median copyright â© isuog published john wiley amp sons ltd copyright â© isuog published john wiley sons ltd
10.1093/mnras/sty796 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047157879&doi=10.1093%2fmnras%2fsty796&partnerID=40&md5=378cc20870d9c1f780944b4f769e2e93 0,extend cmmc monte carlo markov chain sampler reionization simulations perform parameter estimation directly light cones cosmic cm signal brings theoretical analysis closer tomographic cm observations achievable next generation interferometers like hydrogen epoch reionization array square kilometre array parameter recovery therefore account modes evolve redshift frequency additionally simulated data easily corrupted resemble real data using light cone version cmmc quantify biases recovered astrophysical parameters use cm power spectrum co evolution approximation fit light cone mock observation ignoring light cone effect assumptions significantly bias recovered astrophysical parameters lead underestimation associated uncertainty however significant biases ïƒ occur cm signal evolves rapidly e epochs reionization heating overlap significantly foreground removal efficient allowing large physical scales k â‰² mpc used analysis ii theoretical modelling accurate within per cent power spectrum amplitude â© author published oxford university press behalf royal astronomical society
10.1103/PhysRevLett.120.262702 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049370396&doi=10.1103%2fPhysRevLett.120.262702&partnerID=40&md5=2a3172d8286677225ba2d27402db3d5d 1,canadian penning trap mass spectrometer californium rare isotope breeder upgrade caribu facility used measure masses eight neutron rich isotopes nd sm measurements first push region nuclear masses relevant formation rare earth abundance peak aâˆ¼ rapid neutron capture process compare results theoretical predictions obtained reverse engineering mass surface best reproduces observed solar abundances region markov chain monte carlo technique measured masses consistent reverse engineering predictions neutron star merger wind scenario â© american physical society
10.1088/1361-6420/aaca8f https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051219538&doi=10.1088%2f1361-6420%2faaca8f&partnerID=40&md5=00f6b72f572b8c372ff485e1d36bee96 1,traditional imaging algorithms within ultrasonic non destructive testing community typically assume material inspected primarily homogeneous heterogeneities sub wavelength scales medium generally heterogeneous nature assumption contribute poor detection sizing characterisation defects prior knowledge varying wave speeds within component allow accurate imaging defects leading better decisions treat damaged component work endeavours reconstruct inhomogeneous wave speed maps random media simulated ultrasonic phased array data achieved via application reversible jump markov chain monte carlo method sampling based approach within bayesian framework inverted maps used conjunction imaging algorithm correct deviations wave speed reconstructed flaw images used quantitatively assess success methodology using full matrix capture data arising finite element simulation phased array inspection heterogeneous component six fold improvement flaw location achieved taking account reconstructed wave speed map exploits almost priori knowledge material internal structure receiver operating characteristic curves calculated demonstrate enhanced probability detection achieved material speed map accounted â© iop publishing ltd
10.1080/12269328.2018.1486738 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049122053&doi=10.1080%2f12269328.2018.1486738&partnerID=40&md5=d10ebeb8b5ad83407f5de532d365538c 0,different sizes pore spaces play different roles fluid flow properties rocks advantages image analysis employed study effect different sizes pore spaces including micropores â€“ â âµm mesopores â€“ â âµm macropores â âµm contribution permeability carbonates first original binarized photomicrographs subdivided three images contains one class pores three dimensional digital models images reconstructed using markov chain monte carlo method models integrated using superposition operation finally lattice boltzmann method used estimate permeability model results show higher percentage macropores provides higher permeability growth micropores percentage insignificant effect flow properties due lack pores connectivity spite negligible permeability micropores lonely improve carbonate rock permeability cooperation meso macropores estimated permeability superposed digital models closer reality compared processed models reconstructed without pore differentiation â© taylor francis rights reserved
10.13465/j.cnki.jvs.2018.12.024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053667315&doi=10.13465%2fj.cnki.jvs.2018.12.024&partnerID=40&md5=8a0f268d310c1cfc73a86628c9fc3a94 0,within framework probability information theory paper presents methodology finite element fe model class selection selecting suitable modeling parameters update fe models based bayesian evidence inference markov chain monte carlo mcmc method amount information needed extracted measurement data explicitly quantified procedure fe model updating introducing concept information divergence employed penalizing complexity fe parameterization trade complexity given fe model class corresponding information theoretic interpretation order obtain relatively simple fe parameterization scheme keeping similar model data matching avoid fitting problem arisen excessive modeling parameters efficiently validity presented methodology verified numerical simulation experimental verification carried two story bolt connected steel frame â© editorial office journal vibration shock right reserved
10.1088/1361-6420/aac9b3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049741759&doi=10.1088%2f1361-6420%2faac9b3&partnerID=40&md5=7c2f5de83e1e5cb3867650322d7a6529 0,majorization minimization mm standard iterative optimization technique consists minimizing sequence convex surrogate functionals mm approaches particularly successful tackle inverse problems statistical machine learning problems regularization term sparsity promoting concave function however due non convexity solution found mm depends initialization uniform initialization natural often employed strategy boils penalizing coefficients equally first mm iteration yet arbitrary choice lead unsatisfactory results severely determined inverse problems source imaging magneto electro encephalography eeg framework hierarchical bayesian modeling hbm alternative approach encode sparsity work shows certain hierarchical models simple alternating scheme compute fully bayesian maximum posteriori map estimates leads exact sequence updates standard mm strategy see adaptive lasso parallel outlined show improve upon mm techniques probing multimodal posterior density using markov chain monte carlo mcmc techniques firstly show samples provide well informed initializations help mm schemes reach better local minima secondly demonstrate reveal different modes posterior distribution order explore quantify inherent uncertainty ambiguity ill posed inference procedure context eeg mode corresponds plausible configuration neural sources crucial data interpretation especially clinical contexts results simulations real datasets show number type sensors affect uncertainties estimates â© iop publishing ltd
10.1063/1.5041544 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049783110&doi=10.1063%2f1.5041544&partnerID=40&md5=2107ab0e51368d89ba6df402527643d0 0,deal variation correlation structure accident data along recognized covariate effects develop spatio temporal model multivariate accident count data based multivariate poisson lognormal model introduce linear combinations random impulses capture spatial correlation temporal effects lagged observations added model model estimation carried using markov chain monte carlo methods simulated data sets used assessing performance model advantage new model copes three sources variations time space multivariate data variations also provides information time space dependency model also capable providing improvement accuracy count data modelling â© author
10.1088/1742-5468/aac915 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049672218&doi=10.1088%2f1742-5468%2faac915&partnerID=40&md5=3c98a2d735f3b8fb6248bde10a18f27e 0,describe simple method umbrella trajectory sampling markov chains method allows estimation large deviation rate functions path extensive dynamic observables arbitrary number models within certain family general relationship probability distributions dynamic observables members family extended fluctuation relation dynamic observable chosen entropy production members family include forward markov chain time reverse whose probability distributions related expected simple fluctuation relation â© iop publishing ltd sissa medialab srl
10.1109/ACCESS.2018.2849213 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049139955&doi=10.1109%2fACCESS.2018.2849213&partnerID=40&md5=d313d481b7b4b2efaa5a50333d0a30f3 0,graphical models provide effective way reveal complicated associations data especially learn structures among large numbers variables respect observations high dimensional space paper novel graphical algorithm integrates dynamic time warping dtw measure birth death markov chain monte carlo bdmcmc methodology dtwd bdmcmc proposed modeling intrinsic correlations buried data dtw ratio dtw euclidean distance ed targeted calibrate warping observation sequences approach bdmcmc bayesian framework used structure learning sparse graphical models detail modified dtw distance matrix first developed construct weighted covariance instead traditional covariance calculated ed build bayesian gaussian models weighted covariance aim robust problems sequence distortion moreover weighted covariance used limited prior information facilitate initial graphical structure finally employ bdmcmc determination reconstructed gaussian graphical model initialization beneficial improve convergence bdmcmc sampling implement method broad simulated data test ability deal different kinds graphical structures paper demonstrates effectiveness proposed method comparison rivals competitively applied gaussian graphical models copula gaussian graphical models addition apply method explore real network attacks genetic expression data â© ieee
10.1109/SBSE.2018.8395774 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050186972&doi=10.1109%2fSBSE.2018.8395774&partnerID=40&md5=f0d36ed6332f6eb180f4b09f5ed2f1a5 0,paper shows application markov chain monte carlo method mcmc generation synthetic wind speed time series variations within method discussed divide states transition matrix convert states speeds include seasonality series article also discusses best metrics evaluate performance time series statistical parameters probability distribution autocorrelation function analyzed â© ieee
10.17713/ajs.v47i3.752 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050478492&doi=10.17713%2fajs.v47i3.752&partnerID=40&md5=4a17bb243244bb73ca12e7ab9821c04e 0,article presents procedures parameter estimation based type ii progressively hybrid censored fuzzy lifetime data classical well bayesian procedures estimation unknown model parameters developed purpose considered problem point estimation parameter rayleigh distribution estimators obtained maximum likelihood ml estimator method moments mm estimator computational approach ca estimator bayes estimator highest posterior density hpd credible intervals unknown parameter obtained using markov chain monte carlo mcmc technique numerical illustration real data set considered â© austrian statistical society rights reserved
10.1093/MNRAS/STY558 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049963826&doi=10.1093%2fMNRAS%2fSTY558&partnerID=40&md5=e9aab43ebf04d8904cc8ac93eab34ac9 1,present spiderman secondary eclipse phase curve integrator temperature mapping fast code calculating exoplanet phase curves secondary eclipses arbitrary surface brightness distributions two dimensions using geometrical algorithm code solves exactly area sections disc planet occulted star code written c user friendly python interface optimized run quickly loss numerical precision approximately models generated per second typical use making markov chain monte carlo analyses practicable modular nature code allows easy comparison effect multiple different brightness distributions data set test case apply code archival data phase curve wasp b using physically motivated analytical model two dimensional brightness map model provides good fit data however overpredicts temperature nightside speculate due presence clouds nightside planet additional reflected light dayside testing simple cloud model find best fitting model geometric albedo â± require hot nightside also test variation map parameters function wavelength find statistically significant correlations spiderman available download https github com tomlouden spiderman â© authors
10.1103/PhysRevC.97.064612 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049003285&doi=10.1103%2fPhysRevC.97.064612&partnerID=40&md5=9ba07d3b3422decd56918ab480269edb 0,background able rigorously quantify uncertainties reaction models crucial moving field forward even though bayesian methods becoming increasingly popular nuclear theory yet implemented applied reaction theory problems purpose purpose work investigate using bayesian methods uncertainties optical potentials generated fits elastic scattering data subsequent uncertainties transfer predictions also study differences two reaction models parameters constrained similar manner well impact reducing experimental error bars data used constrain parameters method use bayes theorem combined markov chain monte carlo determine posterior distributions parameters optical model constrained neutron proton deuteron target elastic scattering potentials used predict transfer cross sections within adiabatic wave approximation distorted wave born approximation results study number reactions involving deuteron projectiles energies range mev nucleon targets mass a= case ca p ca transfer ground state described detail comparative study effect size experimental errors also performed five transfer reactions studied results compiled order systematically identify trends conclusions uncertainties transfer cross sections vary significantly depending reaction uncertainties reduced smaller experimental error bars used constrain potentials reduction trivially related error reduction also find smaller uncertainties using adiabatic formulation using distorted wave born approximation â© american physical society
10.3901/JME.2018.12.115 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052104866&doi=10.3901%2fJME.2018.12.115&partnerID=40&md5=5944ce7f3614eae331921d676d64bfbe 0,novel remaining useful life rul estimation method proposed based data driven method bayesian theory remaining useful life estimation complex mechanical systems firstly condition monitoring data similar systems fused form health index indicating degradation degree systems state model data driven method bayesian model state model parameters built bayesian theory line condition monitoring data system estimated bayesian model model parameters updated markov chain monte carlo mcmc rul system estimated last turbofan engine case used show effectiveness present method â© journal mechanical engineering
10.1136/bjophthalmol-2018-312198 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048873917&doi=10.1136%2fbjophthalmol-2018-312198&partnerID=40&md5=241005c2ca2a17b44b0ebd98d4747e77 0,background aim clarify nature relationship novel oral anticoagulants noacs traditional anticoagulation respect intraocular bleeding methods comprehensive literature search october yielded randomised controlled trials bayesian markov chain monte carlo analysis employed investigate relationship across multiple trials varying noacs random effects informative priors ors applied risk intraocular bleeding due various treatment measures mantel haenszel pairwise analyses also performed total participants different randomised controlled trials received apixaban received dabigatran received edoxaban received rivaroxaban received warfarin results edoxaban significantly associated reduced risk intraocular bleeding comparison warfarin ci findings non significant however apixaban noac trend increased event rate warfarin bayesian markov chain monte carlo modelling indicated edoxaban greatest chance producing lowest rate bleeding surface cumulative ranking curve pooled pairwise analysis supported network analysis results favouring edoxaban warfarin ci p= well subgroup analysis low dose edoxaban versus warfarin ci conclusion analysis suggests edoxaban may paramount agent reducing intraocular bleeding rates given paucity reporting data rare event future research confirmation strongly recommended â© article author employer unless otherwise stated text article rights reserved
10.1088/1757-899X/371/1/012020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049789787&doi=10.1088%2f1757-899X%2f371%2f1%2f012020&partnerID=40&md5=0c0c932d3acabd30cbb7658355664324 0,compared conventional concrete products pervious concrete usually features high water permeability rate low compressive strength due lack fine aggregates thus determination optimal mix design ingredients recognized effective mechanism achieve trade compressive strength permeability rate paper proposed markov chain monte carlo based approach approximate optimal mix design pervious concrete achieve relatively high compressive strength maintaining desired permeability rate proved proposed approach effectively converges optimal solutions convergence rate accuracy rely control parameter used proposed algorithm number simulations carried results show proposed system converges optimal solutions quickly derived optimal mix design â© published licence iop publishing ltd
10.1109/ICCCC.2018.8390433 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050083081&doi=10.1109%2fICCCC.2018.8390433&partnerID=40&md5=a560e7801969b1860f6b3469d36492fa 0,paper proposes ensemble kalman filter implementation non linear data assimilation ensemble based method moments background error distributions approximated means ensemble model realizations precision background covariance estimated via modified cholesky decomposition order decrease impact sampling errors hyper parameters estimated samples posterior distribution estimated via markov chain monte carlo mcmc method mcmc implementation enhanced means linear approximations observation operator posterior ensembles built using series rank one updates prior cholesky factors experimental tests carried using lorenz model numerical results evidence degree observational operator increases accuracy proposed filter affected even full observational networks posterior errors much lower backgrounds cases several order magnitudes â© ieee
10.1080/03610926.2017.1346805 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031495115&doi=10.1080%2f03610926.2017.1346805&partnerID=40&md5=21c7d75d2922e765e133d4a13912de6d 0,properties high dimensional bingham distributions studied kume walker fallaize kypraios propose bayesian inference bingham distribution use developments bayesian computation distributions doubly intractable normalizing constants mã ller etâ al murray ghahramani mackay however rely heavily two metropolis updates need tune article propose instead model selection marginal likelihood â© taylor francis group llc
10.1109/TMI.2018.2848104 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048890082&doi=10.1109%2fTMI.2018.2848104&partnerID=40&md5=5039f1493a77c3a6399d869110cee2e9 0,computed tomography trade quality reconstructed image radiation dose received patient order find appropriate compromise image quality reconstructed images radiation dose important reliable methods evaluating quality reconstructed images successful family methods assessment image quality task based image quality assessment often involves use model observers assesses quality image reconstruction deriving figure merit present bayesian framework used task based image quality assessment framework applicable binary classification problems normally distributed observations make additional assumption covariance matrix image classes choose particular non informative prior parameters model allows us derive expression bayes factor binary classification problem best knowledge novel introduce novel model observer based bayes factor developed methodology estimating posterior distribution figure merit type classification problem compared classical statistical approaches bayesian approach advantage provides full characterization uncertainty figure merit choice prior allows us design simple monte carlo algorithm efficiently sample posterior figure merit ideal observer contrast common bayesian procedures rely computationally expensive markov chain monte carlo sampling shown training samples sufficient size estimated credible intervals figure merit coverage probabilities close credibility approach reasonably used within classical statistical framework well ieee
10.1109/JIOT.2018.2847697 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048614410&doi=10.1109%2fJIOT.2018.2847697&partnerID=40&md5=c4a671f8252e4ce648b9a0998fbdaf29 0,consider problem blind calibration sensor network sensor gains offsets estimated noisy observations unknown signals general non identifiable problem unless restrictive assumptions signal subspace sensor observations imposed show signal observed sensors follows known dynamic model additive noise sensor gains offsets identifiable propose dynamic bayesian nonparametric model infer sensors x gains offsets model allows different sensor clusters observe different unknown signals without knowing sensor clusters priori develop offline algorithm using block gibbs sampling linearized forward filtering backward sampling method estimates sensor clusters gains offsets jointly furthermore practical implementation also propose online inference algorithm based particle filtering local markov chain monte carlo simulations using synthetic dataset experiments two real datasets suggest proposed methods perform better several blind calibration methods including sparse bayesian learning approach methods first cluster sensor observations estimate gains offsets ieee
10.1016/j.rse.2018.04.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045119533&doi=10.1016%2fj.rse.2018.04.006&partnerID=40&md5=79114fdef9522981ad8195e816ec129a 0,surface air temperature sat critical metric used assess regional warming cooling patterns maximum minimum sats required evaluate model predictions climate extremes since station sat data irregularly distributed land surface temperature lst values derived moderate resolution imaging spectroradiometer modis data used estimate regional sat using linear regression methods deviations sat lst largely dependent space time hampers estimation linear regression especially maximum sat obtain accurate regional sat estimates three stage hierarchical bayesian hb model proposed incorporates modis lsts model covariates specifies deviations structured dependence modis lst fields sampling model parameters estimation sat values implemented bayesian paradigm using markov chain monte carlo algorithm sensitivity analyses involving various model configurations running processes discussed help build robust hb model model performance evaluated using station measurements used modeling process rmses k k monthly maximum minimum sats respectively evaluation indicates hb modeling effective method estimate sat modis lst verified hb model covariate inputs modis daytime nighttime lsts used reproduce monthly maximum minimum sats spatially continuous qinghai province northwestern china â€“ comparison modis lst hb estimated sat found spatial structure warming patterns lst sat show significant distinctions implying substituted one another assessing regional warming trends spatial heterogeneity hb model estimation able provide thorough insights regional sat status changes otherwise biased station deployment â© elsevier inc
10.1109/TAES.2018.2848360 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048643810&doi=10.1109%2fTAES.2018.2848360&partnerID=40&md5=ef204c82844f14bbe50c72b62b6efc61 0,problem considered estimating unambiguously migrating targets observed wideband radar extend previously described sparse bayesian algorithm presence diffuse clutter grid targets hybrid gibbs sampler formulated jointly estimate sparse target amplitude vector grid mismatch assumed autoregressive noise results synthetic fully experimental data show targets actually unambiguously estimated even located blind speeds ieee
10.1002/sim.7627 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042534937&doi=10.1002%2fsim.7627&partnerID=40&md5=049d1585ab7ca7e50904a5f62994905b 0,ecological momentary assessment studies usually produce intensively measured longitudinal data large numbers observations per unit research interest often centered around understanding changes variation people thoughts emotions behaviors hedeker et al developed level mixed effects location scale model allows observed covariates well unobserved variables influence mean within subjects variance level data structure observations nested within subjects ecological momentary assessment studies subjects measured multiple waves within wave subjects measured time li hedeker extended original level model level data structure observations nested within days days nested within subjects including random location scale intercept intermediate wave level however level random intercept model assumes constant response change rate mean variance account changes variance across waves well clustering attributable waves propose comprehensive location scale model allows subject heterogeneity baseline well across different waves level data structure observations nested within waves waves nested within subjects model parameters estimated using markov chain monte carlo methods provide details bayesian estimation approach demonstrate stan statistical software used sample desired distributions achieve consistent estimates proposed model validated via series simulation studies data adolescent smoking study analyzed demonstrate approach analyses clearly favor proposed model show significant subject heterogeneity baseline well change time mood mean variance proposed level location scale model widely applied areas research interest lies consistency addition mean level responses copyright â© john wiley sons ltd
10.1109/TSP.2018.2824286 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045207689&doi=10.1109%2fTSP.2018.2824286&partnerID=40&md5=7f48699ae1aba9a3efcaa10e17dcbc5f 0,paper develop bayesian evidence maximization framework solve sparse non negative least squares nnls problem introduce family probability densities referred rectified gaussian scale mixture r gsm model sparsity enforcing prior distribution solution r gsm prior encompasses variety heavy tailed densities rectified laplacian rectified student distributions proper choice mixing density utilize hierarchical representation induced r gsm prior develop evidence maximization framework based expectation maximization em algorithm using em based method estimate hyper parameters obtain point estimate solution refer proposed method rectified sparse bayesian learning r sbl provide four r sbl variants offer range options computational complexity quality e step computation methods include markov chain monte carlo em linear minimum mean square error estimation approximate message passing diagonal approximation using numerical experiments show proposed r sbl method outperforms existing nnls solvers terms signal support recovery performance also robust structure design matrix â© ieee
10.1103/PhysRevD.97.123525 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049535947&doi=10.1103%2fPhysRevD.97.123525&partnerID=40&md5=8be597254fc62f0fd8a92bd592d50ba9 1,paper investigate new phenomenological parametrization unified dark matter dark energy based polynomial expansion barotropic equation state parameter w parametrization provides well behaving evolution w small big redshifts well far future dark fluid described parametrization behaves big redshifts like dark matter dm therefore one parametrize dark energy dark matter using single dark fluid like case chaplygin gas within parametrization consider two models one dark energy de barotropic parameter fixed second one wâ‰ chosen match best fit data study main cosmological properties models expansion perturbation levels based markov chain monte carlo method currently available cosmic observational data sets constrain models determine cosmological parameters level background clustering matter consider interaction dark matter dark energy directly affects evolution matter clustering model appears perfectly consistent î›cdm model providing unification de dm â© american physical society
10.1080/07350015.2018.1451336 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048792866&doi=10.1080%2f07350015.2018.1451336&partnerID=40&md5=a7207e96380251c8b080792ea1dd022e 1,introduce class large bayesian vector autoregressions bvars allows non gaussian heteroscedastic serially dependent innovations make estimation computationally tractable exploit certain kronecker structure likelihood implied class models propose unified approach estimating models using markov chain monte carlo mcmc methods application involves macroeconomic variables find bvars flexible covariance structures outperform standard variant independent homoscedastic gaussian innovations sample model fit sample forecast performance â© american statistical association
10.3758/s13428-018-1069-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048368853&doi=10.3758%2fs13428-018-1069-9&partnerID=40&md5=fafbbfd9866efdbc03c330e25a388b42 0,bayesian literature shown hamiltonian monte carlo hmc algorithm powerful efficient statistical model estimation especially complicated models stan software program built upon hmc introduced means psychometric modeling estimation however systemic guidelines implementing stan log linear cognitive diagnosis model lcdm saturated version many cognitive diagnostic model cdm variants article bridges gap stan application bayesian lcdm estimation modeling procedures stan code demonstrated detail strategy extended cdms straightforwardly â© psychonomic society inc
10.1080/00207721.2018.1464607 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046484234&doi=10.1080%2f00207721.2018.1464607&partnerID=40&md5=609ef2f7f1f9c2fe4db325dc2a8682e1 0,paper presents type heavy tailed market microstructure models scale mixtures normal distributions mm smn include two specific sub classes viz slash student distributions bayesian perspective markov chain monte carlo mcmc method constructed estimate parameters latent variables proposed mm smn models two evaluating indices namely deviance information criterion dic test white noise hypothesis standardised residual used compare mm smn models classic normal market microstructure mm n model stochastic volatility models scale mixtures normal distributions sv smn empirical studies daily stock return data show mm smn models accommodate possible outliers observed returns use mixing latent variable results also indicate heavy tailed mm smn models better model fitting mm n model market microstructure model slash distribution mm best model fitting finally two evaluating indices indicate market microstructure models three different distributions superior corresponding stochastic volatility models â© â© informa uk limited trading taylor francis group
10.1145/3192366.3192409 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049555316&doi=10.1145%2f3192366.3192409&partnerID=40&md5=e2736ac4e4558ad606c85b5a50df8398 0,introduce inference metaprogramming probabilistic programming languages including new language constructs formalism first demonstration effectiveness practice instead relying rigid black box inference algorithms hard coded language implementation previous probabilistic programming languages inference metaprogramming enables developers dynamically decompose inference problems subproblems apply inference tactics subproblems alternate incorporating new data performing inference existing data explore multiple execution traces probabilistic program implemented tactics include gradient based optimization markov chain monte carlo variational inference sequental monte carlo techniques inference metaprogramming enables concise expression probabilistic models inference algorithms across diverse fields computer vision data science robotics within single probabilistic programming language â© copyright held owner author
10.1016/j.jclepro.2018.03.173 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045223687&doi=10.1016%2fj.jclepro.2018.03.173&partnerID=40&md5=a0d299a184caa13b41c9a92565488b2c 1,solar profile component outage create considerable impact solar generation paper proposes markov chain model incorporates factors solar generation model considers solar farm generating unit multiple generation states state characterized generating photovoltaic arrays ambient temperature solar radiation probability frequency transition rate generation states obtained collected solar profile samples component reliability parameters three generation performance indices describe solar generation perspective energy time frequency defined estimated proposed model accuracy efficiency proposed model verified sequential monte carlo simulation approach using collected solar profile samples six distinctive sites north dakota usa influence component reliability parameters seasonal solar profile pattern photovoltaic module type solar generation investigated details â© elsevier ltd
10.3847/1538-4357/aac2bc https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049202831&doi=10.3847%2f1538-4357%2faac2bc&partnerID=40&md5=48a583e719e2e8685939fe66d58fad6a 2,shape damping profile kink oscillations coronal loops recently allowed transverse density profile loop estimated requires accurate measurement damping profile distinguish gaussian exponential damping regimes otherwise unknowns observables forward modeling transverse intensity profile may also used estimate width inhomogeneous layer loop providing independent estimate one unknowns analyze oscillating loop seismological determination transverse structure inconclusive except supplemented additional spatial information transverse intensity profile temporal analysis describes motion coronal loop kink oscillation damped resonant absorption spatial analysis based forward modeling transverse euv intensity profile loop isothermal optically thin approximations use bayesian analysis markov chain monte carlo sampling apply spatial temporal models individually simultaneously data compare results numerical simulations combining two methods allows inhomogeneous layer width density contrast calculated possible data method applied individually demonstrate assumption exponential damping profile leads significantly larger error inferred density contrast ratio compared gaussian damping profile â© american astronomical society rights reserved
10.3847/1538-4357/aac2d9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049172012&doi=10.3847%2f1538-4357%2faac2d9&partnerID=40&md5=d13aaa3bfafed1829f736413f34ce83b 1,first gravitational wave event merger binary neutron star system gw detected recently associated short gamma ray burst grb low isotropic luminosity âˆ¼ erg peak energy e p âˆ¼ kev initial main emission origin short grb still debate plausible interpretation due axis emission structured jet consider two possibilities first since best fit spectral model main pulse grb cutoff power law hard low energy photon index î± = + consider axis photosphere model develop theory photosphere emission structured jet find model reproduce low energy photon index softer blackbody enhancing high latitude emission model naturally account observed spectrum best fit lorentz factor along line sight âˆ¼ demands significant delay merger jet launching alternatively consider emission produced via synchrotron radiation optically thin region expanding jet decreasing magnetic fields model require delay jet launching demands larger bulk lorentz factor along line sight perform markov chain monte carlo fitting data within framework models obtain good fitting results cases â© american astronomical society rights reserved
10.1007/s11222-018-9817-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048308224&doi=10.1007%2fs11222-018-9817-3&partnerID=40&md5=db4829daa46fa5dd78869d541253f4e2 0,paper introduces framework speeding bayesian inference conducted presence large datasets design markov chain whose transition kernel uses unknown fraction fixed size available data randomly refreshed throughout algorithm inspired approximate bayesian computation literature subsampling process guided fidelity observed data measured summary statistics resulting algorithm informed sub sampling mcmc generic flexible approach contrary existing scalable methodologies preserves simplicity metropolisâ€“hastings algorithm even though exactness lost e chain distribution approximates posterior study quantify theoretically bias show diverse set examples yields excellent performances computational budget limited available cheap compute show setting summary statistics maximum likelihood estimator supported theoretical arguments â© springer science+business media llc part springer nature
10.1109/ICACI.2018.8377503 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049806071&doi=10.1109%2fICACI.2018.8377503&partnerID=40&md5=291eb3b51b6a951e7ecb82febc3721a7 0,high availability product electronic flight instrument system efis complicated redundancy structures fulfill high safety integrity requirement paper presents comprehensive study availability analysis efis using dynamic fault tree dft approach based markov chain modularization method static fault sub tree solved binary decision diagram bdd dynamic fault sub tree solved markov chain novel markov chain expression utilized avoid state explosion dynamic fault sub tree besides minimal cut sequence set mcss generated last monte carlo simulation carried verify theoretical results â© ieee
10.1007/s10742-018-0184-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048075544&doi=10.1007%2fs10742-018-0184-5&partnerID=40&md5=e7c56eefa69e7037bd70dcd6c6b714c5 0,paper address problem accounting informative missing context ecological momentary assessment studies sometimes referred intensive longitudinal studies study unit gets measured intensively time intermittent missing usually present present shared parameter modeling approach links primary longitudinal outcome potentially informative missingness common set random effects summarize subjectsâ€™ specific traits terms mean location variability scale primary outcome conditional random effects allowed exhibit heterogeneity terms mean within subject variance unlike previous methods largely rely numerical integration approximation estimate model full bayesian approach using markov chain monte carlo adolescent mood study example illustrated together series simulation studies results comparison conventional approaches suggest accounting common unobserved random subject mean variance effects shared primary outcome missingness models significantly improve model fit also provide benefit understanding missingness affect inference primary outcome â© springer science+business media llc part springer nature
10.1109/PDP2018.2018.00114 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048752835&doi=10.1109%2fPDP2018.2018.00114&partnerID=40&md5=eaae836146aea0c0390ddd9f608a8656 1,models biological systems often many unknown parameters must determined order model behavior match experimental observations commonly used methods parameter estimation return point estimates best fit parameters insufficient models high dimensional constrained result bayesian methods treat model parameters random variables attempt estimate probability distributions given data become popular systems biology bayesian parameter estimation often relies markov chain monte carlo mcmc methods sample model parameter distributions slow convergence mcmc sampling major bottleneck one approach improving performance parallel tempering pt physics based method uses swapping multiple markov chains run parallel different temperatures accelerate sampling temperature markov chain determines probability accepting unfavorable move swapping higher temperatures chains enables sampling chain escape local minima work compared mcmc performance pt commonly used metropolis hastings mh algorithm six biological models varying complexity found simpler models pt accelerated convergence sampling complex models pt often converged cases mh became trapped non optimal local minima also developed freely available matlab package bayesian parameter estimation called ptempest http github com ruleworld ptempest closely integrated popular bionetgen software rule based modeling biological systems â© ieee
10.1016/j.applthermaleng.2018.04.028 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045260782&doi=10.1016%2fj.applthermaleng.2018.04.028&partnerID=40&md5=4500d726433847bee18f92b26d8009fc 0,study shell tube heat exchanger sthx design based seven continuous independent design variables proposed delayed rejection adaptive metropolis hasting dram utilized powerful tool markov chain monte carlo mcmc sampling method reverse sampling rs method used find probability distribution design variables shell tube heat exchanger thanks probability distribution uncertainty analysis also performed find quality variables addition decision making strategy based confidence intervals design variables total annual cost tac provides final selection design variables results indicated high accuracies estimation design variables leads marginally improved performance compared commonly used optimization methods order verify capability proposed method case study also presented shows significant cost reduction feasible respect multi objective single objective optimization methods furthermore selected variables good quality terms probability distribution lower tac also achieved results show costs proposed design lower obtained optimization method reported previous studies algorithm also used determine impact using probability values design variables rather single values obtain best heat transfer area pumping power particular reduction tac achieved case considered â©
10.1016/j.matdes.2018.03.037 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044127902&doi=10.1016%2fj.matdes.2018.03.037&partnerID=40&md5=5131efea444e2ad3926a23524a2edab9 1,instrumented indentation enables rapid characterization mechanical behavior small material volumes heterogeneous deformation fields beneath indenter however make difficult infer intrinsic constitutive properties e g young modulus yield strength inverse problem addressed literature using optimization techniques generally unable yield robust values properties interest quantify property uncertainty furthermore current approaches tend exhibit high sensitivity error definitions optimization techniques employed order overcome difficulties propose alternate approach involves two main steps development gaussian process kriging surrogate model using finite element models spherical indentation ii inverse solution using bayesian framework markov chain monte carlo sampling approaches demonstrated using selected case studies â© elsevier ltd
10.3389/fgene.2018.00195 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048285917&doi=10.3389%2ffgene.2018.00195&partnerID=40&md5=db70e50771043c122a872b57988a8750 0,widely used method prediction complex traits animal plant breeding genomic best linear unbiased prediction gblup quantitative genetics setting blup linear regression phenotypes pedigree genomic relationship matrix depending type input information available normality distributions random effects model residuals required blup gaussian assumption made implicitly potential downside gaussian linear regressions sensitive outliers genetic environmental origin present simple relative fully bayesian analysis implement robust alternatives blup using linear model residual laplace distributions instead gaussian one evaluate methods milk yield records italian brown swiss cattle grain yield data inbred wheat lines using three traits measured accessions arabidopsis thaliana methods use markov chain monte carlo sampling model hyper parameters viewed regularization knobs tuned via cross validation uncertainty predictions evaluated employing bootstrapping random reconstruction training testing sets found e g test day milk yield cows flowering time frigida expression arabidopsis best predictions often obtained robust methods results obtained encouraging stimulate investigation generalization â© gianola cecchinato naya schã¶n
10.7498/aps.67.20172639 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053027245&doi=10.7498%2faps.67.20172639&partnerID=40&md5=d4a18ad2d64a3e5317637703d432f1df 0,laser micro doppler md effect capable obtaining obvious modulation weak vibration detection helps estimate target micro motion parameters high precision may extend application field md subtle identification recognition laser detection multiple scattering points field view generate singlechannel multi component scmc signal moreover micro doppler features component overlapped time frequency domain similar micro motion parameters overlapped scmc signal makes estimation md parameters difficult problem good method far paper separate parameter estimator based maximum likelihood framework proposed deal underdetermined problem first detailed period scanning method presented improve estimation accuracy micro motion frequency singular value ratio svr spectrum amplitude ratio information component extracted svr spectrum closed form expressions maximum likelihood estimation mle remaining micro motion parameters derived mean likelihood estimation used approximate performance mle high nonlinearity multi peak distribution shape likelihood function lf laser md signal lead incorrect estimation result end new lf based energy spectrum characteristics designed new lf acts smoothing filter probability density function ideal pdf distribution form one smooth peak obtained modification requirements initialization reduced robustness low snr situation increased markov chain monte carlo sampling employed implement mle gibbs method chosen solve multi dimensional parametric problems detailed process listed end simulation results prove feasibility high efficiency proposed method accuracy parameter estimation reaches cramer rao boundary inverse radon transform used comparison experiment results show precise estimation advantage presented method â© chinese physical society
10.1002/asia.201800074 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047431068&doi=10.1002%2fasia.201800074&partnerID=40&md5=a7b48e01ba9a72a4fd3c9e5e933fe954 0,coii coordination polymer built mixed azide zwitterionic pyridinium ions temperature dependent magnetic properties described used markov chain monte carlo mcmc method fit data found following results strong correlations model parameters data k well fitted magnetism model â© wiley vch verlag gmbh co kgaa weinheim
10.1109/TPAMI.2018.2832641 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048196937&doi=10.1109%2fTPAMI.2018.2832641&partnerID=40&md5=0bb70a0bd428836afa5c32a3568320c1 0,latent dirichlet allocation lda topic model widely used natural language processing machine learning approaches training model rely iterative algorithms makes difficult run lda big corpora best analyzed parallel distributed computational environments indeed current approaches parallel inference either x converge correct posterior require storage large dense matrices memory present novel sampler overcomes problems show sampler faster empirically theoretically previous gibbs samplers lda employing novel p x f lya urn based approximation sparse partially collapsed sampler lda prove approximation error vanishes data size making algorithm asymptotically exact property importance large scale topic models addition show via explicit example contrary popular belief topic modeling literature partially collapsed samplers efficient fully collapsed samplers conclude comparing performance algorithm approaches well known corpora ieee
10.1080/03610926.2017.1342839 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031095042&doi=10.1080%2f03610926.2017.1342839&partnerID=40&md5=f652e0609fbf0a751cb9f6f544723daa 0,purpose paper develop bayesian analysis zero inflated hyper poisson model markov chain monte carlo methods used develop bayesian procedure model bayes estimators compared simulation maximum likelihood estimators regression modeling model selection also discussed case deletion influence diagnostics developed joint posterior distribution based functional bregman divergence includes ïˆ divergence several others divergence measures itakuraâ€“saito kullbackâ€“leibler ï‡ divergence measures performance approach illustrated artificial real apple cultivation experiment data related apple cultivation â© taylor francis group llc
10.1080/14697688.2017.1383627 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041355624&doi=10.1080%2f14697688.2017.1383627&partnerID=40&md5=bf75afae2bff0dd1a10bff6e34655b58 1,bond rating transition probability matrices tpms built one year time frame many practical purposes like assessment risk portfolios computation banking capital requirements e g new ifrs regulation one needs compute tpm probabilities default smaller time interval context continuous time markov chains ctmc several deterministic statistical algorithms proposed estimate generator matrix focus expectation maximization em algorithm bladt sorensen j r stat soc ser b stat method â€“ ctmc absorbing state estimation workâ€™s contribution threefold firstly provide directly computable closed form expressions quantities appearing em algorithm associated information matrix allowing easy approximation confidence intervals previously quantities estimated numerically considerable computational speedups gained secondly prove convergence single set parameters weak conditions tpm problem finally provide numerical benchmark results known algorithms particular several problems related credit risk em algorithm propose padded new formulas error criteria outperforms known algorithms several metrics particular much less overestimation probabilities default higher ratings statistical algorithms â© author published informa uk limited trading taylor francis group
10.1007/s10851-017-0783-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038395952&doi=10.1007%2fs10851-017-0783-8&partnerID=40&md5=ecc0c68a3b67b6ff857293db19c85947 0,present novel tracking system adaptively selects shape posterior time selection efficiently performed uncertainty calibrated markov chain monte carlo ucmcmc sampler conventional trackers posterior typically described single prior distribution hand tracker allows posterior multiple prior distributions namely normal studentâ€™s distribution choose appropriate distribution according tracking environment optimal distribution determined ucmcmc sampler process reducing uncertainty shape experimental results demonstrate proposed multi shape posterior helps improve tracking performance terms accuracy â© springer science+business media llc part springer nature
473.5868193654559 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050003839&partnerID=40&md5=b78ce8c30f786d753b735a4eef8d59cd 0,proposes new bayesian mcmc algorithm dynamic stochastic copula models dependence parameters unobserved state variables presents performance proposed mcmc algorithm simulations mcmc algorithm draws state variables acceptancerejection metropolis hastings algorithm using candidate generating probability density function obtained approximating probability density function observed variables normal distribution dependence parameter empirical example analyzed stochastic copula models kospi index hsce index hang seng china enterprise index returns january december using proposed algorithm bayesian inference model comparison results stochastic copula models gaussian copula student copula clayton copula frank copula rotated gumbel copula plackett copula showed student copula model selected best model model comparisons results imply even though gaussian stochastic copula model capture â€˜near asymptotic dependenceâ€™ may exist extreme tail dependence captured gaussian stochastic copula model â© korean econometric society rights reserved
10.1371/journal.pone.0199123 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048824088&doi=10.1371%2fjournal.pone.0199123&partnerID=40&md5=5a876fa50fea2c6aef73cada40612eca 0,oceanographic field programs often use î´ n biogeochemical measurements situ rate measurements investigate nitrogen cycling planktonic ecosystem structure however integrative modeling approaches capable synthesizing distinct measurement types lacking develop novel approach incorporating î´ n isotopic data existing markov chain monte carlo mcmc random walk methods solving linear inverse ecosystem models test ability approach recover food web indices nitrate uptake nitrogen fixation zooplankton trophic level secondary production derived forward models simulating planktonic ecosystems california current amazon river plume show mcmc î´ n approach typically better job recovering ecosystem structure standard mcmc l minimum norm l mn approaches also outperforms l mn î´ n approach furthermore find mcmc î´ n approach robust removal input equations hence well suited typical pelagic ecosystem studies system usually vastly constrained approach easily extendable use î´ c isotopic measurements variable carbon nitrogen stoichiometry â© stukel et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1016/j.apgeochem.2017.11.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034991410&doi=10.1016%2fj.apgeochem.2017.11.004&partnerID=40&md5=7afde64dc22fb86d16c9129916f7e7fd 0,bdb deep inclined borehole drilled mont terri rock laboratory switzerland enabled acquire relevant data porewater composition opalinus clay opa bounding formations petrophysical measurements carried included water content water accessible porosity grain density determination conservative anion profiles obtained aqueous leaching diffusion experiments performed drillcore samples revealed consistent previous studies carried rock laboratory level diffusive properties also investigated using three experimental setups cubic diffusion radial diffusion diffusion transport parameters used priori values bayesian inversion using markov chain monte carlo method interpret chloride profile opalinus clay based peclet number analysis using transport parameters formerly acquired purely diffusive scenario enabled specifying paleohydrogeological evolution mont terri site folding thrusting jura mountains present time transport parameters â©
10.3969/j.issn.0258-2724.2018.03.019 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052860017&doi=10.3969%2fj.issn.0258-2724.2018.03.019&partnerID=40&md5=7fcaedf696040d6419b533134686969e 0,multiple model analysis applied study groundwater modelling uncertainties caused deviation model structure heterogeneity aquifer media according different natural conditions two hydrogeological conceptual models established using large number model parameter data obtained hydrogeological tests priori information based two conceptual models series seepage field models constructed using adaptive metropolis markov chain monte carlo method acceptance condition adjusted uncertainties modelling output data analysed based corrected akaike information criteron research indicates ergodicity convergence sample parameters affected changes acceptance conditions model output data include following effects results different parameters results different models although effects exist model structure closer objective improving probability obtaining high precision model proportion primary conceptual model variance model delta values greater excluded top models retained cumulative posterior probability proportion second conceptual model variance model delta values greater excluded top models retained cumulative posterior probability top models â© editorial department journal southwest jiaotong university right reserved
10.1029/2017MS001044 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051298065&doi=10.1029%2f2017MS001044&partnerID=40&md5=8220c43a5b71d7685faeb4d4c634d45d 1,boreal lowland bogs extensively studied using eddy covariance ec technique less knowledge exists mountainous peatlands hence half hourly co fluxes ombrotrophic peat bog harz mountains germany measured ec technique growing season exceptionally dry weather spells common biophysical process model net ecosystem exchange used describe measured co fluxes fill data gaps model parameters uncertainties estimated robust inverse modelling bayesian framework using population based markov chain monte carlo sampler focus study correct statistical description error e differences measured simulated carbon fluxes influence distributional assumptions parameter estimates cumulative carbon fluxes uncertainties tested gaussian laplace student distribution error models distribution identified best error model deviance information criterion use led markedly different parameter estimates reduction parameter uncertainty importantly higher estimated cumulative co uptake compared commonly assumed gaussian error distribution open path measurement systems larger measurement error high humidity standard deviation error modeled function measured vapor pressure deficit overall paper demonstrates importance critically assessing influence distributional assumptions estimated model parameters cumulative carbon fluxes land surface atmosphere â© authors
10.1016/j.advwatres.2018.04.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046169672&doi=10.1016%2fj.advwatres.2018.04.006&partnerID=40&md5=0d9d4ee37d402b6f3a16a7d61753934e 1,significant input uncertainty major source error watershed water quality wwq modeling remains challenging address input uncertainty rigorous bayesian framework study develops bayesian analysis input parametric uncertainties baipu approach joint analysis input parametric uncertainties tight coupling markov chain monte carlo mcmc analysis bayesian model averaging bma formal likelihood function approach derived considering lag autocorrelated heteroscedastic skew exponential power sep distributed error model series numerical experiments performed based synthetic nitrate pollution case real study case newport bay watershed california soil water assessment tool swat differential evolution adaptive metropolis dream zs used representative wwq model mcmc algorithm respectively major findings include following baipu implemented used appropriately identify uncertain parameters characterize predictive uncertainty compensation effect input parametric uncertainties seriously mislead modeling based management decisions input uncertainty explicitly accounted baipu accounts interaction input parametric uncertainties therefore provides accurate calibration uncertainty results sequential analysis uncertainties baipu quantifies credibility different input assumptions statistical basis implemented effective inverse modeling approach joint inference parameters inputs â© elsevier ltd
10.1109/TR.2017.2778804 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040599059&doi=10.1109%2fTR.2017.2778804&partnerID=40&md5=58a6668b82b0e7bf5cd172ba4f03475d 2,traditional quantitative risk assessment methods e g event tree analysis static nature e risk indexes assessed operation prevents capturing time dependent variations components systems operate age fail repaired changed address issue develop dynamic risk assessment dra method allows online estimation risk indexes using data collected operation two types data considered statistical failure data refer counts accidents near misses similar systems condition monitoring data come online monitoring degradation target system interest hierarchical bayesian model developed compute reliability safety barriers bayesian updating algorithm integrates particle filtering pf markov chain monte carlo developed update reliability evaluations based statistical condition monitoring data updated safety barriers reliabilities used event tree et consequence analysis risk indexes updated accordingly case study high flow safety system conducted demonstrate developed methods comparison dra method uses statistical failure data shows introducing condition monitoring data system degradation process possible capture system specific characteristics therefore provide complete accurate description risk target system â© ieee
10.1214/17-BA1060 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044400724&doi=10.1214%2f17-BA1060&partnerID=40&md5=f1b980e15658ec16b27f157bba5583f2 2,traditionally field computational bayesian statistics divided two main subfields variational methods markov chain monte carlo mcmc recent years however several methods proposed based combining variational bayesian inference mcmc simulation order improve overall accuracy computational efficiency marriage fast evaluation flexible approximation provides promising means designing scalable bayesian inference methods paper explore possibility incorporating variational approximation state art mcmc method hamiltonian monte carlo hmc reduce required expensive computation involved sampling procedure bottleneck many applications hmc big data problems end exploit regularity parameter space construct free form approximation target distribution fast flexible surrogate function using optimized additive model proper random basis also viewed single hidden layer feedforward neural network surrogate function provides sufficiently accurate approximation allowing fast computation sampling procedure resulting efficient approximate bayesian inference algorithm demonstrate advantages proposed method using synthetic real data problems â© international society bayesian analysis
10.1016/j.jedc.2018.01.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044503624&doi=10.1016%2fj.jedc.2018.01.021&partnerID=40&md5=589c3362a601a1eb27561eef6881e047 0,estimation agent based models currently intense area research recent contributions large extent resorted simulation based methods mostly using form simulated method moments estimation smm however entire branch statistical methods appear promising knowledge never applied far estimate agent based models economics finance markov chain monte carlo methods designed state space models models latent variables latter class models seems particularly relevant agent based models typically consist latent observable variables since characteristics agents mostly observable indeed one might often interested estimating parameters model also infer time development latent variable however agent based models interpreted latent variable models typically characterized non linear dynamics non gaussian fluctuations thus require computational approach statistical inference resort sequential monte carlo smc estimation based particle filter approach used numerically approximate conditional densities enter likelihood function problem approximation simultaneously obtain parameter estimates filtered state probabilities unobservable variable drive dynamics observable time series examples observable series asset returns prices unobservable variables measure agentsâ€™ aggregate sentiment apply smc two selected agent based models speculative dynamics somewhat different flavor empirical application selection financial data includes explicit comparison goodness fit models â© elsevier b v
10.1016/j.spl.2018.01.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044657258&doi=10.1016%2fj.spl.2018.01.020&partnerID=40&md5=89b93df813ab657c8e2b921e3217eb07 0,markov chain monte carlo mcmc popular approach sample high dimensional distributions asymptotic variance commonly used criterion evaluate performance popular mcmc algorithms reversible growing literature development analyses nonreversible mcmc chen hwang showed reversible mcmc improved adding antisymmetric perturbation also raised conjecture improved cycle corresponding graph paper present rigorous proof conjecture proof based fact transition matrix acyclic structure produce minimum commute time vertices â© elsevier b v
10.1109/TPAMI.2017.2711024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021791520&doi=10.1109%2fTPAMI.2017.2711024&partnerID=40&md5=892c6c330eeb208f1d3e1d018e2ff433 0,learning demonstration lfd process building behavioral models task demonstrations provided expert models used e g system control generalizing expert demonstrations previously unencountered situations lfd methods however make strong assumptions expert behavior e g assume existence deterministic optimal ground truth policy require direct monitoring expert controls limits practical use part general system identification framework work consider lfd problem general setting allow arbitrary stochastic expert policies without reasoning optimality demonstrations following bayesian methodology model full posterior distribution possible expert controllers explain provided demonstration data moreover show methodology applied nonparametric context infer complexity state representation used expert learn task appropriate partitionings system state space â© ieee
10.1080/00401706.2018.1429317 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048355285&doi=10.1080%2f00401706.2018.1429317&partnerID=40&md5=d966d1f4fa94e0616f5a24a167d40811 0,bayesian inferential approach noninformative prior introduced analyze ordinal repeatability reproducibility r r data using de mastâ€“van wieringen model approach extended weakly informative prior random effects allow consideration population raters prediction new rater random effects approach also shown result partial pooling estimates across raters addition match probability based measures decompose ordinal r r study data contributions due repeatability due reproducibility defined extensions involving bayesian inference fixed random effects measures illustrated real simulated ordinal r r study data applicable business industry settings methodology implemented using supplemental r package ordinalrr available cran additional supplementary material article available online â© american statistical association american society quality
10.1111/biom.12763 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049006356&doi=10.1111%2fbiom.12763&partnerID=40&md5=06b01a7233bb3f8d541016681b0d1886 2,standard approach fitting captureâ€“recapture data collected continuous time involves arbitrarily forcing data series distinct discrete capture sessions show continuous time models fitted easily discrete time alternatives likelihood factored efficient markov chain monte carlo algorithms implemented bayesian estimation available online r package ctime consider goodness fit tests behavior heterogeneity effects well implementing models allow effects â© international biometric society
10.1111/biom.12782 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030480480&doi=10.1111%2fbiom.12782&partnerID=40&md5=a7d4fc741b8f755c29dbaf080d373da9 0,medical imaging data thousands spatially correlated data points common many fields methods account spatial correlation often require cumbersome matrix evaluations prohibitive data size thus current work either used low rank approximations analyzed data blocks propose method accounts nonstationarity functional connectivity distant regions interest local signals applied large multi subject datasets using spectral methods combined markov chain monte carlo sampling illustrate using simulated data properly accounting spatial dependence improves precision estimates yields valid statistical inference apply new approach study associations cortical thickness alzheimer disease find several regions cortex patients alzheimer disease thinner average healthy controls â© international biometric society
10.1109/TFUZZ.2017.2746064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028732547&doi=10.1109%2fTFUZZ.2017.2746064&partnerID=40&md5=5c642f83291f4b720e32b1490e065a7b 0,paper propose novel approach learning data using rule based fuzzy inference systems model parameters estimated using bayesian inference markov chain monte carlo techniques show applicability method regression classification tasks using synthetic datasets also real world example financial services industry demonstrate method extended knowledge extraction select individual rules bayesian way best explains given data finally discuss advantages pitfalls using method state art techniques highlight specific class problems useful â© ieee
10.1007/s00216-018-1061-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045756308&doi=10.1007%2fs00216-018-1061-3&partnerID=40&md5=6d55869441bc955bf427f35e75660217 0,relatively easy collect chromatographic measurements large number analytes especially gradient chromatographic methods coupled mass spectrometry detection data often hierarchical clustered structure example analytes similar hydrophobicity dissociation constant tend alike retention randomly chosen set analytes multilevel models recognize existence data structures assigning model parameter parameters also estimated data work multilevel model proposed describe retention time data obtained series wide linear organic modifier gradients different gradient duration different mobile phase ph large set acids bases multilevel model consists deterministic equation describing relationship retention time analyte specific instrument specific parameters covariance relationships relating various physicochemical properties analyte chromatographically specific parameters quantitative structureâ€“retention relationship based equations stochastic components intra analyte interanalyte variability model implemented stan provides full bayesian inference continuous variable models markov chain monte carlo methods figure available see fulltext â© springer verlag gmbh germany part springer nature
10.1121/1.5042162 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049408009&doi=10.1121%2f1.5042162&partnerID=40&md5=f476990b6e9c9f8707039b335a38eaf6 1,coprime microphone arrays use sparse sensing achieve greater degrees freedom coprimality microphone subarrays help resolve grating lobe ambiguities result narrow beam frequencies higher spatial nyquist limit allows residual side lobes arising aliasing side lobes mitigated observing broadband sources shown bush xiang j acoust soc peak positions may indicate directions arrival case however one must first ask many sources present answering question work employs model describing scenes potentially multiple concurrent sound sources bayesian inference used first select model data prefer competing models estimating model parameters including particular source locations model linear combination laplace distribution functions one per sound source likelihood function explored markov chain monte carlo method called nested sampling order evaluate bayesian evidence model values increase monotonically model complexity however diminished returns penalized via implementation occam razor â© acoustical society america
10.1016/j.advwatres.2017.11.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046421241&doi=10.1016%2fj.advwatres.2017.11.013&partnerID=40&md5=4605a9469bc811caa98f6956b4aec334 0,bayesian solutions geophysical hydrological inverse problems dependent upon forward model linking subsurface physical properties measured data typically assumed perfectly known inversion procedure however make stochastic solution inverse problem computationally tractable using methods markov chain monte carlo mcmc fast approximations forward model commonly employed gives rise model error potential significantly bias posterior statistics properly accounted present new methodology dealing model error arising use approximate forward solvers bayesian solutions hydrogeophysical inverse problems approach geared towards common case error effectively characterized parametric statistical distribution ii estimated interpolating small number computed model error realizations end focus identification removal model error component residual mcmc using projection based approach whereby orthogonal basis employed projection derived iteration k nearest neighboring entries model error dictionary latter constructed inversion grows specified rate iterations proceed demonstrate performance technique inversion synthetic crosshole ground penetrating radar travel time data considering three different subsurface parameterizations varying complexity synthetic data generated using eikonal equation whereas straight ray forward model assumed inversion case developed approach enables us remove posterior bias obtain realistic characterization uncertainty â© elsevier ltd
10.1017/apr.2018.27 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050670165&doi=10.1017%2fapr.2018.27&partnerID=40&md5=11e130944505c2dbe13434d56888d308 0,develop forward reverse expectation maximization frem algorithm estimating parameters discrete time markov chain evolving certain measurable state space construction frem method develop forward reverse representations markov chains conditioned certain terminal state prove almost sure convergence algorithm markov chain model curved exponential family structure numerical side carry complexity analysis forward reverse algorithm deriving expected cost two application examples discussed â© applied probability trust
10.4230/LIPIcs.SoCG.2018.19 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048985368&doi=10.4230%2fLIPIcs.SoCG.2018.19&partnerID=40&md5=d790eed152d0009babb1484b9e16b0fb 0,examine volume computation general dimensional polytopes general convex bodies defined intersection simplex family parallel hyperplanes another family parallel hyperplanes family concentric ellipsoids convex bodies appear modeling predicting financial crises impact crises economy labor income etc makes detection prime interest public general policy makers particular certain features dependencies markets clearly identify times turmoil describe relationship asset characteristics means copula characteristic either linear quadratic form portfolio components hence copula constructed computing volumes convex bodies design implement practical algorithms exact approximate setting experimentally juxtapose study tradeoff exactness accuracy speed analyze following methods order increasing generality rejection sampling relying uniformly sampling simplex fastest approach inaccurate small volumes exact formulae based computation integrals probability distribution functions method choice intersections single hyperplane optimized lawrence sign decomposition method since polytopes hand shown simple additional structure markov chain monte carlo algorithms using random walks based hit run paradigm generalized nonlinear convex bodies relying new methods computing ball enclosed given body second order cone program latter experimentally extended non convex bodies encouraging results c++ software based cgal eigen available github shown effective dimensions results offer novel effective means computing portfolio dependencies indicator financial crises shown correctly identify past crises â© ludovic calã¨s apostolos chalkis ioannis z emiris vissarion fisikopoulos licensed creative commons license cc th symposium computational geometry socg
10.1051/0004-6361/201731445 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048863170&doi=10.1051%2f0004-6361%2f201731445&partnerID=40&md5=c77dbfad42576e753ad4d635cf01cc6c 0,context paper fourth series evaluating aspix cosmological method based x ray diagrams constructed simple cluster observable quantities namely count rate cr hardness ratio hr core radius rc redshift aims following extensive tests analytical toy catalogues paper iii present results realistic study deg template based maps derived cosmological simulation methods dark matter haloes aardvark simulation ascribed luminosities temperatures core radii using local scaling relations assuming self similar evolution predicted x ray sky maps converted xmm event lists using detailed instrumental simulator xxl pipeline runs resulting sky images produces observed cluster catalogue tests performed allowed us investigate relative power various combinations cr hr rc redshift information two fitting methods used traditional markov chain monte carlo mcmc approach simple minimisation procedure amoeba whose mean uncertainties posteriori evaluated means synthetic catalogues results analysed compared predictions fisher analysis fa results particular catalogue realisation assuming scaling relations perfectly known cr hr combination gives ïƒ ï‰ level cr hr rc z improves â‰¤ adding second hr improves results crhr rc combination lesser extent adding redshift information coefficients mass temperature relation including scatter also fitted cosmological parameters constrained within larger coefficients factor two scatter errors returned mcmc amoeba fa predictions cases excellent agreement always within factor two also study impact scatter mass size relation rc number detected clusters cluster typical sizes usually assumed larger scatter lower number detected objects conclusions present study confirms extends trends outlined previous analyses namely power x ray observable diagrams successfully easily fit time cosmological parameters cluster physics survey selection involving detected clusters accuracy levels quoted considered definitive number simplifying hypotheses made testing purpose affect method way next publication consider greater detail impact cluster shapes selection measurements cluster physics final error budget means hydrodynamical simulations â© eso
10.1093/gji/ggy071 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052655207&doi=10.1093%2fgji%2fggy071&partnerID=40&md5=832af31a8eefd4c053889f2604f76e91 0,paper develops efficient hierarchical trans dimensional trans bayesian algorithm invert magnetotelluric mt data subsurface geoelectrical structure unknown geophysical model parameterization number conductivity layer interfaces dataerror models parameterized auto regressive ar process account potential error correlations reversible jump markov chain monte carlo algorithm adds removes interfaces ar parameters birth death steps applied sample trans posterior probability density model parameterization model parameters error variance ar parameters accounting uncertainties model dimension data error statistics uncertainty estimates conductivity profile provide efficient sampling multiple subspaces different dimensions advanced proposal schemes applied parameter perturbations carried principal component space defined eigen decomposition unit lag model covariance matrix minimize effect inter parameter correlations provide effective perturbation directions length scales parameters new layers birth steps proposed prior instead focused distributions centred existing values improve birth acceptance rates parallel tempering based series parallel interacting markov chains successively relaxed likelihoods applied improve chain mixing model dimensions trans inversion applied simulation study examine resolution model structure according data information content inversion also applied measured mt data set south central australia â© author
10.1002/2017JB015359 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050113486&doi=10.1002%2f2017JB015359&partnerID=40&md5=f7ca8da59527f9b817e930276568029b 0,study presents new statistical method estimate spatial stress pattern earth crust p wave first motions method assumed orientation fault plane distributed randomly uniform distribution direction fault slip parallel direction maximum shear stress fault plane two assumptions spatial stress pattern fits data set p wave first motions estimated smoothness constraint spatial variation stress pattern advantage method require determination focal mechanisms event method applied synthetic data sets demonstrate performance estimated stress pattern agreed given generation data set given pattern changes smoothly space method applied real data set taken aftershocks western tottori earthquake resulting stress pattern consistent estimated previous studies examining data set additionally spatial variation stress rotation across main fault revealed applications show validity benefit new method â© american geophysical union rights reserved
10.1371/journal.pone.0198280 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048165885&doi=10.1371%2fjournal.pone.0198280&partnerID=40&md5=d4fd403aa7d3192e1985be3bde90d4d1 0,campaign malaria control using long lasting insecticide nets llins launched south sudan success campaign often depends upon adequate available resources reliable surveillance data help officials understand existing infections optimal allocation resources malaria control sub national scale therefore paramount success efforts reduce malaria prevalence paper extend existing sir mathematical model capture effect llins malaria transmission available data malaria utilized determine realistic parameter values model using bayesian approach via markov chain monte carlo mcmc methods explore parasite prevalence continued rollout llins three different settings order create sub national projection malaria calculate modelâ€™s basic reproductive number study sensitivity llinsâ€™ coverage efficacy numerical simulation results notice basic reproduction number r confirming substantial increase incidence cases form intervention takes place community work indicates effective use llins may reduce r hence malaria transmission hope study provide basis recommending scaling entry point llinsâ€™ distribution targets households areas risk malaria â© mukhtar et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1142/S0218539318500122 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040918978&doi=10.1142%2fS0218539318500122&partnerID=40&md5=967da6b6d04eafa6f8320260d0f07494 0,paper presents bayesian reliability sampling plans weibull distribution based progressively type ii censored data binomial removals constructing sampling plans decision theoretic approach used dependent bivariate nonconjugate prior employed total cost sampling plan consists sampling time consuming rejection acceptance costs decision rule based bayes estimator survival function lindley approximation used obtain bayes estimates survival function quadratic linex loss functions however poor performance lindley approximation small sample sizes observed metropolis within gibbs markov chain monte carlo mcmc algorithm show significantly improved performance compared lindley approximation use simulation studies evaluate bayes risk determine optimal sampling plans different sample sizes observed number failures binomial removal probabilities minimum acceptable reliability â© world scientific publishing company
10.1007/s12273-017-0413-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044464837&doi=10.1007%2fs12273-017-0413-9&partnerID=40&md5=797be9251dfc68bf55e24f10331e08fc 1,occupancy information office building important asset determining energy efficient operations emergency evacuation building study developed method estimate occupancy distribution multi room office building using bayesian inference markov chain monte carlo algorithm used estimate real time occupancy individual rooms based indoor carbon dioxide concentrations office building made five rooms different physical configurations dimensions rooms air conditioned ventilated central air handling unit carbon dioxide concentration data generated simulation software contamw according given schedule occupancy supply airflow rates room objective present paper investigate effects various parameters bayesian inference accuracy estimation results parameters include probability prior information uncertainty level co data time interval monitoring co â© tsinghua university press springer verlag gmbh germany part springer nature
10.1051/0004-6361/201731635 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048868961&doi=10.1051%2f0004-6361%2f201731635&partnerID=40&md5=6b99e52393d80719e1c53f5fc01cc7ae 0,present investigation radio luminosity functions lfs number counts based karl g jansky large array cosmos ghz large project radio selected sample galaxies robust optical near infrared counterparts excellent photometric coverage allows us construct total radio lf since z âˆ¼ using markov chain monte carlo algorithm fit redshift dependent pure luminosity evolution model data compare previously published vla cosmos lfs obtained individual populations radio selected star forming galaxies galaxies hosting active galactic nuclei classified basis presence absence radio excess respect star formation rates derived infrared emission find excellent agreement thus showing reliability radio excess method selecting two galaxy populations radio wavelengths study radio number counts submicrojansky levels drawn different models evolving lfs show evolving lfs able reproduce observed radio sky brightness even though rely extrapolations toward faint end results also imply new radio emitting galaxy population present î¼jy work suggests selecting galaxies radio flux densities î¼jy yield star forming galaxy cases high percentage galaxies existing around redshift z âˆ¼ thus providing useful constraints planned surveys square kilometer array precursors â© eso
10.1111/sjos.12299 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046805205&doi=10.1111%2fsjos.12299&partnerID=40&md5=8ea270ca8b4ca18424537938b7982156 1,conditional simulation max stable processes allows analysis spatial extremes taking account additional information provided conditions instead observations given sites usually done consider single condition given general functional process may occur context climate models problem turns intractable analytically make use markov chain monte carlo methods sample conditional distribution simulation studies indicate fast convergence markov chains involved application precipitation data utility procedure tool downscale climate data demonstrated â© board foundation scandinavian journal statistics
10.1051/0004-6361/201732128 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049575887&doi=10.1051%2f0004-6361%2f201732128&partnerID=40&md5=b3b89181c970b2b3f3c502042a753c11 0,context interstellar medium ism widely acknowledged display features ascribable magnetized turbulence public release planck data current balloon borne ground based experiments growing amount data tracing polarized thermal emission galactic dust submillimetre provides choice diagnostics constrain properties magnetized turbulence aims aim constrain properties statistical way focussing particular power spectral index î²b turbulent component interstellar magnetic field diffuse molecular cloud polaris flare methods present analysis framework based simulating polarized thermal dust emission maps using model dust density proportional gas density nh magnetic field cubes integrated along line sight los comparing statistically actual data model fields derived fractional brownian motion fbm processes allows precise control one two point statistics parameters controlling model spectral indices density magnetic field cubes rms mean ratios fields mean gas density orientation mean magnetic field plane sky pos dust temperature dust polarization fraction depth simulated cubes explore nine dimensional parameter space markov chain monte carlo analysis yields best fitting parameters associated uncertainties results find power spectrum turbulent component magnetic field polaris flare molecular cloud scales wavenumber k î²b spectral index î²b = â± complements uniform field whose norm pos approximately twice norm fluctuations turbulent component whose position angle respect north south direction ï‡ â° density field nh well represented log normally distributed field mean gas density nh cm fluctuation ratio ïƒnh nh power spectrum index î²n= + also constrain depth cloud pc polarization fraction p agreement planck data simulated maps best fitting parameters quantified ï‡ value slightly larger unity conclusions conclude fbm based model reasonable description diffuse turbulent magnetized ism polaris flare molecular cloud analysis framework able yield quantitative estimates statistical properties dust density magnetic field cloud â© eso
10.21278/brod69208 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049691672&doi=10.21278%2fbrod69208&partnerID=40&md5=146ef1c3bebc8ea2b6e0d72c47db25b6 0,reliability based inspection planning one popular methods determining time inspection repairs various structures way inspection repair times determined mainly putting lower limit reliability index detection measurement cracks one possible outputs time inspecting fatigue cracking one way use output update parameters fatigue reliability equation study statistical distribution parameters problem updated fatigue reliability calculated inspection planning using bayesian updating concept markov chain monte carlo mcmc method metropolisâ€“hasting algorithm distribution crack growth equation material parameters initial crack length updated method application proposed method shown structural member ship â© brodarski institute rights reserved
10.1214/17-BA1063 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044401713&doi=10.1214%2f17-BA1063&partnerID=40&md5=95abab0ac10a45c8ac36f1142f185afc 2,markov chain monte carlo mcmc algorithms become powerful tools bayesian inference however scale well large data problems divide conquer strategies split data batches batch run independent mcmc algorithms targeting corresponding subposterior spread computational burden across number separate computer cores challenge strategies recombining subposteriors approximate full posterior creating gaussian process approximation log subposterior density create tractable approximation full posterior approximation exploited three methodologies firstly hamiltonian monte carlo algorithm targeting expectation posterior density provides sample approximation posterior secondly evaluating true posterior sampled points leads importance sampler asymptotically targets true posterior expectations finally alternative importance sampler uses full gaussian process distribution approximation log posterior density weight initial sample provide estimate posterior expectation measure uncertainty â© international society bayesian analysis
10.1371/journal.pone.0198760 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048167676&doi=10.1371%2fjournal.pone.0198760&partnerID=40&md5=9b352b5ff983ba30aefb6436bac30b54 0,slaughterhouse surveillance post mortem meat inspection provides important mechanism detecting bovine tuberculosis btb infections cattle herds great britain gb complementary live animal skin test based programme explore patterns numbers herd breakdowns detected slaughterhouse surveillance develop bayesian hierarchical regression model assess associations animal level factors odds infected animal detected slaughterhouse allowing us highlight slaughterhouses show atypical patterns detection analyses demonstrate numbers proportions breakdowns detected slaughterhouses increased gb period study â€“ odds animal slaughterhouse case strongly associated region country animal spent life animals living high frequency testing areas england average times odds detection compared animals living scotland also strong effect age animals slaughtered months age times odds detection compared animals slaughtered â€“ months age smaller effects observed cattle spent time farms history btb quarter year animal slaughtered movement test history risks odds detection increased factor year study adjustment variables additional variations risk slaughterhouses breed framework adopted routine annual surveillance reporting carried animal plant health agency may used target detailed investigation meat inspection practices â© mckinley et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1093/jjfinec/nby010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051552102&doi=10.1093%2fjjfinec%2fnby010&partnerID=40&md5=d6420d5d81043f780b3b0aa6f2d2e67a 0,investigate high frequency volatility models analyzing intradaily tick tick stock price changes using bayesian estimation procedures key interest extraction intradaily volatility patterns high frequency integer price changes account discrete nature data via two different approaches ordered probit models discrete distributions allow stochastic volatility modeling variance stochastic function time intraday periodic patterns consider distributions heavy tails address occurrences jumps tick tick discrete prices changes particular introduce dynamic version negative binomial difference model stochastic volatility model develop markov chain monte carlo estimation method takes advantage auxiliary mixture representations facilitate numerical implementation new modeling framework illustrated means tick tick data two stocks nyse different periods different models compared based predictive likelihoods find evidence favor preferred dynamic negative binomial difference model â© author published oxford university press rights reserved
10.1177/0013164417693666 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043387907&doi=10.1177%2f0013164417693666&partnerID=40&md5=39074350f8088eb3a0df26ddb9040744 1,stan new bayesian statistical software program implements powerful efficient hamiltonian monte carlo hmc algorithm date source systematically provides stan code various item response theory irt models article provides stan code three representative irt models including three parameter logistic irt model graded response model nominal response model demonstrate irt model comparison conducted stan provided stan code simple irt models easily extended multidimensional multilevel cases â© â© author
10.1002/prot.25490 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044277394&doi=10.1002%2fprot.25490&partnerID=40&md5=804b1eff9523579a059b5bd8b9dc54e4 0,biological macromolecules often undergo large conformational rearrangements functional cycle simulate structural transitions full atomic detail typically demands extensive computational resources moreover unclear incorporate principled way additional experimental information guide structural transition article develops probabilistic model conformational transitions biomolecules model viewed network anharmonic springs break experimental data support rupture bonds hamiltonian monte carlo internal coordinates used infer structural transitions experimental data thereby sampling large conformational transitions without distorting structure model benchmarked large set conformational transitions moreover demonstrate use probabilistic network model integrative modeling macromolecular complexes based data crosslinking followed mass spectrometry â© wiley periodicals inc
10.1177/1471082X18759140 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044338766&doi=10.1177%2f1471082X18759140&partnerID=40&md5=cb076b5cd8e0a490db0fd51bb58ee49a 3,bayesian methods become increasingly popular past two decades constant rise computational power even complex models estimated virtually modern computer moreover interest shifted conditional mean models probabilistic distributional models capturing location scale shape aspects response distribution covariate effects flexible forms example linear non linear spatial random effects tutorial article discusses select models bayesian distributional regression setting monitor convergence markov chains use simulation based inference also quantities derived original model parametrization exemplify workflow using daily weather data temperatures germany highest mountain b extreme values precipitation whole germany â© â© sage publications
10.1007/s00362-016-0787-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976514994&doi=10.1007%2fs00362-016-0787-2&partnerID=40&md5=e9287a5e600e5ef85ddaba42fecfa87a 2,paper estimation parameters three parameter weibullâ€“gamma distribution based progressively type ii right censored sample studied maximum likelihood bayes parametric bootstrap methods used estimating unknown parameters well lifetime parameters reliability function hazard function coefficient variation approximate confidence intervals unknown parameters well reliability function hazard function coefficient variation constructed based normal approximation asymptotic distribution maximum likelihood estimators mles log transformed mles addition two bootstrap cis also proposed bayes estimates unknown parameters corresponding credible intervals obtained using gibbs within metropolisâ€“hasting samplers procedure furthermore results bayes method obtained balanced squared error loss balanced linear exponential loss analysis simulated data set also presented illustrative purposes finally monte carlo simulation study carried investigate precision bayes estimates mles two bootstrap estimates also compare performance different corresponding cis considered â© author
10.1214/17-BA1051 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040740190&doi=10.1214%2f17-BA1051&partnerID=40&md5=b818eb7a2e858b89334499bcf4c85c38 7,logistic regression separation occurs linear combination predictors perfectly classify part observations sample result finite maximum likelihood estimates regression coefficients exist gelman et al recommended independent cauchy distributions default priors regression coefficients logistic regression even case separation reported posterior modes analyses mean exist cauchy prior natural question whether posterior means regression coefficients exist separation prove theorems provide necessary sufficient conditions existence posterior means independent cauchy priors logit link general family link functions including probit link also study existence posterior means multivariate cauchy priors full bayesian inference develop gibbs sampler based pã³lya gamma data augmentation sample posterior distribution independent student priors including cauchy priors provide companion r package tglm available cran demonstrate empirically even posterior means regression coefficients exist separation magnitude posterior samples cauchy priors may unusually large corresponding gibbs sampler shows extremely slow mixing alternative algorithms u turn sampler nuts stan greatly improve mixing order resolve issue extremely heavy tailed posteriors cauchy priors separation one need consider lighter tailed priors normal priors student priors degrees freedom larger one â© international society bayesian analysis
10.1007/s11009-017-9574-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020745040&doi=10.1007%2fs11009-017-9574-3&partnerID=40&md5=8e3517ca62f58558fa62cfb2dab0ebc4 0,paper proves convergence stationarity certain adaptive mcmc algorithms certain assumptions including easily verifiable upper lower bounds transition densities continuous target density particular transition proposal densities required continuous thus improving previous ergodicity results craiu et al ann appl probab â€“ â© springer science+business media llc
10.1016/j.sste.2018.01.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041552848&doi=10.1016%2fj.sste.2018.01.003&partnerID=40&md5=b0ca11f23f82d4d746c88e8607fcd14c 0,model based approaches analysis areal count data commonplace spatiotemporal analysis bayesian hierarchical models latent process incorporated mean function account dependence space time typically latent process modelled using conditional autoregressive car prior aim paper offer alternative approach car based priors modelling latent process proposed approach based spatiotemporal generalization latent process poisson regression model developed time series setting spatiotemporal dependence autoregressive model latent process modelled transition matrix structured covariance matrix specified error term proposed model parameterizations fitted bayesian framework implemented via mcmc techniques findings based real life examples show proposed approach least effective car based models â©
10.1111/rssa.12352 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041745129&doi=10.1111%2frssa.12352&partnerID=40&md5=1f75c642ca723fa678b814e93af89310 1,statistical agencies increasingly adopting synthetic data methods disseminating microdata without compromising privacy respondents crucial implementation approaches flexible models able capture nuances multivariate structure original data case multivariate categorical data preserving multivariate structure also often involves satisfying constraints form combinations responses logically present data setâ€”like married toddlers pregnant menâ€”also known structural zeros ignoring structural zeros result logically inconsistent synthetic data biased estimates propose use bayesian non parametric method generating discrete multivariate synthetic data subject structural zeros method preserve complex multivariate relationships variables applied high dimensional data sets massive collections structural zeros requires minimal tuning user computationally efficient demonstrate approach synthesizing extract variables us census method produces synthetic samples high analytic utility low disclosure risk â© royal statistical society
10.1016/j.envsoft.2018.03.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044166591&doi=10.1016%2fj.envsoft.2018.03.001&partnerID=40&md5=3cee4c858f7ece5670421ce053cdd7c5 4,efficient bayesian analytical framework developed address challenges uncertainty analysis assess parameter identification problems complex water quality models high dimensional parameter space inclusion multi chain markov chain monte carlo method comprehensive global sensitive analysis gsa guarantees results robust high frequency synthetic data case study conducted efdc water quality module including parameters comprehensive gsa identified completely partially sensitive parameters reducing dimensionality among nine identifiable without significant bias fundamental causes parameter identification problem traced cognitive limitations real water quality assessment process instead data scarcity framework powerful exploring limitations generating reminders model users use bayesian estimates future forecasts providing directions model developers perfect model future work â© elsevier ltd
10.1007/s00454-018-9992-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045057267&doi=10.1007%2fs00454-018-9992-1&partnerID=40&md5=18685e3cf5937b058864d5ae376bf993 1,extend langevin monte carlo lmc algorithm compactly supported measures via projection step akin projected stochastic gradient descent sgd show projected lmc allows sample polynomial time log concave distribution smooth potential gives new markov chain sample log concave distribution main result shows particular target distribution uniform lmc mixes n steps n dimension also provide preliminary experimental evidence lmc performs least well hit run better mixing time n proved lovã¡sz vempala â© springer science+business media llc part springer nature
10.1007/s00477-018-1538-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045121539&doi=10.1007%2fs00477-018-1538-9&partnerID=40&md5=c636d4a608fa787a06812651d3b5154e 1,physically based distributed hydrological models ideal hydrological simulations however models use basic equations pertaining mass energy momentum conservation represent physics process plausibly due lack complete understanding hydrological process soil water assessment tool swat one widely accepted semi distributed conceptual hydrological model used water resources planning however parameterization difficulty calibration process uncertainty associated predictions make applications skeptical study considers assessing predictive uncertainty associated distributed hydrological models existing methods uncertainty estimation demand high computational time therefore make challenging apply complex hydrological models proposed approach employs concepts generalized likelihood uncertainty estimation glue iterative procedure starting assumed prior probability distribution parameters using mutual information mi index sampling behavioral parameter set distributions conditioned observed information successive cycles simulations cycle simulation mi used conjunction markov chain monte carlo procedure sample parameter sets increase number behavioral sets turn helps reduce number cycles simulations analysis method demonstrated case study swat model illinois river basin usa comparison proposed method glue indicates computational requirement uncertainty analysis considerably reduced proposed approach also noted model prediction band derived using proposed method effective compared derived using methods considered study â© springer verlag gmbh germany part springer nature
10.1016/j.jse.2017.11.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039923971&doi=10.1016%2fj.jse.2017.11.013&partnerID=40&md5=cb02e01dd5848f41c0672d74af29cff3 1,background purpose study conduct cost effectiveness analysis arthroscopic bankart open latarjet treatment primary shoulder instability methods cost effectiveness study used markov decision chain monte carlo simulation existing literature reviewed determine survivorship complication rates procedures health utility states eq quality adjusted life years bankart latarjet prospectively collected using variables monte carlo simulation modeled times results reviewing literature overall recurrence rate arthroscopic bankart open latarjet postoperative health utility states equal procedures mean eq p = monte carlo simulation showed bankart incremental cost effectiveness ratio latarjet incremental cost effectiveness ratio p conclusion arthroscopic bankart open latarjet highly cost effective however bankart cost effective latarjet primarily lower health utility state failed latarjet ultimately clinical scenario may favor latarjet ie critical glenoid bone loss certain circumstances decisions made case case basis â© journal shoulder elbow surgery board trustees
10.1214/17-BA1049 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044436139&doi=10.1214%2f17-BA1049&partnerID=40&md5=148f2330c99c8af349b8d8f3e24d3bef 1,evaluating marginal likelihood bayesian analysis essential model selection estimators based single markov chain monte carlo sample posterior distribution include harmonic mean estimator inflated density ratio estimator propose new class monte carlo estimators based single markov chain monte carlo sample class thought generalization harmonic mean inflated density ratio estimators using partition weighted kernel likelihood times prior show estimator consistent better theoretical properties harmonic mean inflated density ratio estimators addition provide guidelines choosing optimal weights simulation studies conducted examine empirical performance proposed estimator demonstrate desirable features proposed estimator two real data sets one prostate cancer study using ordinal probit regression model latent variables power prior construction two eastern cooperative oncology group phase iii clinical trials using cure rate survival model similar objectives â© international society bayesian analysis
10.1007/s00705-018-3764-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041922059&doi=10.1007%2fs00705-018-3764-3&partnerID=40&md5=243f4005b09044431e548e99664008f8 0,previous local national iranian publications indicate iranian hepatitis b virus hbv strains belong hbv genotype aim study analyze evolutionary history hbv infection iran first time based intensive phylodynamic study evolutionary parameters time recent common ancestor tmrca population dynamics infections investigated using bayesian monte carlo markov chain bmcmc effective sample size ess sampling convergence monitored sampling posterior distribution nucleotide substitution rate evolutionary parameters point estimations median parameters obtained iranian hbv isolates genotype sub type ayw origin hbv regarded evolved first eastern border moving westward isfahan province hosted virus afterwards virus moved south west country tmrca hbv iran estimated around credible interval years effective number infections increased exponentially around conversely around onwards effective number hbv infections decreased high rate phylodynamic inference clearly demonstrates unique homogenous pattern hbv genotype compatible steady configuration decreased effective number infections population recent years possibly due implementation blood donation screening vaccination programs adequate molecular epidemiology databases hbv crucial infection prevention treatment programs â© springer verlag gmbh austria part springer nature
10.1007/s13253-018-0319-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045147017&doi=10.1007%2fs13253-018-0319-8&partnerID=40&md5=532b7541abc143e142a9ec5fa103ad6e 0,orbiting carbon observatory oco collects infrared spectra atmospheric properties retrieved oco operational data processing uses optimal estimation oe state art approach inference atmospheric properties satellite measurements one main advantages oe approach computational efficiency characterizes first two moments posterior distribution interest obtain samples posterior using markov chain monte carlo mcmc algorithm compare empirical estimate true posterior oe results focus simulated soundings represent variability physical conditions encountered oco november january treat two retrieval methods ensemble density probabilistic forecasts mcmc yields ensemble posterior oe retrieval result provide first two moments normal distribution compare methods apply univariate multivariate diagnostic tools proper scoring rules general impression study compared mcmc oe retrieval performs reasonably well main quantity interest column averaged co concentration xco full state vector x includes profile co concentrations pressure levels well several atmospheric properties supplementary materials accompanying paper appear line â© international biometric society
10.1111/biom.12790 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032803987&doi=10.1111%2fbiom.12790&partnerID=40&md5=7b99428c6f9922aca6bbc825fe870fef 1,work motivated desire quantify relationships two time series pulsing hormone concentrations locations pulses directly observed may considered latent event processes latent event processes pulsing hormones often associated joint relationship model current approaches jointly modeling pulsing hormone data generally assume pulse one hormone coupled pulse another hormone one one association however pulse coupling often imperfect existing joint models flexible enough imperfect systems article develop flexible class pulse association models incorporate parameters quantifying imperfect pulse associations propose novel use cox process model model pulse events co occur time embed cox process model hormone concentration model hormone concentration observed data spatial birth death markov chain monte carlo used estimation simulations show joint model works well quantifying perfect imperfect associations offers estimation improvements single hormone analyses apply model luteinizing hormone lh follicle stimulating hormone fsh two reproductive hormones use joint model results ability investigate novel hypotheses regarding associations lh fsh secretion obese non obese women â© international biometric society
10.1002/env.2504 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048059480&doi=10.1002%2fenv.2504&partnerID=40&md5=fced3b370fb4e938f0b22874bf772b7d 1,substantial interest assessing exposure environmental mixtures chemical mixtures affects child health researchers also interested identifying critical time windows susceptibility complex mixtures recently developed method called lagged kernel machine regression lkmr simultaneously accounts research questions estimating effects time varying mixture exposures identifying critical exposure windows however lkmr inference using markov chain monte carlo mcmc methods mcmc lkmr computationally burdensome time intensive large data sets limiting applicability therefore develop mean field variational approximation method bayesian inference mfvb procedure lkmr mfvb lkmr procedure achieves computational efficiency reasonable accuracy compared corresponding mcmc estimation method updating parameters using mfvb may take minutes whereas equivalent mcmc method may take many hours several days apply mfvb lkmr programming research obesity growth environment social stressors progress prospective cohort study mexico city results subset progress using mfvb lkmr provide evidence significant positive association second trimester cobalt levels z scored birth weight positive association heightened cesium exposure mfvb lkmr promising approach computationally efficient analysis environmental health data sets identify critical windows exposure complex mixtures copyright â© john wiley sons ltd
10.1371/journal.pone.0199450 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049196848&doi=10.1371%2fjournal.pone.0199450&partnerID=40&md5=d8e8fa933b7172f1b979cb0f44993692 0,background cyd tdv vaccine unusual recommended target population vaccination originally defined age also transmission setting defined seroprevalence originally recommended countries consider vaccination dengue cyd tdv vaccine geographic settings prior infection dengue serotype measured seroprevalence target age group vaccine recommended settings seroprevalence test vaccinate strategies suggested following new analysis sanofi still require age stratified seroprevalence surveys optimise age group targeting address considerations serosurvey design context vaccination program planning methods explore design seroprevalence surveys affects estimates transmission intensity age specific seroprevalence surveys simulated using beta binomial distribution simple catalytic model different combinations age range survey size transmission setting test sensitivity specificity used metropolis hastings markov chain monte carlo algorithm estimate force infection simulated dataset results sampling wide age range led accurate estimates merely increasing sample size narrow age range finding consistent across transmission settings optimum test sensitivity specificity given imperfect test differed setting high sensitivity important high transmission settings high specificity important low transmission settings conclusions assessing vaccination suitability seroprevalence surveys countries ensure appropriate age range sampled considering epidemiological evidence local burden disease â© imai ferguson open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1051/0004-6361/201730921 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048882050&doi=10.1051%2f0004-6361%2f201730921&partnerID=40&md5=2b0d776ad39434770206721950f786a8 0,gaia mission expected make significant contribution knowledge exoplanet systems terms number physical properties develop bayesian methods detection criteria orbital fitting revise detectability exoplanets light flight properties gaia limiting one planet systems first step development simulate gaia data exoplanet systems grid n orbital period eccentricity simulations fit using markov chain monte carlo methods investigate detection rate according three information criteria î”ï‡ î”ï‡ effective number degrees freedom depends mission length find choice markov chain starting point affect quality results therefore consider two limit possibilities ideal case simple method finds starting point assuming circular orbits use simulations assess fraction false positive detections yr yr mission respectively simulations assess detection rate parameters recovered using jeffreys scale evidence fraction false positives passing strong evidence criterion â‰¤ considering yr yr mission using akaike information criterion watanabe akaike information criterion lt lt using bayesian information criterion find chance detecting planet minimum n = sets maximum distance planet detectable âˆ¼ pc âˆ¼ pc jupiter mass neptune mass planets respectively assuming yr mission au semi major axis mâš™ star show distribution accuracy precision orbital parameters recovered period orbital parameter determined best accuracy median relative difference input output periods assuming yr yr mission median accuracy semi major axis orbit recovered median relative error eccentricity also recovered median absolute accuracy â© eso
10.1371/journal.pcbi.1006235 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049368254&doi=10.1371%2fjournal.pcbi.1006235&partnerID=40&md5=1ca838b839b9e809047806b6eea9a5da 0,imaging data become essential tool explore key biological questions various scales example motile behaviour bacteria transport mrna potential transform understanding important transport mechanisms often imaging studies require us compare biological species mutants need quantitatively characterise behaviour mathematical models offer quantitative description system enables us perform comparison relate mechanistic mathematical models imaging data need estimate parameters work study collecting data different temporal resolutions impacts ability infer parameters biological transport models performing exact inference simple velocity jump process models bayesian framework question best choose frequency data collected prominent host studies majority imaging technologies place constraints frequency images taken discrete nature observations introduce errors parameter estimates work mitigate errors formulating velocity jump process model within hidden states framework allows us obtain estimates reorientation rate noise amplitude noisy observations simple velocity jump process demonstrate sensitivity estimates temporal variations sampling resolution extent measurement noise use methodology provide experimental guidelines researchers aiming characterise motile behaviour described velocity jump process particular consider experimental constraints resulting trade temporal sampling resolution observation noise may affect parameter estimates finally demonstrate robustness methodology model misspecification apply inference framework dataset generated aim understanding localization rna protein complexes â© harrison baker http creativecommons org licenses
10.1016/j.csda.2018.01.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041538675&doi=10.1016%2fj.csda.2018.01.013&partnerID=40&md5=b61118c5b90e5ce5cf89d768acb05309 0,parametric conditional copula models allow copula parameters vary set covariates according unknown calibration function flexible bayesian inference calibration function bivariate conditional copula introduced prior distribution set smooth calibration functions built using sparse gaussian process gp prior single index model sim estimation parameters marginal distributions calibration function done jointly via markov chain monte carlo sampling full posterior distribution new conditional cross validated pseudo marginal ccvml criterion used perform copula selection modified using permutation based procedure assess data support simplifying assumption performance estimation method model selection criteria studied via series simulations using correct misspecified models clayton frank gaussian copulas numerical application involving red wine features â© elsevier b v
10.1007/s10827-018-0684-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046767121&doi=10.1007%2fs10827-018-0684-x&partnerID=40&md5=058c8aa193e67c820856437cc9f51740 0,previously reported temperature may significantly influence neural dynamics different levels brain function thus computational neuroscience useful make models scalable wide range various brain temperatures however lack experimental data absence temperature dependent analytical models synaptic conductance allow include temperature effects multi neuron modeling level paper propose first step deal problem new analytical model ampa type synaptic conductance able incorporate temperature effects low frequency stimulations constructed based markov model description ampa receptor kinetics using set coupled odes closed form solution set differential equations found using uncoupling assumption introduced paper simplifications motivated experimental data monte carlo simulation synaptic transmission model may used computationally efficient biologically accurate implementation temperature effects ampa receptor conductance large scale neural network simulations result may open wide range new possibilities researching influence temperature certain aspects brain functioning â© author
10.1051/0004-6361/201731396 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048884068&doi=10.1051%2f0004-6361%2f201731396&partnerID=40&md5=4471cceee7b94237e37640fa4db1e35c 1,investigated shape extinction curve infrared âˆ¼ î¼m orion star forming complex basis work near infrared data acquired visual infrared survey telescope astronomy combination pan starrs mid infrared spitzer photometry obtain colour excess ratios eight passbands fitting series colour colour diagrams fits performed using markov chain monte carlo methods together linear model bayesian formalism resulting colour excess ratios directly interpreted measure extinction law show orion molecular cloud characterized flat mid infrared extinction similar many recently studied sightlines moreover find statistically significant evidence extinction law âˆ¼ î¼m least âˆ¼ î¼m varies across cloud particular find gradient along galactic longitude regions near orion nebula cluster show different extinction law compared l l low mass star forming sites cloud complex variations order likely caused influence massive stars surrounding medium observed general trends measurements agreement model predictions well established new dust grain models able fully reproduce infrared extinction curve also present new extinction map featuring resolution â€² revisit correlation extinction dust optical depth analysis shows cloud substructure sampled background sources affects conversion factor two measures conclusion argue specific characteristics infrared extinction law still well understood orion serve unbiased template future studies â© eso
10.1051/0004-6361/201732327 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048894220&doi=10.1051%2f0004-6361%2f201732327&partnerID=40&md5=ecad373e4e82f5047e49230d57111f63 4,context first gaia data release unlocked access photometric information billion sources g band yet given high level degeneracy extinction spectral energy distribution large passbands gaia g band correction interstellar reddening needed order exploit gaia data aims purpose manuscript provide empirical estimation gaia g band extinction coefficient kg red giants main sequence stars order able exploit first data release dr methods selected two samples single stars one red giants one main sequence samples result cross match gaia dr mass catalogues consist high quality photometry g j ks bands samples complemented temperature metallicity information retrieved apogee dr lamost dr surveys respectively implemented markov chain monte carlo method used g ks versus teff j ks versus g ks calibration relations estimate extinction coefficient kg quantify corresponding confidence interval via bootstrap resampling tested method samples red giants main sequence stars finding consistent solutions results present determination gaia extinction coefficient completely empirical method furthermore provide scientific community formula measuring extinction coefficient function stellar effective temperature intrinsic colour g ks absorption â© eso
10.1016/j.frl.2017.10.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033385926&doi=10.1016%2fj.frl.2017.10.021&partnerID=40&md5=59d89ba47cb793955d3da5e2d2f63167 0,study investigates impact stock market cycles volatility asian markets specifically addresses combined effect jumps asymmetry stochasticity predicting market volatility results indicate stochastic volatility process highly persistent across countries leverage effect size frequency jumps found significant play prominent role computing market volatility empirical results imply stochastic volatility model embedded jump asymmetric component significantly helps measuring volatility especially turbulent periods results major implications policy makers regulators mutual funds hedge funds well institutional investors â© elsevier inc
10.15446/esrj.v22n2.65577 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050793625&doi=10.15446%2fesrj.v22n2.65577&partnerID=40&md5=75eff689f7ceee892ec5832f7d41f4e9 0,time series models often used hydrology meteorology studies model streamflows series order make forecasting generate synthetic series inputs analysis complex water resources systems paper introduce new modeling approach hydrologic meteorological time series assuming continuous distribution data conditional mean conditional variance parameters modeled bayesian methods using standard mcmc markov chain monte carlo methods used simulate samples joint posterior distribution interest two applications real data sets illustrate proposed methodology assuming observations come normal gamma beta distribution first example given time series monthly averages natural streamflows measured year period ranging furnas hydroelectric dam brazil second example given time series air humidity data measured weather station rio claro brazilian city located southeastern brazil applications motivate us introduce new classes models analyze hydrological meteorological time series â© universidad nacional de colombia rights reserved
10.1016/j.amar.2018.04.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045719766&doi=10.1016%2fj.amar.2018.04.002&partnerID=40&md5=3278c2f13c94b3de0d13ea011f213784 2,existence preponderant zero crash sites sites large crash counts present challenges statistical analysis crash count data additionally unobserved heterogeneity crash data due absence important variables negatively impact estimated model parameters traditional negative binomial nb model fixed parameters might adequately handle highly dispersed data unobserved heterogeneity many research efforts involved negative binomialâ€“lindley nb l model random parameters negative binomial rpnb model example attempted improve inference estimated coefficients explicitly accounting extra variation crash data nb l mixed modeling approach provides flexibility account additional dispersion data rp modeling approach accommodates effect unobserved variables allowing model parameters vary one observation another following study proposes combination models â€“ random parameters nb l rpnb l generalized linear model glm â€“ account underlying heterogeneity address excess dispersion results show rpnb l model provides superior goodness fit gof sample data also offers better understanding effects potential contributing factors paper uses bayesian framework provide strategy eliminating potential poor mixing markov chain monte carlo mcmc chains estimation rpnb l model â© elsevier ltd
10.1002/qre.2279 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047941131&doi=10.1002%2fqre.2279&partnerID=40&md5=6895e0fb032e0e9a55ede1e58efd3723 0,based failures parallel series system new distribution called geometric poisson rayleigh distribution proposed properties distribution discussed real data set used compare new distribution distributions progressive stress accelerated life tests considered lifetime item use condition assumed follow geometric poisson rayleigh distribution assumed scale parameter geometric poisson rayleigh distribution satisfies inverse power law stress nonlinear increasing function time cumulative exposure model effect changing stress holds based type progressive hybrid censoring binomial removals maximum likelihood bayes using linear exponential general entropy loss functions estimation methods considered estimate involved parameters point predictors maximum likelihood conditional median best unbiased bayes point predictors future order statistics obtained bayes estimates obtained using markov chain monte carlo algorithm finally simulation study performed numerical computations performed compare performance implemented methods estimation prediction copyright â© john wiley sons ltd
10.1016/j.kint.2018.01.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044330182&doi=10.1016%2fj.kint.2018.01.009&partnerID=40&md5=87ecc9f0b55344720736c2aa6c3e43b0 4,patients chronic kidney disease severely decreased glomerular filtration rate gfr high risk kidney failure cardiovascular disease cvd death accurate estimates risk timing clinical outcomes guide patient counseling therapy therefore developed models using data individuals countries participating international chronic kidney disease prognosis consortium estimated gfr egfr ml min median participant egfr urine albumin creatinine ratio ml min mg g respectively using competing risk regression random effect meta analysis markov processes monte carlo simulations developed two four year models probability timing kidney failure requiring kidney replacement therapy krt non fatal cvd event death according age sex race egfr albumin creatinine ratio systolic blood pressure smoking status diabetes mellitus history cvd hypothetically applied year old white male history cvd systolic blood pressure mmhg egfr ml min urine albumin creatinine ratio mg g four year model predicted chance survival krt chance survival cvd event chance survival chance death first event another cvd event krt risk predictions krt showed good overall agreement published kidney failure risk equation models well calibrated observed risk thus commonly measured clinical characteristics predict timing occurrence clinical outcomes patients severely decreased gfr â© international society nephrology
10.1016/j.mgene.2018.02.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042286463&doi=10.1016%2fj.mgene.2018.02.005&partnerID=40&md5=f9629535b85b4ae2090c01180c8c6410 0,genus impatiens widely distributed areas old world tropics subtropics european united states impatiens examined genetic diversity analysis study indian impatiens studied interspecies genetic diversity based inter simple sequence repeat issr markers morphological characters dna fragments amplified using issr markers polymorphic diversity indices issr markers ranged = = genetic similarity coefficient = average pic value marker results indicate presence high amount genetic diversity among studied impatiens species computed p value obtained mantel test reveals nonsignificant correlation diversity relationship among impatiens shown issr markers morphological characters studied impatiens divided groups based clustering results unweighted pair group method arithmetic mean upgma dendrogram issr morphological data resolution species obtained using issr data limitedly supports sectional classification biogeographic history impatiens based phylogeny using bayesian binary markov chain monte carlo method bbm confirmed south east asian origin impatiens study gave idea interspecies diversity indian impatiens suggests suitability issr markers interspecies diversity studies impatiens â© elsevier b v
10.1007/s10260-017-0384-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022185707&doi=10.1007%2fs10260-017-0384-0&partnerID=40&md5=e055549f7b6a251cfda5f399d9745145 0,use bayesian nonparametrics models increased rapidly last decades driven increasing computational power development efficient markov chain monte carlo algorithms review applications models economic applications including volatility modelling using stochastic volatility models garch type models dirichlet process mixture models uses portfolio allocation problems long memory models flexible forms time dependence flexible extension dynamic nelson siegel model interest rate yields multivariate time series models used macroeconometrics â© springer verlag gmbh germany
10.1063/1.5025545 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048321420&doi=10.1063%2f1.5025545&partnerID=40&md5=0a94b244245cc18ca964f296bd491d62 0,propose bayesian nonparametric approach noise reduction given chaotic time series contaminated dynamical noise based markov chain monte carlo methods underlying unknown noise process possibly exhibits heavy tailed behavior introduce dynamic noise reduction replicator model reconstruct unknown dynamic equations parallel replicate dynamics reduced noise level dynamical perturbations dynamic noise reduction procedure demonstrated specifically case polynomial maps simulations based synthetic time series presented â© author
10.1111/jedm.12178 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048053036&doi=10.1111%2fjedm.12178&partnerID=40&md5=691eb4e6e724c669d33726415674e0ad 0,lord wald test differential item functioning dif studied extensively context multidimensional item response theory mirt framework article lord wald test implemented using two estimation approaches marginal maximum likelihood estimation bayesian markov chain monte carlo estimation detect uniform nonuniform dif mirt models type error power rates lord wald test investigated various simulation conditions including different dif types magnitudes different means correlations two ability parameters different sample sizes furthermore english usage data analyzed illustrate use lord wald test two estimation approaches copyright â© national council measurement education
10.1080/10618600.2018.1438900 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048145700&doi=10.1080%2f10618600.2018.1438900&partnerID=40&md5=85c72002af2ac9f7982f02562197f18d 0,mixtures gaussian distributions studied century construction reference bayesian analysis models remains unsolved general prohibition improper priors due ill posed nature statistical objects difficulty usually bypassed empirical bayes resolution creating new parameterization centered mean possibly variance mixture distribution manage develop weakly informative prior wide class mixtures arbitrary number components demonstrate posterior distributions associated prior minimal sample size proper provide markov chain monte carlo mcmc implementations exhibit expected exchangeability study univariate case extension multivariate location scale mixtures currently study r package called ultimixt associated article supplementary material article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1063/1.5026855 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049408505&doi=10.1063%2f1.5026855&partnerID=40&md5=d4786deb0dfef61ee0ca09c168a61c18 0,paper contributes detecting chaotic behaviors dynamic complex social networks using new feature diffusion aware model two perspectives abnormal links well abnormal nodes proposed approach constructs probabilistic model dynamic complex social networks subsequently applies detect chaotic behaviors measuring deviations model predictive model considers main processes features dynamics evolution nodes features feature diffusion link generation processes dynamic complex social networks feature diffusion process indicates process node former features influence future features neighbors proposed approach validated experiments two real dynamic complex social network datasets google+ twitter approach uses markov chain monte carlo sampling methods like metropolis hastings algorithm slice sampling strategy extract model parameters given real datasets experimental results indicate improved performance characteristics proposed approach comparison baseline approaches terms performance measures accuracy f score matthews correlation coefficient recall precision area roc curve log likelihood â© author
10.1002/jrsm.1285 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040739921&doi=10.1002%2fjrsm.1285&partnerID=40&md5=09128200d7060a71964876e7d0435a81 3,network meta analysis nma gaining popularity comparing multiple treatments single analysis generalized linear mixed models provide unifying framework nma allow us analyze datasets dichotomous continuous count endpoints take account multiarm trials potential heterogeneity trials network inconsistency perform inference within nma models use bayesian methods often advocated standard inference tool markov chain monte carlo mcmc computationally expensive requires convergence diagnostics deterministic approach fully bayesian inference latent gaussian models achieved integrated nested laplace approximations inla fast accurate alternative mcmc show nma models fit class latent gaussian models nma models implemented using inla demonstrate estimates obtained inla close agreement ones obtained mcmc specifically emphasize design treatment interaction model random inconsistency parameters also known jackson model also proposed network meta regression model constructed incorporating trial level covariates jackson model explain possible sources heterogeneity inconsistency network publicly available r package nmainla developed automate inla implementation nma models considered paper three applications illustrate use inla nma â© authors research synthesis methods published john wiley sons ltd
10.1111/biom.12766 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028412236&doi=10.1111%2fbiom.12766&partnerID=40&md5=f7531ef5021dfbaf57c333d7125dec8b 1,sightings previously marked animals extend captureâ€“recapture dataset without added cost capturing new animals marking combined marking resighting methods therefore attractive option animal population studies exist various likelihood based non spatial models spatial versions fitted markov chain monte carlo sampling implemented date focus modeling sightings requires spatial distribution pre marked animals known develop suite likelihood based spatial markâ€“resight models either include marking phase â€œcaptureâ€“markâ€“resightâ€� models require known distribution marked animals narrow sense â€œmarkâ€“resightâ€� new models sacrifice information covariance structure counts unmarked animals estimation maximizing pseudolikelihood simulation based adjustment overdispersion sightings unmarked animals simulations suggest resulting estimates population density low bias adequate confidence interval coverage typical sampling conditions work needed specify conditions ignoring covariance results unacceptable loss precision modify pseudolikelihood include information methods applied study ship rats rattus rattus using live traps video cameras new zealand forest previously published data â© international biometric society
10.1007/s10511-018-9525-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048458212&doi=10.1007%2fs10511-018-9525-x&partnerID=40&md5=e7de0f600712bc2871a3d5eb38a5ef95 0,present î³ ray observations radio galaxy pks using fermi large area telescope data accumulated î³ rays gev detected detection significance ïƒ power law spectrum photon index â± integrated flux fî³ = â± ã— photon cm mev well describes data averaged years observations hint deviation simple power law shape around tens gev energies however low statistics allow one reject power law modeling spectral energy distributions high low x ray states modeled using one zone leptonic models include synchrotron synchrotron self compton processes model parameters estimated using markov chain monte carlo method modeling shows jet pks particles electrons accelerated energies higher tev â© springer science+business media llc part springer nature
10.1111/aogs.13310 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042528302&doi=10.1111%2faogs.13310&partnerID=40&md5=e7396dafdcadde96c89bf61d4891d3ed 0,introduction cesarean section rates continue increase globally prediction intrapartum cesarean section lead preventive measures aim assess association sonographically measured cervical length weeks gestation cesarean section among women planning vaginal birth population women low risk pregnancy gestational diabetes material methods prospective cohort study conducted tertiary referral hospital sydney australia women low risk pregnancy gestational diabetes recruited including nulliparous parous women maternal demographic clinical ultrasound characteristics collected weeks gestation semi bayesian logistic regression markov chain monte carlo simulation used assess relation cervical length cesarean section labor results rates cesarean section cervical length â‰¤ mm cervical length â€“ mm cervical length mm rates respectively nulliparous women semi bayesian analysis odds ratio cesarean section confidence interval â€“ cervical length â€“ mm confidence interval â€“ cervical length mm compared lowest quartile cervical length adjusting maternal age parity height prepregnancy body mass index gestational diabetes induction labor neonatal sex birthweight centile conclusions cervical length weeks gestation associated intrapartum cesarean section â© nordic federation societies obstetrics gynecology
10.1111/2041-210X.13009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045841727&doi=10.1111%2f2041-210X.13009&partnerID=40&md5=ea7507b4ed8a8c1f1e18dd97d5fedfa9 1,stable isotope analysis provides powerful tool identify energy sources fuel consumers understand trophic interactions infer consumer trophic position tp important concept describes ecological role consumers food webs however current methods estimating tp using stable isotopes limited fulfil complete potential isotopic approach instance researchers typically use point estimates key parameters including trophic discrimination factors isotopic baselines explicitly include variance associated parameters calculating tp present â€œtrophicposition â€� r package incorporating bayesian model calculation consumer tp population level using stable isotopes one two baselines combines markov chain monte carlo simulations jags statistical graphical analyses using r model consumer baseline observations using relevant statistical distributions allowing treated random variables calculation tpâ€”a random parameterâ€”for one baseline follows standard equations linking n enrichment per trophic level trophic position baseline e g primary producer primary consumer case two baselines simple mixing model incorporating î´ c allows differentiation two distinct sources nitrogen thus including heterogeneity derived alternatives sources î´ n methods currently implemented â€œtrophicpositionâ€� include loading plotting summarizing stable isotope data either multiple sites communities local assemblage loading trophic discrimination factors internal database generating defining initializing bayesian model tp sampling posterior parameters analysing comparing plotting posterior estimates tp parameters calculating parametric non bayesian tp estimate additionally full documentation including examples multiple vignettes code available download â© authors methods ecology evolution â© british ecological society
10.3390/atmos9060213 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047838085&doi=10.3390%2fatmos9060213&partnerID=40&md5=815ce29718f081ec65f6dc7a52d4eaae 1,paper presents fully non gaussian filter sequential data assimilation filter named cluster sampling filter works directly sampling posterior distribution following markov chain monte carlo mcmc approach prior distribution approximated using gaussian mixture model gmm specifically clustering step introduced forecast phase filter prior density function estimated fitting gmm prior ensemble using data likelihood function posterior density formulated mixture density sampled following mcmc approach four versions proposed filter namely câ„“mcmc câ„“hmc mc câ„“hmc mc câ„“hmc presented câ„“mcmc uses gaussian proposal density sample posterior câ„“hmc extension hamiltonian monte carlo hmc sampling filter mc câ„“mcmc mc câ„“hmc multi chain versions cluster sampling filters câ„“mcmc câ„“hmc respectively multi chain versions proposed guarantee samples taken vicinities probability modes formulated posterior new methodologies tested using simple one dimensional example quasi geostrophic qg model double gyre wind forcing bi harmonic friction numerical results demonstrate usefulness using gmms relax gaussian prior assumption especially hmc filtering paradigm â© authors
10.1145/3194554.3194577 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049476449&doi=10.1145%2f3194554.3194577&partnerID=40&md5=9547e3533bc3673766ceda3f078ce6f1 0,paper presents mc markov chain monte carlo manycore accelerator high throughput domain specific programmable manycore accelerator effectively generates samples provided target distribution mcmc samplers used machine learning image signal processing applications computationally intensive scenarios high throughput samplers paramount importance achieve high throughput platform add two domain specific instructions dedicated hardware whose functions extensively used mcmc algorithms instructions bring number clock cycles needed implement respective functions ã— ã— cluster architecture mc fully placed routed nm tsmc cmos technology vlsi layout cluster occupies area mm consuming power mw running ghz clock frequency proposed mc achieves ã— higher throughput equivalent predecessor penc consumes ã— lower energy per sample also compared shelf platforms jetson tx tx soc mc results ã— ã— higher throughput consumes ã— ã— lower energy per sample generation respectively â© association computing machinery
10.1109/ACCESS.2018.2842088 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047787956&doi=10.1109%2fACCESS.2018.2842088&partnerID=40&md5=c616bce0615fb7887c3ed5417d7e57da 0,transferring complex computing cloud server side leverages cloud based intelligent service robots capable highly complex computing tasks video analysis practical behavior surveillance applications captured videos intelligent service robots continuous action extraction continuous unconstrained video important prerequisite action analysis action classification recognition abnormal event detection crowd emotion sensing paper proposes novel approach action extraction continuous unconstrained video three parts spatial location estimation temporal action path searching spatial temporal action compensation spatial location estimation utilizes human appearance motion cues obtain frame level bounding boxes spatial action proposal results priori searching temporal action paths formulated optimal estimation problem accounting missed detections false alarms spatial location estimation solve temporal action path searching problem propose markov chain monte carlo algorithm illustrate convergence property extensive experiments challenging ucf sports ucf data sets show effectiveness approach obtain superior performance compared state arts â© ieee
10.1109/CSPA.2018.8368705 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048821948&doi=10.1109%2fCSPA.2018.8368705&partnerID=40&md5=1caa383c4f3384dad1ddf41d7ba31126 0,dynamical systems natural convenient way model evolution processes observed practice uncertainty considered incorporated system become known stochastic dynamical systems based observations made stochastic dynamical systems consider issue parameter learning related state estimation problem develop markov chain monte carlo mcmc algorithm iterative method parameter inference within parameter learning steps mcmc algorithm requires perform state estimation target distribution constructed using ensemble kalman filter enkf methodology illustrated using two examples nonlinear stochastic dynamical systems â© ieee
10.1080/03610918.2017.1311915 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021409068&doi=10.1080%2f03610918.2017.1311915&partnerID=40&md5=89967c212fba360ff8f23b136afb4288 0,paper develop bayesian estimation procedure semiparametric models shape constrains approach uses hierarchical bayes framework characterizations shape constrained b splines employ markov chain monte carlo methods model fitting using truncated normal distribution prior coefficients basis functions ensure desired shape constraints small sample properties function estimators provided via simulation compared existing methods real data analysis conducted illustrate application proposed method â© â© taylor francis group llc
10.1109/ACCESS.2018.2840536 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047803394&doi=10.1109%2fACCESS.2018.2840536&partnerID=40&md5=c56bf9fdfd38a8adca8ac21dbaea9897 0,accurate prior knowledge future driving cycle quite essential many research applications related optimal control vehicle transportation especially model predictive control based energy management hybrid electric vehicles therefore adaptive online prediction method variable prediction horizon proposed future driving cycle prediction paper particular two aspects efforts explored first combining markov chain monte carlo theory multi scale single step prediction method proposed compared traditional fixed scale multi step method improving prediction accuracy second adapt variable actual driving cycles online reconstructions driving cycle state filling introduced guarantee continuous robust online application principal component analysis cluster analysis employed adjust real time prediction horizons better overall prediction accuracy end proposed method verified experiment hardware loop simulation showing improvement prediction accuracy fixed horizon prediction method relatively good robustness universality different driving conditions â© ieee
10.1080/03610918.2017.1317804 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021836002&doi=10.1080%2f03610918.2017.1317804&partnerID=40&md5=8008b7935ba0363f2475e65a4150d6e4 0,article addresses various properties different methods estimation unknown parameter length area biased maxwell distributions although main focus estimation frequentist bayesian point view yet various mathematical statistical properties length area biased maxwell distributions moments moment generating function mgf hazard rate function mean residual lifetime function residual lifetime function reversed residual life function conditional moments conditional mgf stochastic ordering measures uncertainty derived briefly describe different frequentist approaches namely maximum likelihood estimator moments estimator least square weighted least square estimators maximum product spacings estimator compare using extensive numerical simulations next consider bayes estimation different types loss function symmetric asymmetric loss functions using inverted gamma prior scale parameter furthermore bayes estimators respective posterior risks computed compared using markov chain monte carlo mcmc algorithm also bootstrap confidence intervals using frequentist approaches provided compare bayes credible intervals finally real dataset analyzed illustrative purposes â© â© taylor amp francis group llc
10.1016/j.jsv.2018.02.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044306993&doi=10.1016%2fj.jsv.2018.02.012&partnerID=40&md5=1fe3febd60782b76bbb52f6de737ca3e 0,novel approach presented work localize simultaneously multiple damaged elements structure along estimation damage severity damaged elements detection damaged elements best achievable eigenvector based formulation derived deal noisy data bayesian inference employed formulation wherein likelihood bayesian algorithm formed basis errors best achievable eigenvectors measured modes approach probable damage locations evaluated bayesian inference generating combinations various possible damaged elements damage locations identified damage severities estimated using bayesian inference markov chain monte carlo simulation efficiency proposed approach demonstrated carrying numerical study involving story shear building found study damage scenarios involving low loss stiffness multiple elements accurately determined localized severities quantified even noise contaminated modal data utilized study introduces term parameter impact evaluated based sensitivity modal parameters towards structural parameters decide suitability selecting particular mode idea damaged elements available demonstrated accuracy efficiency bayesian quantification algorithm increases damage localization carried priori experimental study involving laboratory scale shear building different stiffness modification scenarios shows proposed approach efficient enough localize stories stiffness modification â© elsevier ltd
10.1109/3DV.2017.00043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048769435&doi=10.1109%2f3DV.2017.00043&partnerID=40&md5=80ab2c0a825045b789b8fc635ddce4f0 0,address problem generating variations captured models automatically particularly focus dynamic human shapes observed multi view videos variation essential component motion realism however recent mesh animation datasets tools lack richness given models representing movements type method builds probabilistic low dimensional embedding shape poses using gaussian process dynamical models novel variants motions obtained sampling trajectories manifold using monte carlo markov chain synthesise unlimited number variations input movements also blended version without costly non linear interpolation input movement variations mesh domain output variations statistically similar input movements yet slightly different poses timings show results generated mesh sequences match training examples realism facilitates model dataset augmentation â© ieee
10.16339/j.cnki.hdxbzkb.2018.05.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052913846&doi=10.16339%2fj.cnki.hdxbzkb.2018.05.005&partnerID=40&md5=3c696b1566b004a50ae35835c285fb80 0,issue related multi model structural identification mm st id experimentally researched based sampling method bayesian theory concept basic framework mm st id method based bayesian theory introduced markov chain monte carlo simulation mcmc utilized build finite element fe model libraries since mcmc easy converge low calculation efficiency parameters high dimensions improved mcmc sampling method mm st id introduced matlab strand application programming interface api strategy used update parameters large structural fe model automatically calibrated fe model libraries established used predict responses based posterior probability distribution fe models order verify feasibility effectiveness proposed theory numerical example simply supported beam site large concrete steel tubular truss arch bridge st id investigated based bayesian theory response prediction simple model st id method genetic algorithm ga used comparison results showed proposed mm st id method based bayesian theory much better structural response prediction â© editorial department journal hunan university right reserved
10.1109/ISPA/IUCC.2017.00188 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048376574&doi=10.1109%2fISPA%2fIUCC.2017.00188&partnerID=40&md5=eb2d39509b79aead793b840806903be3 0,mrbayes popular bioinformatics software widely used phylogenetic analysis core algorithm mrbayes metropolis coupled markov chain monte carlo mc however dealing large data sets mc algorithm slow meet researcher requirements although several parallelizations proposed mrbayes mpi message passing interface based mrbayes gpu graphics processing unit based mrbayes still efficient parallel algorithm fully utilize computing power modern cpu computer architecture paper presents new three level hybrid parallel algorithm include data level parallelism dlp thread level parallelism tlp process level parallelism plp used modern multi core computers b compares performance different combinations parallel strategies real world protein data sets experimental results show hybrid parallel algorithm convert computing powers higher speedup furthermore proposed algorithm speedup near speedup one gpu data sets algorithm fit practical use phylogenetic inferences â© ieee
10.1080/00949655.2018.1442469 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042914584&doi=10.1080%2f00949655.2018.1442469&partnerID=40&md5=1fd31067546aa07363de1a066c64530f 0,combining multivariate probit models multivariate partially linear single index models propose new semiparametric latent variable models multivariate ordinal response data based reversible jump markov chain monte carlo technique develop fully bayesian method free knot splines analyse proposed models address problem ordinary gibbs sampler usually converges slowly make use partial collapse parameter expansion techniques algorithm proposed methodology demonstrated simulated real data examples â© informa uk limited trading taylor francis group
10.1109/EDUCON.2018.8363352 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048078626&doi=10.1109%2fEDUCON.2018.8363352&partnerID=40&md5=5f8a4c37e3a84ababfddd8b4f568d55d 0,estimating grades courses yet enrolled students help making decisions towards timely graduation achieving better overall results paper presents evaluation grade prediction future courses using model based collaborative filtering methods probabilistic matrix factorization bayesian probabilistic matrix factorization using markov chain monte carlo prediction model evaluated simulated scenario enrollment cycle winter summer semester based real data set enrollments grades several years authors institution several evaluation metrics used order assess accuracy predictions analyze distribution prediction deviation across study programs grades beside standard approach predicting final grade achieved student future course also devised method estimate student fail course enroll least results showed predicted grades range â± compared actual grades records â© ieee
10.1109/ATSIP.2018.8364492 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048493696&doi=10.1109%2fATSIP.2018.8364492&partnerID=40&md5=95073f0994977364113830ca1f016d2f 0,paper study estimation olive tree biophysical properties driven sentinel image inversion latter based forward backward radiative transfer model rtm forward step done simulating dart model realistic olive tree mock whereas backward done based coupling look table lut markov chain monte carlo mcmc parameters leaf area index lai chlorophyll cab water cw contents mesophyll structure n therefore derived soil reflectance pre calculated based upscaling resolution using planet images moreover obtain significant representation local heterogeneity upscaled resolution estimation results promising â© ieee
10.1007/s00500-018-3244-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047275326&doi=10.1007%2fs00500-018-3244-4&partnerID=40&md5=e257aac58471aa5b4334f999b689200d 0,goal constructing models examples approached different perspectives statistical methods widely used proved effective generating accurate models finite gaussian mixture models widely used describe wide variety random phenomena played prominent role many attempts develop expressive statistical models machine learning however effectiveness limited applications underlying modeling assumptions e g per components densities gaussian reasonably satisfied thus much research efforts devoted developing better alternatives paper focus constructing statistical models positive vectors e vectors whose elements strictly greater zero generalized inverted dirichlet gid mixture shown flexible powerful parametric framework particular propose bayesian density estimation method based upon mixtures gids consideration bayesian learning interesting several respects allows take uncertainty account introducing prior information parameters allows simultaneous parameters estimation model selection allows overcome learning problems related fitting indeed develop reversible jump markov chain monte carlo sampler gid mixtures apply simultaneous clustering feature selection context challenging real world applications concerning scene classification action recognition video forgery detection â© springer verlag gmbh germany part springer nature
10.1109/TCYB.2018.2831792 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047221211&doi=10.1109%2fTCYB.2018.2831792&partnerID=40&md5=b91f7b87b21ca91595a73931f1530403 0,paper unified bayesian max margin discriminant projection framework proposed able jointly learn discriminant feature space max margin classifier different relationships latent representations observations assume latent representation follows normal distribution whose sufficient statistics functions observations function flexibly realized either shallow deep structures shallow structure includes linear nonlinear kernel based functions even convolutional projection trained layerwisely build multilayered convolutional feature learning model take advantage deep neural networks especially highly expressive ability efficient parameter learning integrate bayesian modeling popular neural networks example mltilayer perceptron convolutional neural network build end end bayesian deep discriminant projection proposed framework degenerated existing shallow linear convolutional projection single layer structure moreover efficient scalable inferences realizations different functions derived handle large scale data via stochastic gradient markov chain monte carlo finally demonstrate effectiveness efficiency proposed models experiments real world data including four image benchmarks mnist cifar stl svhn one measured radar high resolution range profile dataset detailed analysis parameters computational complexity ieee
10.1080/02664763.2017.1367368 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028554674&doi=10.1080%2f02664763.2017.1367368&partnerID=40&md5=542073202bb5adb51ba6975eed392612 0,course hypertension cardiovascular disease events e g stroke heart failure occur frequently recurrently scientific interest study may lie estimation treatment effect accounting correlation among event times correlation among recurrent event times comes two sources subject specific heterogeneity e g varied lifestyles genetic variations unmeasurable effects event dependence e event incidences may change risk future recurrent events moreover event incidences may change disease progression may exist event varying covariate effects covariate effects may change event event effect effect prior events future events article propose bayesian regression model accommodates correlation among recurrent events sources also explicitly characterizes event varying covariate effects event effect model especially useful quantifying incidences events change effects covariates risk future events compare proposed model several commonly used recurrent event models apply model motivating lipid lowering trial llt component antihypertensive lipid lowering treatment prevent heart attack trial allhat allhat llt â© informa uk limited trading taylor francis group
10.3389/fphar.2018.00508 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047120193&doi=10.3389%2ffphar.2018.00508&partnerID=40&md5=c1ec565aa993ae42aca47fba0c15b476 0,computational workflow developed facilitate process quantitative vitro vivo extrapolation qivive specifically translation vitro concentration response vivo dose response relationships subsequent derivation benchmark dose value bmd workflow integrates physiologically based pharmacokinetic pbpk modeling global sensitivity analysis gsa approximate bayesian computation abc markov chain monte carlo mcmc simulation given set vitro concentration response data algorithm returns posterior distribution corresponding vivo population based dose response values given route exposure novel aspect workflow rigorous statistical framework accommodating uncertainty parameters pbpk model parameter uncertainty population variability structure pbpk model recognizing model approximation reality sources uncertainty propagate workflow quantified within posterior distribution vivo dose fixed representative vitro concentration demonstrate process comparative purposes similar exercise previously published work describing kinetics ethylene glycol monoethyl ether egme embryotoxic metabolite methoxyacetic acid maa rats undertaken computational algorithm used extrapolate vitro data organism including human ultimately process incorporated user friendly freely available modeling platform currently development simplify process qivive â© mcnally hogg loizou
10.1016/j.fuel.2018.02.018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041840308&doi=10.1016%2fj.fuel.2018.02.018&partnerID=40&md5=6829289d33127400a905b5d0ece6770a 1,embedding complex discrete fractures reservoir simulation required attain realistic flow behavior shale reservoirs however using local grid refinement model discrete fractures computationally expensive nevertheless recent developments methodology called embedded discrete fracture model edfm overcome computational complexity study develop efficient assisted history matching ahm workflow using proxy based markov chain monte carlo algorithm integrating edfm preprocessor workflow automatically perform history matching production forecasting uncertainty quantification successfully applied shale oil well vaca muerta formation â© elsevier ltd
10.1016/j.neuroimage.2018.01.047 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043311755&doi=10.1016%2fj.neuroimage.2018.01.047&partnerID=40&md5=4e1347b65956b04e4837a14e8c50998f 0,introduce new approach bayesian prf model estimation using markov chain monte carlo mcmc sampling simultaneous estimation prf hemodynamic parameters obtain high performance commonly accessible hardware present novel heuristic consisting interpolation precomputed responses predetermined stimuli large cross section receptive field parameters investigate validity proposed approach respect mcmc convergence tuning biases compare different combinations prf compressive spatial summation css dumoulin wandell dw hemodynamic parameter parameter balloon windkessel models within framework without usage new heuristic evaluate estimation consistency log probability across models perform well comparison one model without lookup table within rstan framework using u turn sampler present accelerated computation whole roi parameters one subject finally discuss risks limitations associated usage new heuristic well means resolving found new algorithm valid sampling approach joint prf hemodynamic parameter estimation exhibits high performance â©
10.1088/1742-6596/1022/1/012002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048137361&doi=10.1088%2f1742-6596%2f1022%2f1%2f012002&partnerID=40&md5=d23102cbd29bc6b01723dee0e7d5f7ca 0,bayesian method method used estimate parameters multivariate multiple regression model bayesian method two distributions prior posterior distributions posterior distribution influenced selection prior distribution jeffreys prior distribution kind non informative prior distribution prior used information parameter available non informative jeffreys prior distribution combined sample information resulting posterior distribution posterior distribution used estimate parameter purposes research estimate parameters multivariate regression model using bayesian method non informative jeffreys prior distribution based results discussion parameter estimation î² î obtained expected value random variable marginal posterior distribution function marginal posterior distributions î² î multivariate normal inverse wishart however calculation expected value involving integral function difficult determine value therefore approach needed generating random samples according posterior distribution characteristics parameter using markov chain monte carlo mcmc gibbs sampling algorithm â© published licence iop publishing ltd
10.1103/PhysRevD.97.103020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048087811&doi=10.1103%2fPhysRevD.97.103020&partnerID=40&md5=712d5d32627c30249d0a5b49878286f5 2,leveraging markov chain monte carlo optimization f statistic introduce method hierarchical follow continuous gravitational wave candidates identified wide parameter space semicoherent searches demonstrate parameter estimation continuous wave sources develop framework tools understand control effective size parameter space critical success method monte carlo tests simulated signals noise demonstrate method close theoretical optimal performance â© american physical society
10.1145/3200921.3200934 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048424778&doi=10.1145%2f3200921.3200934&partnerID=40&md5=298a5da2f2a931d6f46f18fcc5edbf43 0,markov models long tradition modeling simulation dynamic systems paper look certain properties discrete time markov chain including entropy trace nd largest eigenvalue better understand role time series analysis simulate number possible input signals fit discrete time markov chain explore properties help sobol indices research motivated recent results analysis cell development xenopus laevis cell biology relied considered entropy measure distinguish development stages time series data calcium levels cells â© copyright held owner author
10.1002/sim.7613 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042193224&doi=10.1002%2fsim.7613&partnerID=40&md5=2bf6e4a7607a499b68c7d8cc2a5b465d 0,juvenile dermatomyositis jdm rare autoimmune disease may lead serious complications even death develop state markov regression model bayesian framework characterise disease progression jdm time gain better understanding factors influencing disease risk transition probabilities disease remission state vice versa function time homogeneous time varying covariates latter types covariates introduced model latent health state function describes patient specific health time accounts variability among patients assume nonparametric prior based dirichlet process model health state function baseline transition intensities disease remission state vice versa dirichlet process induces clustering patients homogeneous risk groups highlight clinical variables affect transition probabilities perform variable selection using spike slab prior distributions posterior inference performed markov chain monte carlo methods data made available uk jdm cohort biomarker study repository hosted ucl institute child health copyright â© john wiley sons ltd
10.3390/w10050621 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046880180&doi=10.3390%2fw10050621&partnerID=40&md5=3c2f83bae86f57ae23717dcca93c2ca3 0,widely used partly deterministic soil andwater assessment tool swat requires large amount spatial input data digital elevation model dem land use soil maps modelers make effort apply specific data possible study area reflect heterogeneous characteristics landscapes regional data especially fine resolution often preferred however data always available computationally demanding despite coarser global data usually free available public previous studies revealed importance single investigations different input maps however remains unknown whether higher resolution data lead reliable results study investigates global regional input datasets affect parameter uncertainty estimating river discharges analyze eight different setups swat model catchment luxembourg combining different land use elevation soil input data metropolis hasting markov chain monte carlo mcmc algorithm used infer posterior model parameter uncertainty conclude higher resolved dem improves general model performance reproducing low flows less detailed soil map improved fit low flows addition detailed land use maps reduce bias model discharge simulations also despite presenting similar parameter uncertainty p factor ranging r factor setups results show disparate parameter posterior distribution indicates assessment sources uncertainty simultaneously compensated fitted parameter values conclude result give guidance future swat applications selection degree detail input data â© authors
10.1002/sim.7612 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041606986&doi=10.1002%2fsim.7612&partnerID=40&md5=292e9a062c4865685cf0a9f93ee31a1e 0,researchers collected multiple measurements patients schizophrenia relatives well control subjects relatives study vulnerability factors schizophrenics near relatives observations across individuals family correlated also multiple outcome measures individuals correlated traditional data analyses model outcomes separately thus provide information interrelationships among outcomes propose novel bayesian family factor model bffm extends classical confirmatory factor analysis model explain correlations among observed variables using combination family member outcome factors traditional methods fitting confirmatory factor analysis models full information maximum likelihood fiml estimation using quasi newton optimization qno convergence problems heywood cases lack convergence caused empirical underidentification contrast modern bayesian markov chain monte carlo handles inference problems easily simulations compare bffm fiml qno settings true covariance matrix identified close identified identified settings fiml qno fails fit data cases respectively mcmc provides stable estimates methods successfully fit data estimates bffm smaller variances comparable mean squared errors illustrate bffm analyzing data data schizophrenics family members copyright â© john wiley sons ltd
10.1088/1681-7575/aabd57 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048238027&doi=10.1088%2f1681-7575%2faabd57&partnerID=40&md5=b7129b7adc9dc3a95d569c4f605b8619 0,bayesian statistical procedure proposed value assignment uncertainty evaluation mass fraction elemental analytes single element solutions distributed nist standard reference materials principal novelty describe use information relative differences observed historically measured values obtained via gravimetry via high performance inductively coupled plasma optical emission spectrometry quantify uncertainty component attributable method differences information encapsulated prior probability distribution method uncertainty component used together information provided current measurement data produce probability distribution value measurand estimate evaluation uncertainty extracted using established statistical procedures â© subject copyright usa contribution nist
10.1021/acs.biochem.7b01264 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046621838&doi=10.1021%2facs.biochem.7b01264&partnerID=40&md5=a5a82f388f8fc6fa14ae9ff5735ef209 0,describe pytc open source python package global fits thermodynamic models multiple isothermal titration calorimetry experiments key features include simplicity ability implement new thermodynamic models robust maximum likelihood fitter fast bayesian markov chain monte carlo sampler rigorous implementation extensive documentation full cross platform compatibility pytc fitting done using application program interface via graphical user interface available download https github com harmslab pytc â© copyright american chemical society
10.1080/10705511.2017.1406803 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039160037&doi=10.1080%2f10705511.2017.1406803&partnerID=40&md5=997d7e51baf0f3745064561ad13adec9 6,article presents dynamic structural equation modeling dsem used study evolution observed latent variables well structural equation models time dsem suitable analyzing intensive longitudinal data observations multiple individuals collected many points time modeling framework encompasses previously published dsem models comprehensive attempt combine time series modeling structural equation modeling dsem estimated bayesian methods using markov chain monte carlo gibbs sampler metropolisâ€“hastings sampler provide detailed description estimation algorithm implemented mplus software package dsem used longitudinal analysis duration number observations across time simulation studies used illustrate framework study performance estimation method methods evaluating model fit also discussed copyright â© taylor francis group llc
10.1080/00273171.2018.1428892 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041819812&doi=10.1080%2f00273171.2018.1428892&partnerID=40&md5=e454fd175be268bbc3214105597c7be9 1,article guide bayesian computation using gibbs sampling demonstrated context latent class analysis lca written students quantitative psychology related fields working knowledge bayes theorem conditional probability experience writing computer programs statistical language r overall goals provide accessible self contained tutorial along practical computation tool begin bayesian computation typically described academic articles technical difficulties addressed hypothetical worked example show bayesian computation broken series simpler calculations assembled together complete computationally complex model details described much explicitly typically available elementary introductions bayesian modeling readers overwhelmed mathematics moreover provided computer program shows bayesian lca implemented relative ease computer program applied large real world data set explained line line outline general steps extend considerations methodological applications conclude suggestions readings â© taylor francis group llc
10.1109/ICCChinaW.2017.8355278 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049621172&doi=10.1109%2fICCChinaW.2017.8355278&partnerID=40&md5=6354152a8039ba84cb1fdd8643b7949d 0,one popular iot system characterized bursty traffic transmission occurrence lower milliseconds multiple hours traditional monte carlo behavioral simulation time consuming usual iot system traffic burst significantly smaller hibernation time number terminals big alternatives analytical approaches using random probability stochastic process theory numerous papers slotted aloha aloha system unfortunately almost results obtained far based full buffer traffic model efficient approach evaluate system performance iot system supporting massive number terminals bursty traffic patterns two analytic methodologies proposed studied paper bursty traffic pattern contention based access system employing aloha access binary exponential back beb set closed form formulae derived first method based probability modeling second method markov chain based analytical model fundamental parameter methods expression packet transmission probability close form expressions derived methods verified two expressions agree well based packet transmission probability close form expressions system performance indicators also derived includes packet loss rate transmission time transmission delay transmission times collision possibility channel utilization efficiency proposed methods verified match real system performance well efficient accurate analytical tools iot system performance evaluation optimization supporting bursty traffic â© ieee
10.1088/1361-6420/aabce7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047256837&doi=10.1088%2f1361-6420%2faabce7&partnerID=40&md5=63a88b5e2872a798e706e450443e77e0 0,study rely bayesian approach estimate seismic velocity first arrival travel times advantage bayesian approach compared linearized ones ability properly quantify uncertainties associated solution however approach remains fairly expensive markov chain monte carlo algorithms used sample posterior distribution efficient number parameters remains within reason therefore first step toward efficient implementation bayesian approach properly parameterize model reduce dimensionality article introduce new parsimonious parameterizations enable us accurately reproduce wave velocity field associated uncertainties first parametric model propose uses random johnson mehl tessellation generalization voronoi tessellation main difference johnson mehl model compared voronoi model shapes generated cells much general cells voronoi tessellation indeed convex polytopes johnson mehl tessellation model yields cells whose boundaries portions hyperboles necessarily convex hence allowing greater variety shapes demonstrate gain efficiency better convergence compared voronoi model second parameterization uses gaussian kernels basis functions purpose provide way reproduce localized variations seismic velocity field first illustrate tomography results synthetic velocity model contains two small anomalies apply methodology advanced realistic synthetic model serves benchmark oil industry finally present example gaussian kernels outperform voronoi johnson mehl models tomography results reveal ability algorithm map velocity heterogeneities accurately using parameters â© iop publishing ltd
10.1080/02331888.2018.1435661 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041902812&doi=10.1080%2f02331888.2018.1435661&partnerID=40&md5=bac6da770fe11b7a151ae843600ba1fe 0,attempt produce realistic stressâ€“strength models article considers estimation stressâ€“strength reliability multi component system non identical component strengths based upper record values family kumaraswamy generalized distributions maximum likelihood estimator reliability asymptotic distribution asymptotic confidence intervals constructed bayes estimates symmetric squared error loss function using conjugate prior distributions computed corresponding highest probability density credible intervals also constructed bayesian estimation lindley approximation markov chain monte carlo method employed due lack explicit forms first time using records uniformly minimum variance unbiased estimator closed form bayes estimator using conjugate non informative priors derived common known shape parameter stress strength variates distributions comparisons performance estimators carried using monte carlo simulations mean squared error bias coverage probabilities finally demonstration presented proposed model may utilized materials science engineering analysis high strength steel fatigue life data â© informa uk limited trading taylor francis group
10.1109/AsianHOST.2017.8353992 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050941131&doi=10.1109%2fAsianHOST.2017.8353992&partnerID=40&md5=d11e6c31f1baedef38d3e2ea18456340 0,true random number generators trngs pivotal cryptography markov chain monte carlo analysis neural network simulation industrial testing gambling etc deterministic pseudo random number sequences inadequate produce satisfactory results demand fast low power trng growing sophisticated applications increasingly moving mobile paper presents energy efficient chip trng design random digital bits extracted jitter noise two free running current starved ring oscillators ros current starved ros exhibit larger jitter noise regular inverter based ros jitter boosted lowering oscillation frequency drain current transistors ros addition jitter source ros power hungry components conventional oscillator based trngs biased subthreshold region proposed design reduce power consumption simulation results based nm v cmos technology show proposed trng consumes î¼w throughput rate mbps outperforms state art chip trngs figure merit pj bit generated bit sequence passes fifteen randomness tests national institute standards technology nist statistical test suite â© ieee
10.1061/(ASCE)HE.1943-5584.0001646 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043505631&doi=10.1061%2f%28ASCE%29HE.1943-5584.0001646&partnerID=40&md5=0fb1e0ce19d57759650463f22a97d0aa 1,imperative cities develop sustainable water management planning strategies order best serve urban communities currently facing increasing population water demand water resources managers often chastened experiencing failures attributed natural extreme droughts floods however recent changes water management systems responding uncertain conditions water managers become thoughtful adverse effects uncertain extreme events performance water supply systems natural hydrologic variability inherent uncertainties associated future climate variations make simulation management water supplies greater challenge hydrologic simulation process one main components integrated water resources management hydrologic simulations incorporate uncertain input values model parameters model structure therefore stochastic streamflow simulation prediction consideration uncertainty propagation performance water supply systems wsss essential phases efficient management systems proposed integrated framework study models wss taking account dynamic nature system utilizing markov chain monte carlo mcmc algorithm capture uncertainties associated hydrologic simulation hydrologic responses results rainfall runoff model three watersheds karaj latyan lar tehran iran case study used inputs reservoirs results confirm uncertainties associated hydrologic model parameters propagate simulation lead wide variation reservoir storage wss performance metrics vulnerability reliability example water storage simulation karaj reservoir vary compared observed values causes contradiction conflict management reservoirs water systems decision making results emphasize importance analyzing wss performance uncertain conditions improve simulation natural processes support water managers efficient decision making process â© american society civil engineers
10.1177/1475921717717106 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042227761&doi=10.1177%2f1475921717717106&partnerID=40&md5=76e2aadeadd55292f7aafb5659e5d5bb 1,article reports development bayesian method assessing damage status railway ballast concrete sleeper based vibration data situ sleeper one important contributions proposed method describe variation stiffness distribution ballast using lagrange polynomial order polynomial decided bayesian approach probability various orders polynomial conditional given set measured vibration data calculated order polynomial highest probability selected plausible order used updating ballast stiffness distribution due uncertain nature railway ballast corresponding model updating problem usually unidentifiable ensure applicability proposed method even unidentifiable cases computational efficient markov chain monte carloâ€“based bayesian method employed proposed method generating set samples important region parameter space approximate posterior updated probability density function ballast stiffness proposed ballast damage detection method verified roving hammer test data segment full scale ballasted track experimental verification results positively show potential proposed method ballast damage detection â© â© author
10.1007/s11222-017-9743-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016124939&doi=10.1007%2fs11222-017-9743-9&partnerID=40&md5=951c8c86163c5c03fa54cf4bf9813c7f 0,new bayesian state parameter learning algorithm multiple target tracking models image observations proposed specifically markov chain monte carlo algorithm designed sample posterior distribution unknown time varying number targets birth death times states well model parameters constitutes complete solution specific tracking problem consider conventional approach pre process images extract point observations perform tracking e infer target trajectories model image generation process directly avoid potential loss information extracting point observations using pre processing step decoupled inference algorithm numerical examples show algorithm improved tracking performance commonly used techniques synthetic examples real florescent microscopy data especially case dim targets overlapping illuminated regions â© springer science+business media new york
10.1190/geo2017-0387.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045062368&doi=10.1190%2fgeo2017-0387.1&partnerID=40&md5=c55caed807bab8f2efe3124aad144645 2,evaluated two step bayesian algorithm seismic reservoir characterization thanks simplifying assumptions computationally efficient applicability reliability method assessed comparison sophisticated computer intensive markov chain monte carlo mcmc algorithm single loop directly estimates petrophysical properties lithofluid facies prestack data two step method first combines linear rock physics model rpm analytical solution linearized amplitude versus angle ava inversion directly estimate petrophysical properties related uncertainties prestack data assumptions gaussian prior model weak elastic contrasts reflecting interface particular use empirical linear rpm properly calibrated investigated area reparameterize linear time continuous p wave reflectivity equation terms petrophysical contrasts instead elastic constants second step downward markov chain prior model used infer lithofluid classes outcomes first step single loop sl mcmc algorithm uses convolutional forward modeling based exact zoeppritz equations adopts nonlinear rpm moreover assumes realistic gaussian mixture distribution petrophysical properties approaches applied onshore seismic data set characterization gas bearing clastic reservoir notwithstanding differences forward model parameterization considered rpm assumed priori probability density functions two methods yield maximum posteriori solutions consistent well log data although gaussian mixture assumption adopted sl method slightly improves description multimodal behavior petrophysical parameters however considered reservoir main difference two approaches remains different computational times sl method much computationally intensive two step approach â© society exploration geophysicists
10.3847/1538-4365/aab76e https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047256754&doi=10.3847%2f1538-4365%2faab76e&partnerID=40&md5=02fd8f949d6ad0b48ca2052fd49d77e3 3,markov chain monte carlo mcmc methods sampling probability density functions combined abundant computational resources transformed sciences especially performing probabilistic inferences fitting models data primarily pedagogical contribution give brief overview basic mcmc method practical advice use mcmc real inference problems give advice method choice tuning performance methods initialization tests convergence troubleshooting use chain output produce report parameter estimates associated uncertainties argue autocorrelation time important test convergence directly connects uncertainty sampling estimate quantity interest emphasize sampling method integrals guides thinking mcmc output best used â© american astronomical society
10.1109/TPWRS.2017.2757980 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030776418&doi=10.1109%2fTPWRS.2017.2757980&partnerID=40&md5=0e3a9df3ca5960a2a6fe25e81a5a1bf9 0,increased competition wholesale electricity markets need new decision making tools strategic producers arisen optimal bidding strategies traditionally modeled stochastic profit maximization problems however producers non negligible market power modeling interactions rival participants fundamental achieved equilibrium hierarchical optimization models efficiency methods relies strategic producer ability model rival participants behavior supply curve substantial gap remains literature modeling uncertainty study introduce bayesian inference approach reveal aggregate supply curve day ahead electricity market proposed algorithm relies markov chain monte carlo sequential monte carlo methods major appeal approach provides complete model uncertainty aggregate supply curve estimate posterior distribution show small case study able reveal accurately aggregate supply curve prior information rival participants finally show piece information used price maker producer order devise optimal bidding strategy â© ieee
10.1098/rspa.2017.0700 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047566297&doi=10.1098%2frspa.2017.0700&partnerID=40&md5=e70428a3f77c2e1d68a302364f6b6ef1 0,building mathematical computer models cities long history core elements models flows spatial interaction dynamics structural evolution article develop stochastic model urban structure formally account uncertainty arising less predictable events standard practice calibrate spatial interaction models independently explore dynamics simulation present two significant results transformative elements first represent structural variables single potential function develop stochastic differential equations model evolution second show parameters spatial interaction model estimated structure alone independently flow data using bayesian inferential framework posterior distribution doubly intractable poses significant computational challenges overcome using markov chain monte carlo methods demonstrate methodology case study london uk retail system â© author published royal society rights reserved
10.1109/LSP.2018.2822550 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044725237&doi=10.1109%2fLSP.2018.2822550&partnerID=40&md5=ee2902bd7e322b92c2c5899010b0ea08 0,parallel factor analysis parafac one popular tensor factorization models even though proven successful diverse application fields performance parafac usually hinges rank factorization typically specified manually practitioner study develop novel parallel distributed bayesian model selection technique rank estimation large scale parafac models proposed approach integrates ideas emerging field stochastic gradient markov chain monte carlo statistical physics distributed stochastic optimization opposed existing methods based heuristics method clear mathematical interpretation significantly lower computational requirements thanks data subsampling parallelization provide formal theoretical analysis bias induced proposed approach experiments synthetic large scale real datasets show method able find optimal model order significantly faster state art â© ieee
10.1109/TPS.2018.2795084 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041858477&doi=10.1109%2fTPS.2018.2795084&partnerID=40&md5=16891f22296e0f0c8b713514a975eb25 0,joint deformation contributes significantly final end effector displacement manipulator especially manipulator form serial kinematics long links manipulators employed demo heavy payload deformation manipulator inevitable magnitude significant order maneuver large object several via points high positioning accuracy remote handling process demo real time computation manipulator deformation conducted crucial demo adaptive position control system displacement compensation three computation effective deformation modeling methods proposed paper parametric modeling method nonparametric deterministic artificial neural network ann modeling method nonparametric bayesian ann modeling method respectively specific joint boom equipped telescopic articulated remote mast taken study object paper nodal deformation joint investigated three modeling methods respectively parametric deformation model derived using structural mechanics whose parameters identified using markov chain monte carlo mcmc method deformation model deterministic ann trained using levenberg marquardt method deformation model bayesian ann trained using mcmc method results show parametric model structural mechanics linear incompetent deformation modeling nonlinearity presents deterministic bayesian anns capable model nodal deformation joint performance deterministic network bayesian network rival one another application scenario paper training bayesian network provide criterions estimation possible ranges modeling outputs probabilistic distribution curves judgment proper size network â© ieee
10.1029/2017GC007399 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047391965&doi=10.1029%2f2017GC007399&partnerID=40&md5=244adcde3c4c9adfb55e6b8d9458fdaa 0,seismic wave velocities offer essential constraints temperature thickness composition lithosphere cratons invert broadband rayleigh wave phase love wave phase velocities measured across kaapvaal craton limpopo belt depth distributions shear wave velocity radial anisotropy upper crust deep upper mantle probabilistic bayesian inversion addresses model nonuniqueness means direct parameter space sampling increase vs moho â€“ km depths occurs across region explained gradual emergence garnet km due spinel peridotite garnet peridotite transformation due exsolution garnet mantle orthopyroxene lateral variations vs gradient provide new information lateral compositional variations cold cratonic lithosphere manifest high shear velocities km depth extent shear velocity anomaly inferred lithospheric thickness increase âˆ¼ km beneath central southwestern kaapvaal âˆ¼ km beneath limpopo belt curiously surface elevation decreases monotonically increasing lithospheric thickness relationship lithospheric thickness topography depends lithospheric composition crustal structure taken account results imply bottom part limpopo lithosphere â€“ km weakly moderately depleted mg â€“ results also show central southwestern kaapvaal lithosphere thinner according kimberlites â€“ ago may thinned mantle plume initially triggered kimberlite eruptions â© american geophysical union rights reserved
10.1016/j.trc.2018.02.019 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043239879&doi=10.1016%2fj.trc.2018.02.019&partnerID=40&md5=7c737585140d0bebcee227c083626fe9 2,railway big data technologies transforming existing track inspection maintenance policy deployed railroads north america paper develops data driven condition based policy inspection maintenance track geometry preventive maintenance spot corrective maintenance taken account investigation month inspection dataset contains variety geometry measurements every foot track first study separates data based time interval inspection run calculates aggregate track quality index tqi track section predicts track spot geo defect occurrence probability using random forests markov chain built model aggregated track deterioration spot geo defects modeled bernoulli process finally markov decision process mdp developed track maintenance decision making optimized using value iteration algorithm compared existing maintenance policy using markov chain monte carlo mcmc simulation maintenance policy developed paper results approximately savings total maintenance costs every mile track â© elsevier ltd
10.3788/OPE.20182605.1201 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052688805&doi=10.3788%2fOPE.20182605.1201&partnerID=40&md5=82619df2ff9ef0c9905a65897ce24a83 0,order realize arbitrary shape object extraction lidar point cloud data method based irregular marked point process proposed firstly random point process defined ground plan random point positioned object projection plan marks associating individual points defined set nodes depict shape object ground plan assumed elevation values ground points followed independent identical gauss distribution objects also characterized gauss distributions individually according bayesian inference object extraction model obtained rjmcmc algorithm designed simulate posterior distribution estimate parameters finally optimal target extraction model obtained according maximum posteriori lidar point cloud data extracted using proposed method according experimental results seen detection accuracy algorithm highest accuracy paper traditional rule mark process extended irregular marking process used fit geometry arbitrary shape target effectively experimental results show method effectively fit arbitrary shape objects â© science press right reserved
10.14358/PERS.84.5.279 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047411307&doi=10.14358%2fPERS.84.5.279&partnerID=40&md5=486ee07fe8c31838440e2ed59eda8476 0,estimation land cover fractions remote sensing images frequently used indicator environmental quality paper focuses quantification land cover fractions urban area berlin germany using simulated hyperspectral enmap data spatial resolution ã— use constrained sparse representation pixel unknown surface characteristics expressed weighted linear combination elementary spectra known land cover class automatically determine elementary spectra image reference data using archetypal analysis simplex volume maximization combine reversible jump markov chain monte carlo method experiments estimation automatically derived elementary spectra compared estimation obtained manually designed spectral library means reconstruction error mean absolute error fraction estimates sum fractions r number used elementary spectra experiments show collection archetypes adequate efficient alternative manually designed spectral library respect mentioned criteria â© american society photogrammetry remote sensing
10.1016/j.ijmedinf.2018.02.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043290149&doi=10.1016%2fj.ijmedinf.2018.02.004&partnerID=40&md5=6966940a89cad569500476a9b4455b2e 0,background telephone nursing first line contact many care seekers aims optimizing performance healthcare system supporting guiding patients correct level care reduce amount unscheduled visits good statistical models describe effects telephone nursing important order study impact healthcare resources evaluate changes telephone nursing procedures objective develop valid model captures complex relationships nurse recommendations patientsâ€™ intended actions patientsâ€™ health seeking behavior using model estimate effects telephone nursing patient behavior healthcare utilization infer potential cost savings methods bayesian ordinal regression modeling data randomly selected patients received telephone nursing inference based markov chain monte carlo mcmc methods model selection using watanabeâ€“akaike information criteria waic model validation using posterior predictive checks standard discrepancy measures results conclusions present robust bayesian ordinal regression model predicts three quarters patientsâ€™ healthcare utilization telephone nursing found evidence model deficiencies patient compliance nurse recommendation varies depends recommended level care agreement level patient prior intention availability different care options time model reveals risk reducing behavior among patients effect telephone nursing recommendation times higher effect patient intended action prior consultation recommendation highest level care effect nurse recommendation lower even non existing recommendation self care telephone nursing found constricting effect healthcare utilization however compliance nurse recommendation closely tied perceptions risk emphasizing importance address caller needs reassurance â© elsevier b v
10.11908/j.issn.0253-374x.2018.05.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051075198&doi=10.11908%2fj.issn.0253-374x.2018.05.014&partnerID=40&md5=30c5e09f3e81b85872c79f7e7cadcd1d 0,based random parameter mixed logit model discrete choice model customer preference heterogeneity established hierarchy auto body product according sampled data obtained sp stated preference survey parameter prior distribution setting markov chain monte carlo simulation method used make bayesian estimation parameters finally mcfadden likelihood ratio test proves random parameter mixed logit model optimal goodness fit better others elucidate customer preference heterogeneity rooted modeling approach helps capture personalized customer needs helps manufacturers anticipate mutiple preferences potential customers assists design development auto body products â© editorial department journal tongji university right reserved
10.1016/j.automatica.2018.01.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041514402&doi=10.1016%2fj.automatica.2018.01.011&partnerID=40&md5=e76290780ea2cc6677f370cad811693c 2,present new method identifying specific module dynamic network possibly feedback loops assuming known topology express dynamics acyclic network composed two blocks first block accounts relation known reference signals input target module second block contains target module using empirical bayes approach model first block gaussian vector covariance matrix kernel given recently introduced stable spline kernel parameters target module estimated solving marginal likelihood problem novel iterative scheme based expectationâ€“maximization algorithm additionally extend method include additional measurements downstream target module using markov chain monte carlo techniques shown iterative scheme solve also formulation numerical experiments illustrate effectiveness proposed methods â© elsevier ltd
10.1109/TCST.2017.2692723 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019905138&doi=10.1109%2fTCST.2017.2692723&partnerID=40&md5=bde2ecf6649047ad234d755aab2fe4d7 0,paper develops compares two stochastic strategies manage glider flight dynamic environment tackle open problem concerning necessity applicability complexity validity using environment model making flight management decisions strategy performance compared two surveillance pursuit tasks require optimal control maximization expected range maintaining altitude within given limits maximization expected range following moving ground vehicle within prescribed distance maintaining altitude within given limits tasks involve flight management decisions glider airspeed time spend climbing randomly encountered thermal first strategy stochastic drift counteraction optimal control sdcoc dynamic programming method relies model sdcoc uses computationally inexpensive yet accurate environment model reflects transition probabilities updrafts downdrafts well thermal locations strengths based existing glider flight data second strategy selective evolutionary generation model free markov chain monte carlo method subject curse dimensionality efficiently searches optimal control online tunable fashion easily adapts dynamic environment however strategy requires tolerance learning decision space exploration strategies perform satisfactorily showcase environment decision space exploitation exploration tradeoff â© ieee
83.01112250057085 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047533341&partnerID=40&md5=1e819d9b2baab844f528f0018c6ca883 0,recent progress increased understanding key controls productivity shale reservoirs quantitative relations regional eagle ford shale production trends geologic parameters investigated clarify geologic parameters exercise dominant control well production rates previously qualitative correlations eagle ford shale demonstrated among depth thickness total organic carbon toc distribution limestone beds average bed thickness regional production eagle ford production wells horizontal necessary use vertical wells penetrated eagle ford map reservoir properties wells database production geological parameters thus geological parameters directly related individual well production therefore spatial interpolation methods derived kriging bayesian methods markov chain monte carlo mcmc sampling algorithms used integrate data sets predict geological properties production well locations spatial gaussianprocess regression modeling conducted investigate primary controls production results suggest month cumulative production eagle ford shale barrels oil equivalent boe increases consistently depth eagle ford thickness ft thickness toc also number limestone beds exceeds production increases number limestone beds corresponding significance code indicates parameters significant production toc depth relates pressure thermal maturation concepts models developed study may assist operators making critical eagle ford shale development decisions transferable shale plays copyright â© society petroleum engineers
10.1002/ecy.2189 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044341861&doi=10.1002%2fecy.2189&partnerID=40&md5=d2ec2f68aa6342bf55fdf065c2fe4e58 1,metapopulation ecology landscape ecology aim understand spatial structure influences ecological processes yet disciplines address problem using fundamentally different modeling approaches metapopulation models describe spatial distribution patches affects colonization extinction often account heterogeneity landscape patches models landscape ecology use detailed descriptions landscape structure often without considering colonization extinction dynamics present novel spatially explicit modeling framework narrowing divide disciplines advance understanding effects landscape structure metapopulation dynamics unlike previous efforts framework allows statistical inference landscape resistance colonization using empirical data demonstrate approach using â yr data threatened amphibian desert ecosystem occupancy data lithobates chiricahuensis chiricahua leopard frog collected buenos aires national wildlife refuge banwr arizona usa following reintroduction results indicated colonization dynamics influenced patch characteristics landscape structure landscape resistance increased increasing elevation distance nearest streambed colonization rate also influenced patch quality semi permanent permanent ponds contributing substantially colonization neighboring ponds relative intermittent ponds ponds hold water intermittently also highest extinction rate modeling framework widely applied understand metapopulation dynamics complex landscapes particularly systems environment habitat patches influences colonization process â© ecological society america
10.1016/j.ijpvp.2018.01.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042733710&doi=10.1016%2fj.ijpvp.2018.01.004&partnerID=40&md5=b9a23ab0530d723d8ed751779dc5fb82 0,novel approach reliability assessment aging gas pipeline systems based bayesian network methodology proposed paper focus improvement pipeline strength prediction multimodal diagnosis performed assessing variation mechanical property e g yield strength within pipe terms material property measurements microstructure composition hardness multimodality measurements integrated bayesian network information fusion model prototype testing carried model verification validation demonstration model updating scheme employs markov chain monte carlo algorithm infer posterior distribution pipe strength using multimodality measurements whereas priors derived literature knowledge systems moreover thickness studies pipe cross sections performed demonstrate mechanical property variation surface bulk finally data training model employed obtain accurate measure probabilistic pipe strength discussions observations future work provided â© elsevier ltd
10.1007/s11432-016-9070-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028950675&doi=10.1007%2fs11432-016-9070-4&partnerID=40&md5=e5e14bf91ef5b21c65acf612720e99a4 1,characterizing understanding structure evolution networks important problem many different fields real world networks especially spatial networks influence one node another tends vary space time due different space distances propagation speeds nodes thus time lag plays essential role interpreting temporal causal dependency among nodes also brings big challenge network structure learning however previous researches aiming learn dynamic network structure treat time lag predefined constant may miss important information include noisy information time lag set small large paper propose dynamic bayesian model adaptive lags dbal simultaneously integrates two usually separate tasks e learning dynamic dependency network structure estimating time lags within one unified framework specifically propose novel weight kernel approach time series segmenting sampling via leveraging samples adjacent segments avoid sample scarcity besides effective bayesian scheme cooperated reversible jump markov chain monte carlo rjmcmc expectation propagation ep algorithm proposed parameter inference extensive empirical evaluations conducted synthetic two real world datasets results demonstrate proposed model superior traditional methods learning network structure temporal dependency â© science china press springer verlag gmbh germany
10.1016/j.ymssp.2017.10.033 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032792122&doi=10.1016%2fj.ymssp.2017.10.033&partnerID=40&md5=43a343ecf652987eb0456039fb354b38 1,probabilistic modeling provides capability represent manipulate uncertainty data models predictions decisions concerned problem learning probabilistic models dynamical systems measured data specifically consider learning probabilistic nonlinear state space models closed form solution available problem implying forced use approximations tutorial provide self contained introduction one state art methodsâ€”the particle metropolis hastings algorithmâ€”which proven offer practical approximation monte carlo based method particle filter used guide markov chain monte carlo method parameter space one key merits particle metropolis hastings algorithm guaranteed converge â€œtrue solutionâ€� mild assumptions despite based particle filter finite number particles also provide motivating numerical example illustrating method using modeling language tailored sequential monte carlo methods intention modeling languages kind open power sophisticated monte carlo methodsâ€”including particle metropolis hastingsâ€”to large group users without requiring know underlying mathematical details â© elsevier ltd
10.18576/amis/120310 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047100150&doi=10.18576%2famis%2f120310&partnerID=40&md5=a0a05bf1456e439dbb547774f4992991 0,article based progressively type ii censored schemes step stress partially accelerated life test model maximum likelihood bayes two parametric bootstrap methods used estimating unknown parameters kumaraswamy inverse weibull distribution acceleration factor asymptotic confidence interval estimates model parameters acceleration factor also evaluated using fisher information matrix classical bayes estimators obtained explicit form markov chain monte carlo method used tackle problem allows us construct credible interval involved parameters finally analysis simulated data set also presented illustrative purposes â© nsp natural sciences publishing cor
10.1111/bmsp.12114 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028842025&doi=10.1111%2fbmsp.12114&partnerID=40&md5=aa6d1c5fa3ca248041a5b2f0e3885051 4,provide refined diagnostic feedback collateral information item response times rts study proposed joint modelling attributes response speed using item responses rts simultaneously cognitive diagnosis illustration extended deterministic input noisy â€˜andâ€™ gate dina model proposed joint modelling responses rts model parameter estimation explored using bayesian markov chain monte carlo mcmc method pisa computer based mathematics data analysed first real data estimates treated true values subsequent simulation study follow simulation study ideal testing conditions conducted well evaluate model parameter recovery results indicated model parameters well recovered using mcmc approach incorporating rts dina model improve attribute profile correct classification rates result accurate precise estimation model parameters â© british psychological society
502.33166864975476 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048634346&partnerID=40&md5=2e1d6f95652d8006c0c520b5a66f90e3 0,objective compare effect different approaches missing data replacement regression coefficient estimates r length stay hospital expenditure methods data extracted medical records patients head neck neoplasms admitted sichuan cancer hospital r used generating processing simulated datasets various scenarios established setting different proportions missing data missing mechanisms using monte carlo method three strategies tested replacing missing data complete case method expectation maximization em markov chain monte carlo method mcmc regression coefficient estimates r standardized length stay standardized logarithmic hospital expenditure calculated using strategies compared original complete dataset terms accuracy magnitude differences r precision differences standard error r results three replacement methods acceptable within limit reâ± se missing data generated using mar mechanism less data simulated missing using mcar mar mechanism em method best estimation precision conclusion missing data replacement consider proportion missing data potential mechanisms involved â© sichuan university rights reserved
10.12989/sss.2018.21.5.601 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049567661&doi=10.12989%2fsss.2018.21.5.601&partnerID=40&md5=0f35e463797d996ae7eebb2dbe73240d 0,estimated probabilistic model wind data based conventional approach may high discrepancy compared true distribution uncertainty caused instrument error limited monitoring data sequential quadratic programming sqp algorithm based finite mixture modeling method developed companion paper conducted formulate joint probability density function pdf wind speed direction using wind monitoring data investigated bridge established bivariate model wind speed direction represents features available wind monitoring data characterize stochastic properties wind parameters subsequent wind monitoring data study bayesian inference approach considering uncertainty proposed update wind parameters bivariate probabilistic model slice sampling algorithm markov chain monte carlo mcmc method applied establish multi dimensional complex posterior distribution analytically intractable numerical simulation examples univariate bivariate models carried verify effectiveness proposed method addition proposed bayesian inference approach used update optimize parameters bivariate model using wind monitoring data investigated bridge results indicate proposed bayesian inference approach feasible employed predict bivariate distribution wind speed direction limited monitoring data copyright â© techno press ltd
10.1029/2018WR022735 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046723556&doi=10.1029%2f2018WR022735&partnerID=40&md5=024a1669879dc0853d512c0d57239a16 0,monte carlo mc simulations transport random porous networks indicate high variances lognormal permeability distribution transport passive tracer non fickian model non fickian dispersion random porous networks using discrete temporal markov models show temporal models capture spreading behavior accurately true despite fact slow velocities strongly correlated time studies suggested persistence low velocities render temporal markovian model inapplicable compared previously proposed temporal stochastic differential equations case specific drift diffusion terms models presented require fewer modeling assumptions moreover show discrete temporal markov models used represent dispersion unstructured networks widely used model porous media new method proposed extend state space temporal markov models improve model predictions presence extremely low velocities particle trajectories extend applicability model higher temporal resolutions finally shown combining multiple transitions temporal models efficient computing particle evolution compared correlated ctrw spatial increments equal lengths links network â© american geophysical union rights reserved
10.1007/s11222-017-9750-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018798470&doi=10.1007%2fs11222-017-9750-x&partnerID=40&md5=40a1d21a3532d1d5f9cbdb1a512af937 1,com poisson regression increasingly popular model count data main advantage permits model separately mean variance counts thus allowing covariate affect different ways average level variability response variable key limiting factor use com poisson distribution calculation normalisation constant accurate evaluation time consuming always feasible circumvent problem context estimating bayesian com poisson regression resorting exchange algorithm mcmc method applicable situations sampling model likelihood computed normalisation constant algorithm requires draw sampling model case com poisson distribution done efficiently using rejection sampling illustrate method benefits using bayesian com poisson regression model simulation two real world data sets different levels dispersion â© author
10.1016/j.resconrec.2018.01.016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041408379&doi=10.1016%2fj.resconrec.2018.01.016&partnerID=40&md5=e73a5062409562f7fe7e3e05d3fc6308 0,paper analyses production ethanol brazil using extensive plant based ethanol sugar production database including multiple variables involved ethanol production chain end generalized mixed model used markov chain monte carlo methods applying mcmcglmm package r software environment results obtained confirmed expected signs ethanol production major drivers contextual variables also shed light terms relative importance nature whether structural conjunctural exogenous main conclusions paper contextual variables contribute increase ethanol production brazil order importance sugarcane milling sugar production price ratios ethanol sugar policy implications sector derived â© elsevier b v
10.1093/sysbio/syx087 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050723466&doi=10.1093%2fsysbio%2fsyx087&partnerID=40&md5=c55588fbafaa7c7bfdcd35671343dbc4 1,phylogenetics inference evolutionary trees molecular sequence data dna enterprise yields valuable evolutionary understanding many biological systems bayesian phylogenetic algorithms approximate posterior distribution trees become popular computationally expensive means phylogenetics modern data collection technologies quickly adding newsequences already substantial databases current techniques bayesian phylogenetics computation must start anew time sequence becomes available making costly maintain date estimate phylogenetic posterior considerations highlight need online bayesian phylogenetic method update existing posterior new sequences provide theoretical results consistency stability methods online bayesian phylogenetic inference based sequential monte carlo smc markov chain monte carlo first show consistency result demonstrating method samples correct distribution limit large number particles next derive first reported set bounds phylogenetic likelihood surfaces change new sequences added bounds enable us characterize theoretical performance sampling algorithms bounding effective sample size ess given number particles show ess guaranteed grow linearly number particles smc sampler grows surprisingly result holds even though dimensions phylogenetic model grow new added sequence â© author
10.1534/genetics.117.300673 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046354287&doi=10.1534%2fgenetics.117.300673&partnerID=40&md5=8cfc21024f9e40706ec4df7005283865 0,recent technical methodological advances greatly enhanced genome wide association studies gwas advent low cost whole genome sequencing facilitates high resolution variant identification development linear mixed models lmm allows improved identification putatively causal variants essential correcting false positive associations due sample relatedness population stratification lmms commonly restricted quantitative variables however phenotypic traits association studies often categorical coded binary case control ordered variables describing disease stages address issues devised method genomic association studies implements generalized lmm glmm bayesian framework called bayes glmm bayes glmm four major features support categorical binary quantitative variables cohesive integration previous gwas results related traits correction sample relatedness mixed modeling model estimation markov chain monte carlo sampling maximal likelihood estimation applied bayes glmm whole genome sequencing cohort alzheimerâ€™s disease sequencing project study contains individuals families alzheimerâ€™s disease diagnosed one four confidence levels using bayes glmm identified four variants three loci significantly associated alzheimerâ€™s disease two variants rs rs lie prkar b pdgfa coded proteins localized glial vascular unit pdgfa transcript levels associated alzheimerâ€™s disease related neuropathology summary work provides implementation flexible generalized mixed model approach bayesian framework association studies â© genetics society america
10.1016/j.ymssp.2017.10.023 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037808799&doi=10.1016%2fj.ymssp.2017.10.023&partnerID=40&md5=3657e71662f75cb6845cc23d3827f42c 1,previous paper authors introduced flexible methodology reconstructing mechanical sources frequency domain prior local information nature location linear time invariant structure proposed approach derived bayesian statistics ability mathematically accounting experimenter prior knowledge however since maximum posteriori estimate computed posterior uncertainty regularized solution given measured vibration field mechanical model regularization parameter assessed answer legitimate question paper fully exploits bayesian framework provide markov chain monte carlo algorithm credible intervals statistical measures mean median mode parameters force reconstruction problem â© elsevier ltd
10.1109/TSG.2016.2606700 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044154332&doi=10.1109%2fTSG.2016.2606700&partnerID=40&md5=3ff7bc71784439adf3766454465e7b1c 2,influences network reconfiguration distributed generations dgs distribution system state estimation dsse measurement placement ignored active distribution systems paper considering network reconfiguration output uncertainties dgs robust measurement placement method active distribution systems proposed based measurement saturation analysis heuristic algorithm first saturation number determined measurement saturation characteristic chosen measurement number impacts different network topologies represented various weights robust measurement placement model computed markov chain analytic hierarchy process addition gaussian mixture model applied approximate power fluctuations dgs uncertainties caused measurements considered monte carlo simulations accuracy dsse different network topologies guaranteed proposed robust measurement placement method simulation results based ieee bus bus distribution systems demonstrate effectiveness proposed method â© ieee
10.1109/TII.2018.2802497 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041527866&doi=10.1109%2fTII.2018.2802497&partnerID=40&md5=6cade3f6ce666b72aaa49b938ea9ec4f 0,recently proposed ieee mac introduced new prioritized contention access pca transfer time critical packets lower channel access latency compared carrier sense multiple access collision avoidance csma ca paper first propose novel markov chain based analytical model unslotted csma ca pca industrial applications unslotted model extended derive analytical model slotted csma ca pca primary emphasis laid understanding performance pca compared csma ca different traffic classes industrial applications performance analysis shows slotted pca achieves reduction delay power consumption respectively compared slotted csma ca whereas unslotted pca achieves delay reduction reduction power consumption compared unslotted csma ca without significant loss reliability proposed analytical models slotted unslotted ieee mac offer satisfactory performance less error validated using monte carlo simulations also performance verified using real time testbed â© ieee
10.5731/pdajpst.2017.008094 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049746479&doi=10.5731%2fpdajpst.2017.008094&partnerID=40&md5=cee0216026dea1e6f89048a350852c05 0,biotherapeutics vaccines potency measured bioassay compares concentrationresponse curves new batch reference standard acceptable accuracy precision potency measurement critical manufacturing products characteristics bioassay typically assessed procedure carried samples spanning acceptable range product early development however full validation study carried late development costly relates likelihood eventual program success reasons laboratory may look alternative ways ensure validity bioassay across range support product development one alternative combines information reduced procedure using reference standard relative potency concentration response data sets together computer simulation estimate missing relative potency values across desired range fits reduced dataset provide estimates bioassay model parameters shaped potency assay follows four parameter logistic relationship along estimates variancecovariance structure independent experimental unit e g well well animal animal errors using bayesian markov chain monte carlo modeling predictive distribution concentration response data desired levels relative potency generated results use reduced procedure compared results calculated full dataset monte carlo simulation motivating example â© pda inc
10.1371/journal.pone.0196435 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047177670&doi=10.1371%2fjournal.pone.0196435&partnerID=40&md5=764b6ac5497596be3be0da7984b7a38f 0,major challenge systems biology infer parameters regulatory networks operate noisy environment single cell stochastic regime hard distinguish noise real signal infer noise contribution dynamical behavior genetic network displays oscillatory dynamics even harder infer parameters produce oscillations address issue introduce new estimation method built combination stochastic simulations mass action kinetics ensemble network simulations match average periodogram phase model data method relatively fast compared metropolis hastings monte carlo methods easy parallelize applicable large oscillatory networks large cells single cell expression data sets quantifies noise impact observed dynamics standard errors estimated rate coefficients typically two orders magnitude smaller mean single cell experiments order cells also provide method assess goodness fit stochastic network using hilbert phase single cells analysis phase departures null model communication cells consistent hypothesis stochastic resonance describing single cell oscillators stochastic resonance provides physical mechanism whereby intracellular noise plays positive role establishing oscillatory behavior may require model parameters rate coefficients differ substantially extracted macroscopic level measurements populations millions communicating synchronized cells â© caranica et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1002/env.2497 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045665550&doi=10.1002%2fenv.2497&partnerID=40&md5=8b0e7d0700adeced89242022e9b9d5cf 0,knowledge characteristics earthquake ground motion fundamental earthquake hazard assessments small distances relative sourceâ€“site distance uniform site conditions expected ground motion variability also expected insignificant however despite located characterized uniform lava rock site condition considerable peak ground acceleration pga variations observed stations small aperture array covering approximately â km accelerographs southwest iceland ã–lfus earthquake magnitude may sequence aftershocks propose novel bayesian hierarchical model pga variations accounting separately earthquake event effects station effects event station effects efficient posterior inference scheme based markov chain monte carlo mcmc simulations proposed new model variance station effect certainly different zero according posterior density indicating individual station effects different one another bayesian hierarchical model thus captures observed pga variations quantifies extent source recording sites contribute overall variation ground motions relatively small distances lava rock site condition copyright â© john wiley sons ltd
10.2112/SI85-058.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051372260&doi=10.2112%2fSI85-058.1&partnerID=40&md5=35b9d19d400445b060d12b48eede9abb 0,coastal erosion caused tractive force wave accelerating areas study hydraulic experiment considered pickup concept carried understand phenomenon since existing methods deriving suspended sediment concentrations ssc likely affect results image processing techniques used preliminary experiments conducted process relevant data necessarily involves uncertainty two step bayesian markov chain monte carlo method mcmc used quantitatively derive first step relationship image grayscale turbidity relationship ssc turbidity presented quantative analysis show sediment pickup rate sluice gate designed rapid openning generate solitary wave optimum opening speed derived experimental result indicated physical characteristics wave suspended sediment pickup rate closely related relationship changed according wave breaking solitary wave pickup function presented adapting einstein essential concepts precise pickup rate used basic data prevention coast erosion management shoreline â© coastal education research foundation inc
10.1016/j.adhoc.2018.01.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044473466&doi=10.1016%2fj.adhoc.2018.01.006&partnerID=40&md5=b2d07e606d1ff5f3cabae2e54a28b588 0,provide tool performance evaluation ieee sleep mode enabled novel model based real time queueing analysis proposed paper low rate wireless personal area network lr wpan composed multiple nodes send packets coordinator considered queueing behaviour ieee node sleep mode enabled differs others packet arrivals sleep period accumulate beginning active period makes heavier load beginning time model analyses behaviour dividing active portion superframe backoff slots using embedded discrete time markov chain model concept virtual service time introduced model makes proposed queueing model novel different typical ones accuracy proposed model validated monte carlo simulations existing typical application scenarios indicates proposed queueing model accurately evaluate performance ieee context application scenarios described simulations â© elsevier b v
10.1016/j.jpdc.2018.01.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041471445&doi=10.1016%2fj.jpdc.2018.01.001&partnerID=40&md5=576673abbc8895a6baceff271cd94e01 6,paper propose coupled multiplex network framework model epidemic spreading corresponding information diffusion among population model far information perception epidemics concerned individuals divided two classes namely aware unaware ones meanwhile awareness diffusion depicted utilizing traditional contact process perspective infectious disease spreading contagion dynamics among nodes characterized classic sir susceptibleâ€“infectiveâ€“recovered model based microscopic markov chain approach build probability tree describe switching process different states intensively perform theoretical analysis state transition particular analytically derive epidemic threshold regarding disease propagation correlated multiplex network topology coupling relationship two transmission dynamics compared extensive numerical monte carlo mc simulations clearly found achieved analytical results concur mc simulations current results beneficial substantially enhance predictability epidemic outbreaks within many realistic dissemination cases â© elsevier inc
10.1534/g3.117.300406 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046621018&doi=10.1534%2fg3.117.300406&partnerID=40&md5=9ca2c11abc9c857c8dc61d03bacd8709 0,genomic selection gs become tool selecting candidates plant animal breeding programs case quantitative traits common assume distribution response variable approximated normal distribution however known selection process leads skewed distributions vast statistical literature skewed distributions skew normal distribution particular interest research distribution includes third parameter drives skewness generalizes normal distribution propose extension bayesian whole genome regression skew normal distribution data context gs applications usually number predictors vastly exceeds sample size however also applied number predictors smaller sample size used stochastic representation skew normal random variable allows implementation standard markov chain monte carlo mcmc techniques efficiently fit proposed model predictive ability goodness fit proposed model evaluated using simulated real data results compared obtained bayesian ridge regression model results indicate proposed model better fit good conventional bayesian ridge regression model prediction based dic criterion cross validation respectively computing program coded r statistical package c programming language fit proposed model available supplementary material â© pã©rez rodrã­guez et al
10.1371/journal.pone.0197954 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047473699&doi=10.1371%2fjournal.pone.0197954&partnerID=40&md5=7435d26dfe7a7425e9e01131364363c2 0,statistical inference widely used powerful tool learning natural processes diverse fields statistical software platforms ad model builder admb template model builder tmb particularly popular ecological literature typically used perform frequentist inference complex models however lack capabilities flexible efficient markov chain monte carlo mcmc integration recently u turn sampler nuts mcmc algorithm gained popularity bayesian inference software stan efficient high dimensional complex hierarchical models introduce r packages adnuts tmbstan provide nuts sampling parallel interactive diagnostics shinystan admb source code modified provide nuts tmb models linked directly stan describe packages provide case studies demonstrating use contrast performance stan tmb models show test accuracy laplace approximation using nuts complex models performance admb tmb typically within + speed stan one tmb case study found inaccuracies laplace approximation potentially leading biased inference adnuts provides new method estimating hierarchical admb models previously infeasible tmb users fit model frequentist bayesian paradigms including using nuts test validity laplace approximation marginal likelihood arbitrary subsets parameters software developments extend available statistical methods admb tmb user base additional effort user â© monnahan kristensen open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1371/journal.pcbi.1006181 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048195917&doi=10.1371%2fjournal.pcbi.1006181&partnerID=40&md5=cd4d79f51a31fc5076cdc8b634cba60a 0,common challenge systems biology quantifying effects unknown parameters estimating parameter values data many systems task computationally intractable due expensive model evaluations large numbers parameters work investigate new method performing sensitivity analysis parameter estimation complex biological models using techniques uncertainty quantification primary advance significant improvement computational efficiency replacement model simulation evaluation polynomial surrogate model demonstrate method two models mating budding yeast smaller ode model heterotrimeric g protein cycle larger spatial model pheromone induced cell polarization small number model simulations used fit polynomial surrogates used calculate global parameter sensitivities surrogate models also allow rapid bayesian inference parameters via markov chain monte carlo mcmc eliminating model simulations step application ode model shows results consistent published single point estimates model data added benefit calculating correlations pairs parameters larger pde model surrogate models allowed convergence distribution parameters otherwise computationally prohibitive using simulations mcmc step inferred parameter distributions certain cases peaked values different published values showed wide range parameters permit polarization model strikingly results suggested different diffusion constants active versus inactive cdc achieve good polarization consistent experimental observations another yeast species pombe â© renardy et al http creativecommons org licenses
10.1063/1.5025627 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047653592&doi=10.1063%2f1.5025627&partnerID=40&md5=4134b161dafae9ca95775bab0406d2c2 0,introduce monte carlo algorithm efficiently compute transport properties chaotic dynamical systems method exploits importance sampling technique favors trajectories tail distribution displacements deviations diffusive process prominent search initial conditions using proposal correlates states markov chain constructed via metropolis hastings algorithm show method outperforms direct sampling method also metropolis hastings methods alternative proposals test general method numerical simulations box map lorentz gas systems â© author
10.1061/(ASCE)CP.1943-5487.0000750 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041702334&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000750&partnerID=40&md5=f6aa0b1d2156a6e400acf8a84833f716 3,aim model based structural identification identify suitable models values model parameters determine structure behavior comparing measurements predictions well known methodologies traditional implementations bayesian model updating shown inaccurate cases characterized systematic uncertainties unknown spatial correlations error domain model falsification edmf another approach structural identification approach easy understand practicing engineers provide robust parameter identification without assumptions spatial correlations performance approaches involving sampling affected number model evaluations generated based prior knowledge parameter value distributions paper focuses new sampling technique called radial basis function sampling rbfs application edmf generate set candidate models represents behavior structure certain confidence level radial basis function sampling provides good exploration parameter space even limited number samples results reduced computation times full scale bridge singapore tested new index sampling quality proposed compare approach sampling techniques latin hypercube sampling lhs markov chain monte carlo mcmc finally cross validation method used verify robustness approach sensitivity sampling prediction reliability â© american society civil engineers
10.1016/j.clon.2018.01.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041899239&doi=10.1016%2fj.clon.2018.01.007&partnerID=40&md5=29112011da77b6ce10a64ab3715461b8 1,proton beam therapy pbt still relatively new cancer treatment clinical evidence base relatively sparse mathematical modelling offers assistance selecting patients pbt predicting demand service discrete event simulation normal tissue complication probability quality adjusted life years markov chain models mathematical statistical modelling techniques currently used none dominant new evidence outcome data become available pbt comprehensive models emerge less dependent specific technologies radiotherapy planning delivery â© royal college radiologists
10.1016/j.fct.2018.03.040 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044953341&doi=10.1016%2fj.fct.2018.03.040&partnerID=40&md5=12586b52b158bbb15d4c8e1ba031dbe8 1,investigation heavy metals content rice oryza sativa associated health risks carried residents iranshahr city iran average daily rice consumption citizens widely used rice brands market iranshahr determined using questionnaire besides concentration heavy metals gathered rice samples measured inductively coupled plasma mass spectrometry icp ms monte carlo uncertainty simulation utilized conducting exposure assessment investigating non carcinogenic effects studied elements well carcinogenic effect concentrations cd pb cu al mo â± â± â± â± â± â± mg kgâˆ’ respectively al â± mg kgâˆ’ dâˆ’ cd â± mg kgâˆ’ dâˆ’ highest lowest estimated daily intake respectively except â± calculated hazard quotient investigated elements showed non carcinogenic health risk besides simulation carcinogenic risk effect e revealed ingestion studied rice brands cause cancer risk due lifetime consumption results show consumption rice iranshahr city potential source exposure studied elements â© elsevier ltd
10.1016/S2214-109X(18)30059-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045197275&doi=10.1016%2fS2214-109X%2818%2930059-7&partnerID=40&md5=0651553e32ba4abe79e70608f636a303 1,background progress achieve fourth millennium development goal reducing mortality rate children younger years since remarkable however work remains done sustainable development goal era estimates mortality rates national level hide disparities within countries assessed disparities mortality rates household economic status low income middle income countries lmics method estimated country year specific mortality rates wealth quintile basis household wealth indices lmics using bayesian statistical model estimated association quintile specific national level mortality rates assessed levels trends absolute relative disparity mortality rate poorest richest quintiles among quintiles findings lmics excluding china aggregated mortality rate â· uncertainty interval ui â· â€“ â· deaths per livebirths poorest households first quintile â· â· â€“ â· deaths per livebirths richest households fifth quintile outcomes middle quintiles largest absolute decline mortality rate occurred two poorest quintiles â· ui â· â€“ â· deaths per livebirths poorest quintile â· â· â€“ â· deaths per livebirths second poorest quintile difference mortality rate poorest richest quintiles decreased significantly â· ui â· â€“ â· deaths per livebirths poorest richest mortality rate ratio however remained similar â· ui â· â€“ â· â· â· â€“ â· â· â· â€“ â· â€“ around half total deaths occurred poorest two quintiles â· â· less third richest two quintiles â· â· â· regions differences mortality rate first fifth quintiles decreased significantly ranging â· ui â· â€“ â· deaths per livebirths eastern europe central asia â· â· â€“ â· deaths per livebirths south asia ratios mortality rate first quintile mortality rate fifth quintile significantly â· two regions â· ui â· â€“ â· east asia pacific excluding china â· â· â€“ â· south asia eastern southern africa smallest ratio â· ui â· â€“ â· model suggested expected ratio mortality rate first quintile mortality rate fifth quintile increases national level mortality rate decreases interpretation lmics excluding china combined absolute disparities mortality rate poorest richest households narrowed significantly since whereas relative differences remained stable narrow rich poor gap mortality rate relative scale targeted interventions focus poorest populations needed funding national university singapore un children fund united states agency international development bill melinda gates foundation â© author published elsevier ltd open access article cc license
10.1038/s41372-017-0026-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039171776&doi=10.1038%2fs41372-017-0026-2&partnerID=40&md5=ba2e45da6c2be3e67440ca2a2be4e37d 0,abstract available
10.1158/1078-0432.CCR-17-3542 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047795245&doi=10.1158%2f1078-0432.CCR-17-3542&partnerID=40&md5=68b47c0bee761a1bbb8b67c0a2056dac 0,purpose compare predict cancermath two widely used prognostic models invasive breast cancer taking account clinical utility furthermore unclear whether models improved experimental design dataset women used model development bayesian variable selection algorithm implemented stochastically search important interaction terms among predictors derived models compared three independent datasets n â¼ examined calibration discrimination performed decision curve analysis results cancermath demonstrated worse calibration performance compared predict estrogen receptor er â€“positive er negative tumors decline discrimination performance er positive er negative tumors respectively new models matched performance predict terms calibration discrimination offered improvement decision curve analysis showed predictions models clinically useful treatment decisions made risk thresholds er positive tumors thresholds er negative tumors within threshold ranges cancermath provided lowest clinical utility among models conclusions survival probabilities predict offer improved accuracy discrimination cancermath using predict make treatment decisions offers greater clinical utility cancermath range risk thresholds new models performed well predict better suggesting setting including interaction terms offers predictive benefit â© american association cancer research
10.1002/bimj.201700176 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042385693&doi=10.1002%2fbimj.201700176&partnerID=40&md5=258d36afb18fb4dbdd9f750294a72d6a 0,paper panel count data analysis recurrent events considered analysis useful studying tumor infection recurrences clinical trial observational studies bivariate gaussian cox process model proposed jointly model observation process recurrent event process bayesian nonparametric inference proposed simultaneously estimating regression parameters bivariate frailty effects baseline intensity functions inference done markov chain monte carlo fully developed computational techniques predictive inference also discussed bayesian setting proposed method shown efficient via simulation studies clinical trial dataset skin cancer patients analyzed illustrate proposed approach â© wiley vch verlag gmbh co kgaa weinheim
10.1007/s11306-018-1351-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044506676&doi=10.1007%2fs11306-018-1351-y&partnerID=40&md5=8fe48e23287c0c812cba0ec9ebe23175 0,introduction aid development better algorithms h nmr data analysis alignment peak fitting important characterise model chemical shift changes caused variation ph number protonation sites key parameter theoretical relationship ph chemical shift traditionally estimated molecular structure often unknown untargeted metabolomics applications objective aim use observed nmr chemical shift titration data estimate number protonation sites range urinary metabolites methods pool urine healthy subjects titrated range ph â€“ standard h nmr spectra acquired positions peaks corresponding identified metabolites recorded theoretical model chemical shift fit data using bayesian statistical framework using model selection procedures markov chain monte carlo algorithm estimate number protonation sites molecule results estimated number protonation sites found correct peaks cases number sites incorrectly estimated due close pka values limited amount data required ph range conclusions given appropriate data possible estimate number protonation sites many metabolites typically observed h nmr metabolomics without knowledge molecular structure approach may valuable resource development future automated metabolite alignment annotation peak fitting algorithms â© author
10.3150/15-BEJ785 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034834546&doi=10.3150%2f15-BEJ785&partnerID=40&md5=698842a0e0b428b98492975da3db80f0 3,establish quantitative bounds rates convergence asymptotic variances iterated conditional sequential monte carlo csmc markov chains associated particle gibbs samplers j r stat soc ser b stat methodol main findings essential boundedness potential functions associated csmc algorithm provide necessary sufficient conditions uniform ergodicity csmcmarkov chain well quantitative bounds uniformly geometric rate convergence furthermore show csmc markov chain even geometrically ergodic essential boundedness hold many applications interest sufficiency quantitative bounds rely novel non asymptotic analysis expectation standard normalizing constant estimate respect doubly conditional smc algorithm addition results csmc imply rate convergence improved arbitrarily increasing n number particles algorithm presence mixing assumptions rate convergence kept constant increasing n linearly time horizon translate sufficiency boundedness condition csmc sufficient conditions particle gibbs markov chain geometrically ergodic quantitative bounds geometric rate convergence imply convergence properties particle gibbs markov chain corresponding gibbs sampler results complement recently discovered related conditions particle marginal metropolis hastings pmmh markov chain â© isi bs
10.1142/S0219024918500218 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046808746&doi=10.1142%2fS0219024918500218&partnerID=40&md5=a2a325ea0fac63767d7e82f5af40475e 0,paper studies fitting markov chain potential models interest rate derivative prices four currencies simultaneously using sequential monte carlo methodology particle filtering potential approach starts markov process supposed drive random observations many studies markov process taken diffusion fewer studies worked finite state markov chain seems first study attempt fit models data available data show impressive agreement fitted models market prices â© world scientific publishing company
10.1002/2017GC007347 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046551872&doi=10.1002%2f2017GC007347&partnerID=40&md5=7727625279bb09a9c9aac521b88c915e 1,understanding enigmatic intraplate volcanism tristan da cunha region requires knowledge temperature lithosphere asthenosphere beneath measured phase velocity curves rayleigh waves using cross correlation teleseismic seismograms array ocean bottom seismometers around tristan constrained region average shear velocity structure inferred temperature lithosphere asthenosphere beneath hotspot ocean bottom data set presented challenges required data processing measurement approaches different tuned land based arrays stations derived robust phase velocity curve tristan area inverted shear wave velocity profile using probabilistic markov chain monte carlo approach model shows pronounced low velocity anomaly least km depth formula presented low velocity zone â€“ km low reported hawaii âˆ¼ km probably indicates less pronounced thermal anomaly possibly less partial melting petrological modeling shows seismic bathymetry data consistent moderately hot mantle mantle potential temperature â€“ â°c excess â€“ â°c compared global average melt fraction smaller purely seismic inversions petrological modeling indicate lithospheric thickness â€“ km consistent recent estimates receiver functions presence warmer average asthenosphere beneath tristan consistent hot upwelling plume deep mantle however excess temperature determine smaller reported major hotspots particular hawaii â© american geophysical union rights reserved
10.1016/j.prevetmed.2017.02.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017168674&doi=10.1016%2fj.prevetmed.2017.02.017&partnerID=40&md5=c9bb3f0461c9f9b0ea8ca0bd98185828 11,bovine tuberculosis btb cattle global health problem eradication disease requires accurate estimates diagnostic test performance optimize efficiency objective study statistical meta analyses obtain estimates sensitivity se specificity sp different ante mortem post mortem diagnostic tests btb cattle using data systematic review scientific literature published â€“ diagnostic se sp estimated using bayesian logistic regression models adjusting confounding factors random effect terms used account unexplained heterogeneity parameters models implemented using markov chain monte carlo mcmc posterior distributions diagnostic parameters adjustment covariates confounding factors obtained using inverse logit function estimates se sp tuberculin skin tests ifn î³ blood test compared estimates published â€“ median se single intradermal comparative cervical tuberculin skin sicct test standard interpretation bayesian credible intervals cri wide cri median sp sicct test cri estimates ifn î³ blood test bovine purified protein derivative ppd avian ppd early secreted antigen target culture filtrate protein esat cfp esat cfp cri cri respectively se cri cri sp study provides overview accuracy range contemporary diagnostic tests btb cattle better understanding diagnostic test performance essential design effective control strategies evaluation â©
10.1214/16-BJPS345 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045506660&doi=10.1214%2f16-BJPS345&partnerID=40&md5=b9eb11d20b43c4152fa0f9e969d56fbf 0,mixture models provide flexible representation heterogeneity finite number latent classes bayesian point view markov chain monte carlo methods provide way draw inferences models particular number subpopulations considered unknown sophisticated methods required perform bayesian analysis reversible jump markov chain monte carlo alternative method computing posterior distribution simulation case problems associated bayesian analysis class models frequent called â€œlabel switchingâ€� problem however level heterogeneity population increases problems expected become less frequent modelâ€™s performance improve thus aim work evaluate normal mixture model fit using simulated data different settings heterogeneity prior information mixture proportions simulation study also presented evaluate modelâ€™s performance considering number components known estimating finally model applied censored real dataset containing antibody levels cytomegalovirus individuals â© brazilian statistical association
10.1103/PhysRevD.97.092007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048687794&doi=10.1103%2fPhysRevD.97.092007&partnerID=40&md5=8afa6fc5d791c401e3f876f986a5f31f 2,report response liquid xenon low energy electronic recoils kev beta decays tritium drift fields v cm v cm v cm using xenon detector data simulation fitting method based markov chain monte carlo used extract photon yields recombination fluctuations experimental data photon yields measured two lower fields agreement literature additional measurements higher field v cm presented electronic nuclear recoil discrimination well dependence drift field photon detection efficiency investigated low energies results provide new measurements energy region interest dark matter searches using liquid xenon â© american physical society
10.1002/jeab.330 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048044760&doi=10.1002%2fjeab.330&partnerID=40&md5=83e567acfd193ff69718c1d3cf52d2c6 3,models generate event records general scope regarding dimensions target behavior measure set predicted event records generate predictions dependent variable compute event records subjects sense models generate event records permit us freely multivariate analysis explore proposition conducted multivariate examination catania operant reserve single vi schedules transition using markov chain monte carlo scheme approximate bayesian computation although found systematic deviations implementation catania operant reserve observed data e g mismatches shape interresponse time distributions general approach demonstrated represents avenue modelling behavior transcends typical constraints algebraic models â© society experimental analysis behavior
10.5812/ijcm.62863 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048713898&doi=10.5812%2fijcm.62863&partnerID=40&md5=3c847bf8131802c7c48067e1c33623c4 0,background rapid progression medical health sciences caused survival studies patients long term survival especially chronic diseases breast cancer cure models applicable analyze data objectives aim study determine risk factors associated breast cancer using mixture cure fraction model methods studied data patients referred cancer research center shahid beheshti university medical sciences patients visited treated followed october data analyzed mixture cure fraction model based gmw generalized modified weibull distribution inferences obtained bayesian approach using standard mcmc markov chain monte carlo methods analyses performed using spss v openbugs software significant level considered results follow period deaths occurred breast cancer one year overall survival rate covariates numbers metastatic lymph nodes histologic grade statistically significant also cure fraction estimation obtained conclusions patients long term survival cure models interesting model study survival models estimate parameters better traditional models cox model paper mixture cure fraction model based gmw fitted analysing survival times patients breast cancer â© cancer research center crc shahid beheshti university medical sciences
10.1007/s12517-018-3576-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046868202&doi=10.1007%2fs12517-018-3576-5&partnerID=40&md5=f3caea146f7203a4d85863f3a4aa494a 0,elastic properties rock used help evaluate reservoir properties distinctive properties shale low porosity permeability anisotropy complicated mineral components limit application traditional petrophysical experimental method elastic properties shale easy obtain work proposed workflow used advanced markov chain monte carlo mcmc method reconstruct digital cores rocks shale reservoir used finite element method fem calculate equivalent static elastic moduli shale digital cores method overcomes limitation direct elastic property measurement equivalent bulk shear moduli cores different compositions obtained result reveals moduli anisotropic different sensitivities different components equivalent moduli linearly decrease three cases namely increase clays b increase porosity c increase organic matter content hand equivalent moduli linearly increase three cases namely increase plagioclase content b increase calcite content c increase pyrite content different clays equivalent moduli rocks vary elastic moduli clay form power functions meanwhile bulk modulus affected type pore fluid shear modulus insensitive â© saudi society geosciences
10.1177/0013164418777569 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047832862&doi=10.1177%2f0013164418777569&partnerID=40&md5=ec2d1def9e7e6cf4640e5276af9f1447 0,plausible values used either estimate population level statistics compute point estimates latent variables well known five plausible values usually sufficient accurate estimation population level statistics large scale surveys minimum number plausible values needed obtain accurate latent variable point estimates unclear especially relevant item response theory irt model estimated mcmc markov chain monte carlo methods mplus point estimates irt ability parameter interest mplus estimates posterior distribution ability parameter order obtain point estimates ability parameter number plausible values drawn posterior distribution individual ability parameter mean posterior mean ability estimate used individual ability point estimate note conducted simulation study investigate many plausible values needed obtain accurate posterior mean ability estimates results indicate minimum number plausible values required obtain point estimates irt ability parameter comparable marginal maximum likelihood estimation mmle expected posteriori eap estimates real dataset used demonstrate comparison mmle eap point estimates posterior mean ability estimates based different number plausible values â© author
10.1177/0962280216662298 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043468751&doi=10.1177%2f0962280216662298&partnerID=40&md5=0b2d7798a3eca2d1819052310cec45f6 1,many medical ecological processes involve change shape whereby one trajectory changes another trajectory specific time point little investigation study design needed investigate models consider class fixed effect change point models underlying shape comprised two joined linear segments also known broken stick models extend model include two sub groups different trajectories change point change change class also include missingness model account individuals incomplete follow simulation study consider relationship sample size estimates underlying shape existence change point classification error sub group labels use bayesian framework account missing labels analysis simulation performed using standard markov chain monte carlo techniques simulation study inspired cognitive decline measured mini mental state examination extended model appropriate due commonly observed mixture individuals within studies exhibit accelerated decline find even studies modest size n = individuals observed past change point fixed effect setting change point detected reliably estimated across range observation errors â© â© author
10.1016/j.jmva.2017.11.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038256959&doi=10.1016%2fj.jmva.2017.11.006&partnerID=40&md5=763ec6244f4cc4c167c090d86be872b8 0,paper introduces multivariate circularâ€“linear poly cylindrical distribution obtained combining projected skew normal show flexibility proposal closure marginalization quantify multivariate dependence due non identifiability issue proposal inherits projected normal computational problem arises overcome bayesian framework adding suitable latent variables showing posterior samples obtained post processing estimation algorithm output specific prior choices approach enables us implement markov chain monte carlo algorithm relying gibbs steps updates parameters done working multivariate normal likelihood proposed approach also used projected normal proof concept simulated examples show ability algorithm recovering parameter values solve identification problem proposal used real data example turning angles circular variables logarithm step lengths linear variables four zebras modeled jointly â© elsevier inc
10.3847/1538-3881/aab95c https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047335032&doi=10.3847%2f1538-3881%2faab95c&partnerID=40&md5=7b4fdd75886ce83653ed6b588fa3e507 3,space based high contrast imaging mission concepts studying rocky exoplanets reflected light currently community study develop inverse modeling framework estimate science return missions given different instrument design considerations combining exoplanet albedo model instrument noise model ensemble markov chain monte carlo sampler explore retrievals atmospheric planetary properties earth twins function signal noise ratio n resolution r forward model includes rayleigh scattering single layer water clouds patchy coverage pressure dependent absorption due water vapor oxygen ozone simulate data r = î¼m n = nm e habex luvoir type instruments ns simulate data wfirst paired starshade includes two photometric points î¼m r = spectroscopy î¼m given noise model wfirst type detectors find weak detections water vapor ozone oxygen achieved observations least r = n = r = n = improved detections meaningful constraints achieved r = n = data wfirst data offer limited diagnostic information needing least n = weakly detect gases scenarios place limits planetary radius constrain surface gravity thus planetary mass â© american astronomical society rights reserved
10.1093/mnras/sty291 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043496919&doi=10.1093%2fmnras%2fsty291&partnerID=40&md5=ac4022b3b594253a3493fa3b31d94852 2,report mid uv muv observations taken hubble space telescope hst wfc swift uvot galex nuv transitional millisecond pulsars xss j psr j + radio pulsar states systems detected images showed muv variability similar orbital phases muv luminosities pulsars comparable suggests emission processes involved objects similar estimated limits mass ratio companion temperature inclination distance xss j using markov chain monte carlo algorithm fit published folded optical light curves using resulting parameters modelled muv light curves hst filters resulting models failed fit muv observations fixing mass ratio xss j value reported studies obtained distance kpc larger one derived dispersion measure kpc assuming uniform prior mass ratio distance similar radio measurements however requires undermassive companion mâš™ conclude direct heating model alone fully explain observations optical muv therefore additional radiation source needed source intrabinary shock contributes muv flux likely optical one well radio pulsar state muv orbital variations psr j + detected galex suggest presence asymmetric intrabinary shock â© author published oxford university press behalf royal astronomical society
10.1111/ddi.12707 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042368055&doi=10.1111%2fddi.12707&partnerID=40&md5=892ca9f991c23864b5fcedb1f8140d32 1,aim develop novel modelling framework analysing spatio temporal spread biological invasions framework integrates different invasion drivers disentangles roles determining observed invasion patterns fitting models historical distribution data case study application analyse spread common ragweed ambrosia artemisiifolia location central europe methods lattice system represents actual landscapes environmental heterogeneity modelling covers spatio temporal invasion sequence grid integrates effects environmental conditions local invasion suitability role invaded cells spatially implicit â€œbackgroundâ€� introductions propagule sources within cell invasion level bulk multiple dispersal means modular framework design facilitates flexible numerical representation modelled invasion processes customization model complexity used framework build contrast increasingly complex models fitted using bayesian inference approach parameters estimated markov chain monte carlo mcmc results modelled invasion drivers codetermined â artemisiifolia invasion pattern inferences individual drivers depended processes modelled concurrently hence changed quantitatively qualitatively models among others roles environmental variables assessed substantially differently subject whether models included explicit source recipient cell relationships spatio temporal variability source cell strength human mediated dispersal means largest fit improvements found integrating filtering effects environment spatio temporal availability propagule sources main conclusions modelling framework provides straightforward means build integrated invasion models address hypotheses roles mutual relationships different putative invasion drivers statistical nature generic design make suitable studying many observed invasions efficient invasion modelling important represent changes spatio temporal propagule supply explicitly tracking speciesâ€™ colonization sequence establishment new populations â© john wiley sons ltd
10.1111/geb.12722 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042176962&doi=10.1111%2fgeb.12722&partnerID=40&md5=224f1ee63a958e9badeaa5c78e36231b 1,aim community assembly traditionally assumed result speciation colonization mediated available niche space paradigm expanded theory niche space also saturated intersexual adaptive divergence ecological sexual dimorphism interspecific competition relaxed theory termed â€˜niche packing equivalenceâ€™ predicts evolution ecological sexual dimorphism constrains ecological opportunity otherwise lead ecological speciation colonization saturation niches different species constrains divergent selection divergence sexes therefore sexes species equivalent yet antagonistic units niche occupation present comprehensive test niche packing equivalence theory ecological time scales assemblage level date location south america major taxa studied liolaemus lizards methods identified liolaemus assemblages varying species richness sexual size dimorphism ssd distributed across wide environmental range used mixed effects models permutation tests markov chain monte carlo mcmc regressions quantify relationship ssd species richness partitioned body size niche dimension sexes amongst species tested non overlapping body size distributions regressed ssd species richness assemblage environmental predictors using multi model inference structural equation modelling results sexual dimorphism declines increasing species richness strong signal tension two remains following phylogenetic control pattern accompanied evidence constraints body size partitioning amongst species sexes two units niche saturation tend overlap however across assemblages species richness ssd correlate different environmental variables suggesting tension context specific main conclusions evidence supports prediction sexual dimorphism species richness alternative outcomes adaptive radiation however antagonism mediated suite environmental predictors influence dimorphism species richness differentially â© john wiley sons ltd
10.1093/mnras/sty079 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043489597&doi=10.1093%2fmnras%2fsty079&partnerID=40&md5=c1a08eb18922b0446cf04793b574b1a3 0,ground breaking detections gravitational waves black hole mergers ligohave rekindled interest primordial black holes pbhs possibility dark matterbeing composed pbhs suggested pbhs tens solar masses serveas dark matter candidates recent analytical studies demonstrated compact ultra faintdwarf galaxies serve sensitive test pbh dark matter hypothesis since stars insuch halo dominated system heated massive pbhs present daydistribution provide strong constraints pbh mass study explore thisscenario detailed calculations using combination dynamical simulations andbayesian inference methods joint evolution stars pbh dark matter followedwith fokker planck code phaseflow run large suite simulations differentdark matter parameters use markov chain monte carlo approach constrain pbhproperties observations ultra faint galaxies find two body relaxation betweenthe stars pbh drives stellar core size increases central stellar velocitydispersion using observed half light radius velocity dispersion stars compactultra faint dwarf galaxies joint constraints infer dwarfs may cored darkmatter halo central density range pc pbhs may havea mass range constitute substantial fraction dark matter â© author published oxford university press behalf royal astronomical society
10.1002/ece3.4006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045411195&doi=10.1002%2fece3.4006&partnerID=40&md5=0ed37a7a5ea0e86133f09393efeb412e 0,thermal acclimation hypothesized offer selective advantage seasonal habitats may underlie disparities geographic range size among closely related species similar ecologies understanding relationship also critical identifying species sensitive warming climates study north american plethodontid salamanders investigate whether acclimation ability associated speciesâ€™ latitudinal extents thermal range environments inhabit quantified variation thermal physiology measuring standard metabolic rate smr different test acclimation temperatures species salamanders varying latitudinal extents phylogenetically controlled markov chain monte carlo generalized linear mixed model mcmcglmm employed determine whether differences smr wide narrow ranging species different acclimation temperatures addition tested relationship acclimation ability species environmental temperature ranges inhabit investigated trade critical thermal maximum ctmax thermal acclimation ability mcmcglmm results show significant difference acclimation ability wide narrow ranging temperate salamanders salamanders wide latitudinal distributions maintain slightly increase smr subjected higher test acclimation temperatures whereas several narrow ranging species show significant metabolic depression also found significant positive relationships acclimation ability environmental thermal range acclimation ability ctmax wide ranging salamander species exhibit greater capacity thermal acclimation narrow ranging species suggesting selection acclimation ability may key factor enabling geographic expansion areas greater thermal variability given narrow ranging salamanders found poor acclimation ability lower tolerance warm temperatures likely susceptible environmental warming associated anthropogenic climate change â© authors ecology evolution published john wiley sons ltd
10.1016/j.spinee.2017.09.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033489191&doi=10.1016%2fj.spinee.2017.09.009&partnerID=40&md5=38e413d4ee6cacf27f69b588a157145a 0,background context chronic opioid therapy associated worse patient reported outcomes pros following spine surgery however little literature exists relationship opioid use pros following epidural steroid injections radicular pain purpose evaluated association pre injection opioid use pros following spine epidural steroid injection study design study retrospective analysis prospective longitudinal registry database patient sample total patients within database undergoing epidural steroid injections esis institution degenerative structural spine diagnoses met inclusion criteria included study outcome measures patient reported outcomes disability oswestry disability index neck disability index odi ndi quality life euroqol eq pain numerical rating scale scores back pain neck pain leg pain arm pain nrs bp np lp ap assessed baseline months post injection methods multivariable proportional odds logistic regression models created examine relationship pre injection opioid use post injection pros logistic regression bayesian markov chain monte carlo parameter estimation used investigate possible cutoff value pre injection opioid use effectiveness esi measured minimum clinically important difference mcid odi ndi decreases results total patients complete month follow following esi analyzed mean pre injection daily morphine equivalent amount mea mg confidence interval ci mgâ€“ mg cohort pre injection opioid use associated slightly higher odds worse disability odds ratio p= leg arm pain p= scores months post injection significant association pre injection opioid use mcid odi ndi found although cutoff mg day might serve significant threshold conclusion increased pre injection opioid use impact long term outcomes esis degenerative spine diseases pre injection mea around mg day may represent threshold month effectiveness esi back neck related disability decreases epidural steroid injection effective treatment modality pain patients using opioids part multimodal strategy opioid independence â©
10.1109/TVCG.2018.2832097 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046363098&doi=10.1109%2fTVCG.2018.2832097&partnerID=40&md5=5d4370e88c086f12ddb0f31793aa4682 0,introduce data driven method generate large number plausible closely interacting human pose pairs given motion category e g wrestling salsa dance much difficulty acquiring close interactions using sensors approach utilizes abundant existing video data cover many human activities instead treating data generation problem one reconstruction either acquisition direct data lifting video annotations present solution based markov chain monte carlo mcmc sampling focus efficient sampling space close interactions rather pose spaces develop novel representation called interaction coordinates ic encode poses interactions integrated manner plausibility pose pair defined based ics respect annotated pose pairs video show sampling based approach able efficiently synthesize large volume plausible closely interacting pose pairs provide good coverage input pose pairs ieee
10.1002/sim.7583 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040655380&doi=10.1002%2fsim.7583&partnerID=40&md5=be499a776309af311b77e7c11af9dc90 0,controlled imputation method refers class pattern mixture models commonly used sensitivity analyses longitudinal clinical trials nonignorable dropout recent years pattern mixture models assume participants experimental arm dropout similar response profiles control participants worse outcomes otherwise similar participants remain experimental treatment spite popularity controlled imputation formally developed longitudinal binary ordinal outcomes partially due lack natural multivariate distribution endpoints paper propose approaches implementing controlled imputation binary ordinal data based respectively sequential logistic regression multivariate probit model efficient markov chain monte carlo algorithms developed missing data imputation using monotone data augmentation technique sequential logistic regression parameter expanded monotone data augmentation scheme multivariate probit model assess performance proposed procedures simulation analysis schizophrenia clinical trial compare fully conditional specification last observation carried forward baseline observation carried forward imputation methods copyright â© john wiley sons ltd
10.1080/15598608.2018.1460885 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046105147&doi=10.1080%2f15598608.2018.1460885&partnerID=40&md5=be35b6195afe1a6197e4887327e74515 0,article introduce new distribution namely defective dagum distribution ddd improper distribution seen extension type dagum distribution useful accommodate survival data presence cure fraction applications survival methods medical data cure fraction defined proportion patients cured disease become long term survivors great advantage ddd cure fraction written function one parameter also considered presence censored data covariates maximum likelihood bayesian methods estimation model parameters presented simulation study provided evaluate performance maximum likelihood method estimating parameters bayesian analysis posterior distributions parameters estimated using markov chain monte carlo mcmc method example involving real data set presented model based new distribution easy use good alternative analysis real time event data presence censored information cure fraction â© grace scientific publishing llc
10.1063/1.5021242 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046142657&doi=10.1063%2f1.5021242&partnerID=40&md5=1bc2a3cdf118a97e552072208ac6aa8c 0,stochastic simulations biochemical networks vital importance understanding complex dynamics cells tissues however existing methods perform simulations associated computational difficulties addressing remains daunting challenge present introduce selected node stochastic simulation algorithm snssa allows us exclusively simulate arbitrary selected subset molecular species possibly large complex reaction network algorithm based analytical elimination chemical species thereby avoiding explicit simulation associated chemical events species instead described continuously terms statistical moments derived stochastic filtering equation resulting substantial speedup compared gillespie stochastic simulation algorithm ssa moreover show statistics obtained via snssa profit variance reduction significantly lower number monte carlo samples needed achieve certain performance demonstrate algorithm using several biological case studies simulation time reduced orders magnitude â© author
10.1007/s00446-018-0332-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046015826&doi=10.1007%2fs00446-018-0332-8&partnerID=40&md5=613e98e770f2638101740e84617ec408 0,local computation linial focsâ€™ naor stockmeyer stocâ€™ studies whether locally defined distributed computing problem locally solvable classic local computation tasks goal distributed algorithms construct feasible solution constraint satisfaction problem csp locally defined network paper consider problem sampling uniform csp solution distributed algorithms formula presented model ask whether locally definable joint distribution locally sample able use markov random fields gibbs distributions model locally definable joint distributions give two distributed algorithms based markov chains called lubyglauber localmetropolis believe represent two basic approaches distributed gibbs sampling algorithms achieve respective mixing times formula presented formula presented typical mixing conditions n number vertices formula presented maximum degree graph show time bound formula presented optimal distributed sampling also show strong formula presented lower bound particular sampling independent set graphs maximum degree formula presented gives strong separation sampling constructing locally checkable labelings â© author
10.1080/02626667.2018.1457219 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046032909&doi=10.1080%2f02626667.2018.1457219&partnerID=40&md5=c7b2d14c6c0f4e47c6f0ff230974d8c3 0,statistical study made temporal trend extreme rainfall region extremadura spain period â€“ hierarchical spatio temporal bayesian model gev parameterization extreme data employed bayesian model implemented markov chain monte carlo framework allows posterior distribution parameters intervene model estimated results show decrease extreme rainfall winter spring slight increase autumn uncertainty trend parameters obtained hierarchical approach much smaller uncertainties obtained gev model applied locally also found negative relationship nao index extreme rainfall extremadura winter increase observed intensity nao index winter spring slight decrease autumn â© iahs
10.1109/ICOIACT.2018.8350803 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050465590&doi=10.1109%2fICOIACT.2018.8350803&partnerID=40&md5=db0957e88e880948c36df57d2d956b2e 0,national examination un one standard evaluation systems education indonesia results un used consideration development provision assistance educational units effort improve quality education research done get best model average un value hierarchically structured paper employ two level hierarchical linear model nine characteristics school first level four characteristics district city second level complexity model increasing due pattern average un value follows normal mixture distribution pattern bayesian hierarchical mixture normal approach coupled markov chain monte carlo mcmc therefore employed estimate model numerically results show based dic value hierarchical normal mixture model four components un value better performance one level mixture regression model explaining variability average value un â© ieee
10.3389/fpsyg.2018.00607 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046096859&doi=10.3389%2ffpsyg.2018.00607&partnerID=40&md5=460007f5ccbc0303b84063aa22932adf 1,joint models item response times rts response accuracy ra local item dependence composed local ra dependence local rt dependence two components usually caused common stimulus emerge pairs thus violation local item independence joint models called paired local item dependence address issue paired local item dependence applying joint cognitive diagnosis models cdms study proposed joint testlet cognitive diagnosis modeling approach proposed approach extension zhan et al incorporates two types random testlet effect parameters one ra rts account paired local item dependence model parameters estimated using full bayesian markov chain monte carlo mcmc method pisa computer based mathematics data analyzed demonstrate application proposed model brief simulation study conducted demonstrate acceptable parameter recovery consequence ignoring paired local item dependence â© zhan liao bian
10.1109/ICOMET.2018.8346456 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050985121&doi=10.1109%2fICOMET.2018.8346456&partnerID=40&md5=30da782e69b0bbb01956684e720db7d5 1,markov chain monte carlo mcmc methods widely used various areas study appraise posterior inference bayesian framework analyze properties complex systems prevailing theory investigations demonstrate convergence well constructed mcmc schemes appropriate limiting distribution variety different conditions diversification use mcmc schemes urges modelers exploit calibration environmental models especially calibration hydrological models always remained key challenge hydrologic well hydraulic engineers designing hydraulic structures primarily depends truthfulness models study mcmc sampler scheme utilized calibration uncertainty analysis hydrological model sampler scheme named differential evolution adaptive metropolis dream runs multiple chains simultaneously global exploration automatically tunes scale orientation proposal distribution randomized subspaces search application dream improve authenticity model parameters also provides information uncertainty limits predictions helps deciding factor safety design procedures conceptual model used model parameters acquired mcmc sampling procedure calibration validation done using different time slots efficacy dream method expressed temporal scenarios using nash sutcliffe efficiency measure â© ieee
10.1007/s00366-018-0610-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045855864&doi=10.1007%2fs00366-018-0610-x&partnerID=40&md5=faaae17fdd307458449181a6dd1be7ba 0,field measured data reflect real response soil slopes rainfall infiltration provide representative estimates situ soil properties study efficient probabilistic back analysis method characterization spatial variability soil properties used investigate effects field responses various monitoring schemes characterization spatial variability unsaturated soil slope hypothetical heterogeneous slope spatially varied saturated hydraulic conductivity subjecting steady state rainfall infiltration analyzed numerical example spatially varied soil saturated hydraulic conductivity parameterized karhunenâ€“loã¨ve expansion kle given covariance random variables corresponding truncated kle terms considered variables estimated bayesian inverse method synthetic pore water pressure data corrupted artificial noise utilized measurement data nine schemes various locations spacings depths monitoring sections discussed results show local variability reduced substantially around monitoring points pore pressure spatial variability estimated accurately smaller spacing measurement points measurement points installed spacing posterior average cov ks field around rmse map field ã— âˆ’ schemes different depths rmses map field change much posterior uncertainty estimated field reduced increase borehole depth â© springer verlag london ltd part springer nature
10.5194/isprs-annals-IV-3-127-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046789328&doi=10.5194%2fisprs-annals-IV-3-127-2018&partnerID=40&md5=4af747efbc263c024f68835ce8e498e4 0,aftermath wartime attacks often felt long war ended numerous unexploded bombs may still exist ground typically areas documented called impact maps based detection bomb craters paper proposes method automatic detection bomb craters aerial wartime images taken second world war object model bomb craters represented ellipses probabilistic approach based marked point processes determines likely configuration objects within scene adding removing new objects current configuration respectively changing positions modifying ellipse parameters randomly creates new object configurations configuration evaluated using energy function high gradient magnitudes along border ellipse favored overlapping ellipses penalized reversible jump markov chain monte carlo sampling combination simulated annealing provides global energy optimum describes conformance predefined model generating impact map probability map defined created automatic detections via kernel density estimation setting threshold areas around detections classified contaminated uncontaminated sites respectively results show general potential method automatic detection bomb craters automated generation impact map heterogeneous image stock â© authors
10.1007/s11045-018-0577-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045751326&doi=10.1007%2fs11045-018-0577-1&partnerID=40&md5=f84a1dbee828da16e49128eb8460fcba 0,new stochastic nonlocal denoising method based adaptive patch size presented quality restored image improved choosing optimal nonlocal similar patch size site image individually method contains two phase first phase search similar patches base adaptive patch size second phase design denoising algorithm making use similar image patches obtained first step multiple clusters similar patches pixel point searched using markov chain monte carlo sampling many times following adjust patch size according consistency multiple clusters processing repeated obtain optimal patch size corresponding optimal patch cluster get estimation noise free patch cluster employing modified two directional non local method furthermore denoised image obtained using method superposition approach theoretical analysis simulation results show method feasible effective â© springer science+business media llc part springer nature
10.1109/ICCSNT.2017.8343738 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049662771&doi=10.1109%2fICCSNT.2017.8343738&partnerID=40&md5=ccad54e41ea41f9d46ec084953d76ff0 0,based fact image signals possess block sparsity practical application environment novel compressed sensing cs algorithm block sparse image proposed paper namely double level binary tree dbt bayesian model proposed block sparse image time relationship root node leaf node dbt structure defined genetic characteristic block clustering block sparse image executed successfully effectively utilizing markov chain monte carlo mcmc method simulation results prove proposed method block sparse image signal get better recovery results less computation time â© ieee
10.1007/s11538-018-0430-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045666945&doi=10.1007%2fs11538-018-0430-6&partnerID=40&md5=8a5beee9e057fec436c75bac065bfb5d 0,number coupling strategies presented stochastically modeled biochemical processes time dependent parameters particular stacked coupling introduced shown via number examples provide exceptionally low variance generated paths coupling useful numerical computation parametric sensitivities fast estimation expectations via multilevel monte carlo methods provide requisite estimators cases â© society mathematical biology
10.3390/s18041243 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045733767&doi=10.3390%2fs18041243&partnerID=40&md5=b4565b61d050faef42b842b1d67ca67c 1,microscale uncertainties related geometry morphology polycrystalline silicon films constituting movable structures micro electro mechanical systems mems investigated joint numerical experimental approach chip testing device designed fabricated deform compliant polysilicon beam previous studies showed scattering input output characteristics device properly described statistical features related morphology columnar polysilicon film etching process adopted release movable structure taken account work high fidelity finite element model device used feed transitional markov chain monte carlo tmcmc algorithm estimation unknown parameters governing aforementioned statistical features reduce computational cost stochastic analysis synergy proper orthogonal decomposition pod kriging interpolation adopted results reported batch nominally identical tested devices terms measurement error affected probability distributions overall youngâ€™s modulus polysilicon film overetch depth â© authors licensee mdpi basel switzerland
10.1016/j.geoderma.2017.12.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038207851&doi=10.1016%2fj.geoderma.2017.12.010&partnerID=40&md5=13ba11ed1cfb30b158aec5869daf7499 1,one first soil forming processes marine fluviatile clay soils ripening irreversible change physical chemical soil properties especially consistency influence air used bayesian binomial logistic regression bblr update map showing unripened subsoils reclamation area west netherlands similar conventional binomial logistic regression blr bblr binary target variable subsoil ripened unripened modelled bernoulli distribution logit transform `probability success parameter bernoulli distribution modelled linear combination covariates soil type freeboard desired water level ditches compared surface level mean lowest groundwater table capture available information bayesian statistics combines legacy data summarized â€˜priorâ€™ probability distribution regression coefficients actual observations research focused quantifying influence priors different information levels combination different sample sizes resulting parameters maps combined subsamples different size ranging original dataset observations priors representing different levels trust legacy data investigated effect sample size prior distribution map accuracy resulting posterior parameter distributions calculated markov chain monte carlo simulation vary centrality well dispersion especially smaller datasets informative priors decreased dispersion pushed posterior central values towards prior central values interestingly resulting probability maps almost similar however associated uncertainty maps different informative prior decreased prediction uncertainty using â€˜overall accuracyâ€™ validation metric found optimal value prior information level indicating standard deviation legacy data regression parameters multiplied effect detectable smaller datasets area curve validation statistic provide meaningful optimal multiplier standard deviation bayesian binomial logistic regression proved flexible mapping tool accuracy gain compared conventional logistic regression marginal may outweigh extra modelling computing effort â© elsevier b v
10.1002/hyp.11464 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044226097&doi=10.1002%2fhyp.11464&partnerID=40&md5=84ce5b260998e2443375a3ac7359df29 0,finding operational parameter vector always challenging application hydrologic models parameterization limited information observations leading uncertainty best parameter vectors thus beneficial find every possible behavioural parameter vector paper presents new methodology called patient rule induction method parameter estimation prim pe define behavioural parameter vectors located parameter space prim pe used discover regions parameter space containing acceptable model behaviour algorithm consists initial sampling procedure generate parameter sample sufficiently represents response surface uniform distribution within â€œgood enoughâ€� region e performance better predefined threshold rule induction component prim used define regions parameter space acceptable parameter vectors located investigate ability different situations methodology evaluated using four test problems prim pe sampling procedure also compared markov chain monte carlo sampler known differential evolution adaptive metropolis dreamzs algorithm finally spatially distributed hydrological model calibration problem two settings three parameter calibration problem parameter calibration problem solved using prim pe algorithm results show prim pe method captured good enough region parameter space successfully using boxes three parameter parameter problems respectively good enough region used global sensitivity analysis provide broad range parameter vectors produce acceptable model performance moreover specific objective function model structure size boxes used measure equifinality copyright â© john wiley sons ltd
10.1103/PhysRevE.97.042119 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045390322&doi=10.1103%2fPhysRevE.97.042119&partnerID=40&md5=c4d6de63033846ecf8a85fc5cad4c444 0,present path integral formulation darcy equation one dimension random permeability described correlated multivariate lognormal distribution path integral evaluated markov chain monte carlo method obtain pressure distributions shown agree solutions corresponding stochastic differential equation dirichlet neumann boundary conditions extension approach flow random media two three dimensions discussed â© american physical society
10.1186/s12859-018-2099-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045277015&doi=10.1186%2fs12859-018-2099-0&partnerID=40&md5=f4684fdaaf86ba5b48286ad5599b0afd 0,background somatic copy number alternations scnas utilized infer tumor subclonal populations whole genome seuqncing studies usually read count ratios tumor normal paired samples serve inferring proxy existing scna based subclonal population inferring tools consider gc bias tumor normal sample fature fully offset read count ratio however found read count ratio scna segments presents log linear biased pattern influence existing read count ratios based subclonal inferring tools performance currently correction tools take account read ratio bias results present pre scnaclonal tool improving tumor subclonal population inferring correcting gc bias scnas level pre scnaclonal first corrects gc bias using markov chain monte carlo probability model accurately locates baseline dna segments containing scnas hierarchy clustering model show pre scnaclonal superiority exsiting gc bias correction methods level subclonal population conclusions pre scnaclonal run independently well serving pre processing gc correction step conjuntion exsiting scna based subclonal inferring tools â© author
10.1186/s12955-018-0879-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045246890&doi=10.1186%2fs12955-018-0879-x&partnerID=40&md5=c92cff5675557faf7468d9fda39ed41c 0,background longitudinal invariance perquisite valid comparison oral health related quality life ohrqol scores time item response theory irt models assess measurement invariance allow better estimation associations predictors latent construct extending irt models study aimed investigate longitudinal invariance two item short forms child perception questionnaire cpq regression short form rsf item impact short form isf identify factors associated adolescents ohrqol change methods students equivalent us grades born april may age randomly selected secondary schools invited participate study followed years data cpq rsf cpq isf demographics oral health behavior status collected explanatory graded response models fitted short forms cpq data assessing longitudinal invariance factors associated ohrqol bayesian estimation method monte carlo markov chain mcmc gibbs sampling adopted parameter estimation credible intervals used inference results data children age baseline children age follow analyzed years old children healthier oral health behavior better gum status families parents employed parents education level found associated better ohrqol four items among short forms lacked longitudinal invariance statistical adjustment longitudinal invariance ohrqol found improved general years predictor associated ohrqol follow decreased family income ohrqol worsened years conclusions irt explanatory analysis enables valid identification factors associated ohrqol changes time provides important information oral healthcare researchers policymakers â© author
10.1109/TCBB.2018.2825327 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045296828&doi=10.1109%2fTCBB.2018.2825327&partnerID=40&md5=9107ad277c25b200f249a664b2e34b18 0,ordinary differential equations odes provide powerful formalism model molecular networks mechanistically however inferring model structure given set time course measurements large number alternative molecular mechanisms challenging open research question existing search heuristics designed finding single best model configuration account uncertainty selecting network components study present novel markov chain monte carlo approach performing bayesian model structure inference ode models formulate metropolis algorithm explores model space efficiently suitable obtaining probabilistic inferences network structure method special parallelization possibilities demonstrated using simulated data furthermore apply method time course rna sequencing data set infer structure transiently evolving core regulatory network steers helper th cell differentiation results agreement earlier finding th lineage specific differentiation program evolves three sequential phases analysis provides us probabilistic predictions molecular interactions active different phases th cell differentiation oapa
10.1186/s12885-018-4308-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045020949&doi=10.1186%2fs12885-018-4308-7&partnerID=40&md5=fac38cb14adc63d03a2bc4a5286e46f6 0,background sorafenib transarterial chemoembolization tace might provide survival benefit advanced hepatocellular carcinoma hcc adopting either first line therapy carries major cost resource implications aimed estimate cost effectiveness sorafenib tace advanced hcc methods markov model constructed hypothetical cohort patients aged years advanced hcc child pugh b cirrhosis year time frame three strategies full dose adjusted sorafenib tace compared two cost settings china usa transition probabilities utility costs extracted systematic review articles sensitivity analysis monte carlo analysis conducted results full dose adjusted sorafenib respectively produced quality adjusted life years qalys tace produced qalys incremental cost effectiveness ratio icer full dose sorafenib versus tace qaly china whereas full dose sorafenib dominant strategy icer qaly compared tace usa compared full dose sorafenib dose adjusted sorafenib dominant strategy negative icers china qaly usa qaly however dose adjusted sorafenib available currently full dose sorafenib compared tace acceptability curves shown full dose sorafenib optimal strategy accepted thresholds wtp two countries specifically full dose sorafenib cost effective treatment compared tace wtp set usa whereas china tace favorable full dose sorafenib wtp set conclusions dose adjusted sorafenib may cost effective compared full dose sorafenib tace advanced hcc patients however confining comparisons full dose sorafenib tace full dose sorafenib cost effective patients accepted thresholds wtp â© author
10.1103/PhysRevE.97.042406 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045006650&doi=10.1103%2fPhysRevE.97.042406&partnerID=40&md5=a4590ab0da0409917c1d89263bcb6c3b 0,competition main driver population dynamics shapes genetic composition populations assembly ecological communities neutral models assume individuals equivalent dynamics governed demographic shot noise steady state species abundance distribution sad reflects mutation extinction equilibrium recently many empirical theoretical studies emphasized importance environmental variations affect coherently relative fitness entire populations consider two generic time averaged neutral models relative fitness species fluctuates independently time mean zero first model describes system local competition linear fitness dependence birth death rates second model b competition global fitness dependence nonlinear due nonlinearity model b admits noise induced stabilization mechanism facilitates invasion new mutants self consistent mean field approach used reduce multispecies problem two species dynamics large n asymptotics emerging set fokker planck equations presented solved analytic expressions shown fit sads obtained extensive monte carlo simulations numerical solutions corresponding master equations â© american physical society
10.1109/TNSE.2018.2823324 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045221359&doi=10.1109%2fTNSE.2018.2823324&partnerID=40&md5=2eea0493d8c5735fb0c0ff2d87a75172 0,work proposes novel hybrid mixed membership blockmodels hmmb integrate three canonical network models capture characteristics real world interactions community structure mixed membership power law distributed node degrees sparsity hybrid model provides capacity needed realism enabling control inference individual attributes interest mixed membership popularity rigorous inference procedure developed estimating parameters model iterative bayesian updates targeted initialization improve identifiability estimation mixed membership parameters cram x e r rao bound derived quantifying information content terms fisher information matrix effectiveness proposed inference demonstrated simulations estimates achieve covariances close cram x e r rao bound maintaining good truth coverage illustrate utility proposed model inference procedure application detecting community cue nodes success depends accurately estimating mixed memberships performance evaluations simulated real world data show inference hmmb able recover mixed memberships presence challenging community overlap leading significantly improved detection performance algorithms based network modularity simpler models oapa
10.1080/17415977.2017.1322078 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019217535&doi=10.1080%2f17415977.2017.1322078&partnerID=40&md5=a8786be8c16ebbe141c4baa964cdb897 0,paper presents innovative application new class parallel interacting markov chains monte carlo solve bayesian history matching bhm problem bhm consists sampling posterior distribution given bayesian theorem markov chain monte carlo mcmc well suited sampling principle type distribution however number iteration required traditional single chain mcmc prohibitive bhm applications furthermore history matching typically highly nonlinear inverse problem leads complex posterior distributions characterized many separated modes therefore single chain trapped local mode parallel interacting chains interesting way overcome problem shown paper addition presented new approaches define starting points parallel chains validation purposes proposed methodology firstly applied simple challenging cross section reservoir model many modes posterior distribution afterwards application realistic case integrated geostatistical modelling also presented results showed combination parallel interacting chain capabilities distributed computing commonly available nowadays promising solve bhm problem â© informa uk limited trading taylor francis group
10.1080/01621459.2017.1294075 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040770199&doi=10.1080%2f01621459.2017.1294075&partnerID=40&md5=25e3dffd8186e7104b384c6a6d98ce96 2,many markov chain monte carlo techniques currently available rely discrete time reversible markov processes whose transition kernels variations metropolisâ€“hastings algorithm explore generalize alternative scheme recently introduced physics literature peters de target distribution explored using continuous time nonreversible piecewise deterministic markov process metropolisâ€“hastings algorithm trial move region lower target density equivalently higher â€œenergy â€� current state rejected positive probability alternative approach particle moves along straight lines around space facing high energy barrier rejected path modified bouncing barrier reformulating algorithm using inhomogeneous poisson processes exploit standard sampling techniques simulate exactly markov process wide range scenarios interest additionally target distribution given product factors dependent subsets state variables posterior distribution associated probabilistic graphical model method modified take advantage structure allowing computationally cheaper â€œlocalâ€� bounces involve state variables associated factor state variables keep evolving context leveraging techniques chemical kinetics propose several computationally efficient implementations experimentally new class markov chain monte carlo schemes compares favorably state art methods various bayesian inference tasks including high dimensional models large datasets supplementary materials article available online â© â© american statistical association
10.1080/01621459.2017.1287080 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048095380&doi=10.1080%2f01621459.2017.1287080&partnerID=40&md5=e7765e6af19539d1aa9a16c3deb8c7b3 0,factor models used wide range areas two issues bayesian versions models lack invariance ordering scaling variables computational inefficiency article develops invariant efficient bayesian methods estimating static factor models approach leads inference depend upon ordering scaling variables provide arguments explain invariance beginning identified parameters subject orthogonality restrictions use parameter expansions obtain specification computationally convenient conditional posteriors show significant gains computational efficiency identifying restrictions commonly employed result interpretable factors loadings using approach imposed ex post allows us investigate several alternative identifying noninvariant schemes without need respecify resample model illustrate methods two macroeconomic datasets â© â© american statistical association
10.1080/07350015.2016.1164707 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018180266&doi=10.1080%2f07350015.2016.1164707&partnerID=40&md5=a005e73d2038818097e5d22523f35e4e 2,restrictions risk pricing dynamic term structure models dtsms tighten link cross sectional time series variation interest rates make absence arbitrage useful inference expectations article presents new econometric framework estimation affine gaussian dtsms restrictions risk prices addresses issues large model space model uncertainty using bayesian approach simulation study demonstrates good performance proposed method data u â treasury yields calls tight restrictions risk pricing level risk priced changes slope affect term premia incorporating restrictions changes model implied short rate expectations term premia interest rate persistence higher maximally flexible model hence expectations future short rates variableâ€”restrictions risk prices help resolve puzzle implausibly stable short rate expectations literature consistent survey evidence conventional macro wisdom restricted models attribute large share secular decline long term interest rates expectations future nominal short rates supplementary materials article available online â© american statistical association
10.1080/07350015.2016.1141096 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044229110&doi=10.1080%2f07350015.2016.1141096&partnerID=40&md5=21bebda8c36afdf5d0f30f0a4be3be57 1,email marketing increasingly important tool todayâ€™s businesses article propose counting process based bayesian method quantifying effectiveness email marketing campaigns conjunction customer characteristics model explicitly addresses seasonality data accounts impact customer characteristics purchasing behavior evaluates effects email offers well interactions customer characteristics using proposed method together propensity score based unit matching technique alleviating potential confounding analyze large email marketing dataset online ticket marketplace evaluate short long term effectiveness email campaigns shown email offers increase customer purchase rate immediately longer term customersâ€™ characteristics length shopping history purchase recency average ticket price average ticket count number genres purchased also affect customersâ€™ purchase rate strong positive interaction uncovered email offer purchase recency suggesting customers inactive recently likely take advantage promotional offers supplementary materials article available online â© american statistical association
10.1080/03639045.2017.1405430 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035766963&doi=10.1080%2f03639045.2017.1405430&partnerID=40&md5=f8b3888bdd18562fc7005894b473192c 0,paper propose stochastic gamma process model assessing similarity two dissolution profiles based proposed stochastic model utilize difference factor similarity factor test similarity two dissolution profiles based bootstrap confidence intervals performances proposed methods compared multivariate test procedure via monte carlo simulation studies proposed testing methods shown powerful effectively controlling error rate proposed model provides simple yet useful alternative parametric statistical model assessing similarity two dissolution profiles methods illustrated numerical example â© informa uk limited trading taylor francis group
10.1093/jas/sky041 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045137534&doi=10.1093%2fjas%2fsky041&partnerID=40&md5=af7cb947a828b1281e3b00504c9b0985 0,reproductive performance important component cattle production standpoint economic sustainability commercial beef enterprises heifer pregnancy hpg stayability stay genetic predictions selection tools published red angus association america raaa assist improvements reproductive performance given importance hpg stay profitability commercial beef enterprises objective study identify qtl associated hpg stay red angus cattle genome wide association study gwas performed using deregressed hpg stay ebv calculated using single trait animal model generation pedigree data spring raaa national cattle evaluation individual animal possessed snp genotypes individual animals deregressed ebv reliability gt merged genotype file marker quality control performed criteria sifting genotypes consisted removing markers following found average call rate less minor allele frequency lt lack hardyâ€“weinberg equilibrium p lt extreme linkage dis equilibrium r gt criteria resulted animals snp available gwas association studies performed using bayes cï€ model bolt software package marker significance calculated posterior probability inclusion ppi number instances specific marker sampled divided total number samples retained markov chain monte carlo chains nine markers ppi â‰¥ identified qtl associated hpg bta twelve markers ppi â‰¥ identified qtl associated stay bta â© author
10.1080/01621459.2017.1286241 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048085888&doi=10.1080%2f01621459.2017.1286241&partnerID=40&md5=244d057eb665c5685114de4ca4630ce9 0,introduce wavelet domain method functional analysis variance fanova based bayesian hierarchical model employs graphical hyperprior form markov grove mg â€”that collection markov treesâ€”for linking presence absence factor effects location scale combinations thereby incorporating natural clustering factor effects wavelet domain across locations scales inference model enjoys analytical simplicity computational efficiency specifically posterior full hierarchical model available closed form pyramid algorithm operationally similar mallatâ€™s pyramid algorithm discrete wavelet transform dwt achieving exact bayesian inference computational efficiencyâ€”linear number observations number locationsâ€”as carrying dwt particular posterior probabilities presence factor contributions functional variation directly available pyramid algorithm posterior samples factor effects drawn directly exact posterior standard markov chain monte carlo investigate performance method extensive simulation show substantially outperforms existing wavelet domain fanova methods variety common settings illustrate method analyzing orthosis data supplementary materials article available online â© â© american statistical association
10.1080/15366367.2018.1437306 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044833588&doi=10.1080%2f15366367.2018.1437306&partnerID=40&md5=3be3e3c88e1a5d2334b024f0a5ae6c0c 0,interest bayesian analysis item response theory irt models grown tremendously due appeal paradigm among psychometricians advantages methods analyzing complex models availability general purpose software possible models include models reflect multidimensionality due designed test structure construct irrelevant variance mixed item formats using markov chain monte carlo methods models estimated evaluated model fit addition discussing bayesian analysis analyses three irt models designed account extreme response style illustrated irtree multidimensional nominal response model mnrm modified generalized partial credit model mpcm results indicated may little impact model choice substantive trait estimates data set studied herein model fit results favored mnrm mpcm irtree model â© taylor francis
10.1080/15598608.2017.1343693 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025596312&doi=10.1080%2f15598608.2017.1343693&partnerID=40&md5=5c10cc66fa7535ea8f353901fa9eb705 0,recent years many efforts develop new statistical distribution flexibility fitted well complex data article consider statistical inference six parameter mcdonald extended weibull distribution mcew based progressively type ii censored sample maximum likelihood estimates mles six parameters asymptotic distribution obtained based asymptotic distribution asymptotic confidence limits parameters computed also propose bootstrap confidence intervals parameters bayes estimates associated highest posterior density credible intervals computed using markov chain monte carlo mcmc method including gibbs sampling technique metropolisâ€“hastings algorithm simulation experiments performed compare proposed methods corresponding confidence intervals different censoring schemes finally concluding remarks given â© grace scientific publishing llc
10.1080/01621459.2016.1264957 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041512198&doi=10.1080%2f01621459.2016.1264957&partnerID=40&md5=f4b2d68cbd6b796c88395857482ca931 2,decision tree ensembles extremely popular tool obtaining high quality predictions nonparametric regression problems unmodified however many commonly used decision tree ensemble methods adapt sparsity regime number predictors larger number observations recent stream research concerns construction decision tree ensembles motivated generative probabilistic model influential method bayesian additive regression trees bart framework article take bayesian point view problem show construct priors decision tree ensembles capable adapting sparsity predictors placing sparsity inducing dirichlet hyperprior splitting proportions regression tree prior characterize asymptotic distribution number predictors included model show prior easily incorporated existing markov chain monte carlo schemes demonstrate approach yields useful posterior inclusion probabilities predictor illustrate usefulness approach relative decision tree ensemble approaches simulated real datasets supplementary materials article available online â© â© american statistical association
10.1080/10807039.2017.1394174 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035123230&doi=10.1080%2f10807039.2017.1394174&partnerID=40&md5=bd52f8c810e3df6846246e29a9fe868d 0,influence various heterogeneous parameters stochastic uncertain factors pollutant particles industrial effluents water system investigated using advection dispersion equation ade bayesian approximation decay coefficient decomposed exact part deviation part coefficient used find errors deviation decay flow pollutants two bayesian models developed analyze posterior distributions find bayes factor stochastic covariance estimation bayesian calibration focused characteristics mechanistic statistical approximation efficiency accuracy developed models checked results obtained basis confidence interval markov chain monte carlo simulation used acquire convergence point parameters posterior estimation stochastic covariance white noise represents effect random factors river system analysis revealed rate decay dependent upon duration distance traveled pollutants collaboration ade bayesian approximation encourage water quality management environmental modeling â© taylor francis group llc
10.1080/10618600.2017.1366913 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046690915&doi=10.1080%2f10618600.2017.1366913&partnerID=40&md5=b5311952640d24ce40ac026cdf59cc03 1,topic models specifically class latent dirichlet allocation lda widely used probabilistic modeling text markov chain monte carlo mcmc sampling posterior distribution typically performed using collapsed gibbs sampler propose parallel sparse partially collapsed gibbs sampler compare speed efficiency state art samplers topic models five well known text corpora differing sizes properties particular propose compare two different strategies sampling parameter block latent topic indicators experiments show increase statistical inefficiency partial collapsing smaller commonly assumed compensated speedup parallelization sparsity larger corpora also prove partially collapsed samplers scale well size corpus proposed algorithm fast efficient exact used modeling situations ordinary collapsed sampler supplementary materials article available online â© â© american statistical association institute mathematical statistics interface foundation north america
10.1016/j.cageo.2018.01.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044630004&doi=10.1016%2fj.cageo.2018.01.011&partnerID=40&md5=c7b8e7ac7073f2c1b142725ec63d7e1f 3,paper presents new computer code developed solve magnetotelluric mt inverse problem using bayesian trans dimensional markov chain monte carlo algorithm mt data sensitive depth distribution rock electric conductivity reciprocal resistivity solution provided probability distribution called posterior probability distribution ppd conductivity depth together ppd interface depths ppd sampled via reversible jump markov chain monte carlo rjmcmc algorithm using modified metropolis hastings mh rule accept discard candidate models along chains optimal parameterization inversion process generally unknown trans dimensional approach used allow dataset indicate probable number parameters needed sample ppd algorithm tested two simulated datasets set mt data acquired clare basin county clare ireland simulated datasets correct number conductive layers depth associated electrical conductivity values retrieved together reasonable estimates uncertainties investigated parameters results inversion field measurements compared results obtained using deterministic method well log data nearby borehole ppd good agreement well log data showing main structure high conductive layer associated clare shale formation study demonstrate new code go beyond algorithms developend using linear inversion scheme used pass subjective choices parameterizations e number horizontal layers parameterization estimate realistic uncertainties retrieved parameters algorithm implemented using simple mpi approach independent chains run isolated cpu take full advantage parallel computer architectures case large number data master slave appoach used master cpu samples parameter space slave cpus compute forward solutions â© authors
10.13195/j.kzyjc.2017.0213 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048893443&doi=10.13195%2fj.kzyjc.2017.0213&partnerID=40&md5=d4dbcda3fe15b4c5cf7a9382fb9623fb 0,prediction models basis scientific formulation emergency disposal rescue measures order quickly accurately construct forecasting model sudden water pollution accidents paper regards problem bayesian estimation problem obtains posterior probability density function model parameters according finite difference method bayesian inference using improved metropolis hastings sampling method reasonable prediction model parameters obtained taking sudden water pollution event certain open channel example effects different observation noises parameters calibration results discussed two scenarios non uniform flow control non uniform flow non equal capacity control compared parameter true value bayesian markov chain monte carlo method results show improved bayesian markov chain monte carlo method give better parameter value application good anti noise provide new approach build forecast model sudden water pollution accidents â© editorial office control decision right reserved
10.1016/j.soildyn.2018.01.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044639054&doi=10.1016%2fj.soildyn.2018.01.014&partnerID=40&md5=6bfcc768e40c637efd2ead743a9dd4bc 0,conduct numerical experiments estimate variability linear nonlinear soil amplifications due uncertainty shallow wave velocity profiles derived surface wave phase velocity inversions using markov chain monte carlo method first generate synthetic observed phase velocities rayleigh waves two three layer models shallow soil final models sampling explain well true wave velocity profiles phase velocities also estimate uncertainties model parameter synthetic strong motion applied engineering bedrock sampled models obtain surface motion assuming linear nonlinear amplifications found nonlinear amplification shows less variability also flatter spectral shape linear amplification particularly high frequencies distributions ground motion proxies generally less uncertainty nonlinear amplification well also find observational errors phase velocities less influence variability nonlinear amplification linear case result caused high damping factor applied nonlinear soil response â© elsevier ltd
10.1002/stc.2140 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040604080&doi=10.1002%2fstc.2140&partnerID=40&md5=bba025d8329c56917c428333724ed844 1,paper proposes bayesian method structural model updating damage detection using modal data recently developed markov chain monte carlo algorithm adopted handle model updating problem proposed bayesian method focuses calculation posterior probability distribution function uncertain model parameters addition probable values uncertain parameters associated uncertainties calculated consideration effects modeling error measurement noise experimental case study carried shear building model laboratory conditions study identifiability model updating problem following proposed bayesian method results demonstrate change posterior probability distribution function uncertain parameters amount measured information also demonstrates ability proposed method handle unidentifiable problems proposed bayesian method applied structural damage detection calculating probability distribution extent damage various structural components demonstrate proposed bayesian damage detection method ambient vibration tests carried story steel frame bolted connections joint damage simulated loosening bolts target beam column connection model updating results show uncertainty associated rotational stiffness steel joints high rendering problem almost unidentifiable although problem almost unidentifiable calculated probability distribution damage extent still locate damaged joint estimate damage extent e percentage reduction rotational stiffness together associated uncertainty copyright â© john wiley sons ltd
10.3997/1873-0604.2017064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047529657&doi=10.3997%2f1873-0604.2017064&partnerID=40&md5=ca0b18546473bb4f39cdbe0058a0ce00 0,surface nuclear magnetic resonance technique capable providing insight subsurface aquifer properties produce estimates aquifer properties spatial distribution water content parameters controlling duration nuclear magnetic resonance signal inversion required essential reliable interpretation estimated subsurface models understanding uncertainty correlation parameters estimated models quantify parameter uncertainty correlation surface nuclear magnetic resonance inversion markov chain monte carlo approach demonstrated markov chain monte carlo approaches previously employed invert surface nuclear magnetic resonance data primary focus quantifying parameter uncertainty focus paper investigate whether parameters estimated models exhibit correlation one another equally important building reliable interpretation subsurface understanding parameter uncertainty utility markov chain monte carlo approach demonstrated investigation three questions first question investigates whether parameters describing water content thickness layer exhibit strong correlation question stems applying concepts known electromagnetic surveys layer thickness layer resistivity parameters strongly correlated surface nuclear magnetic resonance inversion water contentâ€“layer thickness correlation surface nuclear magnetic resonance large effects quantifying total water content affect ability identify layer boundaries second question examines whether parameter controlling duration nuclear magnetic resonance signal exhibits correlation water content layer thickness parameters resolution surface nuclear magnetic resonance typically consider duration signal focuses primarily distribution current amplitudes form suite transmit pulses common treat regions short duration signal greater uncertainty important understand whether signal duration controls resolution medium long duration signals well third question explores parameter uncertainty produced markov chain monte carlo approach consistent produced alternative approach based upon posterior covariance matrix linearised inversion ability markov chain monte carlo approach thoroughly explore model space provides means improve reliability surface nuclear magnetic resonance aquifer characterisations quantifying parameter uncertainty correlation â© european association geoscientists engineers
10.1007/s13137-017-0101-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044538117&doi=10.1007%2fs13137-017-0101-z&partnerID=40&md5=08a9db2bb7693dd26bc7ce30e285935b 1,monte carlo methods deal generating random variates probability density functions order estimate unknown parameters general functions unknown parameters compute expected values variances covariances one generally works multivariate normal distribution due central limit theorem however random variables normal distribution random variables different distribution combined normal distribution valid anymore monte carlo method needed get expected values variances covariances random variables distributions different normal distribution error propagation monte carlo methods discussed methods generating random variates multivariate normal distribution multivariate uniform distribution monte carlo integration presented leading samplingâ€“importance resampling algorithm markov chain monte carlo methods provide metropolis algorithm gibbs sampler additional ways generating random variates special topic gibbs sampler computing propagating large covariance matrices task arises instance geopotential determined satellite observations example minimal detectable outlier shows monte carlo method used determine power hypothesis test â© springer verlag gmbh germany part springer nature
10.1016/j.dsp.2018.01.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041405475&doi=10.1016%2fj.dsp.2018.01.004&partnerID=40&md5=fa5d06a065568755e65f502d30318925 2,many applications signal processing require estimation parameters interest given set observed data specifically bayesian inference needs computation posteriori estimators often expressed complicated multi dimensional integrals unfortunately analytical expressions estimators found real world applications monte carlo methods feasible approach powerful class monte carlo techniques formed markov chain monte carlo mcmc algorithms generate markov chain stationary distribution coincides target posterior density work perform thorough review mcmc methods using multiple candidates order select next state chain iteration respect classical metropolisâ€“hastings method use multiple try techniques foster exploration sample space present different multiple try metropolis schemes ensemble mcmc methods particle metropolisâ€“hastings algorithms delayed rejection metropolis technique highlight limitations benefits connections differences among different methods compare numerical simulations â© elsevier inc
10.1051/ro/2017076 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049627997&doi=10.1051%2fro%2f2017076&partnerID=40&md5=73780c6a022bc567cee0da6c6d294171 0,one fundamental problems supply chain management design effective inventory control policies models stochastic demands efficient inventory management maintain high customers service level reduce unnecessary stock expenses significant key factors profit loss organization study new formulation inventory system analyzed discrete markov modulated demand employ simulation based optimization combines simulated annealing pattern search ranking selection saps rs methods approximate near optimal solutions problem determining values demand employ novel approach achieve minimum cost total scm supply chain management network proposed approach hybrid improved cuckoo search algorithm ics genetic algorithm ga presented main platform solve problem computational results demonstrate effectiveness applicability proposed approach â© edp sciences roadef smai
10.1142/S0218539318500109 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040703321&doi=10.1142%2fS0218539318500109&partnerID=40&md5=a9018d69311048309664d8920a41a532 1,three parameter burr type xii distribution pbxiid quite flexible contains wide range distribution shapes fitting lifetime data however difficult obtain reliable estimates pbxiid quantiles censored samples evaluating reliability lifetime data work metropolis hastings markov chain monte carlo h mcmc procedure proposed obtain reliable maximum likelihood estimates mles pbxiid quantiles type ii censored sample moreover parametric bootstrap percentile procedure used obtain confidence interval quantile pbxiid performance proposed h mcmc method evaluated view monte carlo simulations two examples regarding survival lifetimes breast cancer patients reliability inference lifetimes oil well pumps sucker rod oil pumping systems applied illustrate applications proposed h mcmc method bootstrap procedure â© world scientific publishing company
10.1016/j.jhydrol.2018.02.026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043474435&doi=10.1016%2fj.jhydrol.2018.02.026&partnerID=40&md5=65272fe4e1e3756e3b484e9ab9de144f 1,essay illustrates recent developments differential evolution adaptive metropolis dream matlab toolbox vrugt delineate sample behavioural solution space set theoretic likelihood functions used within glue limits acceptability framework beven binley beven freer beven work builds dream abc algorithm sadegh vrugt enhances significantly accuracy cpu efficiency bayesian inference glue particular shown lack adequate sampling model space might lead unjustified model rejection â© elsevier b v
10.5705/ss.202016.0378 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045687807&doi=10.5705%2fss.202016.0378&partnerID=40&md5=cb07fd6dd4081a30450be00889fd3452 0,naive importance sampling estimator based samples single importance density numerically unstable consider generalized importance sampling estimators samples one probability distribution combined study problem markov chain monte carlo context independent samples replaced markov chain samples chains converge respective target distributions polynomial rate two finite moment conditions show central limit theorem holds generalized estimators develop easy implement method calculate valid asymptotic standard errors based batch means provide batch means estimator calculating asymptotically valid standard errors geyer reverse logistic estimator illustrate method via three examples particular generalized importance sampling estimator used bayesian spatial modeling binary data perform empirical bayes variable selection batch means estimator enables standard error calculations high dimensional settings â© institute statistical science rights reserved
10.1002/net.21805 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040249259&doi=10.1002%2fnet.21805&partnerID=40&md5=3f32299533c375c94d33995ff5deecce 0,counting number independent sets important problem graph theory combinatorics optimization social sciences however polynomial time exact calculation even reasonably close approximation widely believed impossible since existence implies efficient solution various problems non deterministic polynomial time complexity class cope approximation challenge express independent set counting problem rare event estimation problem develop multilevel splitting algorithm generally capable delivering accurate results using manageable computational effort even applied large graphs apply algorithm counting optimization finding maximum independent set problems show compares favorably existing state art â© wiley periodicals inc
10.1016/j.jeconom.2017.11.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042878221&doi=10.1016%2fj.jeconom.2017.11.009&partnerID=40&md5=ea6217ce4788c58cd2bb70abb5683e41 0,vector autoregressive var models main work horse models macroeconomic forecasting provide framework analysis complex dynamics present macroeconomic variables whether classical bayesian approach adopted var models linear gaussian innovations limit model ability explain relationships macroeconomic series propose nonparametric var model allows nonlinearity conditional mean heteroscedasticity conditional variance non gaussian innovations approach differs previous studies modelling stationary transition densities using bayesian nonparametric methods bayesian nonparametric var bayesnp var model applied us uk macroeconomic time series compared bayesian var models show bayesnp var flexible model able account nonlinear relationships well heteroscedasticity data terms short run sample forecasts show bayesnp var predictively outperforms competing models â© authors
10.1007/s10208-016-9340-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995773214&doi=10.1007%2fs10208-016-9340-x&partnerID=40&md5=6821402a9d52732c4951b9826c27e685 1,metropolis algorithms approximate sampling probability measures infinite dimensional hilbert spaces considered generalization preconditioned crankâ€“nicolson pcn proposal introduced new proposal able incorporate information measure interest numerical simulation bayesian inverse problem indicates metropolis algorithm proposal performs independently state space dimension variance observational noise moreover qualitative convergence result provided comparison argument spectral gaps particular shown generalization inherits geometric convergence metropolis algorithm pcn proposal â© sfocm
468.57353725042196 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047839332&partnerID=40&md5=bd5a5b9fca658d3066cf6a6dba55aa63 0,ranking comparing items crucial collecting information preferences many areas marketing politics mallows rank model among successful approaches analyse rank data computational complexity limited use particular form based kendall distance develop new computationally tractable methods bayesian inference mallows models work right invariant distance method performs inference consensus ranking items also based partial rankings top k items pairwise comparisons prove items none assessors ranked influence maximum posteriori consensus ranking therefore ignored assessors many heterogeneous propose mixture model clustering homogeneous subgroups cluster specific consensus rankings develop approximate stochastic algorithms allow fully probabilistic analysis leading coherent quantifications uncertainties make probabilistic predictions class membership assessors based ranking items predict missing individual preferences needed recommendation systems test approach using several experimental benchmark datasets c valeria vitelli ã˜ystein sã rensen marta crispino arnoldo frigessi elja arjas
10.1016/j.im.2017.08.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027521493&doi=10.1016%2fj.im.2017.08.001&partnerID=40&md5=5f7ec6d38377710d817fd7643263631e 1,study investigates influences consumersâ€™ extent online search e number relevant web stores visited purchase dataset containing website visitation transaction activities panel us consumers used test hypotheses developed study results indicate diminishing effect competitive density extent search use advanced information technologies induces searches consumers also search experience products search products contrast prediction nonelectronic market furthermore online purchase experience increases product specific experience reduces prepurchase search â© elsevier b v
15.178621326817021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048047668&partnerID=40&md5=91757f78b18e8cdb83ced5d16e4ec71c 0,latent dirichlet allocation lda well known topic model often used make inference regarding properties collections text documents lda hierarchical bayesian model involves prior distribution set latent topic variables prior indexed certain hyperparameters even though large impact inference usually chosen either ad hoc manner applying algorithm whose theoretical basis firmly established present method based combination markov chain monte carlo importance sampling estimating maximum likelihood estimate hyperparameters method may viewed computational scheme implementation empirical bayes analysis comes theoretical guarantees key feature approach provide theoretically valid error margins estimates experiments synthetic real data show good performance methodology keywords empirical bayes inference latent dirichlet allocation markov chain monte carlo model selection topic modelling â© clint p george hani doss
10.1177/0962280216659312 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042844754&doi=10.1177%2f0962280216659312&partnerID=40&md5=0915106a495df3fa369314bcddd9cca5 0,longitudinal zero inflated count data encountered frequently substance use research assessing effects covariates risk factors outcomes often time terminal event death dropout repeated measure count responses collected subject setting longitudinal counts censored terminal event time terminal event may depend longitudinal outcomes study described herein expand class joint models longitudinal survival data accommodate zero inflated counts time event data using cox proportional hazards model piecewise constant baseline hazard use bayesian framework via markov chain monte carlo simulations implemented bugs programming language via extensive simulation study apply joint model obtain estimates accurate corresponding independence model apply proposed method alpha tocopherol beta carotene lung cancer prevention study â© â© author
34.28685268496534 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047752050&partnerID=40&md5=7f037032bac92d28fcbe20acbf3df491 0,develop traffic conflict model signalized intersections traffic conflict data extracted h video data signalized intersections accounting traffic conflict heterogeneity random parameters poisson lognormal rp pln traffic conflict model random effects poisson lognormal pln traffic conflict model developed posterior distributions models parameters estimated bayesian method markov chain monte carlo mcmc simulation using deviance information criterion residual standardization decision coefficient goodness fit models compared results show traffic conflict models handle traffic conflict heterogeneity however goodness fit rp pln traffic conflict model performs pln traffic conflict model given variables remained unchanged increase crossing volume increase right turn crossing rc traffic conflict increase right turn volume increase rc traffic conflict increase proportion large vehicles increase rc traffic conflict raised pavement channelized islands decrease rc traffic conflict respectively acceleration lane decrease rc traffic conflict increase right turn radius decrease rc traffic conflict installation right turn yield sign decrease rc traffic conflict setting protected right turn phase decrease rc traffic conflict â© editorial department china journal highway transport right reserved
10.1051/0004-6361/201731313 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046660610&doi=10.1051%2f0004-6361%2f201731313&partnerID=40&md5=cce3513bb6a3f8ab251af9cfcf2a9b85 0,aims fit log normal function dwarf orbital surface density distribution gas giant planets mass range times jupiter au methods used markov chain monte carlo approach explore likelihoods various parameter values consistent point estimates data given assumed functional form results fit consistent radial velocity microlensing direct imaging observations well motivated theoretical phenomenological points view predicts results future surveys present probability distributions parameter maximum likelihood estimate solution conclusions suggest function makes physical sense widely used functions explore implications results design future exoplanet surveys â© eso
10.1016/j.ejor.2017.09.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030452527&doi=10.1016%2fj.ejor.2017.09.014&partnerID=40&md5=9c2446a7a5a043658812b694fdeecc93 1,large cities emerging economies traditional retail present high density multiple independently owned small stores city block consequently faced stockout consumers may substitute different product store also switch neighboring store suppliers may take advantage behavior strategically supplying stores coherent manner study problem using consumer choice models build two consumer choice models consumer behavior first build nested logit model consumer choice process consumer chooses store first level selects product second level consider exogenous substitution model models consumer may substitute either store level product level furthermore estimate parameters two models using markov chain monte carlo algorithm bayesian manner numerically find nested logit model outperforms exogenous substitution model estimating substitution probabilities information consumersâ€™ purchase records helps improve estimation accuracies first choice probabilities substitution probabilities beginning inventory level low finally show explicitly including substitution behavior inventory optimization process significantly increase expected profit â© elsevier b v
10.3390/en11040802 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045415099&doi=10.3390%2fen11040802&partnerID=40&md5=ba4b5591e8a256cb9162e7b01272b273 0,performance gap expected actual energy performance buildings elements stimulated interest situ measurements research employed quasi static analysis methods estimate heat loss metrics u values without taking advantage rich time series data often recorded paper presents dynamic bayesian based method estimate thermophysical properties building elements situ measurements analysis includes markov chain monte carlo mcmc estimation priors uncertainty analysis model comparison select appropriate model data two case study dwellings used illustrate model performance u value estimates dynamic static methods within error estimates dynamic model generally requiring much shorter time series static model dynamic model produced robust results times year including average indoor outdoor temperature difference low external temperatures large daily variation measurements subjected direct solar radiation probability distributions parameters may provide insights thermal performance elements dynamic methods presented herein may enable wider characterisation performance building elements built supporting work reduce performance gap â© authors
10.1007/s12046-018-0861-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045691299&doi=10.1007%2fs12046-018-0861-7&partnerID=40&md5=b7eea394315ca6c2d54f4f87d95dfe4b 0,paper reports estimation unknown boundary heat flux fin using bayesian inference method setup consists rectangular mild steel fin dimensions ã— ã— â mm aluminium base plate dimensions ã— ã— â mm fin subjected constant heat flux base fin setup modelled using ansys problem considered conjugate heat transfer fin navierâ€“stokes equation solved obtain flow parameters grid independence study carried fix number grids study considered reduce computational cost computational fluid dynamics cfd replaced artificial neural network ann forward model markov chain monte carlo mcmc powered metropolisâ€“hastings sampling algorithm along bayesian framework used explore estimation space sensitivity analysis estimated temperature respect unknown parameter discussed know dependency temperature parameter paper signifies effect prior model execution inverse algorithm different noise levels unknown heat flux estimated surrogated temperature estimates reported mean maximum posteriori map standard deviation effect priori information estimated parameter also addressed standard deviation estimation process referred uncertainty associated estimated parameters â© indian academy sciences
10.1016/j.jcde.2017.10.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044143240&doi=10.1016%2fj.jcde.2017.10.002&partnerID=40&md5=45950d2a75684470e59de2780f3ba642 0,study model probabilistic fatigue life based zhurkov model suggested using stochastically statistically estimated lethargy coefficients fatigue life model derived using zhurkov life model deterministically validated using real fatigue life data reference process firstly lethargy coefficient related failure materials must obtained rupture time stress quasi static tensile test experiments performed using hs r steel however lethargy coefficient discrepancies due inherent uncertainty variation material properties experiments bayesian approach employed estimating lethargy coefficient fatigue life model using markov chain monte carlo mcmc sampling method considering uncertainties samples obtained one proceed posterior predictive inference fatigue life life model shown reasonable compared experimental fatigue life data result predicted fatigue life observed significantly decrease accordance increasing relative stress conditions â© society computational design engineering
10.3390/e20040262 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045839139&doi=10.3390%2fe20040262&partnerID=40&md5=bd3b8b8d9e12ed32afb65765464cc888 1,regression analysis sample selection bias arises dependent variable partially observed result sample selection study introduces maximum entropy maxent process regression model assumes amaxent prior distribution nonparametric regression function finds maxent process regression model includes well known gaussian process regression gpr model special case special maxent process regression model e gpr model generalized obtain robust sample selection gaussian process regression rsgpr model deals non normal data sample selection various properties rsgpr model established including stochastic representation distributional hierarchy magnitude sample selection bias properties used paper develop hierarchical bayesianmethodology estimate themodel involves simple computationally feasible markov chain monte carlo algorithm avoids analytical numerical derivatives log likelihood function model performance rsgpr model terms sample selection bias correction robustness non normality prediction demonstrated results simulations attest good finite sample performance â© authors
10.1016/j.spasta.2018.03.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045698255&doi=10.1016%2fj.spasta.2018.03.002&partnerID=40&md5=e227a5805715b4b269e39e5cbbd7d093 0,spatial econometric models widely used analyzing cross sectional data spatial dependence primary interest although proven successful bayesian estimation via markov chain monte carlo mcmc spatial econometric models computationally demanding size data complexity models grow paper proposes two variational bayes methods scalable computationally faster estimating general spatial autoregressive matrix exponential spatial specification models hybrid mean field variational bayes mfvb method integrated nonfactorized variational bayes infvb method hybrid mfvb method assumes posterior independence applicable yield accurate results tends underestimate posterior variances comparison infvb method provides robust results accounting posterior dependence computationally appealing due parallelization demonstrate variational bayesian inference faster scalable alternative mcmc approach bayesian spatial econometric modeling effectiveness proposed methods spatial econometric models demonstrated simulated examples real world data application â© elsevier b v
10.1007/s41549-018-0027-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045751686&doi=10.1007%2fs41549-018-0027-z&partnerID=40&md5=c0299cef7ba9a95e305e4986de0710e0 0,study examines impact outlier adjusted data business cycle inferences using coincident indicators composite index ci japan estimate ci business cycles study proposes markov switching dynamic factor model incorporating studentâ€™s distribution idiosyncratic noise factor equation furthermore model includes stochastic volatility process identify whether large shock associated business cycle empirical analysis factor idiosyncratic component fat tail error distributions estimated ci recession probabilities close published economic social research institute compared estimated ci using adjusted data set outlier adjustment reduces depth recession moreover results shock decomposition show financial crisis mid caused increase clustering shocks large unexpected shocks contrast great east japan earthquake derived idiosyncratic noise cause recession analyzing whether use sample includes outliers associated business cycle desirable use outlier adjusted data set â© springer international publishing ag part springer nature
10.1007/s00357-018-9248-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044072631&doi=10.1007%2fs00357-018-9248-z&partnerID=40&md5=b81209221d53bf89fe41396e6f6775ab 1,paper discusses challenges presented tall data problems associated bayesian classification specifically binary classification existing methods handle current methods include parallelizing likelihood subsampling consensus monte carlo new method based two stage metropolis hastings algorithm also proposed purpose algorithm reduce exact likelihood computational cost tall data situation first stage new proposal tested approximate likelihood based model full likelihood based posterior computation conducted proposal passes first stage screening furthermore method adopted consensus monte carlo framework two stage method applied logistic regression hierarchical logistic regression bayesian multivariate adaptive regression splines â© classification society north america
10.1002/ecy.2174 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043711634&doi=10.1002%2fecy.2174&partnerID=40&md5=ef4de60b1dcb7ba852b317a34b442d39 0,recently major theoretical advances quantification partitioning diversity within among communities regions ecosystems however applying advances real data remains challenge ecologists often end describing samples rather estimating diversity components underlying study system existing approaches easily provide statistical frameworks testing ecological questions offer one avenue using hierarchical bayesian approach estimate posterior distributions underlying â€œtrueâ€� relative abundances species within unit sampled posterior estimates relative abundance used existing formulae estimate partition diversity result posterior distribution diversity metrics describing knowledge beliefs study system approach intuitively leads statistical inferences addressing biologically motivated hypotheses via bayesian model comparison using simulations demonstrate approach well better approximating â€œtrueâ€� diversity community relative naã¯ve ad hoc bias corrected estimates moreover model comparison correctly distinguishes alternative hypotheses distribution diversity within among samples finally use empirical ecological dataset illustrate approach used address questions makeup diversities assemblages local regional scales â© ecological society america
10.1177/0962280215626947 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042847045&doi=10.1177%2f0962280215626947&partnerID=40&md5=86c8998fc1dd1ac0c86cc9b7251f43dd 0,accelerated failure time model popular model analyze censored time event data analysis model without assuming parametric distribution model error challenging model complexity enhanced presence large number covariates developed nonparametric bayesian method regularized estimation regression parameters flexible accelerated failure time model novelties method lie modeling error distribution accelerated failure time nonparametrically modeling variance function mean adopting variable selection technique modeling mean proposed method allowed identifying set important regression parameters estimating survival probabilities constructing credible intervals survival probabilities evaluated operating characteristics proposed method via simulation studies finally apply new comprehensive method analyze motivating breast cancer data surveillance epidemiology end results program estimate five year survival probabilities women included surveillance epidemiology end results database diagnosed breast cancer â© â© author
10.1016/j.econlet.2018.02.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044282225&doi=10.1016%2fj.econlet.2018.02.005&partnerID=40&md5=beb4629ee3827fd542f98905cd7e10dc 0,bayesian alternative zhuo presented method general interest presents explicit formula local sensitivity log marginal likelihood observations vary small amount remarkable feature formula easy compute require knowledge marginal likelihood invariably extremely difficult compute similar expressions derived posterior moments functions interest including inefficiency methods examining prior sensitivity straightforward way also presented methods illustrated context stochastic production frontier â©
10.1534/genetics.117.300489 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045020060&doi=10.1534%2fgenetics.117.300489&partnerID=40&md5=9015e91e40365336d1d805e7ca8c16cb 6,open question human evolution importance polygenic adaptation adaptive changes mean multifactorial trait due shifts allele frequencies across many loci recent years several methods developed detect polygenic adaptation using loci identified genome wide association studies gwas though powerful methods suffer limited interpretability detect sets populations evidence polygenic adaptation unable reveal history multiple populations processes occurred address created method detect polygenic adaptation admixture graph representation historical divergences admixture events relating different populations time developed markov chain monte carlo mcmc algorithm infer branch specific parameters reflecting strength selection branch graph additionally developed set summary statistics fast compute indicate branches likely experienced polygenic adaptation show via simulations methodâ€”which call polygraphâ€”has good power detect polygenic adaptation applied human population genomic data around world also provide evidence variants associated several traits including height educational attainment self reported unibrow influenced polygenic adaptation different populations human evolution â© genetics society america
10.1115/1.4038934 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041903882&doi=10.1115%2f1.4038934&partnerID=40&md5=32aeb23f5cf769a43589d2d86ce02dd8 0,operations maintenance activities significant impact energy cost offshore wind turbines analytical methods reliability block diagrams markov processes along simulation approaches widely used planning optimizing operations maintenance actions industrial systems generalized stochastic petri nets gspns predicates coupled monte carlo simulation mcs applied paper model planning operations maintenance activities offshore wind turbine merits gspn modeling complex multicomponent systems addressed three maintenance categories classified according size weight components replaced logistics involved vessels maintenance crew spares associated delays costs included model weather windows accessing wind turbine also modeled corrective maintenance cm based replacements age dependent preventive maintenance pm imperfect repair modeled compared terms wind turbine performance e g availability loss production operations maintenance costs â© asme
10.1016/j.meegid.2018.01.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041509404&doi=10.1016%2fj.meegid.2018.01.021&partnerID=40&md5=74b4308505009398574d56b23a44177b 0,performed detailed genetic analyses partial hemagglutininâ€“neuraminidase hn gene human respirovirus hrv strains children acute respiratory illness â€“ iwate prefecture japan addition performed analyses evolutionary timescale gene using bayesian markov chain monte carlo mcmc method furthermore analyzed pairwise distances performed selective pressure analyses followed linear b cell epitope mapping n glycosylation phylodynamic analyses phylogenetic tree showed strains diversified around rate molecular evolution ã— âˆ’ substitutions site year although pairwise distances relatively short â± mean â± standard deviation sd two positive selection sites cys trp leu ser amino acid substitutions found active catalytic sites six epitopes estimated study three mouse monoclonal antibody binding sites amino acid positions overlapped two epitopes belonging subcluster c strains bayesian skyline plot analyses indicated subcluster c strains increasing whereas subcluster c strains declined based results iwate strains divided two subclusters subcluster evolved independently moreover results suggested predicted linear epitopes epitopes candidates hrv vaccine motif better understand details molecular evolution hrv studies needed â© elsevier b v
10.1371/journal.pone.0195117 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045275859&doi=10.1371%2fjournal.pone.0195117&partnerID=40&md5=1cd1313df6f75fb83413733a2eceee7d 1,background hepatitis c second fastest growing infectious disease china standard care chronic hepatitis c china pegylated interferon plus ribavirin pr associated tolerability efficacy issues interferon ribavirin free oral regimen comprising daclatasvir dcv asunaprevir asv displays higher efficacy tolerability recently approved china objectives study estimate cost effectiveness dcv+asv weeks chronic hepatitis c genotype b treatment naã¯ve patients compared pr regimen weeks china methods cohort based markov model developed chinese payer perspective project lifetime outcomes treating patients average age two hypothetical regimens dcv+asv pr chinese specific health state costs efficacy data used annual discount rate base case analysis sensitivity analysis conducted results hcv genotype b treatment naã¯ve patients dcv+asv proved dominant pr cost saving â¥ usd gains qalys life years respectively lifetime risk compensated cirrhosis decompensated cirrhosis hepatocellular carcinoma liver related death greatly reduced dcv+asv univariate sensitivity analysis demonstrated key influencers discount rate time horizon initial disease severity sustained virological response rate dcv+asv scenarios resulting additional benefit probabilistic sensitivity analysis demonstrated dcv+asv high likelihood cost effective conclusion dcv+asv effective well tolerated regimen treat chronic hcv genotype b infection treatment naã¯ve patients also cost effective pr regimen dcv +asv benefit public health reimbursement system china â© lu et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1177/0962280216660127 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042848765&doi=10.1177%2f0962280216660127&partnerID=40&md5=f3efebdd6e4242074ce0dfd6f5da1a37 0,background biomarker series indicate disease progression predict clinical endpoints treatment prescribed depending biomarker confounding indication might introduced treatment modifies marker profile risk failure objective aim highlight flexibility two stage model fitted within bayesian markov chain monte carlo framework purpose monitored prostate specific antigens prostate cancer patients treated external beam radiation therapy presence rising prostate specific antigens external beam radiation therapy salvage hormone therapy prescribed reduce prostate specific antigens concentration risk clinical failure illustration confounding indication focused assessment prognostic value hormone therapy prostate specific antigens trajectory risk failure methods used two stage model within bayesian framework assess role prostate specific antigens profile clinical failure accounting secondary treatment prescribed indication modeled prostate specific antigens using hierarchical piecewise linear trajectory random changepoint residual prostate specific antigens variability expressed function prostate specific antigens concentration covariates survival model included hormone therapy baseline characteristics individual predictions prostate specific antigens nadir timing prostate specific antigens slopes nadir provided longitudinal process results showed positive associations increased prostate specific antigens nadir earlier changepoint steeper post nadir slope increased risk failure importantly highlighted significant benefit hormone therapy effect observed prostate specific antigens trajectory accounted survival model conclusion modeling strategy particularly flexible accounted multiple complex features longitudinal survival data including presence random changepoint time dependent covariate â© â© author
10.1371/journal.pone.0196548 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046012648&doi=10.1371%2fjournal.pone.0196548&partnerID=40&md5=38475a49ee46c296de4c1c27f97da1d0 0,background yunnan greatest share reported human immunodeficiency virus hiv acquired immunodeficiency syndrome aids cases china recent years hiv prevalence incidence remained stubbornly high men sex men msm follow dynamics hiv epidemic among msm hiv genetic characteristics genetic transmission networks investigated methods blood samples newly diagnosed hiv cases among msm continuously collected fixed sites january december kunming city yunnan province partial gag pol env genes sequenced used phylogenetic genotypic drug resistance analyses genetic characteristics predominant hiv strains analyzed bayesian markov chain monte carlo mcmc method genetic transmission networks identified genetic distance substitutions site bootstrap support results among hiv positive msm reported â€“ various genotypes identified including crf ae crf bc unique recombinant forms urfs crf bc crf b subtype b crf b effective population sizes eps crf ae crf bc increased exponentially approximately â€“ â€“ respectively genetic transmission networks constructed pol sequences msm diagnosed â€“ msm identified distinct clusters multiple male partners associated high probability identification genetic transmission networks clusters contained individuals diagnosed different years individuals networks potential transmission partners links proportion msm links higher among diagnosed â€“ constituent ratios potential transmission partners areas showed significant difference among msm kunming cities yunnan provinces additionally surveillance drug resistance mutations sdrms identified individuals conclusion study revealed various hiv genotypes circulating among msm kunming msm partners easily detected transmission networks early diagnosed msm remained active transmission networks findings suggested routine interventions combined hiv testing linkage care early antiretroviral therapy among hiv positive msm â© chen et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1007/s13198-017-0688-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045975536&doi=10.1007%2fs13198-017-0688-3&partnerID=40&md5=80067a567331ee47155041d3eace1365 0,article deals classical bayesian estimation parameters log logistic distribution using random censorship model maximum likelihood estimators asymptotic confidence intervals based observed fisher information matrix parameters derived bayes estimators parameters generalized entropy loss function using independent gamma priors obtained bayesian computation tierneyâ€“kadaneâ€™s approximation markov chain monte carlo mcmc methods used also highest posterior credible intervals parameters based mcmc method constructed monte carlo simulation study carried compare behavior various estimators developed article finally real data analysis performed illustration purposes â© society reliability engineering quality operations management sreqom india division operation maintenance lulea university technology sweden
10.1016/j.patcog.2017.11.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040353756&doi=10.1016%2fj.patcog.2017.11.021&partnerID=40&md5=727e109148d5621b7b38a217dedca57f 1,partially observable hidden markov model extension hidden markov model hidden state conditioned independent markov chain structure motivated presence discrete metadata event type may partially reveal hidden state emanates separate process scenario encountered keystroke dynamics whereby user typing behavior dependent text typed assumption user either active passive state typing keyboard key names event types partially reveal hidden state due presence relatively longer time intervals words sentences letters word using five public datasets proposed model shown consistently outperform anomaly detectors including standard hmm biometric identification verification tasks generally preferred hmm monte carlo goodness fit test â©
10.1017/S0950268818000651 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044622571&doi=10.1017%2fS0950268818000651&partnerID=40&md5=d64d9d0ea92f86b4993dbe8931f251ba 0,lack gold standard diagnostics combination multiple diagnostic tests composite diagnostic standard used measure pneumococcal pneumonia pp pneumococcal vaccine trials estimated accuracy composite diagnostic standards pp used previous randomised controlled trials simple formulas systematic literature review identified five eligible trials trials used different combinations diagnostic tests pp estimated values sensitivity minimum specificity composite diagnostic standards varied substantially trials respectively without standardizing outcome measurements pneumococcal vaccine efficacy estimates pp comparable trials pooled estimates biased copyright â© cambridge university press
10.1109/TVCG.2018.2793618 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041637332&doi=10.1109%2fTVCG.2018.2793618&partnerID=40&md5=5e7c420dc55a4b2c48954956d45549ab 1,games experiences designed virtual augmented reality usually require player move physically play poses substantial challenge level designers player physical experience level need considered otherwise level may turn exhausting challenging enough paper presents novel approach optimize level designs considering physical challenge imposed upon player completing level motion based games game level represented assembly chunks characterized exercise intensity levels impose players formulate game level synthesis optimization problem chunks assembled way achieve optimized level intensity allow synthesis game levels varying lengths solve trans dimensional optimization problem reversible jump markov chain monte carlo technique demonstrate approach applied generate game levels motion based virtual reality games user evaluation validates effectiveness approach generating levels desired amount physical challenge â© ieee
973.8904310666601 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049146967&partnerID=40&md5=9d9a7eabdd35a06145f83826465a4aa9 0,objective current treatment options available patients unresectable hilar cholangiocarcinoma cca endoscopic biliary drainage ebd using metal stent percutaneous transhepaticbiliary drainage ptbd palliative care however information regarding cost effectiveness available study aimed compare cost utility palliative biliary drainage ebd ptbd palliative care materials methods used methods evaluation direct calculation markov decision analysis model cost treatment quality adjusted life years qaly ebd ptbd palliative care groups collected cohorts unresectable hilar cca database tertiary care hospital thailand transition probabilities derived international literature cohorts base case sensitivity analysis also performed results compared palliative care incremental cost per additional qaly gained ebd ptbd using direct calculation method baht us baht us per qaly gained respectively result concordance markov model icer ebd ptbd baht us baht us per qaly gained respectively according probabilistic sensitivity analysis using markov model ebd preferable palliative care willingness pay wtp higher baht us per qaly gained ptbd cost effective compared palliative care wtp threshold wtp threshold thai baht threshold thailand us per qaly gained neither ebd ptbd found cost effective threshold palliative care cost effective conclusion ebd cost effective ptbd compared palliative care cases unresectable hilar cca wtp threshold thailand palliative care cost effective â© medical association thailand rights reserved
10.1124/dmd.117.078790 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042715142&doi=10.1124%2fdmd.117.078790&partnerID=40&md5=3ea1608afc96f40df40e58f3ceb46ad4 3,understanding liver exposure hepatic transporter substrates clinical studies often critical typically governs pharmacodynamics drug drug interactions toxicity certain drugs however challenging task since currently easy method directly measure drug concentration human liver using bosentan example demonstrate new approach estimate liver exposure based observed systemic pharmacokinetics clinical studies using physiologically based pharmacokinetic modeling prediction verified accurate precise using sensitivity analysis bosentan predicted pseudo steady state unbound liver unbound systemic plasma concentration ratio confidence interval drug drug interaction e cyp cyp b induction inhibition hepatic transporters e bile salt export pump multidrug resistance associated proteins sodium taurocholate cotransporting polypeptide predicted based estimated unbound liver tissue plasma concentrations validation refinement conclude approach may serve predict human liver exposure complement methods involving tissue biopsy imaging copyright â© american society pharmacology experimental therapeutics
10.1371/journal.pone.0193525 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045989470&doi=10.1371%2fjournal.pone.0193525&partnerID=40&md5=603f2793a272353d446705863514edfa 0,respiratory syncytial virus rsv important pathogen global significance ba one predominant lineages ba genotype group b rsv acquired bp duplication g protein gene describe local global evolutionary dynamics second hyper variable region c terminal g protein gene ba lineage total sequences including study genbank strains different countries used phylogenetic analysis analysis showed study strains clustered ba ba ba sab genotype group b rsv performed time scaled evolutionary clock analyses using bayesian markov chain monte carlo methods also carried glycosylation selection pressure mutational entropy network analyses ba lineage time recent common ancestor tmrca ba genotype ba lineage estimated years hpd â€“ hpd â€“ respectively nucleotide substitution rate ba genotype ã— âˆ’ hpd â€“ ã— âˆ’ substitution site year slightly faster ba lineage ã— âˆ’ hpd â€“ ã— âˆ’ ba lineage categorized sub lineages ii iii based bayesian network analyses local transmission pattern suggested ba predominant lineage ba viruses circulating india since though showing fluctuations effective population size ba lineage established global distribution report different countries past years present study augments understanding rsv infection epidemiological dynamics warranting steps towards overall global surveillance â© haider et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1177/0146621618762743 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045422625&doi=10.1177%2f0146621618762743&partnerID=40&md5=fde62f24f0705ade663fb1706164da53 1,commonly known respondents exhibit different response styles responding likert type items example respondents tend select extreme categories e g strongly disagree strongly agree whereas tend select middle categories e g disagree neutral agree furthermore respondents tend disagree every item e g strongly disagree disagree whereas others tend agree every item e g agree strongly agree cases fitting standard unfolding item response theory irt models assume response style yield poor fit biased parameter estimates although attempts develop dominance irt models accommodate various response styles models usually restricted specific response style used unfolding data study general unfolding irt model proposed combined softmax function accommodate various response styles via scoring functions parameters new model estimated using bayesian markov chain monte carlo algorithms empirical data set used demonstration purposes followed simulation studies assess parameter recovery new model well consequences ignoring impact response styles parameter estimators fitting standard unfolding irt models results suggest new model exhibit good parameter recovery seriously biased estimates response styles ignored â© author
10.1016/j.spasta.2018.03.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044647476&doi=10.1016%2fj.spasta.2018.03.005&partnerID=40&md5=e05f55a00afb0a7332a66ae94292ea79 0,paper construct hierarchical model spatial compositional data used reconstruct past land cover compositions terms coniferous forest broadleaved forest unforested open land five time periods past years europe model consists gaussian markov random field gmrf dirichlet observations block updated markov chain monte carlo mcmc including adaptive metropolis adjusted langevin step used estimate model parameters sparse precision matrix gmrf provides computational advantages leading fast mcmc algorithm reconstructions obtained combining pollen based estimates vegetation cover limited number locations scenarios past deforestation output dynamic vegetation model evaluate uncertainties predictions novel way constructing joint confidence regions entire composition prediction location proposed hierarchical model ability reconstruct past land cover evaluated cross validation time periods comparing reconstructions recent past present day european forest map evaluation results promising model able capture known structures past land cover compositions â© elsevier b v
10.1111/2041-210X.12952 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040785365&doi=10.1111%2f2041-210X.12952&partnerID=40&md5=57d265908e4130f490063a0179708f13 2,state transition simulation models stsms provide general framework forecasting landscape dynamics including projections vegetation land use land cover lulc change stsm method divides landscape spatially referenced cells simulates state cell forward time discrete time stochastic process using monte carlo approach response number possible transitions current limitation stsm method however state variables must discrete present new approach extending stsm order account continuous state variables called stsm stocks flows stsm sf stsmâ€“sf method allows number continuous stocks defined every spatial cell stsm along suite continuous flows specifying rates stock levels change time change level stock simulated forward time spatial cell discrete time stochastic process method differs traditional systems dynamics approach stock flow modelling stocks flows spatially explicit flows expressed function stsm states transitions demonstrate stsm sf method integrating spatially explicit carbon c budget model stsm lulc change state hawai usa example continuous stocks pools terrestrial c whereas flows possible fluxes c pools importantly several c fluxes triggered corresponding lulc transitions stsm model outputs include changes spatial temporal distribution c pools fluxes across landscape response projected future changes lulc next â years new stsm sf method allows discrete continuous state variables integrated stsm including interactions addition stocks flows stsms provide conceptually simple yet powerful approach characterizing uncertainties projections wide range questions regarding landscape change â© authors methods ecology evolution published john wiley sons ltd behalf british ecological society
10.1093/gji/ggx497 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041854469&doi=10.1093%2fgji%2fggx497&partnerID=40&md5=9bc126244b1b6560d8e39e55205190b2 2,seismic anisotropy provides important information deformation history earth interior rayleigh love surface waves sensitive used determine radial azimuthal shear wave anisotropies depth parameter trade offs give rise substantial model non uniqueness explore trade offs isotropic anisotropic structure parameters present suite methods inversion surface wave phase velocity curves radial azimuthal anisotropies one markov chain monte carlo mcmc implementation inverts rayleigh love dispersion curves radially anisotropic shear velocity profile crust upper mantle another mcmc implementation inverts rayleigh phase velocities azimuthal anisotropy profiles vertically polarized shear velocity depth dependent azimuthal anisotropy azimuthal anisotropy inversion fully non linear forward problem solved numerically different azimuths every model realization ensures linearization biases avoided computations performed parallel order reduce computing time often challenging issue data noise estimation addressed means hierarchical bayesian approach variance noise treated unknown radial anisotropy inversion addition mcmc inversions also present faster non linear gradient search inversions anisotropic structure results two approaches mutually consistent advantage mcmc inversions provide measure uncertainty models applying method broad band data baikal central mongolia region determine radial anisotropy crust transition zone depths robust negative anisotropy vsh lt vsv asthenosphere km depths presents strong new evidence vertical component asthenospheric flow consistent upward flow thick lithosphere siberian craton thinner lithosphere central mongolia likely give rise decompression melting scattered sporadic volcanism observed baikal rift area proposed previously inversion phase velocity data west central italy azimuthal anisotropy reveals clear change shear wave fast propagation direction km depths near lithosphere asthenosphere boundary orientation fabric lithosphere roughly e w parallel direction stretching last orientation fabric asthenosphere nw se matching fast directions inferred shear wave splitting probably indicating direction asthenospheric flow author published oxford university press rights reserved
10.7782/JKSR.2018.21.3.233 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050944926&doi=10.7782%2fJKSR.2018.21.3.233&partnerID=40&md5=398b9c96ea3a77b8f13493b6f013b572 0,paper intends describe methodological ideas analyzing field failure data components operating different environments accomplish statistical method predicting reliability life proposed using bayesian inference used main algorithm markov chain monte carlo mcmc algorithm allows us approximate posterior distribution calculated using bayesian inference evaluated difference two groups using bayesian p value result confirmed reliability characteristics air compressors different operating environments different â© korean society railway rights reserved
10.1088/1674-4527/18/4/47 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045623187&doi=10.1088%2f1674-4527%2f18%2f4%2f47&partnerID=40&md5=8b18558bf835a7a6e88d4390db996309 0,present new analyses variations c diagrams three algol type eclipsing binary stars ad tw cas iv cas used published minima times including visual photographic well newly determined ones superwasp observations determined orbital parameters rd bodies systems statistically significant errors using code based genetic algorithms markov chain monte carlo simulations confirmed multiple nature ad triple star model tw cas proposed quadruple star model iv cas â© national astronomical observatories cas iop publishing ltd
10.12928/TELKOMNIKA.v16i2.7510 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044372100&doi=10.12928%2fTELKOMNIKA.v16i2.7510&partnerID=40&md5=cb36f317e9bd4fa2e544a62fc9f3b90f 0,paper proposes important issues signal segmentation signal disturbed multiplicative noise number segments unknown bayesian approach proposed estimate parameter parameter includes number segments location segment amplitude posterior distribution parameter simple equation bayes estimator easily determined reversible jump markov chain monte carlo mcmc method adopted overcome problem reversible jump mcmc method creates markov chain whose distribution close posterior distribution performance algorithm shown simulation data result simulation shows algorithm works well application algorithm used segment synthetic aperture radar sar signal advantage method number segments position segment change amplitude estimated simultaneously â© universitas ahmad dahlan
10.1088/1538-3873/aaaaa8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044197959&doi=10.1088%2f1538-3873%2faaaaa8&partnerID=40&md5=c7bc8080b35fc6af3c612745a9ed54a5 8,radvel open source python package modeling keplerian orbits radial velocity rv timeseries radvel provides convenient framework fit rvs using maximum posteriori optimization compute robust confidence intervals sampling posterior probability density via markov chain monte carlo mcmc radvel allows users float fix parameters impose priors perform bayesian model comparison implemented real time mcmc convergence tests ensure adequate sampling posterior radvel output number publication quality plots tables users may interface radvel convenient command line interface directly python code object oriented thus naturally extensible encourage contributions community â© astronomical society pacific rights reserved
10.1103/PhysRevD.97.074507 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046728016&doi=10.1103%2fPhysRevD.97.074507&partnerID=40&md5=0d1eb6320e2c8778337c621aa5350bf6 0,investigate lattice spacing dependence equilibration time recently proposed multiscale thermalization algorithm markov chain monte carlo simulations algorithm uses renormalization group matched coarse lattice action prolongation operation rapidly thermalize decorrelated initial configurations evolution using corresponding target lattice action defined finer scale focusing nontopological long distance observables pure su gauge theory provide quantitative evidence slow modes markov process provide dominant contribution rethermalization time suppressed contribution toward continuum limit despite associated timescales increasing based numerical investigations conjecture prolongation operation used herein produce ensembles indistinguishable target fine action distribution sufficiently fine coupling given level statistical precision thereby eliminating cost rethermalization â© authors published american physical society published american physical society terms â»https creativecommons org licenses â» creative commons attribution international license distribution work must maintain attribution author published article title journal citation doi funded scoap
10.1093/mnras/stx3322 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046116929&doi=10.1093%2fmnras%2fstx3322&partnerID=40&md5=9a3f25d2bd8d974bf4f68060b2a5e750 0,three gamma ray millisecond pulsars msps psr j + psr j + psr j confirmed common feature phase aligned radio gamma ray bands geometric two pole caustic model physical outer gap model revised outer gap model three dimensional retarded magnetic dipole perturbation magnetic field observed features msps studied order obtained best fitting model parameters markov chain monte carlo technique used reasonable gev band light curves three msps given calculations indicate msps emit high energy photons smaller inclination angles î± â‰ˆ â° â° larger view angles î¶ â‰ˆ â° â° smaller perturbation factor âˆˆ â‰ˆ note factor âˆˆ describing strength perturbed magnetic field less zero two models magnetic field caused current induced play leading role pulsed location msps â© author
10.1007/s11069-016-2549-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984822347&doi=10.1007%2fs11069-016-2549-9&partnerID=40&md5=e3e3e263ea860424dd7c8d36ba3b3dc8 1,earthquakes cluster space time resulting nonlinear damage effects compute earthquake interactions using coulomb stress transfer theory dynamic vulnerability concept ductility capacity reduction combine processes generic multi risk framework risk scenarios simulated using variant markov chain monte carlo method apply proposed approach thrust fault system northern italy considering earthquakes characteristic magnitudes range different levels tectonic loading ï„ë™ =â âˆ’ âˆ’ âˆ’ bar year generic stock fictitious low rise buildings different ductility capacities î¼î”â =â describe processâ€™ stochasticity non stationary poisson earthquake probabilities binomial damage state probabilities find earthquake clustering yields tail fattening seismic risk curve effect amplified damage dependent fragility due clustering impact clustering alone average important dynamic vulnerability spatial extent former phenomenon greater latter one â© author
10.1093/mnras/stx3299 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041326572&doi=10.1093%2fmnras%2fstx3299&partnerID=40&md5=07157a4e4769f67e4b65a06e3121de9d 1,previous studies rotation law outer galactic disc mainly used gas tracers clump giants explore f stars alternatives provide much denser sampling outer disc gas tracers experienced significantly less velocity scattering older clump giants first investigation confirms suitability stars role work based spectroscopy photometrically selected stars red calcium triplet region chosen mitigate effects interstellar extinction stars located two low galactic latitude sightlines longitudes l = â° sampling strong galactic rotation shear l = â° near anticentre use markov chain monte carlo parameter fitting stellar parameters radial velocities measured distances computed obtained trend radial velocity distance inconsistent existing flat slowly rising rotation laws gas tracers brand amp blitz reid et al instead results fit obtained huang et al disc clump giants favoured rising circular speeds alternative interpretation terms spiral arm perturbation straight forward assess role undetected binaries sample distance error may introducing bias show former minor factor random errors trend circular velocity within â± kms â© author
10.1007/s40840-016-0311-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044731277&doi=10.1007%2fs40840-016-0311-9&partnerID=40&md5=906351d141e63765318bd5dc7ac496f9 2,accelerated life testing widely used product life testing experiments since provides significant reduction time cost testing article assume lifetime items use condition follows two parameter distributions power hazard function partially accelerated life tests based progressive type ii censored samples considered maximum likelihood bayes parametric bootstrap methods used estimating unknown parameters based normal approximation asymptotic distribution mles approximate confidence intervals parameters derived two bootstrap confidence intervals also proposed classical bayes estimates obtained explicit form propose apply markov chain monte carlo mcmc technique gibbs within metropolisâ€“hasting algorithm applied generate mcmc samples posterior density function based generated samples bayes estimates highest posterior density credible intervals unknown parameters computed finally analysis simulated data set also presented illustrate proposed estimation methods developed â© malaysian mathematical sciences society penerbit universiti sains malaysia
10.1007/s11203-016-9153-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006341971&doi=10.1007%2fs11203-016-9153-1&partnerID=40&md5=b9c6c519cd1288df8f25b99503355510 1,given sample discretely observed compound poisson process consider non parametric estimation density f jump sizes well intensity î» take bayesian approach problem specify prior f dirichlet location mixture normal densities independent prior î» assumed compactly supported possess positive density respect lebesgue measure show suitable assumptions posterior contracts around pair î» f essentially logarithmic factor nî” rate n number observations î” mesh size process sampled emphasis high frequency data î” â†’ obtained results also valid fixed î” either case assume nî” â†’ âˆž main result implies existence bayesian point estimates converging frequentist sense probability î» f rate also discuss practical implementation approach computational problem dealt inclusion auxiliary variables develop markov chain monte carlo algorithm samples joint distribution unknown parameters mixture density introduced auxiliary variables numerical examples illustrate feasibility approach â© author
10.1016/j.spasta.2018.03.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045245009&doi=10.1016%2fj.spasta.2018.03.007&partnerID=40&md5=b8f57fab9e7b67f874171b1c5df900f5 0,propose formal specification sum zero constrained intrinsic conditional autoregressive icar models specification first projects vector proper conditional autoregressive spatial random effects onto subspace projected vector constrained sum zero takes limit proper conditional autoregressive model approaches icar model result show sum zero constrained icar model singular gaussian distribution zero mean vector unique covariance matrix previously sum zero constraints typically imposed vector spatial random effects icar models within markov chain monte carlo mcmc algorithm known centering fly mathematically informal way impose sum zero constraint obscures actual joint density spatial random effects contrast present work elucidates unique distribution icar random effects explicit expressions resulting unique covariance matrix density function useful development bayesian methodology spatial statistics useful practitioners illustrate practical relevance results using bayesian model selection jointly assess spatial dependence fixed effects â© elsevier b v
10.1093/mnras/sty095 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045769001&doi=10.1093%2fmnras%2fsty095&partnerID=40&md5=54ac0bd4f88dd617dd9483c7784c8e8c 1,present large scale galaxy structure cl j z discovered ukidss uds field made galaxy groups clusters spreading mpc report vlt vimos spectroscopic follow program combined past spectroscopy allowed us confirm four galaxy clusters mâš™ dozen associated groups star forming galaxy overdensities two additional filamentary structures z foreground background clusters lt z lt also confirmed along line sight structure subcomponents different formation stages clusters core dominated passive galaxies established red sequence remaining structures mix star forming galaxy overdensities forming groups presence quiescent galaxies core latter shows pre processing already happened groups fall theirmoremassive neighbours spectroscopy allows us derive spectral index measurements e g emission absorption line equivalent widths strength ã… break valuable investigate star formation history structure members based line measurements select population post starburst galaxies galaxies preferentially found within virial radius clusters supporting scenario recent quenching prompted gas stripping dense intracluster medium derive stellar age estimates using markov chain monte carlo based spectral fitting quiescent galaxies find correlation ages colours stellar masses favours top formation scenario red sequence catalogue redshifts uds released alongside paper via mnras online data â© authors
68.0161192877431 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044177231&partnerID=40&md5=988f79e2420d3a1f3f6a9ad9fe7615b4 0,introduction bipolar disorder severe chronic pleomorphic often recurrent lead severe abnormalities lif function purpose study determine factors related time interval relapse bipolar disorder materials methods retrospective study patients bipolar disorder avicenna hospital mashhad collected study patients least one relapse bipolar disorder included survival time defined elapsed time discharge readmission due relapse disease patients wereadmitted beginning end due illness include study followed end log skew normal accelerated failure time model fitted identify factors related time relapse estimation parameters obtained based bayesian approach using markov chain monte carlo algorithm open bugs results estimate mean median time discharge readmission months respectively age family history drug use gender significant association time relapse male younger patients drug users positive family history disease experienced recurrence disease earlier mentioned variables model stress education associated recurrence disease conclusion given time interval discharge recurrence type bipolar disorder low men young people family history positive drug users recommended identify strategies prevent relapse delay groups â© semnan university medical sciences rights reserved
10.1093/molbev/msx294 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044739219&doi=10.1093%2fmolbev%2fmsx294&partnerID=40&md5=df83c598aaf95c779207bf5cf2523d79 0,phylogenetic models assume evolutionary process stationary reversible addition biologically improbable assumptions also impair inference generating models likelihood depend position root consequently root tree inferred part analysis yet identifying root position key component phylogenetic inference provides point reference polarizing ancestor descendant relationships therefore interpreting tree paper investigate effect relaxing unrealistic reversibility assumption allowing position root another unknown propose two hierarchical models centered reversible model perturbed allow nonreversibility models differ degree structure imposed perturbations analysis performed bayesian framework using markov chain monte carlo methods software provided illustrate performance two nonreversible models analyses simulated data using two types topological priors apply models real biological data set radiation polyploid yeasts robust biological opinion root position finally apply models second biological alignment rooted tree controversial ribosomal tree life compare two nonreversible models conclude useful inferring position root real biological data â© author published oxford university press behalf society molecular biology evolution
10.1111/2041-210X.12931 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034660398&doi=10.1111%2f2041-210X.12931&partnerID=40&md5=9fd8597b5d88588b366dc0b87920d394 1,several new growth models proposed account life history trade offs occur indeterminately growing species allocate energy somatic growth reproduction models improve understanding lifetime growth life history difficult fit conventional growth models increased data demands multiple growth phases increased parameterization serve barriers adoption proper use new models review comment confounding issues model fitting several models provide advice surmounting issues simulation test example model lester biphasic growth model using several common fitting approaches highlight biases precision approach provide guiding documents using r jags code bayesian markov chain monte carlo likelihood profiling approaches generally provided best fits simpler approaches unbiased precise sampled data relatively high quality e g moderate sample sizes juvenile adult phases model assumptions met bayesian hierarchical approaches accommodate complicated data scenarios e g unbalanced design across multiple populations provide example approach recovering growth trajectories inferring growth associated trait variation environmental effects across multiple populations conventional growth models provide limited inference life history many biphasic growth models provide direct inference multiple life history traits difficult fit recommended approaches herein provide path forward fitting biphasic growth models variety scenarios allowing wider application tests life history ecological theory â© authors methods ecology evolution â© british ecological society
10.1007/s12021-018-9369-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042946733&doi=10.1007%2fs12021-018-9369-x&partnerID=40&md5=bcb5fd5a459979b04d546408740c674f 0,mathematical modeling powerful tool enables researchers describe experimentally observed dynamics complex systems starting robust model including model parameters necessary choose appropriate set model parameters reproduce experimental data however estimating optimal solution inverse problem e finding set model parameters yields best possible fit experimental data challenging problem present work use different optimization algorithms based frequentist approach well monte carlo markov chain methods based bayesian inference techniques solve considered inverse problems first probe two case studies synthetic data study models described stochastic non delayed linear second order differential equation stochastic linear delay differential equation third case study thalamo cortical neural mass model fitted eeg spectral power measured general anesthesia induced anesthetics propofol desflurane show proposed neural mass model fits well observed eeg power spectra particularly power spectral peaks within î´ âˆ’ âˆ’ hz î± âˆ’ âˆ’ hz frequency ranges furthermore case study perform practical identifiability analysis estimating confidence regions parameter estimates interpret corresponding correlation sensitivity matrices results indicate estimating model parameters analytically computed spectral power able accurately estimate unknown parameters avoiding computational costs due numerical integration model equations â© springer science+business media llc part springer nature
10.1002/sim.7568 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042913946&doi=10.1002%2fsim.7568&partnerID=40&md5=ab4242ef96ce6a09155845d31696c9a0 0,first goal united nations â€“ â€“ hiv aids elimination strategy ensure hiv positive people know hiv status estimating prevalence hiv among people eligible screening allows assessment number additional cases might diagnosed continued screening efforts group present methods estimating prevalence hiv status verified gold standard among test positive initial imperfect screening test known sensitivity specificity develop maximum likelihood estimators asymptotic confidence intervals use scenarios total number test negatives known scenario unknown scenario derive bayesian prevalence estimators account non negligible uncertainty previous estimates sensitivity specificity scenario estimator consistently outperformed scenario estimator simulations demonstrating use recording number test negatives public health screening programs less accurate tests sensitivity specificityâ â performance estimators comparable suggesting circumstances prevalence still estimated adequate precision number test negatives unknown however use bayesian approach account uncertainty sensitivity specificity especially recommended scenario estimator particularly sensitive misspecification values r code implementing methods available hsph harvard edu donna spiegelman software copyright â© john wiley sons ltd
10.1002/sim.7570 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037666251&doi=10.1002%2fsim.7570&partnerID=40&md5=39a076963dfd0fe296dcc93492813ca2 0,long term health effects air pollution often estimated using spatio temporal ecological areal unit study design leads following statistical challenges estimate spatially representative pollution concentrations areal unit allow uncertainty estimated concentrations estimating health effects simultaneously estimate joint effects multiple correlated pollutants article proposes novel stage bayesian hierarchical model addressing challenges inference based markov chain monte carlo simulation first stage multivariate spatio temporal fusion model predicting areal level average concentrations multiple pollutants monitored modelled pollution data second stage spatio temporal model estimating health impact multiple correlated pollutants simultaneously accounts uncertainty estimated pollution concentrations novel methodology motivated new study impact particulate matter nitrogen dioxide concentrations respiratory hospital admissions scotland results suggest pollutants exhibit substantial independent health effects â© authors statistics medicine published john wiley sons ltd
10.1007/s11749-018-0580-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044591373&doi=10.1007%2fs11749-018-0580-8&partnerID=40&md5=830316248dc09247567214b7a52d1434 0,bayesian inference covariance matrix usually performed placing inverse wishart multivariate jeffreys prior density different reasons present drawbacks alternative covariance matrix modelled separating standard deviations correlations separation strategy takes advantage fact usually straightforward flexible set priors standard deviations correlations rather covariance matrix hand priors must preserve positive definiteness correlation matrix obtained considering cholesky decomposition correlation matrix whose entries reparameterized using trigonometric functions efficiency trigonometric separation strategy tss shown application hidden markov models hmms conditional distributions multivariate normal case unknown number hidden states estimation conducted using reversible jump markov chain monte carlo algorithm based split combine birth death moves whose design straightforward use tss finally example remote sensing described hmm containing tss used segmentation multi colour satellite image â© sociedad de estadã­stica e investigaciã³n operativa
10.1109/INCISCOS.2017.26 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050945578&doi=10.1109%2fINCISCOS.2017.26&partnerID=40&md5=50271f29acdc28fc62c0c442a4603f4e 0,el presente documento muestra un anã¡lisis de los perfiles de voltaje que son un indicador de la confiabilidad de un sistema elã©ctrico ya que la red se comporta implementando la carga de vehã­culos elã©ctricos en una curva de demanda tã­pica residencial en funciã³n de varios escenarios de carga de los vehã­culos elã©ctricos es posible determinar si la red actual de la empresa de distribuciã³n tiene la infraestructura necesaria para poder suministrar la carga de los vehã­culos elã©ctricos la demanda residencial este anã¡lisis se realiza travã©s del algoritmo de monte carlo utilizando cadenas de markov lo que nos permite obtener un resultado ã³ptimo confiable de este estudio gracias las probabilidades de las cadenas de markov el anã¡lisis estã¡ asociado la predicciã³n de la potencia mã¡xima requerida para satisfacer el perã­odo pico de demanda en los sistemas de distribuciã³n con predominio de carga residencial buscando tambiã©n la planificaciã³n de las redes para aumentar la eficiencia calidad confiabilidad del suministro de energã­a en horas punta â© ieee
10.5194/gmd-11-1199-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044718023&doi=10.5194%2fgmd-11-1199-2018&partnerID=40&md5=0c561faa08b99967f352fa9395a43558 0,estimating methane ch emissions natural wetlands complex estimates contain large uncertainties models used task typically heavily parameterized parameter values well known study perform bayesian model calibration new wetland ch emission model improve quality predictions understand limitations models detailed process model analyze contains descriptions ch production anaerobic respiration ch oxidation gas transportation diffusion ebullition aerenchyma cells vascular plants processes controlled several tunable parameters use hierarchical statistical model describe parameters obtain posterior distributions parameters uncertainties processes adaptive markov chain monte carlo mcmc importance resampling time series analysis techniques estimation analysis utilizes measurement data siikaneva flux measurement site southern finland uncertainties related parameters modeled processes described quantitatively process level flux measurement data able constrain ch production processes methane oxidation different gas transport processes posterior covariance structures explain parameters processes related additionally flux flux component uncertainties analyzed annual daily levels parameter posterior densities obtained provide information regarding importance different processes also useful development wetland methane emission models square root helsinki model methane build emission peatlands sqhimmeli hierarchical modeling allows us assess effects parameters annual basis results calibration cross validation suggest early spring net primary production used predict parameters affecting annual methane production even though calibration specific siikaneva site hierarchical modeling approach well suited larger scale studies results estimation pave way regional global scale bayesian calibration wetland emission models â© author
10.1080/02664763.2018.1454893 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044469211&doi=10.1080%2f02664763.2018.1454893&partnerID=40&md5=851bfd38899f2743f26043b9ecbd010d 0,proteomics identification proteins complex mixtures proteins extracted biological samples important problem among experimental technologies mass spectrometry ms popular one protein identification ms data typically relies â€˜two stepâ€™ procedure identifying peptide first followed separate protein identification procedure next setup interdependence peptides proteins neglected resulting relatively inaccurate protein identification article propose markov chain monte carlo based bayesian hierarchical model first kind protein identification integrates two steps performs joint analysis proteins peptides using posterior probabilities remove assumption independence proteins using clustering group priors proteins based assumption proteins sharing biological pathway likely present absent together correlated complete conditionals proposed joint model tractable propose implement gibbs sampling scheme full posterior inference provides estimation statistical uncertainties relevant parameters model better operational characteristics compared two existing â€˜one stepâ€™ procedures range simulation settings well two well studied datasets â© informa uk limited trading taylor francis group
10.3390/atmos9040126 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044430963&doi=10.3390%2fatmos9040126&partnerID=40&md5=5d68e26a5acc3d39e56daafba24486bc 2,paper propose efficient enkf implementation non gaussian data assimilation based gaussian mixture models markov chain monte carlo mcmc methods proposed method works follows based ensemble model realizations prior errors estimated via gaussian mixture density whose parameters approximated means expectation maximization method using iterative method observation operators linearized current solutions posterior modes estimated via mcmc implementation acceptance rejection criterion similar metropolis hastings rule experimental tests performed lorenz model results show proposed method decrease prior errors several order magnitudes root mean square error sense nearly sparse dense observational networks â© authors
10.3389/fnins.2018.00184 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044871556&doi=10.3389%2ffnins.2018.00184&partnerID=40&md5=786233cebba3e3667c3ef213cd93024d 0,relating disease status imaging data stands increase clinical significance neuroimaging studies many neurological psychiatric disorders involve complex systems level alterations manifest functional structural properties brain possibly clinical biologic measures propose bayesian hierarchical model predict disease status able incorporate information functional structural brain imaging scans consider two stage whole brain parcellation partitioning brain subregions model accounts correlations voxels different brain regions defined parcellations approach models imaging data uses posterior predictive probabilities perform prediction estimates model parameters based samples drawn joint posterior distribution using markov chain monte carlo mcmc methods evaluate method examining prediction accuracy rates based leave one cross validation employ importance sampling strategy reduce computation time conduct whole brain voxel level prediction identify brain regions highly associated disease based voxel level prediction results apply model multimodal brain imaging data study parkinson disease achieve extremely high accuracy general model identifies key regions contributing accurate prediction including caudate putamen fusiform gyrus well several sensory system regions â© xue bowman kang
10.1186/s13690-018-0264-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044844860&doi=10.1186%2fs13690-018-0264-6&partnerID=40&md5=dd5944523eb6bea19c09008c0cc0a33b 0,background term malnutrition generally refers nutrition nutrition study uses term refer solely deficiency nutrition ethiopia child malnutrition one serious public health problem highest world purpose present study identify high risk factors malnutrition test different statistical models childhood malnutrition thereafter weighing preferable model model comparison criteria methods bayesian gaussian regression model used analyze effect selected socioeconomic demographic health environmental covariates malnutrition five years old child inference made using bayesian approach based markov chain monte carlo mcmc simulation techniques bayesx results study found variables sex child preceding birth interval age child father education level source water mother body mass index head household sex mother age birth wealth index birth order diarrhea child size birth duration breast feeding showed significant effects children malnutrition ethiopia age child mother age birth mother body mass index also important factors non linear effect child malnutrition ethiopia conclusions thus present study emphasizes special care variables sex child preceding birth interval father education level source water sex head household wealth index birth order diarrhea child size birth duration breast feeding age child mother age birth mother body mass index combat childhood malnutrition developing countries â© author
10.1109/CompComm.2017.8322960 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049744026&doi=10.1109%2fCompComm.2017.8322960&partnerID=40&md5=c6801ebabed9ac76fa75d12559ff1614 0,many statistical problems formulated missing data problems data augmentation algorithm inverse bayes formula important tools constructing iterative optimization samplings via introduction unobserved data latent variables markov chain monte carlo method data augmentation algorithm autocorrelation nevertheless convergence rate data augmentation algorithm known genetic linkage model true inverse bayes formula method article analyze convergence rates data augmentation algorithm inverse bayes formula method genetic linkage model simulation results get convergence rates â© ieee
10.1080/00218464.2016.1268055 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010638186&doi=10.1080%2f00218464.2016.1268055&partnerID=40&md5=e582c11b7a49e59a350d965be92b63d5 0,adhesively bonded joints used several industrial sectors cohezive zone modes used predict adhesive mechanical behaviour work presents approach calibrate cohesive zone models czm means statistical inverse analysis bayesian framework inverse problems used infer czm model parameters solution corresponds exploration posterior probability density function model parameters exploration posterior density performed means markov chain monte carlo mcmc methods mixing population based mcmc adaptive metropolis ad strategies assessment approach performed using measured data single lap shear experimental set measured data test specimens used calibration measured data five test specimens used model validation proposed stochastic effective model czm parameters predictions maximum force maximum displacement provided effective model accordance measured data used validation â© taylor francis
10.1098/rsos.171519 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044257439&doi=10.1098%2frsos.171519&partnerID=40&md5=60c0aebb56efe50738ee183a05ba057f 0,model evidence considered bayesian statisticians gold standard model selection ratio model evidence two models giving bayes factor calculation often viewed computationally demanding many applications contrast widely used deviance information criterion dic different measure balances model accuracy complexity commonly considered much faster alternative however recent advances computational tools efficient multi temperature markov chain monte carlo algorithms steppingstone sampling ss thermodynamic integration schemes enable efficient calculation bayesian model evidence paper compares capability e ability select true model speed e cpu time achieve given accuracy dic model evidence calculated using ss three important model classes considered linear regression models mixed models compartmental models widely used epidemiology dic found correctly identify true model applied linear regression models led incorrect model choice two cases hand model evidence led correct model choice cases considered importantly perhaps surprisingly dic model evidence found run similar computational speeds result reinforced analytically derived expressions â© authors
10.5194/hess-22-1917-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044238613&doi=10.5194%2fhess-22-1917-2018&partnerID=40&md5=21435a0c415dc3ad3ec0a1fee6db33f8 0,profiles temperature time series commonly used determine hyporheic flow patterns hydraulic dynamics streambed sediments although hyporheic flows past research focused determining magnitude vertical flow component varies spatially study used portable sensor temperature array three heat pulse sources measure flow direction magnitude gmm water sediment interface short gmin heat pulses injected one three heat sources temperature response monitored period gmin breakthrough curves sensors analysed using heat transport equation parameter estimation uncertainty analysis undertaken using differential evolution adaptive metropolis dream algorithm adaption markov chain monte carlo method estimate flux orientation measurements conducted field sand tank extensive range controlled hydraulic conditions validate method use short duration heat pulses provided rapid accurate assessment technique determining dynamic multi directional flow patterns hyporheic zone basis improved understanding biogeochemical processes water streambed interface â© author
10.3847/1538-4357/aaaf6b https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044731941&doi=10.3847%2f1538-4357%2faaaf6b&partnerID=40&md5=63e6a64d61c7941ad483349509b16d40 2,consider possible observation fast radio bursts frbs planned future radio telescopes investigate well dispersions redshifts signals might constrain cosmological parameters construct mock catalogs frb dispersion measure dm data employ markov chain monte carlo analysis forecast compare existing constraints flat î›cdm model well popular extensions include dark energy equation state curvature parameters find scatter dm observations caused inhomogeneities intergalactic medium igm poses big challenge utility frbs cosmic probe optimistic case high number events low igm variance frbs aid improving current constraints particular frbs combined cmb+bao+sne+h data find biggest improvement comes constraint also find dark energy equation state poorly constrained constraint curvature parameter î©k shows improvement combined current constraints frbs combined future baryon acoustic oscillation bao data cm intensity mapping find little improvement constraints baos alone however inclusion frbs introduces additional parameter constraint turns comparable existing constraints suggests frbs provide valuable information cosmological baryon density intermediate redshift universe independent high redshift cmb data â© american astronomical society rights reserved
10.1007/s11222-018-9809-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044206001&doi=10.1007%2fs11222-018-9809-3&partnerID=40&md5=9a74d625736de1d0cf575cb272f68711 0,gibbs sampling widely used markov chain monte carlo mcmc method numerically approximating integrals interest bayesian statistics mathematical sciences many implementations mcmc methods extend easily parallel computing environments inherently sequential nature incurs large synchronization cost case study illustrated paper show gibbs sampling fully data parallel manner graphics processing unit large class exchangeable models admit latent variable representations approach takes systems perspective emphasis placed efficient use compute hardware demonstrate method horseshoe probit regression model find implementation scales effectively thousands predictors millions data points simultaneously â© author
10.1088/1742-6596/973/1/012054 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045641321&doi=10.1088%2f1742-6596%2f973%2f1%2f012054&partnerID=40&md5=ee3b7058e41fe0d4c9d676a7815c10e0 0,propose new general numerical method aimed solve integro differential equations variable coefficients problem consideration arises finance context pricing barrier options wide class stochastic volatility models jumps handle effect correlation price variance use suitable substitution processes construct markov chain approximation variation process small time intervals apply maturity randomization technique result system boundary problems integro differential equations constant coefficients line vertex chain solve arising problems using numerical wiener hopf factorization method approximate formulae factors efficiently implemented means fast fourier transform finally use recurrent procedure moves backwards time variance tree demonstrate convergence method using monte carlo simulations compare results results obtained wiener hopf method closed form expressions factors â© published licence iop publishing ltd
10.1088/1475-7516/2018/03/033 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045336973&doi=10.1088%2f1475-7516%2f2018%2f03%2f033&partnerID=40&md5=11888ddebfcabb744e3d99462547eba5 0,derive observational constraint spherical inhomogeneity void centered position angular power spectrum cosmic microwave background cmb local measurements hubble parameter late time behaviour void assumed well described called î› lematre tolman bondi î›ltb solution restrict models asymptotically homogeneous models approximated flat friedmann lematre robertson walker model late time î›ltb models parametrized four parameters including value cosmological constant local hubble parameter two parameters used parametrize observed distance redshift relation î›ltb models constructed compatible given distance redshift relation including conventional parameters cmb analysis characterize models seven parameters total local hubble measurements reflected prior distribution local hubble parameter result markov chains monte carlo analysis cmb temperature polarization anisotropies found inhomogeneous universe models vanishing cosmological constant ruled expected however significant density around us still compatible angular power spectrum cmb local hubble parameter â© iop publishing ltd sissa medialab
10.1002/sim.7555 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037643262&doi=10.1002%2fsim.7555&partnerID=40&md5=606729101faa5281c959bbea20a65f0e 0,assessing association binary trait covariates binary response may subject unidirectional misclassification unidirectional misclassification occur revealing particular level trait associated type cost social desirability financial cost feasibility addressing misclassification commonly obscured model identification issues current paper attempts study efficacy inference binary response variable subject unidirectional misclassification theoretical perspective demonstrate key model parameters possess identifiability except case single binary covariate practical standpoint logistic model quantitative covariates weakly identified sense fisher information matrix may near singular make learning parameters difficult certain parameter settings even quite large samples cases stronger identification enables model provide effective adjustment unidirectional misclassification extension poisson approximation binomial model reveals identifiability poisson zero inflated poisson models fully identified models proposed method adjusts misclassification based learning data binary models difficulty identification method useful sensitivity analyses potential impact unidirectional misclassification copyright â© john wiley sons ltd
10.1016/j.vaccine.2018.02.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041898922&doi=10.1016%2fj.vaccine.2018.02.020&partnerID=40&md5=3273f0432b7d0d10acd4ac65341ec6b6 4,background expansion childhood vaccination programs low middle income countries substantial public health success story indicators performance intervention programmes coverage levels numbers covered typically measured national statistics scale large regions due survey design administrative convenience operational limitations mask heterogeneities â€˜coldspotsâ€™ low coverage may allow diseases persist even overall coverage high hence decrease inequities accelerate progress towards disease elimination goals fine scale variation coverage better characterized methods using measles example cluster level demographic health surveys dhs data used map vaccination coverage km spatial resolution cambodia mozambique nigeria varying age group categories children five years using bayesian geostatistical techniques built suite publicly available geospatial covariates implemented via markov chain monte carlo mcmc methods results measles vaccination coverage found strongly predicted â€“ covariates geostatistical models remoteness consistently selected key variable output ã— km maps revealed significant heterogeneities within three countries captured using province level summaries integration population data showed time surveys districts attained coverage one component global vaccine action plan targets conclusion elimination vaccine preventable diseases requires strong evidence base guide strategies inform efficient use limited resources approaches outlined provide route moving beyond large area summaries vaccination coverage mask epidemiologically important heterogeneities detailed maps capture subnational vulnerabilities output datasets built open data methods flexible format aggregated operationally relevant administrative unit levels â© author
10.1016/j.ecolmodel.2018.01.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041440662&doi=10.1016%2fj.ecolmodel.2018.01.014&partnerID=40&md5=77ffa1511c931da5fee30464445736e3 1,forest models increasingly used study ecosystem functioning simulation carbon fluxes productivity different biomes plant functional types world several forest models based concept light use efficiency lue rely mostly simplified mathematical structure empirical parameters require little amount data run computations usually fast however possible calibration issues must investigated order ensure reliable results addressed important issue delayed convergence calibrating lue models characterized multiplicative structure bayesian approach tested two models prelued horn schulz model applying three markov chain monte carlo based algorithms different number iterations different sets prior parameter distributions increasing information content results showed recently proposed algorithms adaptive calibration confer clear advantage metropolisâ€“hastings random walk algorithm forest models used high number iterations required stabilize convergence region partly explained multiplicative mathematical structure models high correlations parameters use empirical parameters neither ecological physiological meaning information content prior distributions parameters play major role reaching convergence lower number iterations conclude need careful approach calibration solve potential problems applying models characterized multiplicative mathematical structure moreover calibration proved time consuming mathematically difficult advantages using computationally fast user friendly model lost due calibration process needed obtain reliable results â© elsevier b v
10.1109/CAMSAP.2017.8313187 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050734368&doi=10.1109%2fCAMSAP.2017.8313187&partnerID=40&md5=b2d076e661b0ada3e48109a6296d2f00 0,paper investigate new imaging denoising algorithm single photon applications classical poisson noise assumption hold precisely consider two different acquisition scenarios unknown intensity profile recovered subsampled measurements following binomial geometric distributions whose parameters nonlinearly related intensities interest adopting bayesian approach flexible prior model assigned unknown intensity field adaptive markov chain monte carlo methods used perform bayesian inference particular allows us automatically adjust amount regularisation required satisfactory image inpainting restoration performance proposed model method assessed quantitatively series experiments conducted controlled data results obtained promising future analysis multidimensional single photon images â© ieee
10.1109/CAMSAP.2017.8313170 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050731405&doi=10.1109%2fCAMSAP.2017.8313170&partnerID=40&md5=1b4ec059f9cf565832ec81f0e6e89afb 1,report results series numerical studies examining convergence rate approximate representations î± stable distributions highly intractable class distributions inference purposes proposed representation turns intractable inference infinite dimensional series parameters approximately conditionally gaussian representation standard inference procedures expectation maximization em markov chain monte carlo mcmc particle filtering readily applied previously proved asymptotic convergence representation study rate convergence finite values truncation parameter c allows selection appropriate truncations different parameter configurations accuracy required model convergence examined directly terms cumulative distribution functions densities application berry theorems parseval theorems results indicate behaviour representations significantly superior representations simply truncate series gaussian residual term â© ieee
10.1109/CAMSAP.2017.8313132 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050740015&doi=10.1109%2fCAMSAP.2017.8313132&partnerID=40&md5=4370665445a0a4144f094d46b7a71a6a 0,many natural systems neurons firing brain basketball teams traversing court give rise time series data complex nonlinear dynamics gain insight systems decomposing data segments explained simpler dynamic units motivation underlying class recurrent switching linear dynamical systems rslds build standard slds introducing model discrete transition probabilities depend observations continuous latent states previous work relied markov chain monte carlo algorithms augmentation schemes inference methods applied limited class recurrent dependencies relax constraints consider recurrent dependencies specified arbitrary parametric nonlinear functions derive two structure exploiting variational inference algorithms challenging models leverage conditionally linear gaussian markovian nature models perform efficient posterior inference â© ieee
10.1146/annurev-statistics-031017-100141 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043485393&doi=10.1146%2fannurev-statistics-031017-100141&partnerID=40&md5=570f3fd996d5d126d9a2eb5c7351a093 0,markov chain monte carlo methods revolutionized mathematical computation enabled statistical inference within many previously intractable models context hamiltonian dynamics proposed efficient way building chains explore probability densities efficiently method emerges physics geometry links extensively studied past thirty years aim review provide comprehensive introduction geometric tools used hamiltonian monte carlo level accessible statisticians machine learners users methodology basic understanding monte carlo methods complemented discussion recent advances field believe become increasingly relevant scientists copyright â© annual reviews rights reserved
10.1109/AICCSA.2017.43 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046092320&doi=10.1109%2fAICCSA.2017.43&partnerID=40&md5=b1a124a2cee0767f685cde6f22ab86fa 1,propose bayesian approach learn finite generalized inverted dirichlet mixture models developed approach performs simultaneous parameters estimation model complexity determination feature selection via reversible jump markov chain monte carlo rjmcmc algorithm challenging application concerns video forgery detection deployed validate statistical framework show merits â© ieee
10.1146/annurev-statistics-031017-100232 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043476178&doi=10.1146%2fannurev-statistics-031017-100232&partnerID=40&md5=a6458cda5d642ba57d3c57155dab5c50 2,state space models used incorporate subject knowledge underlying dynamics time series introduction latent markov state process user specify dynamics process together state relates partial noisy observations made inference prediction involve solving challenging inverse problem calculating conditional distribution quantities interest given observations article reviews monte carlo algorithms solving inverse problem covering methods based particle filter ensemble kalman filter discuss challenges posed models high dimensional states joint estimation parameters state inference history state process also point potential new developments important tackling cutting edge filtering applications copyright â© annual reviews rights reserved
10.1109/TAC.2018.2813004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043402386&doi=10.1109%2fTAC.2018.2813004&partnerID=40&md5=6c7d8c265fa786f36e1447fd76585b46 0,bayesian nonlinear system identification one major classes dynamic model nonlinear autoregressive exogenous input narx model widely studied date markov chain monte carlo mcmc methods developed tend accurate also slow converge contribution present novel computationally efficient solution sparse bayesian identification narx model using variational inference orders magnitude faster mcmc methods sparsity inducing hyper prior used solve structure detection problem key results include successful demonstration method low signal noise ratio signals db successful benchmarking terms speed accuracy number algorithms bayesian lasso reversible jump mcmc forward regression orthogonalisation lasso simulation error minimisation pruning accurate identification real world system electroactive polymer demonstration first time numerically propagating estimated nonlinear time domain model parameter uncertainty frequency domain ieee
10.1080/03610926.2018.1440306 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042944127&doi=10.1080%2f03610926.2018.1440306&partnerID=40&md5=823cf78d5994987cfa47aedb94615431 1,bayesian approach based markov chain monte carlo technique proposed non homogeneous gamma process power law shape function vague informative priors formalized quantities â€œphysicalâ€� meaning provided point interval estimation process parameters functions thereof developed well prediction observable quantities useful defining maintenance strategy proposed useful approximations derived conditional unconditional mean median residual life reduce computational time finally proposed approach applied real dataset â© taylor francis group llc
10.5194/npg-25-145-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042903647&doi=10.5194%2fnpg-25-145-2018&partnerID=40&md5=3b86a555a741cec56d8bf026e758a964 1,develop general framework frequency analysis irregularly sampled time series based lomb scargle periodogram extended algebraic operators accounting presence polynomial trend model data addition periodic component background noise special care devoted correlation trend periodic component new periodogram cast welch overlapping segment averaging wosa method order reduce variance also design test significance wosa periodogram background noise model background noise stationary gaussian continuous autoregressive moving average carma process general classical gaussian white red noise processes carma parameters estimated following bayesian framework provide algorithms compute confidence levels wosa periodogram fully take account uncertainty carma noise parameters alternatively theory using point estimates carma parameters provides analytical confidence levels wosa periodogram accurate markov chain monte carlo mcmc confidence levels threshold number data points less costly computing time estimate amplitude periodic component least squares methods derive approximate proportionality squared amplitude periodogram proportionality leads new extension periodogram weighted wosa periodogram recommend frequency analyses irregularly sampled data estimated signal amplitude also permits filtering frequency band results generalise unify methods developed fields geosciences engineering astronomy astrophysics also constitute starting point extension continuous wavelet transform developed companion article lenoir crucifix methods presented paper available reader python package wavepal â© author
10.5194/npg-25-175-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042934130&doi=10.5194%2fnpg-25-175-2018&partnerID=40&md5=d123f5e42fa5f5685b9ebcbf49dc2062 1,geophysical time series sometimes sampled irregularly along time axis situation particularly frequent palaeoclimatology yet far general framework handling continuous wavelet transform time sampling irregular br br provide framework end define scalogram continuous wavelet transform equivalent extended lomb scargle periodogram defined part study lenoir crucifix signal analysed modelled sum locally periodic component time frequency plane polynomial trend background noise mother wavelet adopted morlet wavelet classically used geophysical applications background noise model stationary gaussian continuous autoregressive moving average carma process general traditional gaussian white red noise processes scalogram smoothed averaging neighbouring times order reduce variance shannon nyquist exclusion zone however defined area corrupted local aliasing issues local amplitude time frequency plane estimated least squares methods also derive approximate formula linking squared amplitude scalogram based property define new analysis tool weighted smoothed scalogram recommend analyses estimated signal amplitude also gives access band ridge filtering finally design test significance weighted smoothed scalogram stationary gaussian carma background noise provide algorithms computing confidence levels either analytically monte carlo markov chain methods analysis tools presented article available reader python package wavepal â© copernicus gmbh rights reserved
10.1080/03610926.2017.1316858 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029725923&doi=10.1080%2f03610926.2017.1316858&partnerID=40&md5=e1fb70118d0760f9c284d9159635b130 0,article present analysis head neck cancer data using generalized inverse lindley stressâ€“strength reliability model propose bayes estimators estimating p x x represent survival times two groups cancer patients observed different therapies x assumed independent generalized inverse lindley random variables common shape parameter bayes estimators obtained considerations symmetric asymmetric loss functions assuming independent gamma priors since posterior becomes complex possess closed form expressions bayes estimators lindleyâ€™s approximation markov chain monte carlo techniques utilized bayesian computation extensive simulation experiment carried compare performances bayes estimators maximum likelihood estimators basis simulated risks asymptotic bootstrap bayesian credible intervals also computed p x â© taylor francis group llc
10.1080/02331888.2017.1405419 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034645929&doi=10.1080%2f02331888.2017.1405419&partnerID=40&md5=c1bf1ad40b48382dac7fd0e9514f7775 0,article devoted development product spacings estimator progressive hybrid type censoring scheme binomial removals experimental units assumed follow inverse lindley distribution propose bayes estimator associated scale parameter based product spacings function simultaneously compare obtained usual bayesian estimation procedure estimators obtained squared error loss function along corresponding hp intervals evaluated using markov chain monte carlo technique classical product spacings estimator also derived compared maximum likelihood estimator addition average asymptotic confidence intervals applicability proposed methods demonstrated analysing real data guinea pigs affected tuberculosis considered censoring scheme â© informa uk limited trading taylor francis group
10.1115/1.4037450 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042803982&doi=10.1115%2f1.4037450&partnerID=40&md5=bdebecbad569543db5d0aabf91367d80 5,transitional markov chain monte carlo tmcmc one efficient algorithms performing markov chain monte carlo mcmc context bayesian uncertainty quantification parallel computing architectures however features associated efficient sampling also responsible introducing bias sampling demonstrate markov chains subsample tmcmc may result uneven chain lengths distort intermediate target distributions introduce bias accumulation stage tmcmc algorithm remedy drawback tmcmc proposing uniform chain lengths without burn algorithm emphasizes sequential importance sampling sis mcmc proposed bayesian annealed sequential importance sampling basis removes bias original tmcmc time increases parallel efficiency demonstrate advantages drawbacks basis modeling bridge dynamics using finite elements disk wall collision using discrete element methods copyright â© asme
10.1016/j.ymssp.2017.09.035 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032864707&doi=10.1016%2fj.ymssp.2017.09.035&partnerID=40&md5=38dc0f9f670f3e6a27bb7aa664c400c8 0,problem combined state parameter estimation nonlinear state space models based bayesian filtering methods considered novel approach combines rao blackwellized particle filters state estimation markov chain monte carlo mcmc simulations parameter identification proposed order ensure successful performance mcmc samplers situations involving large amount dynamic measurement data low measurement noise study employs modified measurement model combined importance sampling based correction parameters process noise covariance matrix also included quantities identified study employs rao blackwellization step two stages one associated state estimation problem particle filtering step secondly evaluation ratio likelihoods mcmc run satisfactory performance proposed method illustrated three dynamical systems computational model nonlinear beam moving oscillator system b laboratory scale beam traversed loaded trolley c earthquake shake table study bending torsion coupled nonlinear frame subjected uniaxial support motion â© elsevier ltd
10.1007/s11222-017-9730-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014057596&doi=10.1007%2fs11222-017-9730-1&partnerID=40&md5=e7ad92a947011337b29626ce2ddd04c6 0,describe parallel markov chain monte carlo methods propagate collective ensemble paths local covariance information calculated neighbouring replicas use collective dynamics eliminates multiplicative noise stabilizes dynamics thus providing practical approach difficult anisotropic sampling problems high dimensions numerical experiments model problems demonstrate dramatic potential speedups compared various alternative schemes attainable â© author
10.1016/j.quageo.2017.11.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037355286&doi=10.1016%2fj.quageo.2017.11.003&partnerID=40&md5=13bde687616ebeec2da695fae047606a 1,study presents mcdosee new fitting program esr dating dose response curve drc fitting dose calculation standalone software specifically designed remove assumed data weighting instead obtain full probabilistic solution drc propagating uncertainties associated measured esr intensities uses non linear bayesian framework specifically markov chain monte carlo mcmc scheme based metropolis hastings algorithm solution probability distribution equivalent dose according precision measurements paper investigate capabilities limitations mcdosee comparing results obtained originpro â® proven commonly used commercial software package two programs evaluated known dose samples random archaeological tooth enamel quartz samples using three commonly used drc fitting functions found programs provide highly consistent results comparing dose estimates obtained programs found solutions statistically indistinguishable regardless data weighting assumption used originpro also found mcdosee offers increased precision ending results compared commercial software long measured esr uncertainty remains within sigma range mean error value measured esr uncertainties dataset accuracy fitting results given mcdosee undeniably dependent measurement accuracy emphasises need proper assessment experimental errors esr intensities copy program available supplementary information basic instructions use provided well recommendations ensure reliable accurate fitting results â© elsevier b v
10.1016/j.dsp.2017.11.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037533509&doi=10.1016%2fj.dsp.2017.11.012&partnerID=40&md5=a9c2aea5be181929369e9448996c6725 0,monte carlo methods essential tools bayesian inference gibbs sampling well known markov chain monte carlo mcmc algorithm extensively used signal processing machine learning statistics employed draw samples complicated high dimensional posterior distributions key point successful application gibbs sampler ability draw efficiently samples full conditional probability density functions since general case possible order speed convergence chain required generate auxiliary samples whose information eventually disregarded work show auxiliary samples recycled within gibbs estimators improving efficiency extra cost novel scheme arises naturally pointing relationship standard gibbs sampler chain rule used sampling purposes numerical simulations involving simple real inference problems confirm excellent performance proposed scheme terms accuracy computational efficiency particular give empirical evidence performance toy example inference gaussian processes hyperparameters learning dependence graphs regression â© elsevier inc
10.1016/j.jclepro.2017.11.246 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039419525&doi=10.1016%2fj.jclepro.2017.11.246&partnerID=40&md5=b41840b554b27a8b65df0739c825fca5 2,parameter uncertainty inherent reservoir operation affects operation model robustness considered conventional operation focusing improving hydropower generation attention paid ecological environment protection recently riverine ecosystem protection requires environmental flow e flow management sustain near natural flow regime whether e flow management reservoir operation impact uncertainty reservoir operation parameter uncertainty rarely considered reservoir operation e flow management study framework proposed performing parameter uncertainty analysis reservoir operation associated e flow management e flow requirements hydropower generation considered reservoir operation sustain harmonious development ecological environment human society compare effect different e flow managements uncertainty reservoir operation three e flow management scenarios set metropolis hastings algorithm markov chain monte carlo mcmc sampling approach applied parameter estimation uncertainty quantification used framework case study nuozhadu hydropower station lancang river southern china test effectiveness results demonstrated parameter uncertainty greatly affects robustness reservoir operation model comparison reservoir operation different e flow management scenarios shows detailed e flow management effectively reduce uncertainty reservoir operation sustain near natural flow regime river â© elsevier ltd
10.1109/TITS.2017.2700481 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019887969&doi=10.1109%2fTITS.2017.2700481&partnerID=40&md5=5a211e21000125ed731da3d99d22382b 3,geo location data check ins made online social media offers us information new ways understand activity location choices large number people however one major challenges using check data missing activities since users share activities voluntarily paper present probabilistic modeling approach reconstruct user activity location sequences incomplete activity participation information specifically answer question predict individual next activity duration location given incomplete trajectory data model describes dynamics individual activity participation behavior evolving continuous time semi markov modeling approach used capture stochastic processes involved activity generation mechanism present particle based markov chain monte carlo sampler run inference model develop expectation maximization algorithm learn unknown parameters model incomplete trajectory data finally method applied synthetically generated activity location sequences data set foursquare check ins users new york city experiments show method successfully extract true transition duration distributions given incomplete trajectory information proposed approach help building many intelligent transportation applications using check data â© ieee
10.1016/j.ijar.2017.12.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041487626&doi=10.1016%2fj.ijar.2017.12.005&partnerID=40&md5=290420e36f6110d36db7af685083bf0a 1,official statistics interest data integration increasingly growing due need extracting information different sources however effects procedures validity resulting statistical analyses disregarded long time recent years largely recognized linkage error free procedure linkage errors false links missed links invalidate reliability estimates standard statistical models paper consider general problem making inference using data probabilistically linked explore effect potential linkage errors production small area estimates describe existing methods propose compare new approaches classical bayesian perspective perform simulation study assess pros cons proposed method simulation scheme aims reproducing realistic context small area estimation record linkage procedures â© elsevier inc
10.1109/TCBB.2015.2485223 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044972648&doi=10.1109%2fTCBB.2015.2485223&partnerID=40&md5=dd5909b497410e5aeba6ecf494f3c221 1,differential gene expression testing analysis commonly applied rna seq data statistical tests identify genes significantly different across phenotypes extend testing paradigm multivariate gene interactions classification perspective goal detect novel gene interactions phenotypes interest achieved novel computational framework comprised hierarchical statistical model rna seq processing pipeline corresponding optimal bayesian classifier markov chain monte carlo sampling monte carlo integration compute quantities analytical formulation exists performance illustrated expression dataset dietary intervention study identify gene pairs low classification error yet identified differentially expressed additionally released software package perform obc classification rna seq data open source license available http bit ly obc package â© ieee
10.1016/j.icheatmasstransfer.2018.02.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042868661&doi=10.1016%2fj.icheatmasstransfer.2018.02.001&partnerID=40&md5=c9979b57a0ba33b9ba847b6e481898ce 0,communication deals solution inverse parameter estimation problem dual phase lag heat conduction model case considered involves heating metal oxide semiconductor field effect transistor time spatial scales validity classical heat conduction model based fourier law considers infinite speed propagation thermal waves questioned markov chain monte carlo method applied estimation parameters within bayesian framework statistics using simulated transient temperature measurements â© elsevier ltd
10.1111/jmi.12623 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041953179&doi=10.1111%2fjmi.12623&partnerID=40&md5=5e70ffa6dffea57d31b9fd73e25692df 5,thresholded gaussian random field model developed microstructure porous materials defining random field solution stochastic partial differential equation allows flexible modelling nonstationarities material facilitates computationally efficient methods simulation model fitting markov chain monte carlo algorithm developed used fit model three dimensional confocal laser scanning microscopy images methods applied study porous ethylcellulose hydroxypropylcellulose polymer blend used coating control drug release pharmaceutical tablets aim investigate mass transport material depends microstructure derive number goodness fit measures based numerically calculated diffusion material used combination measures characterize geometry pore structure assess model fit model found fit stationary parts material well â© authors journal microscopy â© royal microscopical society
10.1016/j.knosys.2017.12.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037722756&doi=10.1016%2fj.knosys.2017.12.005&partnerID=40&md5=a538c704204b84b23fdf9658e9e01ef5 0,traditionally research network theory focused studying graphs equivalent entities failing deliberate useful supplementary information related dynamic properties complex network interactions paper tries study evolution process dynamic complex networks multilayer perspective analyzing properties naturally multilayered web based directed complex social networks google+ twitter undirected collaborative networks dblp astro ph thereby proposing new non parametric knowledge based multilayer link recommendation approach paper investigates layersâ€™ evolution throughout network evolution inspects evolution node membership different layers infinite factorial hidden markov model finally formulates intra layer inter layer link generation process markov chain monte carlo sampling strategies driven simulate parameters proposed multilayer model using certain synthetic real complex network datasets experimental results indicate great improvements performance proposed multilayer link recommendation approach terms certain analyzed performance measures â© elsevier b v
10.1061/AJRUA6.0000949 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045306299&doi=10.1061%2fAJRUA6.0000949&partnerID=40&md5=fb01de6861da968526a36be2bc81615a 0,study investigates use big data analytics uncertainty quantification applies proposed framework structural diagnosis prognosis smart sensor technology making progress low cost online monitoring becoming increasingly possible large quantities data acquired monitoring thus exceeding capacity traditional data analytics techniques authors explore software application technique parallelize data analytics efficiently handle high volume velocity variety sensor data next forward inverse problems uncertainty quantification investigated efficient computational approach authors use bayesian methods inverse problem diagnosis parallelize numerical integration techniques markov chain monte carlo simulation particle filter predict damage growth structure remaining useful life forward problem monte carlo simulation used propagate uncertainties aleatory epistemic future state software approach applied drive parallelization multiple finite element analysis fea runs thus greatly saving computational cost proposed techniques illustrated efficient diagnosis prognosis alkali silica reactions concrete structure â© american society civil engineers
10.1016/j.image.2018.01.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041452771&doi=10.1016%2fj.image.2018.01.003&partnerID=40&md5=25e9a64ab2db9364190c4c9db32a3b86 0,microscopic analysis paper printing shows regularly spaced dots whose random shape depends printing technology configuration printer well paper properties modelling identification paper ink interactions required qualifying printing quality controlling printing process application authentication well paper proposes approach identify authentic printer source using micro tags consisting microscopic printed dots embedded documents random shape features modelled extracted signature particular printer paper propose probabilistic model consisting vector parameters using spatial interaction binary model inhomogeneous markov chain parameters determine location describe diverse micro random structures microscopic printed dots markov chain monte carlo mcmc algorithm thus developed approximate minimum mean squared error estimator performance assessed numerical simulations real printed dots common printing technologies conventional offset waterless offset inkjet laser used assess effectiveness model â© elsevier b v
10.1109/TPAMI.2017.2689007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041965843&doi=10.1109%2fTPAMI.2017.2689007&partnerID=40&md5=b9e67b1801fb14d8f11b8734e9bce95f 1,paper present attribute grammar solving two coupled tasks parsing image semantic regions ii recovering scene structures regions proposed grammar consists set production rules describing kind spatial relation planar surfaces scenes production rules used decompose input image hierarchical parse graph representation graph node indicates planar surface composite surface different stochastic image grammars proposed grammar augments graph node set attribute variables depict scene level global geometry e g camera focal length local geometry e g surface normal contact lines surfaces geometric attributes impose constraints node springs parse graph probabilistic framework develop markov chain monte carlo method construct parse graph optimizes image recognition scene reconstruction purposes simultaneously evaluated method public benchmarks newly collected datasets experiments demonstrate proposed method capable achieving state art scene reconstruction single image â© ieee
10.1115/1.4037557 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047053286&doi=10.1115%2f1.4037557&partnerID=40&md5=7397417ab97b0d2a74824bd8db07b3f2 0,demonstrate statistical procedure learning high order eddy viscosity model evm experimental data using improve predictive skill reynoldsaveraged navier stokes rans simulator method tested three dimensional transonic jet crossflow jic configuration process starts cubic eddy viscosity model cevm developed incompressible flows fitted limited experimental jic data using shrinkage regression shrinkage process removes terms model except intercept linear term quadratic one involving square vorticity shrunk eddy viscosity model implemented rans simulator calibrated using vorticity measurements infer three parameters calibration bayesian solved using markov chain monte carlo mcmc method probability density distribution inferred parameters constructed thus quantifying uncertainty estimate phenomenal cost using flow simulator inside mcmc loop mitigated using surrogate models curve fits support vector machine classifier svmc used impose prior belief regarding parameter values specifically exclude nonphysical parameter combinations calibrated model compared terms predictive skill simulations using uncalibrated linear cevms find calibrated model one quadratic term accurate uncalibrated simulator model also checked flow condition model calibrated copyright â© asme
10.1016/j.ultras.2017.11.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037544171&doi=10.1016%2fj.ultras.2017.11.017&partnerID=40&md5=2af9083f3760fb379e6c14499fad5a8b 2,paper presents study model assessment predicting structural fatigue life using lamb waves lamb wave coupon testing performed model development three damage sensitive features namely normalized energy phase change correlation coefficient extracted lamb wave data used quantify crack size four data driven models proposed average relative error probability detection pod proposed two measures evaluate performance four models study influence model choice probabilistic fatigue life prediction probability density functions actual crack size obtained pod models given lamb wave data crack growth model parameters statistically identified using bayesian parameter estimation markov chain monte carlo simulations model assessment influence model choice fatigue life prediction made using coupon testing data artificial cracks realistic lap joint testing data naturally developed cracks â© elsevier b v
10.1109/TCST.2017.2672402 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014865203&doi=10.1109%2fTCST.2017.2672402&partnerID=40&md5=d5884da22a87731add90615b523b7208 2,battery impedance spectroscopy models given fractional order fo differential equations discrete time domain give rise state space models latent process markovian parameter estimation models therefore challenging especially noncommensurate fo models paper propose bayesian approach identify parameters generic fo systems computational challenge tackled particle markov chain monte carlo methods implementation specifically designed non markovian setting two examples provided first example approach applied identify battery commensurate fo model single constant phase element cpe using real data compare proposed approach instrumental variable method consider noncommensurate fo model one cpe synthetic data sets investigating proposed method enables study various effects parameter identification data length magnitude input signal choice prior measurement noise â© ieee
10.1002/cjs.11343 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030667645&doi=10.1002%2fcjs.11343&partnerID=40&md5=dc2fa6e491833b1e51df60e3f13bd38b 0,markov chain monte carlo mcmc sampling posterior distribution corresponding massive data set computationally prohibitive producing one sample requires number operations linear data size article introduce new communication free parallel method â€œlikelihood inflating sampling algorithm lisa â€� significantly reduces computational costs randomly splitting data set smaller subsets running mcmc methods â€œindependentlyâ€� parallel subset using different processors processor used run mcmc chain samples sub posterior distributions defined using â€œinflatedâ€� likelihood function develop strategy combining draws different sub posteriors study full posterior bayesian additive regression trees bart model performance method tested using simulated data large socio economic study canadian journal statistics â€“ â© statistical society canada â© statistical society canada
10.1016/j.regsciurbeco.2018.01.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041464100&doi=10.1016%2fj.regsciurbeco.2018.01.001&partnerID=40&md5=38a6a44c1527899d9bc78628cc2f834c 0,great deal literature regarding use non geographically based connectivity matrices combinations geographic non geographic structures spatial econometrics models explore alternative approaches constructing convex combinations different types dependence observations pace lesage well hazä±r et al use convex combinations different connectivity matrices form single weight matrix used conventional spatial regression estimation inference example case two weight matrices w w reflecting different types dependence cross section regions firms individuals etc located space wc=î³ w + âˆ’î³ w â‰¤î³ â‰¤ matrix wc reflects convex combination two weight matrices scalar parameter î³ indicating relative importance assigned type dependence explore issues arise producing estimates inferences general cross sectional regression relationships bayesian framework propose two procedures estimate models assess finite sample properties monte carlo experiments illustrate methodology application ceo salaries sample nursing homes located texas two types weights considered one reflecting spatial proximity nursing homes peer group proximity arise salary benchmarking literature â© elsevier b v
10.1093/icesjms/fsx175 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045131314&doi=10.1093%2ficesjms%2ffsx175&partnerID=40&md5=9b0f41461c97a4e964a315fa401f8cde 0,uncertainty coming assessment models leads risk decision making ignoring misestimating result erroneous management action parameters selectivity survey catchabilities present wide range shapes introduction smooth functions widely used assessment models allows flexibility capture underlying nonlinear structures work simulation study emulating sardine population carried compare three different methods uncertainty estimation multivariate normal distribution bootstrap without relative bias correction markov chain monte carlo mcmc order study performance depending model complexity five different scenarios defined depending shape smooth function fishing mortality simulated datasets performance measured terms point estimation coefficients variation bias skewness coverage probabilities correlation approaches model fitting carried using framework three methods result similar performance main differences found observation variance parameters bootstrap multivariate normal approach result underestimation parameters general mcmc considered better performance able detect skewness showing small relative bias reaching expected coverage probabilities also efficient terms time consumption comparison bootstrapping â© author published oxford university press behalf international council exploration sea rights reserved permissions please e mail journals permissions oup com
10.1111/biom.12717 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019013185&doi=10.1111%2fbiom.12717&partnerID=40&md5=b6db9585507487920eb7cd444805a21e 0,advanced hepatocellular carcinoma hcc limited treatment options poor survival therefore early detection critical improving survival patients hcc current guidelines high risk patients include ultrasound screenings every six months ultrasounds operator dependent sensitive early hcc serum î± fetoprotein afp widely used diagnostic biomarker limited sensitivity elevated hcc cases incorporate second blood based biomarker desâ€™ î³ carboxy prothrombin dcp shown potential screening marker hcc data hepatitis c antiviral long term treatment cirrhosis halt c trial valuable source data study biomarker screening hcc assume trajectories afp dcp follow joint hierarchical mixture model random changepoints allows distinct changepoint times subsequent trajectories biomarker changepoint indicators jointly modeled markov random field distribution help detect borderline changepoints markov chain monte carlo methods used calculate posterior distributions used risk calculations among future patients determine whether patient positive screen screening algorithm compared alternatives simulations studies range possible scenarios halt c trial using cross validation â© international biometric society
10.1002/asmb.2276 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030463357&doi=10.1002%2fasmb.2276&partnerID=40&md5=48787ffbf82c58e1427e4ee11fb6d1a2 0,one major challenges associated measurement customer lifetime value selecting appropriate model predicting customer future transactions among models pareto negative binomial distribution pareto nbd prevalent noncontractual relationships characterized latent customer defections ie defections observed firm happen however model applications shortcomings firstly methodological shortcoming pareto nbd like lifetime transaction models based statistical distributions assumes number transactions customer follows poisson distribution however many applications empirical distribution fit poisson model secondly computational concern implementation pareto nbd model presents estimation challenges specifically related numerous evaluation gaussian hypergeometric function finally model provides parameters output insufficient link individual purchasing behavior socio demographic information predict behavior new customers paper model customer lifetime transactions using conway maxwell poisson distribution generalization poisson distribution offering flexibility better fit real world discrete data estimate parameters propose markov chain monte carlo algorithm easy implement use bayesian paradigm provides individual customer estimates help link purchase behavior socio demographic characteristics opportunity target individual customers copyright â© john wiley sons ltd
10.1007/s00180-017-0747-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021864084&doi=10.1007%2fs00180-017-0747-x&partnerID=40&md5=dbf94a1172e4b7b3946b625ff292c719 0,paper introduces new computationally efficient markov chain monte carlo mcmc estimation algorithm bayesian analysis zero one zero one inflated beta regression models algorithm computationally efficient sense low mcmc autocorrelations computational time simulation study shows proposed algorithm outperforms slice sampling random walk metropolisâ€“hastings algorithms small large sample settings empirical illustration loss given default banking model demonstrates usefulness proposed algorithm â© springer verlag gmbh germany outside usa
10.1093/gji/ggx500 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042069843&doi=10.1093%2fgji%2fggx500&partnerID=40&md5=0201eb664a5afaf2a55de609f0c2008f 0,apply bayesian markov chain monte carlo mcmc formalism inversion refraction seismic traveltime data sets derive velocity models linear arrays e profiles sources seismic receivers typical refraction data sets especially using far offset observations known experimental geometries poor highly ill posed far ideal consequence structural resolution quickly degrades depth conventional inversion techniques based regularization potentially suffer choice appropriate inversion parameters e number distribution cells starting velocity models damping smoothing constraints data noise level etc local model space exploration mcmc techniques used exhaustive sampling model space without need prior knowledge assumptions inversion parameters resulting large number models fitting observations statistical analysis models allows derive average reference solution standard deviation thus providing uncertainty estimates inversion result highly non linear character inversion problem mainly caused experiment geometry allow derive reference solution error map simply averaging procedure present modified averaging technique excludes parts prior distribution posterior values due poor ray coverage thus providing reliable estimates inversion model properties even parts models model discretized set voronoi polygons constant slowness cells triangulated mesh interpolation within triangles forward traveltime calculations performed fast finite difference based eikonal solver method applied data set refraction seismic survey northern namibia compared conventional tomography inversion test synthetic data set known model also presented â© author published oxford university press behalf royal astronomical society
10.1016/j.jmva.2017.11.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037036987&doi=10.1016%2fj.jmva.2017.11.003&partnerID=40&md5=732509e68ff41a8ea5677070cbb71a85 1,paper introduces class scale mixtures normal selection factor smnsf analysis models robust departures normality designed correct sample selection bias various properties class models established including stochastic representation distributional hierarchy quantification sample selection bias hierarchical bayesian methodology also developed estimation purposes involves simple computationally feasible markov chain monte carlo algorithm avoids analytical numerical derivatives log likelihood function results simulation studies attest good finite sample performance new model terms sample selection bias reduction robustness outliers data illustration included â© elsevier inc
10.1007/s11222-017-9740-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016062293&doi=10.1007%2fs11222-017-9740-z&partnerID=40&md5=40535a72b9a1e395e57e4ef5a2ee1706 4,particle filters powerful flexible tool performing inference state space models involve collection samples evolving time combination sampling sampling steps sampling step necessary ensure weight degeneracy avoided several situations statistical interest important able compare estimates produced two different particle filters consequently able efficiently couple two particle filter trajectories often paramount importance text propose several ways particular leverage ideas optimal transportation literature general though computing optimal transport map extremely computationally expensive deal introduce computationally tractable approximations optimal transport couplings demonstrate resulting algorithms coupling two particle filter trajectories often perform orders magnitude efficiently standard approaches â© springer science+business media new york
10.1111/biom.12719 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018388561&doi=10.1111%2fbiom.12719&partnerID=40&md5=0a36002af90a09e28264bd9f151ee0ca 1,many studies biomedical time series signals aim measure association frequency domain properties time series clinical behavioral covariates however time varying dynamics associations largely ignored due lack methods assess changing nature relationship time article introduces method simultaneous automatic analysis association time varying power spectrum covariates refer conditional adaptive bayesian spectrum analysis cabs procedure adaptively partitions grid time covariate values unknown number approximately stationary blocks nonparametrically estimates local spectra within blocks penalized splines cabs formulated fully bayesian framework number locations partition points random fit using reversible jump markov chain monte carlo techniques estimation inference averaged distribution partitions allows accurate analysis spectra smooth abrupt changes proposed methodology used analyze association time varying spectrum heart rate variability self reported sleep quality study older adults serving primary caregiver ill spouse â© international biometric society
10.1007/s11222-017-9735-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013177554&doi=10.1007%2fs11222-017-9735-9&partnerID=40&md5=9815e9ddce41726d15a64e6c2bdb3157 0,many research fields scientific questions investigated analyzing data collected space time usually fixed spatial locations time steps resulting geo referenced time series context interest identify potential partitions space study evolution time finite space time mixture model proposed identify level based clusters spatio temporal data study temporal evolution along time frame anticipate space time dependence introducing spatio temporally varying mixing weights allocate observations nearby locations consecutive time points similar clusterâ€™s membership probabilities result clustering varying time space accomplished conditionally clusterâ€™s membership state space model deployed describe temporal evolution sites belonging group fully posterior inference provided bayesian framework monte carlo markov chain algorithms also strategy select suitable number clusters based upon posterior temporal patterns clusters offered evaluate approach simulation experiments illustrate using air quality data collected across europe showing benefit borrowing strength information across space time â© springer science+business media new york
10.21307/stattrans-2018-009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047770179&doi=10.21307%2fstattrans-2018-009&partnerID=40&md5=034a48960d6dfb2269c3820772cf814a 0,presented report seven case studies uses statistics past present intend examples exhaustive intend primarily educational examples readers like know statistics good also encourage readers study detailed reports international year statistics given notes report â© glowny urzad statystyczny rights reserved
10.1093/sysbio/syx065 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043486392&doi=10.1093%2fsysbio%2fsyx065&partnerID=40&md5=f057f2cc0bb6cc0346ed605a3b1e497e 3,chromosome number key feature higher order organization genome changes chromosome number play fundamental role evolution dysploid gains losses chromosome number well polyploidization events may drive reproductive isolation lineage diversification recent development probabilistic models chromosome number evolution groundbreaking work mayrose et al chromevol enabled inference ancestral chromosome numbers molecular phylogenies generated new interest studying role chromosome changes evolution however chromevol approach assumes changes occur anagenetically along branches model events specifically cladogenetic cladogenetic changes may expected chromosome changes result reproductive isolation present new class models chromosome number evolution called chromosse incorporate anagenetic cladogenetic change chromosse models allow us determine mode chromosome number evolution chromosome evolution occurring primarily within lineages primarily lineage splitting clade specific combinations furthermore estimate location timing possible chromosome speciation events phylogeny implemented chromosse bayesian statistical framework specifically software revbayes accommodate uncertainty parameter estimates leveraging full power likelihood based methods tested chromosse accuracy simulations examined chromosomal evolution aristolochia carex section spirostachyae helianthus mimulus sensu lato l primula section aleuritia finding evidence clade specific combinations anagenetic cladogenetic dysploid polyploid modes chromosome evolution â© author
10.1111/2041-210X.12901 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043489725&doi=10.1111%2f2041-210X.12901&partnerID=40&md5=13c8bc4c30918ead87260e742af9588b 0,understanding predicting species traits shaped prevailing environmental conditions important yet challenging task ecology functional trait based approaches replace potentially idiosyncratic species specific response models learning community behaviour across environmental gradients customarily models traits given environment consider trait means predict species functional diversity intra taxon variability traits often thought negligible growing body literature indicates intra taxon trait variability substantial critical structuring plant communities assessing ecosystem function propose flexible joint trait distribution models given environment across species incorporate intra taxon variability well inter site plot variability using bayesian framework joint trait distribution models allow mixed continuous binary ordinal trait variables incorporate dependence among traits enabling joint conditional trait prediction unobserved sites models used inform well known fourth corner problem attempts interpret trait environment matrices demonstrate utility methodology joint predictive trait distributions individual species well joint community weighted trait distributions environments incorporating intra taxon trait variability explicit details probabilistic interpretations random trait environment matrices obtained arising model also provided address fourth corner problem finally joint trait distribution model applied simulated real vegetation data collected greater cape floristic region south africa proposed methodology places fully model based foundation explaining intra taxon trait variation given environment extends utility interpretability commonly applied techniques investigating community weighted traits illuminates randomness fourth corner problem â© authors methods ecology evolution â© british ecological society
10.1016/j.urolonc.2017.10.024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034608835&doi=10.1016%2fj.urolonc.2017.10.024&partnerID=40&md5=ccbd73f97f67adb51fdbc358a1db6d98 0,purpose estimate health system costs prostate cancer disease risk category treatment type identify potential strategies contain cost increase methods markov cohort model developed using clinical pathways us prostate cancer guidelines clinical expertise estimates probabilities various treatments outcomes unit costs sourced systematic reviews meta analyses epidemiological publications national cost reports estimated costs stage disease major treatments age diagnosis reported us dollars one way probabilistic sensitivity analyses assessed potential variation modeled costs results australia wide costs prostate cancer estimated us million rising us million expected increase total increase newly diagnosed low risk cases contribute us million intermediate risk us million high risk us million advanced us million men diagnosed age low risk disease lifetime costs per patient us surgery us radiation therapies primary lesion us active surveillance intermediate high risk disease mean costs per patient us surgery plus radiation us androgen deprivation therapy plus radiation advanced cancer therapies us per patient additional costs managing iatrogenic disease secondary treatments excluded conclusion strategies identifying patients early cancers spread critical contain estimated increase costs next decade increased uptake active surveillance also lead substantial cost savings management low risk prostate cancer â© elsevier inc
10.1007/s11269-017-1863-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034664137&doi=10.1007%2fs11269-017-1863-7&partnerID=40&md5=f7b5f0efc32b1254b1e52a5474c1958b 0,hydroclimatic drought conditions affect hydrological services offered mountain river basins causing severe impacts population becoming challenge water resource managers andean river basins study proposes integrated methodological framework assessing risk failure water supply incorporating probabilistic drought forecasts assists making decisions regarding satisfaction consumptive non consumptive environmental requirements water scarcity conditions monte carlo simulation used assess risk failure multiple stochastic scenarios incorporate probabilistic forecasts drought events based markov chains mc model using recently developed drought index di methodology tested machã¡ngara river basin located south ecuador results grouped integrated satisfaction indexes system dsig demonstrated incorporation probabilistic drought forecasts better target projections simulation scenarios view obtaining realistic situations instead optimistic projections lead riskier decisions moreover contribute effective results order propose multiple alternatives prevention mitigation drought conditions â© springer science+business media b v part springer nature
10.1371/journal.pcbi.1006046 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044730670&doi=10.1371%2fjournal.pcbi.1006046&partnerID=40&md5=3a78ab60151366c93ad954a51e53adf6 0,context ageing population understanding transmission infectious diseases scabies well connected sub units population residential care homes particularly important design efficient interventions mitigate effects diseases present modelling methodology based efficient solution large scale system linear differential equations allows statistical calibration individual based random models real data scabies residential care homes particular review benchmark different numerical methods integration differential equation system select appropriate methods perform inference using markov chain monte carlo test goodness fit model using posterior predictive intervals propagate forward resulting parameter uncertainty bayesian framework consider economic cost delayed interventions scabies quantifying benefits prompt action event detection also revisit previous methodology used assess safety treatments small population sub unitsâ€”in context ivermectinâ€”and demonstrate even slight relaxation implicit assumption homogeneous death rates significantly increases plausibility hypothesis ivermectin cause excess mortality based upon data barkwell shields â© kinyanjui et al
10.1053/j.semtcvs.2018.01.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042634455&doi=10.1053%2fj.semtcvs.2018.01.003&partnerID=40&md5=fe41a4409ec592b8784dd1caf2d83951 0,aimed empirically derive inotrope score predict real time outcomes using doses inotropes pediatric cardiac surgery outcomes evaluated included hospital mortality prolonged hospital length stay composite poor outcome mortality prolonged hospital length stay study population included patients years age undergoing heart operations without cardiopulmonary bypass varying complexity create novel pediatric cardiac inotrope score pcis collected data highest doses commonly used inotropes epinephrine norepinephrine dopamine milrinone first hours heart operation employed hierarchical framework representing discrete probability models continuous latent variables depended dosage drugs particular patient used bayesian conditional probit regression model effects inotropes mean latent variables used markov chain monte carlo simulations simulating posterior samples create score function study outcomes training dataset utilized patients make scientific model online calculator tool accessed https soipredictiontool shinyapps io inotropescoreapp newly proposed empiric pcis demonstrated high degree discrimination predicting study outcomes children undergoing heart operations newly proposed empiric pcis provides novel measure predict real time outcomes using doses inotropes among children undergoing heart operations varying complexity â© elsevier inc
10.1016/j.mbs.2018.01.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041489866&doi=10.1016%2fj.mbs.2018.01.002&partnerID=40&md5=902fc5e049b6fd7b2d0b6e33843d5346 0,spread infectious disease may depend structure network study influence structure parameters network spread epidemic need put parameters epidemic model method moment closure introduces structure parameters epidemic model paper present new moment closure epidemic model based approximation third order motifs networks order motif defined paper determined number edges motif rather number nodes motif defined literature provide general approach deriving set ordinary differential equations describes high degree accuracy spread infectious disease using method establish susceptible infected recovered sir model calculate basic reproduction number sir model find decreases clustering coefficient increases finally perform simulations using proposed model study influence clustering coefficient final epidemic size maximum number infected peak time disease numerical simulations based sir model paper fit stochastic simulations based monte carlo method well different levels clustering results show clustering coefficient poses impediments spread disease sir model â©
10.1371/journal.pone.0193974 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043448562&doi=10.1371%2fjournal.pone.0193974&partnerID=40&md5=0187055b8f07b43f68ac5cd09f74fa81 1,factor analysis broadly used powerful unsupervised machine learning tool reconstruction hidden features recorded mixtures signals case linear approximation mixtures decomposed variety model free blind source separation bss algorithms available bss algorithms consider instantaneous mixing signals case mixtures linear combinations signals delays less explored especially difficult case number sources signals delays unknown determined data well address problem paper present new method based nonnegative matrix factorization nmf capable identifying unknown number sources b delays speed propagation signals c locations sources method used decompose records mixtures signals delays emitted unknown number sources nondispersive medium based recorded data case example electromagnetic signals multiple antennas received asynchronously mixtures acoustic seismic signals recorded sensors located different positions shift frequency induced doppler effect applying method synthetic datasets demonstrate ability identify unknown number sources well waveforms delays strengths signals using bayesian analysis also evaluate estimation uncertainties identify region likelihood positions sources found open access article free copyright may freely reproduced distributed transmitted modified built upon otherwise used anyone lawful purpose work made available creative commons cc public domain dedication
10.1016/j.epidem.2016.11.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009274885&doi=10.1016%2fj.epidem.2016.11.003&partnerID=40&md5=fab328d444e929b832082805cbd5768d 4,real time forecasts infectious diseases help public health planning especially outbreaks forecasts generated mechanistic models used target resources compare impact possible interventions however paremeterising models often difficult real time information behavioural changes interventions routes transmission readily available present semi mechanistic model infectious disease dynamics used real time â€“ west african ebola epidemic show fits ebola forecasting challenge conducted late simulated data mimicking true epidemic assess performance model different situations identify strengths shortcomings approach models one presented combine power mechanistic models flexibility include uncertainty precise outbreak dynamics may important tool combating future outbreaks â© author
10.1016/j.epidem.2017.02.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015326541&doi=10.1016%2fj.epidem.2017.02.011&partnerID=40&md5=cbb1d8e6caa13b10679a868607f2dd15 1,use two modelling approaches forecast synthetic ebola epidemics context rapidd ebola forecasting challenge first approach standard stochastic compartmental model aims forecast incidence hospitalization deaths among general population health care workers second model based renewal equation latent variables forecasts incidence whole population describe fitting forecasting procedures model discuss advantages drawbacks find one model consistently better forecasting â© author
10.1016/j.pocean.2018.02.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042703154&doi=10.1016%2fj.pocean.2018.02.013&partnerID=40&md5=49ab4e4a55da85e976ac11b6aaf8b819 0,study first attempt model spring food webs three sw mediterranean ecosystems different anthropogenic pressures ii project consequence stress function linear inverse models built using monte carlo method coupled markov chains characterize food web status lagoon channel inshore waters high eutrophication chemical contamination bay bizerte offshore waters less anthropogenic pressure ecological network analysis used description structural functional properties food web inter ecosystem comparisons results showed carbon produced phytoplankton inshore waters â€“ mg c mâˆ’ dâˆ’ compared bay mg c mâˆ’ dâˆ’ total ecosystem carbon inputs three food webs supported high primary production mainly due gt âµm algae however three carbon pathways characterized low detritivory high herbivory mainly assigned protozooplankton latter efficient channelling biogenic carbon lagoon channel foods webs acted almost multivorous structure tendency towards herbivorous one whereas bay herbivorous pathway dominant ecological indices revealed lagoon channel food webs systems high total system throughput thus active bay bay food web high relative ascendency value organized specialized interâ€“ecosystem difference due varying levels anthropogenic impact among sites indeed low value finn cycling index indicated three systems disturbed lagoon channel low average path lengths appeared stressed sites undergone higher chemical pollution nutrient loading study shows ecosystem models combined ecological indices provide powerful approach detect change environmental status anthropogenic impacts â©
10.1016/j.autcon.2017.12.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038016515&doi=10.1016%2fj.autcon.2017.12.007&partnerID=40&md5=e8c7046fb7a958087e847c461456e9d4 1,study methodology model predict life cycle performance building faã§ades based stochastic petri nets proposed proposed model evaluates performance rendered faã§ades time evaluating uncertainty future performance coatings performance rendered faã§ades evaluated based discrete qualitative scale composed five condition levels established according physical visual degradation elements study deterioration modelled considering transition times condition states modelled random variable different distributions purpose stochastic petri nets model used formal framework describe problem model validation based probabilistic indicators performance computed using monte carlo simulation probability distribution parameters leading better fit defined maximizing likelihood computed using genetic algorithm study sample rendered faã§ades located portugal analysed degradation condition case study evaluated situ visual inspections model proposed allows evaluating transition rate degradation conditions ii probability belonging given degradation condition time iii mean time permanence degradation condition use petri nets shows accurate traditional approach based markov chains also allows developing future research consider different environmental conditions maintenance actions inspections amongst aspects life cycle analysis existing assets â©
10.1190/geo2017-0183.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042322707&doi=10.1190%2fgeo2017-0183.1&partnerID=40&md5=815406a52d4bb05c5527f06c63339aa8 1,p wave inverse quality factors quantify seismic wave attenuation related several key reservoir parameters porosity saturation viscosity estimating inverse quality factors observed seismic data provides additional useful information gas bearing reservoir prediction first developed approximate reflection coefficient attenuative elastic impedance qei terms inverse quality factors established approach estimate elastic properties p wave impedances density attenuation p wave inverse quality factors seismic data different incidence angles frequencies approach implemented two step inversion model based damped least squares inversion qei bayesian markov chain monte carlo inversion inverse quality factors synthetic data tests confirm p wave impedances inverse quality factors reasonably estimated case moderate data error noise applying established approach real data set suggestive robustness approach furthermore physically meaningful inverse quality factors estimated seismic data acquired gas bearing reservoir â© society exploration geophysicists
10.1002/bimj.201600225 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036577087&doi=10.1002%2fbimj.201600225&partnerID=40&md5=ab87682d4c5537ec7da9d3fa6c2b106c 0,deterministic inputs noisy â€œandâ€� gate dina model popular cognitive diagnosis model cdm psychology psychometrics used identify test takers profiles respect set latent attributes skills work propose estimation method dina model u turn sampler nuts algorithm extension hamiltonian monte carlo hmc method conduct simulation study order evaluate parameter recovery efficiency new markov chain monte carlo method compare two bayesian methods metropolis hastings gibbs sampling algorithms frequentist method using expectationâ€“maximization em algorithm results indicated nuts algorithm employed dina model properly recovers parameters accurate simulated scenarios apply methodology mental health area order develop new method classification respondents beck depression inventory implementation method dina model applied psychological tests potential improve medical diagnostic process â© wiley vch verlag gmbh co kgaa weinheim
10.1007/s00180-017-0724-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016116530&doi=10.1007%2fs00180-017-0724-4&partnerID=40&md5=d6d01b5a38d20693faab76c1e8710270 0,optimal decision rule testing hypothesis using observations statistics two dimensional lattice system theoretically well understood since sun cai j r stat soc ser b stat methodol â€“ however practical use still faces several difficulties include computation local index significance lis paper propose peeling algorithm compute lis equivalently marginal posterior probability indicator true hypothesis site show proposed peeling algorithm several advantages popular markov chain monte carlo methods extensive numerical study application peeling algorithm finding active voxels task based fmri experiment also presented â© springer verlag berlin heidelberg
10.1109/TCBB.2015.2440244 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044921518&doi=10.1109%2fTCBB.2015.2440244&partnerID=40&md5=9aa89cd2184aae026b6890e885a6b1f4 1,ultra high dimensional variable selection become increasingly important analysis neuroimaging data example autism brain imaging data exchange abide study neuroscientists interested identifying important biomarkers early detection autism spectrum disorder asd using high resolution brain images include hundreds thousands voxels however existing methods feasible solving problem due extensive computational costs work propose novel multiresolution variable selection procedure bayesian probit regression framework recursively uses posterior samples coarser scale variable selection guide posterior inference finer scale variable selection leading efficient markov chain monte carlo mcmc algorithms proposed algorithms computationally feasible ultra high dimensional data also model incorporates two levels structural information variable selection using ising priors spatial dependence voxels functional connectivity anatomical brain regions applied resting state functional magnetic resonance imaging r fmri data abide study methods identify voxel level imaging biomarkers highly predictive asd biologically meaningful interpretable extensive simulations also show methods achieve better performance variable selection compared existing methods â© ieee
10.1111/rurd.12072 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044427675&doi=10.1111%2frurd.12072&partnerID=40&md5=2a2f006b2cee233cdeab74d10e217e0d 0,study examines consistency gaps national regional business cycles japan bayesian point view tokyo monopolar system started mid recent descriptive statistics migration per capita income show system continues despite severe crises burst economic bubble lehman brothers bankruptcy explore relationship national regional business cycles system using spatio temporal markov switching model markov chain monte carlo method empirical results show overall regional business cycle kanto region including tokyo identical national business cycle moreover find switches degree spatial dependency occur around turning points business cycles degree spatial dependency tends higher recession â© applied regional science conference arsc john wiley sons australia ltd
10.1007/s40304-017-0123-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042527119&doi=10.1007%2fs40304-017-0123-8&partnerID=40&md5=07016c17af451e849161b32f1ad185f8 0,paper optimum test plan parameter estimation step step stress accelerated life tests presence modified progressive type censoring discussed assumed lifetime test units follows lomax distribution log characteristic life quadratic function stress level maximum likelihood bayesian method used obtain point interval estimators model parameters bayes estimates obtained using markov chain monte carlo simulation based gibbs sampling optimum plan step step stress test modified progressive type censoring developed minimizes asymptotic variance maximum likelihood estimators log scale parameter design stress finally numerical study sensitivity analysis presented illustrate proposed study â© school mathematical sciences university science technology china springer verlag gmbh germany part springer nature
10.1007/s00362-016-0765-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961807634&doi=10.1007%2fs00362-016-0765-8&partnerID=40&md5=bfbbf962c449baefbf47b1144174cef9 1,paper consider system k statistically independent identically distributed strength components component constructed pair statistically dependent elements elements x x â€¦ xk yk follow bivariate kumaraswamy distribution element exposed common random stress follows kumaraswamy distribution system regarded operating least k â‰¤ sâ‰¤ k strength variables exceed random stress multicomponent reliability system given rs k= p least z â€¦ zk exceed zi= min xi yi i= â€¦ k estimate rs k using frequentist bayesian approaches bayes estimates rs k developed using lindleyâ€™s approximation markov chain monte carlo methods due lack explicit forms uniformly minimum variance unbiased exact bayes estimates rs k obtained analytically common second shape parameter known asymptotic confidence interval highest probability density credible interval constructed rs k reliability estimators compared using estimated risks monte carlo simulations real data analysed illustration findings â© springer verlag berlin heidelberg
10.1093/jssam/smx004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044384650&doi=10.1093%2fjssam%2fsmx004&partnerID=40&md5=5f40c8bbece732843e4bac34ff1b3b88 0,skip patterns bounds diverse measurement scales often exacerbate problem item nonresponse analysis survey data sequential variable variable imputation techniques quite successfully applied overcome problems techniques far focused relatively simple designs studies demonstrated consistency methods techniques draw joint posterior predictive distribution missing data consider sequential imputation technique based family hierarchical regression models extending sequential approach correlated data e g clustered data assess performance regression models tailored variable handled computational techniques used approximate posterior predictive distributions based markov chain monte carlo mcmc numerical integration overcome problem intractability present simulation study assessing compatibility approach joint data generation mechanism scenarios studied sequential method leads well calibrated estimates often performs better methods currently available practitioners â© author published oxford university press behalf american association public opinion research rights reserved
10.29220/CSAM.2018.25.2.131 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046888751&doi=10.29220%2fCSAM.2018.25.2.131&partnerID=40&md5=11b010c64822b79eaef70ba4fe526a2d 0,propose robust event date model estimate date target event combination individual dates obtained archaeological artifacts assumed contemporaneous dates affected errors different types laboratory calibration curve errors irreducible errors related contaminations taphonomic disturbances hence possible presence outliers modeling based hierarchical bayesian statistical approach provides simple way automatically penalize outlying data without remove dataset prior information individual irreducible errors introduced using uniform shrinkage density minimal assumptions bayesian parameters show event date model robust models implemented bcal oxcal although generally yields less precise credibility intervals model extended case stratigraphic sequences involve several events temporal order constraints relative dating duration hiatus constraints calculations based markov chain monte carlo mcmc numerical techniques performed using chronomodel software freeware open source cross platform features software presented vibet et al chronomodel v user manual finally compare prior event dates implemented chronomodel prior bcal oxcal involves supplementary parameters defined boundaries phases sequences â© korean statistical society korean international statistical society
10.1093/mnras/stx2982 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040231469&doi=10.1093%2fmnras%2fstx2982&partnerID=40&md5=1713125146158201fdb2750a204fdb51 3,paper study anisotropic universe model bianchi metric using joint lightcurve analysis jla sample type ia supernovae sne ia light curve parameters sne ia vary different cosmological models sne ia samples fit sne ia light curve parameters cosmological parameters simultaneously employing markov chain monte carlo method therefore results amount deviation isotropy dark energy equation state î´ level anisotropy large scale geometry î present totally model independent constraints skewness cosmic shear lt î´ lt lt î lt result consistent standard isotropic universe î´ = î = however moderate level anisotropy geometry universe equation state dark energy allowed besides obvious evidence preferred direction anisotropic axis model â© author published oxford university press behalf royal astronomical society
10.1007/s00180-017-0752-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025427719&doi=10.1007%2fs00180-017-0752-0&partnerID=40&md5=008e47452d074e4c6f3ed694db8b7491 0,new computational strategy produces independent samples joint posterior distribution broad class bayesian spatial spatiotemporal conditional autoregressive models method based reparameterization marginalization posterior distribution massive parallelization rejection sampling using graphical processing units gpus accelerators enables fast sampling small moderate sized datasets approximately observations feasible sampling much larger datasets even using mid range gpu high end cpu gpu based implementation times faster algorithm run serially single cpu numbers effective samples per second orders magnitude higher obtained popular markov chain monte carlo software method implemented r package carrampsocl work provides practical computing strategy fitting popular class bayesian models proof concept gpu acceleration make independent sampling bayesian joint posterior densities feasible â© springer verlag gmbh germany
10.1007/s11336-016-9525-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992727873&doi=10.1007%2fs11336-016-9525-x&partnerID=40&md5=47bc2c3d3f487c3aca7e6be54d991e45 4,statistical methods identifying aberrances psychological educational tests pivotal detect flaws design test irregular behavior test takers two approaches taken past address challenge aberrant behavior detection modeling aberrant behavior via mixture modeling methods flagging aberrant behavior via residual based outlier detection methods paper propose two stage method conceived combination approaches first stage mixture hierarchical model fitted response response time data distinguish normal aberrant behaviors using markov chain monte carlo mcmc algorithm second stage distinction rapid guessing cheating behavior made person level using bayesian residual index simulation results show two stage method yields accurate item person parameter estimates well high true detection rate low false detection rate different manipulated conditions mimicking naep parameters real data example given end illustrate potential application proposed method â© psychometric society
10.1016/j.jcomm.2017.12.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044462264&doi=10.1016%2fj.jcomm.2017.12.003&partnerID=40&md5=f8352925e76eb3914e7a550ae26ae9d6 1,paper propose model oil price dynamics provide estimation method based recent technique named particle filtering model going introduce extends previous model proposed liu tang including non constant volatility jumps spot price dynamics estimation methodology going adopt similar particle markov chain monte carlo pmcmc method proposed andrieu et al spot futures quotation data related wti west texas intermediate analyzed order perform inference procedure models considered allow obtain explicit expressions futures prices functions model parameters turn makes calibration procedure fast accurate time comparison model considered model proposed liu tang provided terms prices forecasting ability inference analysis shows introduction stochastic volatility jumps improve significantly ability model capturing oil price dynamics features â© elsevier b v
10.1111/bcp.13470 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040327287&doi=10.1111%2fbcp.13470&partnerID=40&md5=f94974115fc9880b1c086c4cd09b944d 2,aims topical growth factors accelerate wound healing patients diabetic foot ulcers dfu due absence head head comparisons carried bayesian network meta analysis compare efficacy safety growth factors methods using appropriate search strategy randomized controlled trials topical growth factors compared standard care patients dfu included proportion patients complete healing primary outcome odds ratio confidence interval used effect estimate random effects model used direct indirect comparisons markov chain monte carlo simulation used obtain pooled estimates rankogram generated based surface cumulative ranking curve sucra results total studies participants events included pooled estimates recombinant epidermal growth factor rhegf autologous platelet rich plasma prp recombinant human platelet derived growth factor rhpdgf respectively sucra rhegf sensitivity analyses reveal significant changes pooled estimates rankogram differences observed overall risk adverse events growth factors however growth factors observed lower risk lower limb amputation compared standard care conclusion conclude rhegf rhpdgf autologous prp significantly improved healing rate used adjuvants standard care rhegf may perform better growth factors strength outcomes assessed low findings may applicable dfu infection osteomyelitis findings study needs considered caution results might change findings head head studies â© british pharmacological society
10.1093/mnras/stx3026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040229345&doi=10.1093%2fmnras%2fstx3026&partnerID=40&md5=a7f5f88587e0da5791821dedb6865448 3,studied central regions galactic centre determine circumnuclear disc cnd acts absorber barrier central x rays diffuse emission reprocessing ms chandra observations able detect first time depression x ray luminosity diffuse emission whose size location correspond cnd extracted x ray spectra various regions inside cnd footprint well region footprint observed region located outside footprint simultaneously fitted spectra optically thin plasma whose absorption interstellar medium ism local plasma fitted independently using markov chain monte carlo method hydrogen column density ism ã— cm x ray diffuse emission inside cnd footprint formed plasma kev slightly super solar abundances except iron carbon sub solar plasma cnd turn better described model abundances local hydrogen column density different innermost regions large iron abundance region confirms cnd dominated shock heated ejecta sgr east supernova remnant deduced cnd rather acts barrier galactic centre plasma plasma located outside cnd may correspond collimated outflow possibly created sgr interaction wind massive stars mini spiral material â© author published oxford university press behalf royal astronomical society
10.1016/j.neuroimage.2017.03.039 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016988802&doi=10.1016%2fj.neuroimage.2017.03.039&partnerID=40&md5=e24a3b5475b8428eebebd084e7c6eb95 1,several magnetic resonance imaging mri contrasts sensitive myelin content gray matter vivo ignited ambitions mri based vivo cortical histology ultra high field uhf mri fields beyond crucial provide resolution contrast needed sample contrasts depth cortex get closer layer resolved imaging ex vivo mri human post mortem samples important stepping stone investigate mri contrast cortex validate histology techniques applied situ tissue investigate resolutions needed translate ex vivo findings vivo uhf mri investigate key technology extend uhf studies large human brain samples maintaining high resolution allows investigation layered architecture several cortical areas entire extent complete borders architecture changes channel cylindrical phased array radiofrequency rf receive coil constructed image large post mortem occipital lobe sample ã— ã— mm wide bore human scanner aim achieving high resolution anatomical quantitative mr images compared human head coil maximum signal noise ratio snr increased factor five peripheral cortex although transmit profile circularly polarized transmit mode relatively inhomogeneous large sample challenge successfully resolved parallel transmit using kt points method using setup achieved î¼m anatomical images entire occipital lobe showing increased spatial definition cortical details compared lower resolutions addition able achieve sufficient control snr b b homogeneity multi contrast sampling perform quantitative mapping volume î¼m markov chain monte carlo sampling provided maximum posterior estimates quantitative uncertainty allowing delineation stria gennari entire length width calcarine sulcus discuss custom rf receive coil arrays built specific large post mortem sample sizes provide platform uhf cortical layer specific quantitative mri large fields view â© authors
10.1093/mnras/stx3049 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040235580&doi=10.1093%2fmnras%2fstx3049&partnerID=40&md5=3e43339ed2b7b8abbf2ce1b1fcb272bf 2,orbital parameters binaries intermediate periods difficult measure conventional methods incomplete undertaken new survey applying pulsation timing method kepler light curves main sequence f stars found non eclipsing binaries calculate orbital parameters pb systems single pulsator binaries pb double pulsators tripling number intermediate mass binaries full orbital solutions method reaches small mass ratios q â‰ˆ yields highly homogeneous sample parametrize massratio distribution using inversion markov chain monte carlo forward modelling techniques find skewed towards low mass companions peaking q â‰ˆ solar type primaries exhibit brown dwarf desert across short intermediate periods find small statistically significant ïƒ population extreme mass ratio companions q lt intermediate mass primaries across periods q gt measure binary fraction current f primaries percent â± per cent though find large fraction companions percent â± per cent white dwarfs post mass transfer systems primaries blue stragglers progenitors type ia supernovae barium stars symbiotics related phenomena excluding white dwarfs determine binary fraction original f primaries percent â± per cent parameter space combining measurements literature find binary fraction across periods constant per cent primaries lt mâš™ increases linearly log demonstrating natal discs around massive protostars â‰³ mâš™ become increasingly prone fragmentation finally find eccentricity distribution main sequence pairs much less eccentric thermal distribution â© author
10.1002/sim.7541 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041329594&doi=10.1002%2fsim.7541&partnerID=40&md5=9a44fb520140e4b801a1178c182c4eaf 0,practice count data may exhibit varying dispersion patterns excessive zero values additionally may appear groups clusters sharing common source variation present novel bayesian approach analyzing data model features combine conway maxwell poisson distribution allows overdispersion underdispersion hurdle component zeros random effects clustering propose efficient markov chain monte carlo sampling scheme obtain posterior inference model simulation studies compare hurdle conway maxwell poisson model hurdle poisson model demonstrate effectiveness conway maxwell poisson approach furthermore apply model analyze illustrative dataset containing information number types carious lesions tooth population year olds iowa fluoride study ongoing longitudinal study cohort iowa children began copyright â© john wiley sons ltd
10.23919/APCC.2017.8303984 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050610224&doi=10.23919%2fAPCC.2017.8303984&partnerID=40&md5=d36dc0347fc7c72aa3dc973b98fc4683 0,plasma sheath channel serious impact propagation electromagnetic waves resulting radio blackout problem aerospace communications existing studies plasma sheath channel characteristics analyzed based computer simulations lack real world experimental verification thereby studies failed fully demonstrate high dynamics plasma sheath channel paper experimental communication system based shock tube proposed investigate plasma sheath channel characteristics plasma sheath channel analyzed based experimental results particular high dynamic fast time varying channel characteristics verified analyzing signal amplitude signal phase shift coherence time finally show example using presented channel characteristics non stationary signal segmentation method proposed based reversible jump markov chain monte carlo algorithm applicable plasma sheath channel signal segmentation â© ieee
10.1080/01457632.2017.1305823 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020290839&doi=10.1080%2f01457632.2017.1305823&partnerID=40&md5=a1002e01c66c6d05e6d49f54be2c65c7 0,paper reports use markov chain monte carlo mcmc metropolis hastings mh approach solve inverse heat transfer problem three dimensional steady state conjugate heat transfer teflon cylinder dimensions â mm diameter â mm length uniform volumetric internal heat generation considered goal estimate volumetric heat generation heat transfer coefficient given temperature data certain fixed location surface cylinder internal volumetric heat generation specified input temperature heat transfer coefficient values obtained numerical solution governing equation temperature values also depend heat transfer coefficient obtained solving navierâ€“stokes equation obtain flow information order reduce computational cost neural network trained computational fluid dynamics simulations posed inverse problem wherein volumetric heat generation heat transfer coefficient unknown temperature data known conducting experiments novelty paper simultaneous determination volumetric heat generation heat transfer coefficient experimentally measured steady state temperatures teflon cylinder using mcmc mh inverse model bayesian framework finally estimates reported terms mean maximum posteriori standard deviation uncertainty associated estimated parameters â© taylor francis group llc
10.1080/03610918.2018.1438619 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042367426&doi=10.1080%2f03610918.2018.1438619&partnerID=40&md5=29023f09dc780a011baec47166419b3d 1,current study develop robust bayesian inference generalized inverted family distributions gifd îµ contamination class prior distributions shape parameter î± different possibilities known unknown scale parameter used type ii censoring bartholomew sampling scheme following derivations squared error loss function self linear exponential linex loss function ml ii bayes estimators parameters ii reliability function iii hazard function also present simulation study analysis real data set â© taylor francis group llc
381.71334823635374 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048123311&partnerID=40&md5=7bae440f17558de7de3a6a2386af1ce6 0,inverse problems arise many fields science focusing process explores causal factors set measurements observed compared deterministic methods statistical inversion capable finding global optima nonlinear inverse problems paper propose statistical approach based markov chain monte carlo mcmc method implementation scalable dataset parallel environment message passing interface mpi traditional mcmc method launches one chain time approach simultaneously launch multiple markov chains one inverse problem calculating data misfit applying proper clustering algorithms get good estimation formation parameters different inversion results numerical experimental evidences show parallel approach better performance traditional approaches meanwhile requires much less computational time appropriate resource allocation â© usnc ursi
10.1109/ASPDAC.2018.8297393 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045312615&doi=10.1109%2fASPDAC.2018.8297393&partnerID=40&md5=537ca0c5a1be38c86ac3e6b7ed895c0b 0,effect negative bias temperature instability nbti varies significantly according given workloads thus path delay degradation strongly dependent use case paper propose subset simulation ss framework efficiently accurately finds worst case workload failure probability covering various workloads proposed method workloads yield worst aged delay efficiently generated nbti aware markov chain monte carlo method numerical experiments using benchmark circuits proposed method achieves times speedup compared naive monte carlo method result ss feasible workload gives worst aged delay obtained â© ieee
10.1002/sim.7530 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040746153&doi=10.1002%2fsim.7530&partnerID=40&md5=ad2bd1d664fc4703b3ec5c6a18cd9e9d 0,many disease diagnoses involve subjective judgments qualified raters example inspection mammogram mri ultrasound image clinician becomes part measuring instrument reduce diagnostic errors improve quality diagnoses necessary assess raters diagnostic skills improve skills time paper focuses subjective binary classification process proposing hierarchical model linking data rater opinions patient true disease development outcomes model allows quantification effects rater diagnostic skills bias magnifier patient latent disease severity rating results bayesian markov chain monte carlo mcmc algorithm developed estimate parameters linking patient true disease outcomes rater specific sensitivity specificity estimated using mcmc samples cost theory used identify poor strong performing raters guide adjustment rater bias diagnostic magnifier improve rating performance furthermore diagnostic magnifier shown key parameter present rater diagnostic ability rater larger diagnostic magnifier uniformly better receiver operating characteristic roc curve varying value diagnostic bias simulation study conducted evaluate proposed methods methods illustrated mammography example copyright â© john wiley sons ltd
10.1103/PhysRevE.97.022413 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042234285&doi=10.1103%2fPhysRevE.97.022413&partnerID=40&md5=60ea6d1989408d2dff104a30dc9bc5d2 0,deterministic hill function depends average values molecule numbers account fluctuations molecule numbers argument hill function needs contain means standard deviations correlations present method allows stochastic hill functions constructed dynamical evolution stochastic biocircuits specific topologies stochastic hill functions presented closed analytical form easily incorporated models large genetic regulatory networks using repressive biocircuit example show monte carlo simulations traditional deterministic hill function inaccurately predicts time repression order two magnitudes however stochastic hill function able capture fluctuations thus accurately predicted time repression â© american physical society
10.1103/PhysRevD.97.043520 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043700554&doi=10.1103%2fPhysRevD.97.043520&partnerID=40&md5=7ba9db5a489dc02732df7e43bc4551ef 2,higgs dilaton model scale invariant extension standard model nonminimally coupled gravity containing one additional degree freedom top standard model particle content minimalistic scenario predicts set measurable consistency relations inflationary observables dark energy equation state parameter present alternative derivation consistency relations highlights connections differences î± attractor scenario study far constraints allow one distinguish higgs dilaton model î›cdm wcdm cosmologies end first analyze existing data sets using markov chain monte carlo approach second perform forecasts future galaxy surveys using fisher matrix approach galaxy clustering weak lensing probes assuming best fit values different models remain comparable present ones show euclid ska like missions able discriminate higgs dilaton cosmology î›cdm wcdm â© american physical society
10.1088/1475-7516/2018/02/043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043600145&doi=10.1088%2f1475-7516%2f2018%2f02%2f043&partnerID=40&md5=07d066e4b3914a0dfa7e003686fac9f6 2,revisit constraints planck temperature polarization lensing data impose parameters warm inflation end study warm inflation driven single scalar field quartic self interaction potential weak dissipative regime analyse effect parameters warm inflation namely inflaton self coupling î» inflaton dissipation parameter qp cmb angular power spectrum constrain î» qp number e foldings full planck data tt te ee + lowp lensing performing markov chain monte carlo analysis using publicly available code cosmomc obtain joint well marginalized distributions parameters present results form mean confidence limits parameters also highlight degeneracy î» qp analysis analysis show warm inflation parameters well constrained using planck data â© iop publishing ltd sissa medialab
10.3847/1538-4357/aaaa68 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042702449&doi=10.3847%2f1538-4357%2faaaa68&partnerID=40&md5=dc7f257e00adad290b59c0c85b614888 9,report systematic search emission line around kev spectrum cosmic x ray background using total âˆ¼ ms chandra observations toward cosmos legacy extended chandra deep field south survey fields find marginal evidence feature energy âˆ¼ kev significance ïƒ depending choice statistical treatment line intensity best fit â± ã— ph cm using simple î”ï‡ ph cm markov chain monte carlo used based knowledge chandra reported detection line instruments instrumental origin line remains unlikely however rule statistical fluctuation case results provide ïƒ upper limit ã— ph cm discuss interpretation observed line terms iron line background xvi charge exchange well potentially sterile neutrino decay note detection consistent previous measurements line toward galactic center modeled result sterile neutrino decay milky way dark matter distribution modeled navarro frenk white profile case estimate mass î½ âˆ¼ kev mixing angle sin î = ã— derived values agreement independent estimates galaxy clusters galactic center â© american astronomical society rights reserved
10.3847/1538-4357/aaa9be https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042688972&doi=10.3847%2f1538-4357%2faaa9be&partnerID=40&md5=9d2c07da174c199eb18d92342b8e438b 4,interstellar medium crucial understanding physics active galaxies coevolution supermassive black holes host galaxies however direct gas measurements limited sensitivity uncertainties dust provides efficient indirect probe total gas apply technique large sample quasars whose total gas content prohibitively expensive measure present comprehensive study full î¼m infrared spectral energy distributions redshift quasars selected palomar green sample using photometric measurements mass wise herschel combined spitzer mid infrared î¼m spectra newly developed bayesian markov chain monte carlo fitting method decompose various overlapping contributions integrated spectral energy distribution including starlight warm dust torus cooler dust galaxy scales procedure yields robust dust mass use infer gas mass using gas dust ratio constrained host galaxy stellar mass quasar hosts gas fractions similar massive star forming galaxies although minority seem genuinely gas deficient resembling present day massive early type galaxies result indicates quasar mode feedback occur ineffective host galaxies low redshift quasars also find quasars boost interstellar radiation field heat dust galactic scales cautions common practice using far infrared luminosity estimate host galaxy star formation rate â© american astronomical society rights reserved
10.1109/ACCESS.2018.2807807 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042173085&doi=10.1109%2fACCESS.2018.2807807&partnerID=40&md5=635ce434e9937076d1a01173600e0e58 0,ultrasound contrast imaging uci aims detect flow changes vascular bed help differentiate normal diseased tissues thus providing early screening tool diagnosis treatment monitoring ultrasound contrast agents ucas used uci microbubbles scatter ultrasound non linearly date signal processing research successfully subtracted signals linear response tissue linear signals general provided sensitive detection specific uca signal paper develops method temporal spectral estimation linear non linear ultrasound echo signals technique based non parametric methods coarse estimation followed parametric method within bayesian framework estimation refinement results show pulse location estimated within â± sample points accuracy signals consisting â‰ˆ sample points depending signal type frequency content estimated within mhz deviations frequencies mhz range parametric spectral estimation achieved fold improvement frequency resolution compared fourier based methods revealed previously unresolved frequency information led correct signal classification linear non linear echo signals â© ieee
10.1080/02664763.2017.1288200 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012052974&doi=10.1080%2f02664763.2017.1288200&partnerID=40&md5=63ee40758c12a5dd71f5809de612f8f2 1,paper propose novel bayesian statistical methodology spatial survival data methodology broadens definition survival density hazard functions explicitly modeling spatial dependency using direct derivations functions marginals conditionals also derive spatially dependent likelihood functions finally examine applications derivations geographically augmented survival distributions context louisiana surveillance epidemiology end results registry prostate cancer data â© informa uk limited trading taylor francis group
10.1002/2017GL076429 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041899083&doi=10.1002%2f2017GL076429&partnerID=40&md5=9b7740fb43dc60f64b9a08aed7aa6516 1,accelerating rates quasiperiodic â€œdrumbeatâ€� long period earthquakes lps commonly reported eruptions andesite dacite volcanoes promise insights nature fundamental preeruptive processes improved eruption forecasts apply new bayesian markov chain monte carlo gamma point process methodology investigate exceptionally well developed sequence drumbeat lps preceding recent large vulcanian explosion tungurahua volcano ecuador â hr lp rates increased according inverse power law trend predicted material failure theory retrospectively forecast failure time agrees eruption onset within error lps resulted repeated activation single characteristic source driven accelerating loading rather distributed failure process showing similar precursory trends emerge quite different underlying physics nevertheless sequences clear potential improving forecasts eruptions tungurahua analogous volcanoes â© american geophysical union rights reserved
10.1016/j.physa.2017.11.134 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035357319&doi=10.1016%2fj.physa.2017.11.134&partnerID=40&md5=4b36e02f862739557157355748bf403c 3,traditional complex network theory particularly focused network models network constituents dealt equivalently fail consider supplementary information related dynamic properties network interactions main constraint leading incorrect descriptions real world phenomena incomplete capturing details certain real life problems cope problem paper addresses multilayer aspects dynamic complex networks analyzing properties intrinsically multilayered co authorship networks dblp astro physics presenting novel multilayer model dynamic complex networks model examines layers evolution layers birth death process lifetime throughout network evolution particularly paper models evolution node membership different layers infinite factorial hidden markov model considering feature cascade thereby formulates link generation process intra layer inter layer links although adjacency matrixes useful describe traditional single layer networks representation sufficient describe analyze multilayer dynamic networks paper also extends generalized mathematical infrastructure address problems issued multilayer complex networks model inference performed using markov chain monte carlo sampling strategies given synthetic real complex networks data experimental results indicate tremendous improvement performance proposed multilayer model terms sensitivity specificity positive negative predictive values positive negative likelihood ratios f score matthews correlation coefficient accuracy two important applications missing link prediction future link forecasting experimental results also indicate strong predictivepower proposed model application cascade prediction terms accuracy â© elsevier b v
10.3969/j.issn.1001-8360.2018.02.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047099401&doi=10.3969%2fj.issn.1001-8360.2018.02.001&partnerID=40&md5=e13716fbf86f70a57cd1edcf7431ecd8 0,development urban rail transit network provides alternative routes passengers however passengers usually consider routes e effective route set generation threshold range certain factor e g travel time choose best one set effective routes semi compensatory mixed logit route choice model urban rail transit passengers proposed two sub processes combined based bayesian theory effective function coefficients threshold parameters regarded random variables express differences among passengers choice preferences among thresholds effective route set model estimation method designed combining data augmentation technique markov chain monte carlo method estimate effective function coefficients threshold parameters endogenously based surveyed data guangzhou metro estimations show thresholds reliable proposed model better traditional models respect scenario network structural change caused connection line guangzhou metro network transfer flow volumes transfer stations estimated based proposed model mean absolute error results demonstrate adaptability proposed model travel demand forecasting condition network structural change â© department journal china railway society right reserved
10.1145/3174243.3174259 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050192342&doi=10.1145%2f3174243.3174259&partnerID=40&md5=c10271fe00769a1de42e6e3f551d4d84 0,paper proposes causalearn first automated framework enables real time scalable approximation probability density function pdf context causal bayesian graphical models causalearn targets complex streaming scenarios input data evolves time independence assumed data samples e g continuous time varying data analysis framework devised using hw sw co design approach provide first implementation hamiltonian markov chain monte carlo fpga efficiently sample steady state probability distribution scales considering correlation observed data causalearn customizable limits underlying resource provisioning order maximize effective system throughput uses physical profiling abstract high level hardware characteristics characteristics integrated automated customization unit order tile schedule batch pdf approximation workload corresponding pertinent platform resources constraints benchmark design performance analyzing various massive time series data three fpga platforms different computational budgets extensive evaluations demonstrate two orders magnitude runtime energy improvements compared best known prior solution provide accompanying api leveraged data scientists practitioners automate abstract hardware design optimization â© association computing machinery
10.1016/j.physa.2017.11.076 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035073299&doi=10.1016%2fj.physa.2017.11.076&partnerID=40&md5=ef590f19fe10efc547d1a4d57fc204b9 1,increasingly recognized understanding complex interplay patterns epidemic spreading human behavioral key component successful infection control efforts particular individuals obtain information epidemics respond altering behaviors affect spreading dynamics well besides existence herd like behaviors individuals easy influenced global awareness information paper propose global awareness controlled spreading model gacs explore interplay coupled dynamical processes using global microscopic markov chain approach obtain analytical results epidemic thresholds shows high accuracy comparison lots monte carlo simulations furthermore considering classical models used describe coupled dynamical processes including local awareness controlled contagion spreading lacs model susceptibleâ€“infectedâ€“susceptibleâ€“unawareâ€“awareâ€“unaware sisâ€“uau model single layer occasion make detailed comparisons gacs although comparisons results depend parameters model gacs model always shows strong restrain effects epidemic spreading process results give us better understanding coupled dynamical processes highlights importance considering spreading global awareness control epidemics â© elsevier b v
10.1093/bioinformatics/btx626 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042550998&doi=10.1093%2fbioinformatics%2fbtx626&partnerID=40&md5=f3d381ca52628e4dc034e4f220e4d609 2,summary biological models contain many parameters whose values difficult measure directly via experimentation therefore require calibration experimental data markov chain monte carlo mcmc methods suitable estimate multivariate posterior model parameter distributions methods may exhibit slow premature convergence high dimensional search spaces present pydream python implementation multiple try differential evolution adaptive metropolis dream zs algorithm developed byvrugt ter braak andlaloy vrugt pydream achieves excellent performance complex parameter rich models takes full advantage distributed computing resources facilitating parameter inference uncertainty estimation cpu intensive biological models availability implementation pydream freely available gnu gplv license lopez lab github repository http github com lolab vu pydream contact c lopez vanderbilt edu supplementary informationsupplementary dataare available bioinformatics online â© author published oxford university press
10.1109/PIMRC.2017.8292505 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045275309&doi=10.1109%2fPIMRC.2017.8292505&partnerID=40&md5=7dd42b070a6205765197ef0dbee7c8f7 0,heterogenous networks hetnets using different size cells several different networks multiple wireless access technologies provide large capacities also improving localization accuracy paper propose novel received signal strength rss based inter network cooperative localization framework based metropolis hastings mh algorithm twotier hetnets unknown transmit powers mh based estimation methodology unknown position user equipment transmit powers base stations bss jointly estimated validity proposed method confirmed simulation results â© ieee
10.1109/TCBB.2018.2802911 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042111564&doi=10.1109%2fTCBB.2018.2802911&partnerID=40&md5=c63322ee112cf2fc41abbf9672d2e891 0,subtree prune regraft spr distance metric fundamental way comparing evolutionary trees wide ranging applications study lateral genetic transfer viral recombination markov chain monte carlo phylogenetic inference although rooted version spr distance computed relatively efficiently rooted trees using fixed parameter tractable maximum agreement forest maf algorithms maf formulation known unrooted case correspondingly previous algorithms unable compute unrooted spr distances larger ccby
10.1002/sim.7533 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034573162&doi=10.1002%2fsim.7533&partnerID=40&md5=9d1aabba76c88940db240f4d100eadac 0,drug dilution mic disk diffusion dia common antimicrobial susceptibility assays used hospitals clinics determine unknown pathogen susceptibility various antibiotics since one assay commonly used important assays give similar results calibration dia assay mic assay typically done using error rate bounded method selects dia breakpoints minimize observed discrepancies assays craig proposed model based approach specifically models measurement error rounding processes assay underlying pathogen distribution true monotonic relationship assays assays calibrated focusing matching probabilities correct classification susceptible indeterminant resistant approach results greater precision accuracy estimating dia breakpoints paper expand flexibility model based method introducing bayesian parameter logistic model extending craig original parameter model well bayesian nonparametric spline model describe relationship assays propose ways handle spline knot selection considering many equally spaced knots restricting overfitting via random walk prior treating number location knots additional unknown parameters demonstrate approaches via series simulation studies apply methods real data sets copyright â© john wiley sons ltd
10.3847/1538-4357/aaa9c2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042613883&doi=10.3847%2f1538-4357%2faaa9c2&partnerID=40&md5=433768bb91f97575469b6d6181998fcd 4,present deep spectroscopic observations lyman break galaxy lbg candidate hereafter macs jd z âˆ¼ hubble space telescope hst wfc ir grisms grism observations taken four distinct position angles totaling orbits g grism although orbits relatively uncontaminated along trace macs jd fit three parameter z f w mag lyî± equivalent width ew lbg template three least contaminated grism position angles using markov chain monte carlo approach grism data alone best fit redshift confidence good agreement photometric estimate confidence analysis rules lyî± emission macs jd ïƒ ew ã… consistent highly neutral igm explore scenario red spitzer irac color galaxy previously pointed literature due strong rest frame optical emission lines young stellar population rather ã… break find provide explanation observed irac color requires lower redshift z â‰² less preferred hst imaging data grism data consistent scenarios indicating red irac color still explained ã… break characteristic relatively evolved stellar population interpretation photometry indicates myr stellar population already present galaxy âˆ¼ myr big bang â© american astronomical society rights reserved
10.3389/fncel.2018.00033 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043597927&doi=10.3389%2ffncel.2018.00033&partnerID=40&md5=302c90ce4582e9a04bd187bc70f3d037 0,understanding relationships rates dynamics current wave forms voltage clamp conditions essential understanding phenomena state dependence use dependence fundamental action drugs used anti epileptics anti arrhythmics anesthetics present study mathematically analyze models blocking mechanisms previous experimental studies potassiumchannels shown effect local anesthetics explained binding channels open state therefore examine models describe effect blocking drug binds non inactivating channel open state binding induces inactivation like current decay higher potential steps amplitude induced peak depends voltage concentration blocking drug present study using analytical methods derive criterion existence peak open probability time evolution model arbitrary number closed states ii derive formula relative height peak amplitude iii determine voltage dependence relative peak height two findings apparent dissociation unbinding rate constant important existence peak current waveform association binding rate constant peak exist suffices dissociation rate must smaller absolute value eigenvalues kinetic matrix describing model â© zeberg nilsson ã…rhem
10.1186/s12966-018-0649-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041841279&doi=10.1186%2fs12966-018-0649-5&partnerID=40&md5=7802dd3d7209d07a0d9e0a28ee5d8dad 0,background guided socialization model child behavior smcb cross sectional study examined direct indirect associations parental cognitions behavior home neighborhood environment toddlers personal attributes toddlers physical activity screen time methods participants included toddlers â± years parents role establishing healthy physical activity sedentary behavior habits preps project toddlers screen time personal attributes physical activity screen time specific parental cognitions behaviors home neighborhood environment measured via parental report using preps questionnaire accelerometry measured physical activity available toddlers bayesian estimation structural equation modeling sem using markov chain monte carlo algorithm performed test smcb hypothesized model covariates included toddlers age sex race ethnicity main type childcare family household income results smcb hypothesized screen time model higher parental barrier self efficacy limiting toddlers screen time associated higher parental screen time limiting practices î²= higher parental negative outcome expectations limiting toddlers screen time associated lower parental screen time limiting practices î² = turn higher parental screen time limiting practices associated lower screen time among toddlers î² = parental modeling higher screen time associated higher screen time among toddlers directly î²= indirectly home environment specifically higher screen time among parents associated least one electronic device toddlers bedrooms î²= turn electronics bedroom compared none associated higher screen time among toddlers î²= neighborhood safety associated toddlers screen time sem analysis significant correlations observed smcb variables toddlers physical activity thus analyses performed physical activity conclusions parents interactions home environment may play important role shaping toddlers screen time findings inform family based interventions aiming minimize toddlers screen time future research needed identify correlates toddlers physical activity â© author
10.1103/PhysRevE.97.022112 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042082092&doi=10.1103%2fPhysRevE.97.022112&partnerID=40&md5=47fefa24d8d1e1aea640327293120708 0,study diffusion controlled two species annihilation finite number particles stochastic process particles move diffusively two particles opposite type come contact two annihilate focus behavior three spatial dimensions initial conditions particles confined compact domain generally one species outnumbers find difference number majority minority species conserved quantity controls behavior number difference exceeds critical value minority becomes extinct finite number majority particles survive critical difference finite number particles species survive critical difference î”c grows algebraically total initial number particles n n critical difference scales î”câˆ¼n furthermore initial concentrations two species equal average number surviving majority minority particles m+ exhibit two distinct scaling behaviors m+âˆ¼n âˆ¼n contrast initial populations equal two quantities comparable m+âˆ¼m âˆ¼n â© american physical society
10.1109/ITNEC.2017.8284942 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046701177&doi=10.1109%2fITNEC.2017.8284942&partnerID=40&md5=ee5e1d804b632324d2323a53645aa350 0,blind estimation algorithm based overlapping segment markov chain monte carlo unscented kalman filter mcmc ukf proposed problem spread spectrum code information sequence blind estimation long code direct sequence spread spectrum dsss signal algorithm based bayesian framework model combined idea overlapping segmentation using ukf algorithm solve nonlinear model estimate mean variance posterior probability parameter finally use mcmc method iterate segment spread spectrum sequence sequence splicing complete spread spectrum sequence information sequence estimates algorithm achieve effective estimation short codes long code signals limited type spread spectrum sequences simulation results show proposed algorithm better performance low snr â© ieee
10.1080/03610918.2017.1288244 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020457131&doi=10.1080%2f03610918.2017.1288244&partnerID=40&md5=eba3473bce5a557af8d3a37c6b32a090 0,mixture models frequently used modeling complex data extension em algorithm called ecme proposed compute maximum likelihood estimate parameters symmetric î± stable mixture model sî±smm comprehensive simulation studies performed show performance proposed ecme algorithm robustness sî±smm investigated simulations used model data generated mixture exponential power distributions proposed ecme bayesian approaches applied three sets real data shows proposed ecme algorithm outperforms bayesian paradigm three sets also sî±smm compared mixture normal skew normal skew distributions modeling four sets real data turns sî±smm works well better models considered sî±smm capability robust mixture modeling â© taylor francis group llc
10.1109/ICTUS.2017.8285989 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047124809&doi=10.1109%2fICTUS.2017.8285989&partnerID=40&md5=a73d1304e0c91f76d3133d107e1b8a64 0,discuss interval estimation approach parameters software reliability assessment measures derived discretized software reliability model approach apply markov chain monte carlo mcmc method conducing bayesian interval estimations software reliability assessment shows numerical examples approach using actual fault count data â© ieee
10.1063/1.5017031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041418662&doi=10.1063%2f1.5017031&partnerID=40&md5=febd53c9b296efe7e3e865d977fb578e 2,use markov state models msms analyze dynamics î² hairpin forming peptide monte carlo mc simulations interacting protein crowders two different types crowder proteins bovine pancreatic trypsin inhibitor bpti gb systems temperature used peptide folded unfolded bound unbound crowder molecules four five major free energy minima identified estimate dominant mc relaxation times peptide build msms using range different time resolutions lag times show stable relaxation time estimates obtained msm eigenfunctions fits autocorrelation data eigenfunctions remain sufficiently accurate permit stable relaxation time estimation small lag times point simple estimates based corresponding eigenvalues large systematic uncertainties presence crowders stabilizing effect peptide especially bpti crowders attributed reduced unfolding rate ku folding rate kf left largely unchanged â© author
10.1080/07474938.2015.1032166 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949544964&doi=10.1080%2f07474938.2015.1032166&partnerID=40&md5=971bc18e8b8703d9df3c0fe01a08a148 0,decreasing block rate pricing nonlinear price system often used public utility services residential gas services japan united kingdom provided price schedule discrete continuous choice approach used analyze demand decreasing block rate pricing however nonlinearity problem examined previous studies arises consumerâ€™s budget set set affordable consumption amounts nonconvex hence resulting model includes highly nonlinear functions address problem propose feasible efficient method demand estimation nonconvex budget advantages method follows construction markov chain monte carlo algorithm efficient blanket based hermiteâ€“hadamard integral inequality power mean inequality ii explicit consideration highly nonlinear separability condition often makes numerical likelihood maximization difficult iii introduction normal disturbance discrete continuous choice model nonconvex budget set proposed method applied estimate japanese residential gas demand function evaluate effect price schedule changes policy experiment â© taylor francis group llc
10.1137/16M1108340 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045631248&doi=10.1137%2f16M1108340&partnerID=40&md5=ec736c0102ccf1af9f2474b8669cfa64 2,modern imaging methods rely strongly bayesian inference techniques solve challenging imaging problems currently predominant bayesian computation approach convex optimization scales efficiently high dimensional image models delivers accurate point estimation results however order perform complex analyses example image uncertainty quantification model selection necessary use computationally intensive bayesian computation techniques markov chain monte carlo methods paper presents new highly efficient markov chain monte carlo methodology perform bayesian computation high dimensional models log concave nonsmooth class models central imaging sciences methodology based regularized unadjusted langevin algorithm exploits tools convex analysis namely moreauâ€“yoshida envelopes proximal operators construct markov chains favorable convergence properties addition scaling efficiently high dimensions method straightforward apply models currently solved using proximal optimization algorithms provide detailed theoretical analysis proposed methodology including asymptotic nonasymptotic convergence results easily verifiable conditions explicit bounds convergence rates proposed methodology demonstrated four experiments related image deconvolution tomographic reconstruction total variation ` priors conduct range challenging bayesian analyses related uncertainty quantification hypothesis testing model selection absence ground truth â© society industrial applied mathematics siam
10.1073/pnas.1715640115 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041541402&doi=10.1073%2fpnas.1715640115&partnerID=40&md5=73443e8dc6a40b7360f2e1ff946f3b07 6,plague caused bacterium yersinia pestis spread human populations multiple transmission pathways today human plague cases bubonic caused spillover infected fleas rodent epizootics pneumonic caused inhalation infectious droplets however little known historical spread plague europe second pandemic th centuries including black death led high mortality recurrent epidemics hundreds years several studies suggested human ectoparasite vectors human fleas pulex irritans body lice pediculus humanus humanus caused rapidly spreading epidemics describe compartmental model plague transmission human ectoparasite vector using bayesian inference found model fits mortality curves nine outbreaks europe better models pneumonic rodent transmission results support human ectoparasites primary vectors plague second pandemic including black death ultimately challenging assumption plague europe predominantly spread rats
10.1016/j.compchemeng.2017.11.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037523482&doi=10.1016%2fj.compchemeng.2017.11.011&partnerID=40&md5=7bfd52e772d1a234c68b6d3a74a17d9a 0,inverse problem associated fitting parameters ordinary differential equation ode system data nonlinear multimodal great challenge gradient based optimizers markov chain monte carlo mcmc techniques provide alternative approach solving problems escape local minima design apt mcmc created allow users setup ode simulations python run compiled c++ code combines affine invariant ensemble samplers parallel tempering mcmc techniques improve simulation efficiency simulations use bayesian inference provide probability distributions parameters enable analysis multiple minima parameter correlation benchmark tests result ã—â€“ ã— speedup increase memory usage emcee similar mcmc package python several mcmc hyperparameters analyzed number temperatures ensemble size step size swap attempt frequency heuristic tuning guidelines provided setting hyperparameters â© elsevier ltd
10.1088/1748-0221/13/02/P02004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043583350&doi=10.1088%2f1748-0221%2f13%2f02%2fP02004&partnerID=40&md5=8a641be518c22890d2f9193b2d9b8f8a 0,ricochet experiment seeks measure coherent neutral current elastic neutrino nucleus scattering ceî½ns using dark matter style detectors sub kev thresholds placed near neutrino source mit research reactor mitr operates mw generating approximately ã— î½ second core currently ricochet characterizing backgrounds mitr main component comes form neutrons emitted core simultaneous neutrino signal characterize background wrapped bonner cylinders around thermal neutron detector whose data unfolded via markov chain monte carlo mcmc produce neutron energy spectrum across several orders magnitude discuss resulting spectrum implications deploying ricochet mitr site well feasibility reducing background level via addition polyethylene shielding around detector setup â© iop publishing ltd sissa medialab
10.4230/LIPIcs.STACS.2018.18 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044531120&doi=10.4230%2fLIPIcs.STACS.2018.18&partnerID=40&md5=69f6697ce284150bfc0258d63e2bdeb7 0,approximating stationary probability state markov chain markov chain monte carlo techniques general inefficient standard random walk approaches require p v operations approximate probability p v state v chain mixing time even best available techniques still complexity p v since complexities depend inversely p v grow beyond bound size chain mixing time paper show time reversible markov chains exists simple randomized approximation algorithm breaks â€œsmall p v barrierâ€� â© marco bressan enoch peserico luca pretto
10.1088/1681-7575/aaa5be https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045694539&doi=10.1088%2f1681-7575%2faaa5be&partnerID=40&md5=bebc4274b7382dee3d6abc0f3c436c0f 1,guide expression uncertainty measurement gum includes formulas produce estimate scalar output quantity function several input quantities approximate evaluation associated standard uncertainty contribution presents approximate bayesian counterparts formulas case output quantity parameter joint probability distribution input quantities also taking account information value output quantity available prior measurement expressed form probability distribution set possible values measurand approximate bayesian estimates uncertainty evaluations present long history illustrious pedigree provide sufficiently accurate approximations many applications yet easy implement practice differently exact bayesian estimates involve either analytical numerical integrations markov chain monte carlo sampling approximations describe involve numerical optimization simple algebra therefore make bayesian methods widely accessible metrologists illustrate application proposed techniques several instances measurement isotopic ratio silver commercial silver nitrate odds cryptosporidiosis aids patients height manometer column mass fraction chromium reference material potential difference zener voltage standard â© european physical society
10.1093/gji/ggx461 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042149778&doi=10.1093%2fgji%2fggx461&partnerID=40&md5=ae4f88c23b1b8d66ebba85056a4da405 0,cycle skipping serious issue fullwaveforminversion fwi since leads local minima date fwi algorithms depend local gradient based optimization approaches guarantee convergence towards global minimum misfit function involves local minima starting model far true solution study propose misfit function based non stationary time warping functions calculated solving seismogram registration problem considering inherent cycle skipping local minima issues registration problem use markov chain monte carlo mcmc method solve global optimization approach able directly sample global minimum measure non stationary traveltime differences observed predicted seismograms theapriori constraint sparsity localwarping functions incorporated eliminate unreasonable solutions window selections required procedure comparison approaches measuring traveltime differences proposed method enables us align signals different numbers events property direct consequence usage mcmc optimization sparsity constraints several numerical examples demonstrate proposed misfit function allows us tackle cycle skipping problem construct accurate long wavelength velocity models even without low frequency data good starting models â© authors published oxford university press behalf royal astronomical society
10.21629/JSEE.2018.01.21 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044430610&doi=10.21629%2fJSEE.2018.01.21&partnerID=40&md5=6675aacabbdcf138bf637cf67c81326b 1,maintenance optimization models condition based maintenance cbm consider cost optimal criterion papers dealt availability maximization maintenance applications novel optimal bayesian control approach presented maintenance decision making system deterioration evolves three state continuous time hidden semi markov process considering optimal maintenance policy multivariate bayesian control scheme based hidden semi markov model hsmm developed objective maximize long run expected average availability per unit time proposed approach optimize sampling interval control limit jointly case study using markov chain monte carlo mcmc simulation provided comparison bayesian control scheme based hidden markov model hmm age based replacement policy hotelling multivariate exponentially weihted moving average mewma multivariate cumulative sum mcusum control charts given illustrates effectiveness proposed method â© beijing institute aerospace information
10.1007/s12204-018-1912-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042144086&doi=10.1007%2fs12204-018-1912-2&partnerID=40&md5=927f767889c88544f57301c390cb2e8f 0,performing arts movies become commercial products high profit great market potential previous research works developed comprehensive models forecast demand movies however pay enough attention decision support performing arts special category unlike movies performing arts high dimensional categorical attributes limit samples determining ticket prices different levels still challenge job faced producers distributors terms difficulties factorization machine fm handle huge sparse categorical attributes used work first adaptive stochastic gradient descent asgd markov chain monte carlo mcmc explored estimate model parameters fm fm asgd fm asgd fm mcmc fm mcmc achieve better prediction accuracy compared traditional algorithm addition multi output model proposed determine price multiple price levels simultaneously avoids trouble modelsâ€™ repeating training results also confirm prediction accuracy multi output model compared general single output model â© shanghai jiaotong university springer verlag gmbh germany part springer nature
10.1007/s00477-017-1417-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018250315&doi=10.1007%2fs00477-017-1417-9&partnerID=40&md5=b2e9ba509e82d80b7e3b8976cd781e5c 1,often interest model incidence duration threshold exceedance events environmental variable set monitoring locations data arrive continuous time considered observations two state process yielding sequentially length time threshold state followed length time threshold state returning threshold state etc two state continuous time markov process often referred alternating renewal process process observed truncated time window within window duration state modeled using distinct cumulative intensity specification initially model intensity window using parametric regression specification extend regression specification adding temporal random effects enrich model using realization log gaussian process time one type renewal specification referred gaussian process modulated renewal process introduce gaussian process modulation intensity state model fitting done within bayesian framework clarify fitting customary log gaussian process specification lengthy time window computationally infeasible nearest neighbor gaussian process supplies sparse covariance structure adopted enable tractable computation propose methods generating data models conducting model comparison model applied hourly ozone data four monitoring sites different locations across united states ozone season site obtain estimated profiles crossing crossing intensity functions time addition obtain inference regarding number exceedances distribution duration exceedance events proportion time threshold state time interval â© springer verlag berlin heidelberg
10.1016/j.ress.2017.09.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032584070&doi=10.1016%2fj.ress.2017.09.020&partnerID=40&md5=3580eeea48d184165fd3de4f3ca66011 4,paper investigates bayesian melding method bmm system reliability analysis effectively integrating various available sources expert knowledge data subsystem system levels integration multiple priors investigated linear geometric pooling methods aggregated system prior distributions using various pooling methods including bmm evaluated compared based integrated updated prior distributions three scenarios data availability system subsystems methods posterior system reliability inference proposed computational challenges posterior inferences using sophisticated bmm addressed using adaptive sampling importance sampling sir method numerical example simulation results illustrates applications proposed methods provides insights system reliability analysis using multilevel information â© elsevier ltd
10.1017/S0956792517000079 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017438057&doi=10.1017%2fS0956792517000079&partnerID=40&md5=0f4794330a5631523a3e12e32dbbf52a 7,propose novel algorithm allows sample paths underlying price process local volatility model achieve substantial variance reduction pricing exotic options new algorithm relies construction discrete multinomial tree crucial feature approach similar spirit brownian bridge random path runs backward terminal fixed point initial spot price characterize tree two alternative ways terms optimal grids originating recursive marginal quantization algorithm ii following approach inspired finite difference approximation diffusion infinitesimal generator assess reliability new methodology comparing performance approaches benchmarking competitor monte carlo methods copyright â© cambridge university press
10.1002/qre.2240 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040336014&doi=10.1002%2fqre.2240&partnerID=40&md5=969ddb2b05b351d2e6d1b561221314cd 0,article describes bayes design hybrid censored life testing plans design criterion based posterior variance quantile suitable order proposed weibull lifetime model gamma prior distribution model parameters considered illustration instead using markov chain monte carlo technique compute posterior quantities interest large sample approximation considered easy apply life testing plans presented effect different prior information posterior quantity interest studied copyright â© john wiley sons ltd
10.1016/j.csda.2017.09.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029819485&doi=10.1016%2fj.csda.2017.09.002&partnerID=40&md5=f2e59b39b1563750c77d639096881ec0 0,grouped independence metropolisâ€“hastings gimh markov chain within metropolis mcwm algorithms pseudo marginal methods used perform bayesian inference latent variable models methods replace intractable likelihood calculations unbiased estimates within markov chain monte carlo algorithms gimh method posterior interest limiting distribution suffers poor mixing computationally intensive obtain high precision likelihood estimates mcwm algorithm better mixing properties tends give conservative approximations posterior still expensive new method developed accelerate gimh method using gaussian process gp approximation log likelihood train gp using short pilot run mcwm algorithm new method called gp gimh illustrated simulated data stochastic volatility gene network model new approach produces reasonable posterior approximations examples least order magnitude improvement computing time code implement method gene network example found http www runmycode org companion view â© elsevier b v
10.1002/stc.2089 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040967879&doi=10.1002%2fstc.2089&partnerID=40&md5=448bf4783bf8cab997e0b9e25a8d953f 3,paper presents comprehensive study full scale ambient vibration test modal analysis finite element fe modeling model updating coupled building hong kong coupled building comprised main part complementary part capture dynamic properties building setup ambient vibration test designed conducted modal parameters setup identified following fast bayesian fast fourier transform approach partial mode shapes different setups assembled following least squares method identified modal parameters analyzed discussed detail revealing certain features coupling effects main complementary parts determine equivalent young moduli various structural components fe model coupled building developed updated identified modal parameters bayesian approach followed explicitly handle uncertainties induced modeling error measurement noise ensure model updating method applicable even unidentifiable cases markov chain monte carlo simulation employed proposed method generate samples approximating posterior probability density functions uncertain model parameters close match modal parameters calculated updated fe model identified measured time domain data verified validity proposed fe model study provides valuable experience information development structural model updating structural health monitoring building systems copyright â© john wiley sons ltd
10.1177/1045389X17704911 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041315232&doi=10.1177%2f1045389X17704911&partnerID=40&md5=1c39769f4cd3b2feafa07f65289eda8e 1,article bayesian inference approach applied conduct uncertainty quantification notch damage beam structure using guided lamb wave responses proposed methodology determines notch damage characteristics also quantifies associated uncertainties inferred values correlation crack location extent investigated well information essential decision making structural health monitoring applications first spectral finite element model used characterize lamb wave propagation responses beam lead zirconate titanate actuation sensing elements required accurately capture wave propagation lead zirconate titanate sensor pick reflected wave responses boundaries damages total simulation cases generated varying notch damage extent damage location noise level second markov chain monte carlo techniques employed estimate notch damage location extent guided lamb wave responses random walk metropolis algorithm used finally crack size location associated uncertainties characterized summary proposed probabilistic damage detection successfully demonstrated beam structures using guided wave responses extended structural health monitoring applications â© â© author
10.6038/cjg2018K0759 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052305487&doi=10.6038%2fcjg2018K0759&partnerID=40&md5=fe26abaa05f97e65c24a53411b4cbe37 0,single set vertically aligned fractures embedded purely isotropic background medium may considered long wavelength effective transversely isotropic medium horizontal symmetry axis hti wide azimuth seismic data used invert elastic anisotropic parameters subsurface observing variation subsurface seismic response along different azimuths also contains abundant information reservoir property parameters porosity paper method probabilistic seismic joint inversion reservoir fracture petrophysical parameters driven rock physics models proposed firstly elastic anisotropic parameters fractured rocks derived based amplitude variation angles incidence azimuth avaz statistical rock physics model built characterize interrelationship reservoir petrophysical parameters porosity fracture density fractured parameters create large number samples stochastic simulation using markov chain monte carlo mcmc method expectation maximization em algorithm used estimate posteriori probabilistic density function pdf finally inversion results anisotropic reservoir parameters found place maximum posteriori pdf tests well log data seismic data validate method proposed paper used stably reasonably deriving elastic anisotropic parameters fractured rocks provides reliable method probabilistic seismic inversion reservoir fracture petrophysical parameters porosity fracture density â© science press right reserved
10.1016/j.econlet.2017.11.031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040776433&doi=10.1016%2fj.econlet.2017.11.031&partnerID=40&md5=6e735018be5ebf5add65441f70737ba8 0,paper extends literature calculation interpretation impacts spatial autoregressive models using bayesian framework show individual direct indirect impacts associated exogenous variable introduced nonlinear way models computed theoretically empirically rather averaging individual impacts suggest graphically analyze along confidence intervals calculated markov chain monte carlo mcmc also explicitly derive form gap individual impacts spatial autoregressive model corresponding model without spatial lag show application boston dataset higher spatially highly connected observations â© elsevier b v
10.1016/j.jmp.2017.10.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035036338&doi=10.1016%2fj.jmp.2017.10.005&partnerID=40&md5=28c3a773711fe13948e734d7446f974c 0,fully bayesian framework novel sliceâ€“gibbs algorithm developed estimate multilevel item response theory irt model advantage algorithm recover parameters well based various types prior distributions item parameters including informative non informative priors contrast traditional metropolisâ€“hastings mâ€“h within gibbs algorithm sliceâ€“gibbs algorithm faster efficient due drawing sample acceptance probability one rather tuning proposal distributions achieve reasonable acceptance probabilities especially logistic model without conjugate distribution addition based markov chain monte carlo mcmc output two model assessment methods investigated concerning goodness fit models information criterion method basis marginal likelihood proposed assess different structural multilevel models cross validation method used evaluate overall multilevel irt models feasibility effectiveness sliceâ€“gibbs algorithm investigated simulation studies application using real data involving studentsâ€™ mathematics test achievements reported â© elsevier inc
10.1016/j.jqsrt.2017.10.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033606744&doi=10.1016%2fj.jqsrt.2017.10.020&partnerID=40&md5=24b6196e67f3d7783188902e1a197f3c 1,particle transport markov mixtures addressed called chord length sampling cls methods family monte carlo algorithms taking account effects stochastic media particle propagation generating fly material interfaces crossed random walkers trajectories methods enable significant reduction computational resources opposed reference solutions obtained solving boltzmann equation large number realizations random media cls solutions neglect correlations induced spatial disorder faster albeit approximate might thus show discrepancies respect reference solutions work propose new family algorithms called â€™poisson box samplingâ€™ pbs aimed improving accuracy cls approach transport dimensional binary markov mixtures order probe features pbs methods focus three dimensional markov media revisit benchmark problem originally proposed adams larsen pomraning extended brantley configurations compare reference solutions standard cls solutions new pbs solutions scalar particle flux transmission reflection coefficients pbs shown perform better cls expense reasonable increase computational time â© elsevier ltd
10.1111/rssc.12238 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032905501&doi=10.1111%2frssc.12238&partnerID=40&md5=5c27194915581ce25f7ca3eb4da38429 0,central banks long used dynamic stochastic general equilibrium models typically estimated using bayesian techniques inform key policy decisions paper offers empirical strategy quantifies information content data relative prior distribution using shelf dynamic stochastic general equilibrium model applied quarterly euro area data quarter quarter show monte carlo simulations reveal parameters model structure obscures identification integrating components likelihood function conducting bayesian sensitivity analysis uncover parameters weakly informed data weak identification key structural parameters comparatively simple model raise red flag researchers trying draw valid inferences base policy complex large scale models featuring many parameters â© royal statistical society
10.1016/j.sste.2017.11.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039866817&doi=10.1016%2fj.sste.2017.11.002&partnerID=40&md5=c5efe604f284bf032e79d39a109f7a9c 0,purpose study identify regions diabetes health service shortage american diabetes association ada accredited diabetes self management education dsme recommended diabetes study focus demographic patterns geographic regionalization disease including accessibility availability diabetes education resources critical component understanding confronting differences diabetes prevalence well addressing regional sub regional differences awareness treatment control conducted ecological county level study utilizing publicly available secondary data counties continental u used bayesian spatial cluster model enabled spatial heterogeneities across continental u addressed used american diabetes association ada website identify dsme locations national county level diabetes rates estimated centers disease control prevention identified regions low dsme program availability relative diabetes rates population density u counties least one ada accredited dsme program location based credible intervals age adjusted diabetes rates dsme program locations associated seven thirty five identified clusters seven two clusters positive association identified clusters th percentile average diabetes rates th percentile average dsme location counts found clusters located southeast portion country overall lack relationship diabetes rates dsme center locations u suggesting resources efficiently placed according need clusters high diabetes rates low dsme placements southeast particularly considered additional dsme programming â© elsevier ltd
10.1016/j.jbankfin.2017.10.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033558780&doi=10.1016%2fj.jbankfin.2017.10.017&partnerID=40&md5=0053cbf1aeeb76328e2dbefe7698bc89 0,existence self financing trading strategy replicates money market account fixed future date lower cost current value account constitutes money market bubble mmb understanding whether market exhibits mmb crucial particular derivative pricing mmb precludes existence risk neutral probability measure benchmark approach allows study mmbs formulated real world probability measure require existence risk neutral probability measure using range well known stochastic volatility models study existence mmb us economy find us market exhibits mmb models considered allow suggests derivative pricing hedging care taken making assumptions pertaining existence risk neutral probability measure less expensive portfolios likely exist wide range long term derivatives typical pensions â© elsevier b v
10.1109/TVT.2017.2754552 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030645271&doi=10.1109%2fTVT.2017.2754552&partnerID=40&md5=71133e1e07fe42e3ca28825f0b096cf7 0,requirement growth massive connections fifth generation g system increasing challenge traditional multiple access techniques meet needs exponentially increased number terminals resource constrained networks sparse code multiple access scma technology proposed g communication systems supply stronger connectivity limited resources however low complexity decoding algorithm required scma decoder high computation complexity decoding nonorthogonal signals paper propose high performance low cost decoding algorithm based bayesian program learning method monte carlo markov chain mcmc also propose new mcmc sampling method generate samples joint update parallel jup mcmc sampler simulation results show jup based mcmc scma decoder save computation complexity compared existing decoding method codebook size db performance loss compared maximum likelihood like decoding algorithm â© ieee
10.1177/0962280216628903 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041951244&doi=10.1177%2f0962280216628903&partnerID=40&md5=90b0697a75b379c0db56908940effe27 1,problem multiple hypothesis testing represented markov process new alternative hypothesis accepted accordance relative evidence currently accepted one virtual formally observed process provides probable set non null hypotheses given data plays role markov chain monte carlo approximating posterior distribution apply representation obtain posterior probabilities alternative hypotheses enough test barely defined bayes factors e g bayes factors obtained unknown constant bayes factors may either arise using default improper priors calibrating p values respect corresponding bayes factor lower bound sources evidence used form markov transition kernel space hypotheses approach leads easy interpretable results involves simple formulas suitable analyze large datasets arising gene expression data microarray rna seq experiments â© â© author
10.1371/journal.pgen.1007139 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043333278&doi=10.1371%2fjournal.pgen.1007139&partnerID=40&md5=db272dd0ebc66bf016e58341255469c2 2,simultaneous analysis genetic associations multiple phenotypes may reveal shared genetic susceptibility across traits pleiotropy locus exhibiting overall pleiotropy important identify specific traits underlie association propose bayesian meta analysis approach termed cpbayes uses summary level data across multiple phenotypes simultaneously measure evidence aggregate level pleiotropic association estimate optimal subset traits associated risk locus method uses unified bayesian statistical framework based spike slab prior cpbayes performs fully bayesian analysis employing markov chain monte carlo mcmc technique gibbs sampling takes account heterogeneity size direction genetic effects across traits applied cohort data separate studies multiple traits overlapping non overlapping subjects simulations show cpbayes produce higher accuracy selection associated traits underlying pleiotropic signal subset based meta analysis asset used cpbayes undertake genome wide pleiotropic association study traits large kaiser gera cohort detected six independent pleiotropic loci associated least two phenotypes includes locus chromosomal region q exhibits association simultaneously risk five different diseases dermatophytosis hemorrhoids iron deficiency osteoporosis peripheral vascular disease provide r package â€˜cpbayesâ€™ implementing proposed method â© majumdar et al
10.3758/s13428-017-0869-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016936952&doi=10.3758%2fs13428-017-0869-7&partnerID=40&md5=b639522ae25ccd5abd0df49e32dc5f39 4,multinomial processing tree mpt models class measurement models account categorical data assuming finite number underlying cognitive processes traditionally data aggregated across participants analyzed assumption independently identically distributed observations hierarchical bayesian extensions mpt models explicitly account participant heterogeneity assuming individual parameters follow continuous hierarchical distribution provide accessible introduction hierarchical mpt modeling present user friendly comprehensive r package treebugs implements two important hierarchical mpt approaches participant heterogeneityâ€”the beta mpt approach smith batchelder journal mathematical psychology latent trait mpt approach klauer psychometrika treebugs reads standard mpt model files obtains markov chain monte carlo samples approximate posterior distribution functionality output tailored specific needs mpt modelers provide tests homogeneity items participants individual group parameter estimates fit statistics within subjects comparisons well goodness fit summary plots also propose implement novel statistical extensions include continuous discrete predictors either fixed random effects latent trait mpt model â© author
10.1371/journal.pone.0191768 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041366157&doi=10.1371%2fjournal.pone.0191768&partnerID=40&md5=36b56f1df1092455f502ab8ef8256d3b 0,many coupled human natural systems potential exhibit highly nonlinear threshold response external forcings resulting fast transitions undesirable states eutrophication lake often considerable uncertainties make identifying threshold challenging thus rapid learning critical guiding management actions avoid abrupt transitions adopt shallow lake problem test case compare performance four common data assimilation schemes predict approaching transition order demonstrate complex interactions management strategies ability data assimilation schemes predict eutrophication also analyze results across two different management strategies governing phosphorus emissions shallow lake compared data assimilation schemes ensemble kalman filtering enkf particle filtering pf pre calibration pc markov chain monte carlo mcmc estimation differing core assumptions data assimilation scheme based bayesâ€™ theorem updates prior beliefs system based new information large computational investments enkf pf mcmc show similar skill capturing observed phosphorus lake measured expected root mean squared prediction error enkf followed pf displays highest learning rates low computational cost thus providing reliable signal impending transition mcmc approaches true probability eutrophication strong signal impending transition emerges observations overall find learning rates greatest near regions abrupt transitions posing challenge early learning preemptive management systems abrupt transitions â© singh et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1002/qre.2241 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033550199&doi=10.1002%2fqre.2241&partnerID=40&md5=5a47e29acd729f4bc5cbe6ced548f5cb 2,recent years need accurate dependability modelling encompassing reliability availability maintenance safety favoured emergence novel dynamic dependability techniques able account temporal stochastic dependencies system one successful widely used methods dynamic fault tree introduction dynamic gates enables analysis dynamic failure logic systems fault tolerant reconfigurable systems among dynamic gates priority pand one frequently used gates specification analysis event sequences despite numerous modelling contributions addressing resolution pand gate failure logic consequences coherence behaviour system need examined understand effects engineering decision making scenarios including design optimization sensitivity analysis accordingly aim short communication analyse coherence region pand gate determine coherence bounds improve efficacy dynamic dependability modelling process copyright â© john wiley sons ltd
10.1109/TIT.2017.2742509 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028507815&doi=10.1109%2fTIT.2017.2742509&partnerID=40&md5=ea274843e051ca13c2dee75899e95cc6 0,sampling lattice gaussian distribution emerged important problem coding decoding cryptography paper classic metropolis hastings mh algorithm markov chain monte carlo methods adopted lattice gaussian sampling two mh based algorithms proposed overcome limitation klein algorithm first one referred independent metropolis hastings klein mhk algorithm establishes markov chain via independent proposal distribution show markov chain arising independent mhk algorithm uniformly ergodic namely converges stationary distribution exponentially fast regardless initial state moreover rate convergence analyzed terms theta series leading predictable mixing time symmetric metropolis klein algorithm also proposed proven geometrically ergodic â© ieee
10.1016/j.sste.2017.11.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036509613&doi=10.1016%2fj.sste.2017.11.001&partnerID=40&md5=c718993f371883e0b5dc1ff8253ca2ce 0,approximate bayesia n computation abc provides attractive approach estimation complex bayesian inferential problems evaluation kernel posterior distribution impossible computationally expensive highly parallelizable techniques successfully applied many fields particularly cases traditional approaches markov chain monte carlo mcmc impractical work demonstrate application approximate bayesian inference spatially heterogeneous susceptible exposed infectious removed seir stochastic epidemic models models tractable posterior distribution however mcmc techniques nevertheless become computationally infeasible moderately sized problems discuss practical implementation techniques via open source abseir package r performance abc relative traditional mcmc methods small problem explored simulation well spatially heterogeneous context epidemic chikungunya americas â© elsevier ltd
10.1016/j.powtec.2017.11.031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035799642&doi=10.1016%2fj.powtec.2017.11.031&partnerID=40&md5=044102a0dd3fce320ee3643282c7591e 0,paper investigates layer formation spray coating processes based monte carlo simulation stochastic model coating layer thickness distribution derived couples stochastic process droplet deposition particle surface droplet shape constructed spherical cap model droplets wetting properties contact angle model successfully shown able replace simulation parameter study revealed recommendations designing coating process agreement works authors model used investigate influence overspray coating quality comparison experiments found presence overspray reduces process efficiency also increases coefficient variation resulting layer thickness distribution caused increase droplet size due predominant drying small drops also found higher solid content spray solution increases coefficient variation due decreased number droplets also due greater variability layer thickness droplet introduces â© elsevier b v
10.1097/ALN.0000000000001981 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046574081&doi=10.1097%2fALN.0000000000001981&partnerID=40&md5=fc72be83d0dbcf7dc3af7f9646ccf2ff 3,background cost effectiveness analyses cell salvage cesarean delivery inform national societal guidelines obstetric blood management lacking study examined cost effectiveness cell salvage strategies obstetric hemorrhage societal perspective methods markov decision analysis modeling compared cost effectiveness three strategies use cell salvage every cesarean delivery cell salvage use high risk cases cell salvage societal perspective lifetime horizon assumed base case yr old primiparous woman presenting cesarean delivery strategy integrated probabilities hemorrhage hysterectomy transfusion reactions emergency procedures cell salvage utilization utilities quality life costs societal level one way monte carlo probabilistic sensitivity analyses performed threshold per quality adjusted life year gained used cost effectiveness criterion results cell salvage use cases high risk hemorrhage cost effective incremental cost effectiveness ratio per quality adjusted life year gained routine cell salvage use cesarean deliveries cost effective costing per quality adjusted life year gained results sensitive individual variation model parameters probabilistic sensitivity analysis showed per quality adjusted life year gained threshold likelihood cell salvage use cases high risk hemorrhage favorable conclusions use cell salvage cases high risk obstetric hemorrhage economically reasonable routine cell salvage use cesarean deliveries findings inform development public policies guidelines management obstetric hemorrhage visual abstract online visual overview available article http links lww com aln b â© lippincott williams wilkins rights reserved
10.3934/mbe.2018007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041583214&doi=10.3934%2fmbe.2018007&partnerID=40&md5=535d4db60dabf78a53a78b522d7a98b8 0,mathematical models infectious diseases used inform health policy important first step often calibrate model disease surveillance data specific setting multiple settings increasingly common also perform sensitivity analyses demonstrate robustness lack thereof modeling results requires modeler find multiple parameter sets model produces behavior consistent surveillance data frequently overlooked calibration process nontrivial best inefficient poorly communicated major hurdle overall reproducibility modeling results work describe general approach calibrating infectious disease models surveillance data technique able match surveillance data high accuracy efficient manner based newton raphson method solving nonlinear systems demonstrate robustness use calibration technique multiple models interacting dynamics hiv hsv
10.1016/j.prevetmed.2017.11.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034856291&doi=10.1016%2fj.prevetmed.2017.11.010&partnerID=40&md5=b2c36fc22c55b84f662c55bc0a3900d8 1,using imperfect tests may lead biased estimates disease frequency associations risk factors disease instance longitudinal udder health studies quarters risk incident intramammary infections imi wrongly identified resulting selection misclassification bias respectively diagnostic accuracy possibly improved using duplicate triplicate samples identifying quarters risk subsequently incident imi objectives study evaluate relative impact selection misclassification biases resulting imi misclassification measures disease frequency incidence association hypothetical exposures effect improving sampling strategy collecting duplicate triplicate samples first second sampling also assessed data sets hypothetical cohort study simulated analyzed based separate scenario two common mastitis pathogens representing two distinct prevailing patterns staphylococcus aureus relatively uncommon pathogen low incidence identified excellent sensitivity almost perfect specificity coagulase negative staphylococci cns prevalent high incidence milk bacteriological culture fair se excellent sp generated data sets scenario emulating longitudinal cohort study two milk samples collected one month apart quarter random sample cows herd herds herd level exposure known strength association incidence imi measure association exposure odds ratio estimated using markov chain monte carlo mcmc data set using different sampling strategies single duplicate triplicate samples series parallel interpretation identifying quarters risk incident imi aureus biases small observed incidence versus true incidence imi quarter month cns scenario diagnostic errors two samples led important selection imi quarter month misclassification imi quarter month biases estimation imi incidence respectively biases opposite direction therefore incidence measure obtained using single sampling first second test imi quarter month exactly true value aureus scenario association exposure showed little bias observed versus true cns scenario revealed presence large misclassification bias moving association towards null value versus true little improvement brought using different sampling strategies aiming improving se sp first second sampling using two three interpretation imi definition increasing number samples tests prevent bias situations efforts spared holding single sampling approach others designing longitudinal studies evaluating potential biases best sampling strategy critical choice test â© elsevier b v
10.1007/s11265-016-1147-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042639035&doi=10.1007%2fs11265-016-1147-0&partnerID=40&md5=c397b6eaa3e110033c908914b8a8be49 0,propose computationally highly efficient neyman pearson np tests anomaly detection birth death type discrete time markov chains instead relying extensive monte carlo simulations case baseline np directly approximate log likelihood density match desired false alarm rate therefore obtain efficient implementations proposed algorithms appropriate processing large scale data online applications real time false alarm rate controllability since require parameter tuning algorithms also adaptive non stationarity data source experiments proposed tests demonstrate superior detection power compared baseline np nearly achieving desired rates negligible computational resources â© springer science+business media new york
10.1016/j.jhydrol.2017.12.071 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044861434&doi=10.1016%2fj.jhydrol.2017.12.071&partnerID=40&md5=e64d32d7320bbb2588e040bad4600e45 0,bayesian inference using markov chain monte carlo mcmc provides explicit framework stochastic calibration hydrogeologic models accounting uncertainties however mcmc sampling entails large number model calls easily become computationally unwieldy high fidelity hydrogeologic model simulation time consuming study proposes surrogate based bayesian framework address notorious issue illustrates methodology inverse modeling regional modflow model high fidelity groundwater model approximated fast statistical model using bagging multivariate adaptive regression spline bmars algorithm hence mcmc sampling efficiently performed study modflow model developed simulate groundwater flow arid region oman consisting mountain coast aquifers used run representative simulations generate training dataset bmars model construction bmars based sobolâ€™ method also employed efficiently calculate input parameter sensitivities used evaluate rank importance groundwater flow model system according sensitivity analysis insensitive parameters screened bayesian inversion modflow model saving computing efforts posterior probability distribution input parameters efficiently inferred prescribed prior distribution using observed head data demonstrating presented bmars based bayesian framework efficient tool reduce parameter uncertainties groundwater system â© elsevier b v
10.1007/s11771-018-3747-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042086817&doi=10.1007%2fs11771-018-3747-2&partnerID=40&md5=ede81f4e3f458e95326bb6818f086296 0,reliability remaining useful life rul estimation satellite rechargeable lithium battery rlb significant prognostic health management phm novel bayesian framework proposed reliability analysis synthesizing multisource data including bivariate degradation data lifetime data bivariate degradation means two degraded performance characteristics leading failure system first linear wiener process frank copula function used model dependent degradation processes rlbâ€™s temperature discharge voltage next bayesian method combination markov chain monte carlo mcmc simulations provided integrate limited bivariate degradation data congeneric rlbsâ€™ lifetime data reliability evaluation rul prediction carried phm simulation study demonstrates due data fusion parameter estimations predicted rul obtained model precise models using degradation data ignoring dependency different degradation processes finally practical case study satellite rlb verifies usability model â© central south university press springer verlag gmbh germany part springer nature
10.1016/j.trb.2017.12.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040592261&doi=10.1016%2fj.trb.2017.12.011&partnerID=40&md5=4f8976c6bf687be21f9d8597418a5e85 0,many many matching relationship two sided market widely observed today transportation activities observation matching relationship raises interesting questions factors drive matching two agents formation matching relationship related joint behavior may lead different understandings planning operation answer questions econometric models may best methodology however authorsâ€™ best knowledge lacks well established econometric model explain observed data contains matching relationship two sided transportation market therefore paper proposes innovative ordinal joint response model bridge gap proposed model consists two regression equations first uses latent dependent variable disentangle many many matching relationship second specifies ordered probit equation investigate ordinal outcome joint behavior error terms two equations assumed correlated capture correlation matching process joint behavior example airline airport matching used demonstrate proposed model â© elsevier ltd
10.1371/journal.pcbi.1005965 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042713565&doi=10.1371%2fjournal.pcbi.1005965&partnerID=40&md5=662889f8ee94ccfb8953efa7370d5ed5 3,key constraint genomic testing oncology matched normal specimens commonly obtained clinical practice thus well characterized genomic alterations require normal tissue interpretation significant number alterations unknown whether germline somatic absence matched normal control introduce sgz somatic germline zygosity computational method predicting somatic vs germline origin homozygous vs heterozygous sub clonal state variants identified deep massively parallel sequencing mps cancer specimens method require patient matched normal control enabling broad application clinical research sgz predicts somatic vs germline status alteration identified modeling alterationâ€™s allele frequency af taking account tumor content tumor ploidy local copy number accuracy prediction depends depth sequencing copy number model fit achieved clinical assay sequencing high depth x using mps covering cancer related genes genome wide single nucleotide polymorphisms snps calls made using statistic based read depth local variability snp af validate method first evaluated performance samples lung colon cancer patients sequenced tumors matched normal tissue examined predictions somatic hotspot mutations common germline snps clinical cancer specimens assess impact stromal admixture examined three cell lines titrated matched normal six levels â€“ overall predictions made cases â€“ variants predicted correctly significantly superior performance compared basic approach based af alone applied sgz method cosmic database known somatic variants cancer found fact likely germline â© sun et al
10.1371/journal.pgen.1007198 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043344129&doi=10.1371%2fjournal.pgen.1007198&partnerID=40&md5=c401732fa47dfe868dca40cc6035a239 2,pericentrin conserved centrosomal protein whose dysfunction linked several human diseases implicated many aspects centrosome cilia function precise role unclear examine drosophila pericentrin like protein plp function vivo tissues form centrosomes cilia plp mutant centrioles exhibit four major defects short subtle structural abnormalities disengage prematurely overduplicate organise fewer cytoplasmic mts interphase forming cilia fail establish maintain proper connection plasma membraneâ€”although surprisingly still form axoneme like structure recruit transition zone tz proteins show plp helps assemble â€œpericentriolar cloudsâ€� electron dense material emanate central cartwheel spokes spread outward surround mother centriole propose partial loss structures may largely explain complex centriole centrosome cilium defects observe plp mutant cells â© roque et al
10.1007/s10886-017-0916-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040071025&doi=10.1007%2fs10886-017-0916-y&partnerID=40&md5=148348c44afbf5910b0b7fc82b80c947 0,gas chromatography electroantennographic detection gc ead technique used identification volatile organic compounds vocs pheromones plant host odors physiologically relevant insects although pheromones often elicit large ead responses behaviorally relevant odors may elicit responses difficult discern noise lock amplification long used reduce noise wide range applications utility incorporated gc ead demonstrated previosuly chopping pulsing effluent laden air flowed insect antenna method disadvantage stimulated noise inducing mechanoreceptors cases disturbed electrochemical interfaces preparation limiting performance chopping function necessary lock amplification implemented directly gc effluent using simple deans switch technique applied excised antennae female heliothis virescens responding phenethyl alcohol common voc emitted plants phenethyl alcohol always visible quantifiable flame ionization detector fid chromatogram allowing timing amount stimulus delivered antennal preparation measured new chopper eag configuration antennal preparation shielded air currents room reducing noise dose response model combination markov chain monte carlo mcmc method bayesian inference used estimate compare performance terms error rates involved detection insect responses gc peaks visible fid detector experiments showed predicted single trial phenethyl alcohol detection limit female h virescens antennae expected error rate â pg using traditional eag recording methods compared â€“ â pg th th percentile using deans switch enabled lock amplification corresponding â€“ â db increase signal noise ratio â© springer science+business media llc part springer nature
10.1051/0004-6361/201731345 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042068411&doi=10.1051%2f0004-6361%2f201731345&partnerID=40&md5=1c821c5a2842b2e91170607526b1536b 1,several studies shown stellar activity features occulted non occulted starspots affect measurement transit parameters biasing studies transit timing variations transmission spectra present pytranspot designed model multiband transit light curves showing starspot anomalies inferring transit spot parameters code follows pixellation approach model star corresponding limb darkening spots transiting planet two dimensional cartesian coordinate grid combine pytranspot markov chain monte carlo framework study derive exoplanet transmission spectra provides statistically robust values physical properties uncertainties transiting star planet system validate pytranspot performance analyzing eleven synthetic light curves four different star planet systems transit light curves well studied wasp b system also investigate impact starspots transit parameters derive wavelength dependent transit depth values wasp b covering range ã… indicating flat transmission spectrum â© eso
10.1088/1361-6420/aaa34d https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040994880&doi=10.1088%2f1361-6420%2faaa34d&partnerID=40&md5=2813a02cca8f1aa1ba313665bc92a83f 4,computational inverse problems common detailed accurate forward model approximated computationally less challenging substitute model reduction may necessary meet constraints computing time optimization algorithms used find single estimate speed markov chain monte carlo mcmc calculations bayesian framework use approximate model introduces discrepancy modeling error may detrimental effect solution ill posed inverse problem may severely distort estimate posterior distribution bayesian paradigm modeling error considered random variable using estimate probability distribution unknown one may estimate probability distribution modeling error incorporate inversion introduce algorithm iterates idea update distribution model error leading sequence posterior distributions demonstrated empirically capture underlying truth increasing accuracy since algorithm based rejections requires limited full model evaluations show analytically linear gaussian case algorithm converges geometrically fast respect number iterations data finite dimensional general models introduce particle approximations iteratively generated sequence distributions also prove element sequence converges large particle limit simplifying assumption show numerically linear case rapid convergence occurs respect number iterations additionally show computed examples point estimates obtained iterative algorithm superior obtained neglecting model error â© iop publishing ltd
10.1111/stan.12115 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038933910&doi=10.1111%2fstan.12115&partnerID=40&md5=4a44cdfda92d0c7ab83c5b99ec08b2d3 0,modeling correlation structure returns essential many financial applications considerable evidence empirical studies shown correlation among asset returns stable time recent development multivariate stochastic volatility literature application inverse wishart processes characterize evolution return correlation matrices within inverse wishart multivariate stochastic volatility framework propose flexible correlated latent factor model achieve dimension reduction capture stylized fact â€˜correlation breakdownâ€™ simultaneously parameter estimation based existing markov chain monte carlo methods illustrate proposed model several empirical studies particular use high dimensional stock return data compare model competing models based multiple performance metrics tests results show proposed model describes historic stylized facts reasonably also provides best overall performance â© authors statistica neerlandica â© vvs
10.1177/1471082X17719633 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040771524&doi=10.1177%2f1471082X17719633&partnerID=40&md5=41f2b660a7e79318ea5278ff7d7600f3 0,work propose bayesian quantile regression method response variables mixed discrete continuous distribution point mass zero observations believed left censored true zeros combine information provided quantile regression analysis present complete description probability censored given observed value equal zero also studying conditional quantiles continuous part build markov chain monte carlo method related models literature obtain samples posterior distribution demonstrate suitability model analyse censoring probability simulated example two applications real data first well known dataset econometrics literature women labour britain second considers statistical analysis expenditures durable goods considering information brazil â© sage publications
10.1111/obes.12187 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019881635&doi=10.1111%2fobes.12187&partnerID=40&md5=8dab6ae30e473fb2f7141576140f2c36 0,study consider bayesian methods estimation sample selection model spatially correlated disturbance terms design set markov chain monte carlo algorithms based method data augmentation natural parameterization covariance structure model involves unidentified parameter complicates posterior analysis unidentified parameter â€“ variance disturbance term selection equation â€“ handled different ways algorithms achieve identification parameters bayesian estimator based algorithms account selection bias full covariance structure implied spatial correlation illustrate implementation algorithms simulation study empirical application â© department economics university oxford john wiley sons ltd
10.1002/2017JB014833 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044425922&doi=10.1002%2f2017JB014833&partnerID=40&md5=e9bb178620bc2a10afc9a564fef9e4c9 0,multichannel seismic data acquired recently shatsky rise northwest pacific potential provide important constraints structure rock properties oceanic plateau apply reversible jump markov chain monte carlo sampling technique invert acoustic impedance structure portions processed poststack seismic lines approach applies bayesian inversion formulation also allows quantification uncertainty inversion results also allows automatic estimation number model parameters number layers required fit data greatly simplifying inversion use infer shallow acoustic impedance structure tamu ori volcanoes shatsky rise oceanic plateau since acoustic impedance depends type basalt present results allow estimation lithology therefore insight late stage evolution volcanoes specifically results shallow crust âˆ¼ â km suggest higher percentage massive flow basalts tamu massif compared ori massif percentage pillow basalts geochemically altered basalts higher summit compared flanks volcanoes â© american geophysical union rights reserved
10.1093/mnras/stx2810 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046163630&doi=10.1093%2fmnras%2fstx2810&partnerID=40&md5=fae4611c4991c396d1609ecb9a246fc8 1,test possible deviation cosmic distance duality relation da z + z dl z â‰¡ using standard candles rulers fully model independent manner type ia supernovae used standard candles derive luminosity distance dl z ultracompact radio sources used standard rulers obtain angular diameter distance da z write deviation distance duality relation da z + z dl z = î· z specifically use two parametrizations î· z e î· z = + î· z î· z = + î· z + z parameter î· obtained using markov chain monte carlo methods comparing dl z da z redshift best fitting results î· = â± â± first second parametrizations respectively results depend neither cosmological models matter contents curvature universe â© author
10.3847/1538-4357/aaa3e5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041894542&doi=10.3847%2f1538-4357%2faaa3e5&partnerID=40&md5=e19cb44e0e59086fe7c864223e719743 0,modified broadband photometric reverberation mapping prm code javelin tested availability get broad line region time delays consistent spectroscopic reverberation mapping srm project sdss rm broadband light curves sdss rm quasars produced convolution system transmission curves used test found similar sampling conditions evenly frequently sampled key factor determining whether broadband prm code yield lags consistent srm project flux ratio broad emission line reference continuum line previous findings found critical line continuum flux ratio mean ratios lags prm srm becomes closer unity scatter pronouncedly reduced also tested code subset sdss stripe quasars found program tends give biased lag estimations due observation gaps r l relation prior markov chain monte carlo discarded performance damped random walk drw model power law pl structure function model broadband prm compared found given sdss rm like stripe like light curves drw model performs better carrying broadband prm pl model â© american astronomical society rights reserved
10.1007/s00606-017-1466-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031941082&doi=10.1007%2fs00606-017-1466-z&partnerID=40&md5=893c162a4db2075830e2d1cde71f02b7 0,capparis capparaceae used medicinal plant since ancient time capparis species divided old world new world taxa described sectional division capparis however plastid dna sequence data indian capparis species analyzed previous phylogenetic studies added indian capparis data previous phylogeny analyzed relationship indian capparis old world new world taxa plastid phylogeny presented includes capparis taxa major distribution areas new world african capparoids presented phylogeny used determination biogeographic history capparis recently segregated genera phylogenetic analyses combined plastid data revealed indian capparis closely related old world taxa connections african australian eastern asian species sectional classification old world indian capparis considered study reflected presented plastid phylogeny ancestral area reconstruction using bayesian binary markov chain monte carlo method strongly supports africa ancestral region old world new world capparis molecular marker based genetic diversity studies indian capparis scarce work also includes genetic diversity study indian capparis species utility efficacy issr markers study inter intraspecies variation capparis evident amova results â© springer verlag gmbh austria
10.1109/ITW.2017.8278001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046342290&doi=10.1109%2fITW.2017.8278001&partnerID=40&md5=26c370d20a05f72d9c205bf202ab5040 0,sampling lattice gaussian distribution emerging important problem coding cryptography paper conventional gibbs sampling algorithm demonstrated geometrically ergodic tackling lattice gaussian sampling means induced markov chain converges exponentially fast stationary distribution moreover exponential convergence rate dominated spectral radius forward operator markov chain comprehensive analysis given show convergence performance enhanced usages blocked sampling strategy choices selection probabilities â© ieee
10.1007/s11263-018-1064-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045133041&doi=10.1007%2fs11263-018-1064-8&partnerID=40&md5=e3a694af76662a8dcdd13b6574331358 0,faces natural images often occluded variety objects propose fully automated probabilistic occlusion aware morphable face model adaptation framework following analysis synthesis setup key idea segment image regions explained separate models framework includes morphable face model prototype based beard model simple model occlusions background regions segmentation model parameters inferred single target image face model adaptation segmentation solved jointly using expectationâ€“maximization like procedure e step update segmentation step face model parameters updated face model adaptation apply stochastic sampling strategy based metropolisâ€“hastings algorithm segmentation apply loopy belief propagation inference markov random field illumination estimation critical occlusion handling combined segmentation model adaptation needs proper initialization illumination parameters propose ransac based robust illumination estimation technique applying method large face image database obtain first empirical distribution real world illumination conditions obtained empirical distribution made publicly available used prior probabilistic frameworks regularization synthesize data deep learning methods â© springer science+business media llc part springer nature
10.1016/j.tecto.2017.12.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044641766&doi=10.1016%2fj.tecto.2017.12.021&partnerID=40&md5=ddbcfcda1469b3e200322ddba3720363 0,marine terraces growing fault propagation folds provide valuable insight relationship fold kinematics uplift rates providing means distinguish among otherwise non unique kinematic model solutions investigate relationship two locations north canterbury new zealand kate anticline haumuri bluff northern end hawkswood anticline locations calculate uplift rates previously dated marine terraces using dgps surveys estimate terrace inner edge elevations use markov chain monte carlo methods fit fault propagation fold kinematic models structural geologic data incorporate marine terrace uplift models additional constraint haumuri bluff find marine terraces restored originally horizontal surfaces help eliminate certain trishear models fit geologic data alone kate anticline compare uplift rates different structural positions find spatial pattern uplift rates consistent trishear parallel fault propagation fold kink band model finally use model results compute new estimates fault slip rates â€“ ka kate anticline â€“ ka haumuri bluff ages folds consistent previous estimates onset folding region results consistent previous work age onset folding region provide revised estimates fault slip rates necessary understand seismic hazard posed faults demonstrate value incorporating marine terraces inverse fold kinematic models means distinguish among non unique solutions â© elsevier b v
10.1523/JNEUROSCI.2988-17.2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041317580&doi=10.1523%2fJNEUROSCI.2988-17.2017&partnerID=40&md5=ce975845183c037f760dc089b349c344 2,gonadotrop releasing hormone gnrh neurons produce central output controlling fertility regulated steroid feedback switch estradiol negative positive feedback initiates gnrh surge ultimately triggering ovulation occurs daily basis ovariectomized estradiol treated ovx+e mice gnrh neurons suppressed morning activated afternoon test hypotheses estradiol time day signals alter gnrh neuron responsiveness stimuli gfp identified gnrh neurons brain slices ovx+e ovx female mice recorded morning afternoon differences observed baseline membrane potential current clamp revealed gnrh neurons fired action potentials response current injection positive feedback relative groups different despite reports differing ionic conductances kisspeptin increased gnrh neuron response cells ovx ovx+e mice morning afternoon paradoxically excitability kisspeptin knock mice similar maximum observed control mice unchanged time day estradiol mathematical model applying markov chain monte carlo method estimate probability distributions estradiol time day dependent parameters used predict intrinsic properties underlying excitability changes single identifiable distribution solutions accounted similar gnrh neuron excitability groups positive feedback despite different underlying conductance properties attributable interdependence voltage gated potassium channel properties contrast redundant solutions may explain positive feedback perhaps indicative importance state species survival â© authors
10.1021/acs.iecr.7b04415 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041449955&doi=10.1021%2facs.iecr.7b04415&partnerID=40&md5=d19c0da63cac501ff5dd24db63653891 0,discrete modeling concept establish thermodynamics shannon entropy expressed variables characterize discrete states individual molecules terms interacting neighbors mixture apply method condensed phase lattice fluids paper develops approach proposed vinograd features discrete markov chains sequential lattice construction rigorous use shannon information thermodynamic entropy providing depth discussion modeling concept evolved development comprises improved accuracy compared monte carlo data extension two dimensional three dimensional simple lattice resulting model outperforms quasichemical approximation proposed guggenheim frequently used reference model simple case spherical molecules uniform energetic surface properties illustrate potential starting point developing ge models chemical engineering applications proposed modeling methodology extended using example simple approach dicelike lattice molecules multiple interaction sites surfaces address realistic substances comparison monte carlo simulations shows model capability distinguish isomeric configurations promising basis future ge model development view activity coefficients liquid mixtures â© american chemical society
10.1007/s11063-017-9755-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041199962&doi=10.1007%2fs11063-017-9755-7&partnerID=40&md5=d67223f87427744a4a670436f00b0022 0,hand craft features clustering algorithms constitute main parts unsupervised clustering system performance clustering deteriorates assumed probabilistic distribution data differs true one paper introduces novel method combines systematically deep boltzmann machine dbm dirichlet process based gaussian mixture model dp gmm bypass problem distribution mismatch dbm firstly used extract deep complex data features tactfully designing distributions different layers dbm make compatible dp gmm build distribution consistent clustering system system jointly optimized markov chain monte carlo method succinct updating formulations experimental results two real databases underwater acoustical target show effectiveness robustness proposed clustering method â© springer science+business media llc part springer nature
10.1109/ICSRS.2017.8272818 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046662814&doi=10.1109%2fICSRS.2017.8272818&partnerID=40&md5=8f41d3a58c0d0f2871361e7919662acc 0,reactor protection system rps one important systems instrumentation control systems nuclear power plants npp research rps reliability hot topic field npp safety reliability since lots equipment rps complex relationships among equipment traditional reliability methods fault tree analysis markov chain theory many limitations research rps reliability paper takes preliminary research rps reliability based monte carlo methods simulate behavior every equipment rps monte carlo method get system reliability considering static dynamic characters rps standard monte carlo method needs huge calculation power simulate high reliable system study biased techniques reduce variance improve simulation efficiency research rps reliability â© ieee
10.1109/PESGM.2017.8273971 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046359231&doi=10.1109%2fPESGM.2017.8273971&partnerID=40&md5=af43713e5b56f6346892d824b2573650 0,paper investigates modeling heterogeneous group thermostatically controlled loads tcls discrete time discrete state markov model details markov model development process using statistical learning technique full parameter heterogeneity described evaluated learning process based training data sets obtained via monte carlo simulation individual end users devices performance various markov models evaluated different initial conditions determine representative models approximates tcls dynamics short term long term applications detailed analysis model eigenvalues used derive accurate distribution tcl devices steady state conditions distribution validated tested actual devices simulation study applied group heterogeneous air conditioning devices simulations performed using matlab r â© ieee
10.1109/PESGM.2017.8274181 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046337363&doi=10.1109%2fPESGM.2017.8274181&partnerID=40&md5=0c2039f19adf5443f228ceecd9b17965 0,enhance availability utility scale pv plants generations energy storage systems ess applied planning operation stages important evaluate credible capacity optimally controlled pv ess plants paper credible capacity evaluation method proposed suitable pv farms battery devices sequence monte carlo simulation introduced evaluate effective load carrying capability pv ess plant markov chain presented modeling state transition energy storage system considering fluctuation pv power load optimized dispatch energy storages formulated markov decision process generates optimal control strategy pv ess plant real power system named qinghai grid adopted validate effectiveness practicality proposed method â© ieee
10.1109/ICONDA.2017.8270406 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050584680&doi=10.1109%2fICONDA.2017.8270406&partnerID=40&md5=e1870d119d3cc96e00845db7687c2523 0,recent terror incidents make us question existing surveillance systems still best solution cctvs proven solution large scale surveillance comes solving crimes cctvs played minimal role concept proposed paper idea set overcome shortcomings revolutionize surveillance systems based framework quadcopter autonomous flight capabilities auto tracking feature drone uses image processing algorithm probability hypothesis density phd filtering using markov chain monte carlo mcmc implementation efficiently control swarm quadcopters use energy efficient coverage path planning eecpp problem concept explained paper integrates swarm drones act autonomously image processing key future public monitoring security made full scale device saving precious lives times â© ieee
10.1109/JSYST.2018.2792307 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041324365&doi=10.1109%2fJSYST.2018.2792307&partnerID=40&md5=ac909457ba5b6dba96828fbd928d1169 0,among different subjects related natural gas electricity market paper particularly focused analysis different scenarios exporting natural gas iran second largest reservoirs natural gas world exports different countries hand restructured power system role natural gas growing electricity generation due lower pollution paper analyzes different scenarios exporting natural gas including direct transfer forward hub prices exporting citygate price conversion electricity exporting forward price transferring via power market regard system dynamics applied long term analysis considered scenarios natural gas price modeled markov chain monte carlo long term period models analyzed using data published energy information administration results show exporting natural gas electricity suitable forward price profitable scenarios exporting natural gas demand price profitable transferring electricity via power market meet economic goals even expanding renewable resources ieee
10.1103/PhysRevC.97.014907 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041172885&doi=10.1103%2fPhysRevC.97.014907&partnerID=40&md5=e973332ed814e0c293c3e3c20a52cbdd 2,applying bayesian model data analysis estimate temperature momentum dependence heavy quark diffusion coefficient improved langevin framework posterior range diffusion coefficient obtained performing markov chain monte carlo random walk calibrating experimental data meson raa v three different collision systems relativistic heavy ion collidaer rhic large hadron collider lhc au au collisions gev pb pb collisions tev spatial diffusion coefficient found consistent lattice qcd calculations comparable models estimation demonstrate capability improved langevin model simultaneously describe raa v rhic lhc energies well higher order flow coefficient meson v show applying bayesian analysis able quantitatively systematically study heavy flavor dynamics heavy ion collisions â© american physical society
10.1080/00949655.2017.1381845 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030183876&doi=10.1080%2f00949655.2017.1381845&partnerID=40&md5=6e07f40463d2c066dc470dabc48b8d51 0,practical applications quality count data often compromised due errors variables eivs paper apply bayesian approach reduce bias estimating parameters count data regression models mismeasured independent variables furthermore exposure model misspecified flexible distribution hence approach remains robust departures normality true underlying exposure distribution proposed method also useful realistic situations variance eivs estimated instead assumed known contrast methods correcting bias especially count data eivs regression models conduct simulation studies synthetic data sets using markov chain monte carlo simulation techniques investigate performance approach findings show flexible bayesian approach able estimate values true regression parameters consistently accurately â© informa uk limited trading taylor francis group
10.3847/1538-4357/aaa3fc https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041098276&doi=10.3847%2f1538-4357%2faaa3fc&partnerID=40&md5=4b0c0e73040fbe8238ef3f031bd7f9e8 4,bulge globular clusters gcs metallicities fe h â‰² blue horizontal branches candidates harbor oldest populations galaxy based analysis hst proper motion cleaned color magnitude diagrams filters f w f w determine physical parameters old bulge gcs ngc ngc well defined blue horizontal branches compare results similar data inner halo cluster ngc clusters similar metallicities â‰¤ fe h â‰¤ obtained high resolution spectroscopy derive ages distance moduli reddening values means statistical comparisons observed synthetic fiducial lines employing likelihood statistics markov chain monte carlo method synthetic fiducial lines generated using î± enhanced basti dartmouth stellar evolutionary models adopting canonical âˆ¼ enhanced âˆ¼ helium abundances rr lyrae stars employed determine hb magnitude level providing independent indicator constrain apparent distance modulus helium enhancement shape observed fiducial line compatible helium enhancement ngc ngc average magnitudes rr lyrae stars tend rule hypothesis assuming canonical helium abundances basti dartmouth models indicate three clusters coeval ages âˆ¼ gyr present study also reveals ngc least two stellar populations since cmd shows significantly wide subgiant branch compatible â± â± first second generations respectively â© american astronomical society rights reserved
10.1109/ICCVW.2017.76 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046271970&doi=10.1109%2fICCVW.2017.76&partnerID=40&md5=49e50b04ab7bb116049f26095a5af650 0,hand pose emerging important interface human computer interaction problem hand pose estimation passive stereo inputs received less attention literature compared active depth sensors paper seeks address gap presenting data driven method estimate hand pose stereoscopic camera input introducing stochastic approach propose potential depth solutions observed stereo capture evaluate proposals using two convolutional neural networks cnns first cnn configured siamese network architecture evaluates consistent proposed depth solution observed stereo capture second cnn estimates hand pose given proposed depth unlike sequential approaches reconstruct pose known depth method jointly optimizes hand pose depth estimation markov chain monte carlo mcmc sampling way pose estimation correct errors depth estimation vice versa experimental results using inexpensive stereo camera show proposed system accurately measures pose better competing methods â© ieee
10.1109/CDC.2017.8263872 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046251029&doi=10.1109%2fCDC.2017.8263872&partnerID=40&md5=e02ff086d82b3af9e2e69bf958cf8cc2 0,paper introduce fortiori expectation maximization afem algorithm computing parameters distribution unlabeled correlated point sets presumed generated unlabeled point assumed correspond target independent probability appearance correlated positions propose replacing expectation phase algorithm kalman filter modified within bayesian framework account unknown point labels manifest uncertain measurement matrices also propose mechanism reorder measurements order improve parameter estimates addition use state art markov chain monte carlo sampler efficiently sample measurement matrices process indirectly propose constrained k means clustering algorithm simulations verify utility afem traditional expectation maximization algorithm variety scenarios â© ieee
10.1109/CDC.2017.8263890 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046294187&doi=10.1109%2fCDC.2017.8263890&partnerID=40&md5=1bd0741fe4fa6db756b0452536e384c7 0,objective paper evaluate transient performance conventional monte carlo method called fmc paper fixed number samples following question asked conditions propagated fmc ensemble generated direct sampling unknown true state pdf answer question propagated ensemble viewed realization markov chain fmc process evolution associated transition kernel equation governing evolution fmc transition kernel derived shown systems zero divergence force field â· f = true evolved state pdf invariant distribution propagated fmc transition kernel times equivalence guaranteed systems non zero divergence numerical simulations provided support theoretical claims ensemble quality types dynamic systems â© ieee
10.1080/03610918.2017.1400053 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041016797&doi=10.1080%2f03610918.2017.1400053&partnerID=40&md5=4bcb81bbda90d2cdd33a42787f29d71f 0,combined model accounts different forms extra variability traditionally applied likelihood framework bayesian setting via markov chain monte carlo article integrated nested laplace approximation investigated alternative estimation method combined model count data compared former estimation techniques longitudinal spatial multi hierarchical data scenarios investigated three case studies well simulation study conclusion integrated nested laplace approximation provides fast precise estimation avoiding convergence problems often seen using markov chain monte carlo â© taylor francis group llc
10.1080/03610926.2017.1303732 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029406140&doi=10.1080%2f03610926.2017.1303732&partnerID=40&md5=4f05ef3e40e9e865e98b66840135df79 0,markov switching ms models becoming increasingly popular efficient tools modeling various phenomena different disciplines particular non gaussian time series articlept propose broad class markov switching bilinearâ€“garch processes ms âˆ’ blgarch hereafter obtained adding ms âˆ’ garch model one interaction components observed series volatility process parameterization offers remarkably rich dynamics complex behavior modeling forecasting financial time series data exhibit structural changes models parameters conditional variance allowed vary according latent time homogeneous markov chain finite state space â€œregimes â€� main aim new model capture asymmetric hence purported able capture leverage effect characterized negativity correlation returns shocks subsequent shocks volatility patterns different regimes first basic structural properties new model including sufficient conditions ensuring existence stationary causal ergodic solutions moments properties given second since second order structure provides useful information identify appropriate time series model derive expression covariance function ms âˆ’ blgarch powers consequence find second resp higher order structure similar linear processes hence ms âˆ’ blgarch resp powers admit arma representation finding allows us parameter estimation via gmm procedure proved monte carlo study applied foreign exchange rate algerian dinar single european currency â© taylor francis group llc
10.1021/acs.est.7b04906 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041443933&doi=10.1021%2facs.est.7b04906&partnerID=40&md5=e9bf73c03a4235404d6fd172eb86820c 0,metal contamination major problem many estuaries toxicokinetic models useful tools predicting metal accumulation estuarine organisms managing associated ecological risks however obtaining toxicokinetic parameter values sufficient predictive power challenging dynamic estuarine waters study determined toxicokinetics multiple metals oyster crassostrea hongkongensis dynamic estuary polluted metals using day transplant experiment experiment metal concentrations oysters water suspended particles intensively monitored day intervals toxicokinetic parameters estimated using markov chain monte carlo mcmc method calibrated model capable successfully simulating time course metal bioaccumulation oysters validated predicting bioaccumulation another site estuary furthermore model used assess relative importance different pathways metal bioaccumulation mcmc method distributions instead single values assigned model parameters method makes model predictions probabilistic clearly defined uncertainties thus particularly useful risk assessment metals aquatic systems â© american chemical society
10.1109/ICSIIT.2017.71 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049327768&doi=10.1109%2fICSIIT.2017.71&partnerID=40&md5=599adea32cda01770b78395934570d60 0,simple independent generalized extreme value gev model three stage hierarchical model applied regional climate model outputs temperature extremes tasmania australia parameters model estimated using maximum likelihood hybrid markov chain monte carlo mcmc approach respectively two models compared based well models predict extremes randomly selected locations withheld fitting using root mean squared prediction error rmspe ten times rmspes two models show three stage hierarchical model outperformed simple model showed spatial hierarchical model successfully smoothed shape parameters high values tend pulled low values pushed â© ieee
10.1080/03610918.2017.1414248 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041098761&doi=10.1080%2f03610918.2017.1414248&partnerID=40&md5=2cbbc8dd858a8df76363bcf929f09593 0,partial linear single index model plsim flexibility nonparametric treatment interpretability linear term yet existing literatures mainly focused mean regression quantile regression analysis scarce based free knot spline approximation apply asymmetric laplace distribution implement bayesian quantile regression perform variable selection linear term index vector via binary indicators approach exempt regularity conditions frequentist method execute variable selection quantile regression mutual posterior correction also first work implement jointly plsim fully bayesian framework numerical simulation manifests superiority approach previous methods embodied better efficiency variable selection index vector estimates link function approximation different error distributions illustration application build power consumption model process wastewater treatment emphatically analyze impact water quality factors â© taylor francis group llc
10.1109/ISGTEurope.2017.8260306 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046245594&doi=10.1109%2fISGTEurope.2017.8260306&partnerID=40&md5=eb5cbd572e9e01f29530b2a9d01756f5 0,paper operation management microgrids performed contingencies including outage distributed generators dg energy storage es upstream network considered since microgrids suitable capabilities terms control communication demand response reserve applied improve operation management using monte carlo simulation method markov chain several scenarios generated show possible contingencies various hours scenario reduction method used reducing number scenarios finally two stage stochastic model applied solve day ahead scheduling problem mixed integer linear programming gams consequently effect demand response reduction operation cost demonstrated â© ieee
10.1016/j.ces.2017.10.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032854262&doi=10.1016%2fj.ces.2017.10.003&partnerID=40&md5=f4aecfeed82b3ce621f5f252bfd182dc 1,phase equilibrium loading stripping stages liquidâ€“liquid extraction iron iii hydroxyoxime extractant kerosene studied wide range hydroxyoxime extractant acorga â€“ volâ€“ iron â€“ g l concentrations mechanistic mathematical model explaining phase equilibrium loading stage developed validated new experimental data model accounts non ideality aqueous organic phases composition aqueous sulfate solution calculated speciation electrolytes extended debyeâ€“hã¼ckel model organic phase non ideality loading stage described empirical correlation accounts effect extractant concentration extraction equilibrium constant model parameters fitted measured experimental data using nonlinear regression analysis mechanistic mathematical model explaining co extraction iron copper liquidâ€“liquid extraction developed validated using optimal experiment design markov chain monte carlo algorithm model facilitates optimization copper liquidâ€“liquid extraction circuits iron common impurity industrial systems making process operations challenging â© elsevier ltd
10.1016/j.patrec.2017.11.022 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037543059&doi=10.1016%2fj.patrec.2017.11.022&partnerID=40&md5=f278214ff81b0d210c3a6b5c067c4d15 0,estimating log likelihood gradient respect parameters restricted boltzmann machine rbm typically requires sampling using markov chain monte carlo mcmc techniques save computation time markov chains run small number steps leads biased estimate bias cause rbm training algorithms contrastive divergence cd learning deteriorate adopt idea behind population monte carlo pmc methods devise new rbm training algorithm termed population contrastive divergence pop cd compared cd leads consistent estimate may significantly lower bias computational overhead negligible compared cd variance gradient estimate increases experimentally show pop cd significantly outperform cd many cases observed smaller bias achieved higher log likelihood values however rbm distribution many hidden neurons consistent estimate pop cd may still considerable bias variance gradient estimate requires smaller learning rate thus despite superior theoretical properties advisable use pop cd current form large problems â©
10.1016/j.energy.2017.11.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037356109&doi=10.1016%2fj.energy.2017.11.005&partnerID=40&md5=806604e5373f76daa11f9bd8d10df30a 1,massive deployment plug electric vehicles pevs renewable energy resources res distributed energy storage systems dess gained significant interest smart grid vision however special features operational characteristics created paradigm shift distribution network resource allocation studies paper presents combined model formulation concurrent optimal resource allocation pevs charging stations res dess distribution networks formulation employs general objective function optimizes total annual cost energy acoe decision variables formulation locations capacities pevs charging stations res dess units markov chain monte carlo mcmc simulation model utilized account uncertainties pevs charging demand output generation res units also order enhance accuracy resource allocation problem coordinated control pevs charging res output power dess charging discharging incorporated formulated model formulation decomposed two interdependent sub problems solved using combination metaheuristic deterministic optimization techniques sample case study presented illustrate performance algorithm â© elsevier ltd
10.1109/BigData.2017.8258417 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047755652&doi=10.1109%2fBigData.2017.8258417&partnerID=40&md5=b3476b9c6fe5d0ba3220a1fc2a7d155a 0,e commerce websites yelp com allow users write online reviews products services new customers quick access user experiences covering everything auto repair hospitals however typical user may find difficult identify topic interest due overwhelming amount review information deal issue latent dirichlet allocation lda model used associate meaningful terms text based reviews permitting keyword retrieval individual documents lda powerful unsupervised learning approach widely used topic modeling well related fields conventional implementation lda markov chain monte carlo methodology called collapsed gibbs sampling cgs however due usage random numbers cgs approach results multiple trials data usually inconsistent avoid tendency revise conventional lda approach using variational gibbs sampling vgs vgs eliminates random numbers thus leads consistent results well better performance case study shows improved lda used automatically identify keywords topics online hospital reviews due usage vgs accuracy topic identification consistently improved â© ieee
10.1007/s11222-017-9796-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041797150&doi=10.1007%2fs11222-017-9796-9&partnerID=40&md5=08c6585cbf3bef4b46cd5f4a181e6be5 0,present new bayesian nonparametric approach estimating spectral density stationary time series nonparametric prior based mixture b spline distributions specified regarded generalization bernstein polynomial prior petrone scand j stat â€“ j stat â€“ b choudhuri et al j stat assoc â€“ whittleâ€™s likelihood approximation used obtain pseudo posterior distribution method allows data driven choice number mixture components location knots posterior samples obtained using metropolis within gibbs markov chain monte carlo algorithm mixing improved using parallel tempering conduct simulation study demonstrate complicated spectral densities b spline prior provides accurate monte carlo estimates terms formula presented error uniform coverage probabilities bernstein polynomial prior apply algorithm annual mean sunspot data estimate solar cycle finally demonstrate algorithmâ€™s ability estimate spectral density sharp features using real gravitational wave detector data ligoâ€™s sixth science run recoloured match advanced ligo target sensitivity â© springer science+business media llc part springer nature
10.1103/PhysRevE.97.012113 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040743973&doi=10.1103%2fPhysRevE.97.012113&partnerID=40&md5=ac557dc6fc6d874d23118c5d9facc3dd 0,scalar langevin type process x driven ornstein uhlenbeck noise î· non markovian however joint dynamics x î· described markov process two dimensions even though exists variety techniques analysis markov processes still challenge estimate process parameters solely based given time series x partially observed process e g analyzed bayesian framework using markov chain monte carlo methods alternatively embedding strategy applied first joint dynamics x temporal derivative áºš analyzed subsequently results used determine process parameters x î· paper propose direct approach purely based moments increments x estimated different time increments ï„ given time series stochastic taylor expansion x analytic expressions moments derived used estimate process parameters regression strategy â© american physical society
10.5194/bg-15-187-2018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045831896&doi=10.5194%2fbg-15-187-2018&partnerID=40&md5=1880292d6f26f7aa4da24b205d6c57b0 1,modeling net ecosystem exchange nee regional scale land surface models lsms relevant estimation regional carbon balances studies limited furthermore essential better understand quantify uncertainty lsms order improve important key variable respect prognostic leaf area index lai sensitive forcing data strongly affects modeled nee applied community land model clm bgc rur catchment western germany compared estimated default ecological key parameters modeling carbon fluxes lai parameter estimates previously estimated markov chain monte carlo mcmc approach dream zs four widespread plant functional types catchment found catchment scale annual nee strongly positive default parameter values negative closer observations estimated values thus estimation clm parameters local nee observations highly relevant determining regional carbon balances obtain comprehensive picture model uncertainty clm ensembles set perturbed meteorological input uncertain initial states addition uncertain parameters c grass c crops particularly sensitive perturbed meteorological input resulted strong increase standard deviation annual nee sum î´î nee different ensemble members âˆ¼ g c yr uncertain parameters âˆ¼ g c yr c grass âˆ¼ g c yr c crops perturbed forcings increase uncertainty related impact meteorological forcings leaf onset senescence enhanced reduced drought stress related perturbation precipitation nee uncertainty forest plant functional type pft considerably lower ïƒ nee âˆ¼ g c yr perturbed parameters meteorological forcings initial states conclude lai nee uncertainty clm clearly underestimated uncertain meteorological forcings initial states taken account â© wilson ornithological society rights reserved
10.1051/epjconf/201817006002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041029123&doi=10.1051%2fepjconf%2f201817006002&partnerID=40&md5=abf5ef732c8be8f6a59990a5c6ad4c91 0,gamma spectrometry passive non destructive assay used quantify radionuclides present less complex objects basic methods using empirical calibration standard order quantify activity nuclear materials determining calibration coefficient useless non reproducible complex single nuclear objects waste packages package specifications composition geometry change one package another involve high variability objects current quantification process uses numerical modelling measured scene available data geometry composition data density material screen geometric shape matrix composition matrix source distribution strongly dependent package data knowledge operator backgrounds french commissariat ã l energie atomique cea developing new methodology quantify nuclear materials waste packages waste drums without operator adjustment internal package configuration knowledge method suggests combining global stochastic approach uses among others surrogate models available simulate gamma attenuation behaviour bayesian approach considers conditional probability densities problem inputs markov chains monte carlo algorithms mcmc solve inverse problems gamma ray emission radionuclide spectrum outside dimensions interest objects methodology testing quantify actinide activity different kind matrix composition configuration sources standard terms actinide masses locations distributions activity uncertainties taken account adjustment methodology â© authors published edp sciences
10.1186/s12913-017-2775-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040369374&doi=10.1186%2fs12913-017-2775-1&partnerID=40&md5=6765e5deff64fb609decad1f73f9eeb1 0,background drug markets complex many new drugs registered year little known drives prescription new drugs study attempts lift veil important subject analyzing simultaneously impact several variables prescription novelty methods data provided four swiss sickness funds analyzed data included information insured notably drug intake outcome variable captured novelty age drug prescribed overall variance novelty partitioned across five levels substitutable drug market patient physician region prescription influence several variables measured levels assessed using non hierarchical multilevel model estimated bayesian markov chain monte carlo methods results variation novelty explained substitutable drug market level prescription level newer drugs prescribed markets costlier less concentrated included insured provided drugs included active substances counter drugs average years older generic drugs years older non generics regional disparities terms age prescribed drugs reach years conclusions regulation demand low impact little variation explained patient level physician level contrary market structure e g end patent generic apparition concurrence among producers strong contribution variation drugs ages â© author
10.1103/PhysRevE.97.012106 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040732698&doi=10.1103%2fPhysRevE.97.012106&partnerID=40&md5=b1a5fafb6f026e9fb516261051a4b199 2,totally asymmetric exclusion process tasep classical stochastic model describing transport interacting particles ribosomes moving along messenger ribonucleic acid mrna translation although model widely studied past extent collision particles average distance particle nearest neighbor quantified explicitly provide theoretical analysis quantities via distribution isolated particles classical form model particle occupies single site obtain exact analytic solution using matrix ansatz employ refined mean field approach extend analysis generalized tasep particles arbitrary size theoretical study direct applications mrna translation interpretation experimental ribosome profiling data particular analysis data saccharomyces cerevisiae suggests potential bias detection nearby ribosomes gap distance less approximately three codons leads ambiguity estimating initiation rate protein production flux substantial fraction genes despite ambiguity however demonstrate theoretically interference rate associated collisions robustly estimated show approximately translating ribosomes get obstructed â© american physical society
10.1051/epjconf/201816801008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040970232&doi=10.1051%2fepjconf%2f201816801008&partnerID=40&md5=d4899fd48e1823d82a22202738413db1 0,gravitational waves compact binary systems viewed standard siren probe evolution universe paper summarizes potential ability use gravitational waves constrain cosmological parameters dark sector interaction gaussian process methodology briefly introducing method reconstruct dark sector interaction gaussian process concept standard sirens analysis reconstructing dark sector interaction lisa outlined furthermore estimate constraint ability gravitational waves cosmological parameters et numerical methods use gaussian process markov chain monte carlo finally also forecast improvements abilities constrain cosmological parameters et lisa combined planck â© authors published edp sciences
10.1109/ICUWB.2017.8251009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046036316&doi=10.1109%2fICUWB.2017.8251009&partnerID=40&md5=3001f33735ab0a3829c7aec780c21235 0,one major challenges increase wind power generation uncertain nature wind speed far uncertainty wind speed presented probability distributions also existing models consider uncertainty wind speed primarily view distributions wind speed wind farm homogeneous however uncertainty wind speed models yet considered paper bayesian approach taking account uncertainty inherent wind speed model presented proposed bayesian predictive model wind speed aggregates non homogeneous distributions single continuous distribution therefore result able capture variation among probability distributions wind speeds turbines locations wind farm specifically instead using wind speed distribution whose parameters known estimated parameters considered random whose variations according probability distributions bayesian predictive model rayleigh single model scale parameter proposed also closed form posterior predictive inferences different reasonable choices prior distribution sensitivity analysis presented â© ieee
10.23919/EURAD.2017.8249147 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040868249&doi=10.23919%2fEURAD.2017.8249147&partnerID=40&md5=155380c98f660f863739e769ed0515c5 2,paper tackle task multi target tracking humans indoor setting using low power ghz mimo cmos radar drawback highresolution low power device higher sensitivity noise makes analysis signals challenging therefore pipeline proposed address pre processing radar signal multi target tracking pre processing phase focus handling low signal noise ratio snr eliminating called ghost targets tracking method propose based markov chain monte carlo data association mcmcda thus taking combinatorial approach towards task tracking pipeline tested number real world scenarios shows promising results overcoming significant amount noise associated embedded radar devices â© european microwave association
10.1109/WSC.2017.8247926 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044543652&doi=10.1109%2fWSC.2017.8247926&partnerID=40&md5=4b8dd7dc3a47fb468e9b0bed3d32dc46 0,simulation tail multivariate normal density numerous applications statistics operations research unfortunately simple formula cumulative distribution function multivariate normal law simulation tail frequently approximate article present asymptotically efficient monte carlo estimator quantities related tail multivariate normal distribution estimator leverages upon known asymptotic approximations addition generalize notion asymptotic efficiency monte carlo estimators rare event probabilities sampling properties markov chain monte carlo algorithms regarding new notions propose simple practical markov chain sampler normal tail asymptotically optimal give numerical example finance illustrates benefits asymptotically efficient markov chain monte carlo sampler â© ieee
10.1007/s10614-017-9784-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040079132&doi=10.1007%2fs10614-017-9784-3&partnerID=40&md5=9b9c46644992b66f8800a402c1ad922a 0,stochastic volatility models widely appreciated model time varying volatility empirical finance practice whether leverage effect asset time series one important stylized facts paper context stochastic volatility models main purpose develop bayesian approach testing leverage effect performance developed procedure illustrated simulation studies two empirical examples â© springer science+business media llc part springer nature
10.1109/ETCM.2017.8247445 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043355705&doi=10.1109%2fETCM.2017.8247445&partnerID=40&md5=5839bcb808801329c1cd837144d5e124 4,paper presents reliability model static var compensator svc using innovative algorithm based sequential monte carlo simulation markov chains method employs equivalent circuit svc takes failure rate repair time component input order compute failure rate repair time whole svc system specific contribution investigation presents mathematical pathway model operating conditions svc subject individual operating states components resulting comprehensive reliability model â© ieee
10.1109/EI2.2017.8245412 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049209947&doi=10.1109%2fEI2.2017.8245412&partnerID=40&md5=eb71a647c1158557eb1a7e8aa08111bf 0,distributed integrated energy system dies conductive alleviate energy shortage environment pollution basis planning operation reliability evaluation important development dies firstly paper established reliability evaluation model dies based energy hub model describe complex interconnection different power supply subsystems impacts dynamic behavior thermostatically controlled load reliability evaluation dies analyzed based electric water heater ewh model reliability evaluation dies carried based markov chain monte carlo mcmc simulation feasibility proposed method validated extensive case studies â© ieee
10.1080/10705511.2017.1364968 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030175725&doi=10.1080%2f10705511.2017.1364968&partnerID=40&md5=08726e67a521ed23fb2607dc14b894fb 1,psychological social behavioral medical studies hidden markov models hmms extensively applied simultaneous modeling heterogeneous observation hidden transition analysis longitudinal data however majority existing hmms developed parametric framework without latent variables study considers novel semiparametric hmm comprises semiparametric latent variable model investigate complex interrelationships among latent variables nonparametric transition model examine linear nonlinear effects potential predictors hidden transition bayesian p splines approach markov chain monte carlo methods developed estimate unknown bayesian model comparison statistic employed conduct model comparison empirical performance proposed methodology evaluated simulation studies application data set derived national longitudinal survey youth presented copyright â© taylor francis group llc
10.1080/10705511.2017.1372688 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031788731&doi=10.1080%2f10705511.2017.1372688&partnerID=40&md5=e9669382bbd9b7708ca691207e81ed2c 0,multivariate heterogenous data latent variables common many fields biological medical behavioral social psychological sciences mixture structural equation models multivariate techniques used examine heterogeneous interrelationships among latent variables analysis mixture models determination number mixture components always important challenging issue article aims develop full bayesian approach use reversible jump markov chain monte carlo method analyze mixture structural equation models unknown number components proposed procedure simultaneously efficiently select number mixture components conduct parameter estimation simulation studies show satisfactory empirical performance method proposed method applied study risk factors osteoporotic fractures older people copyright â© taylor francis group llc
10.1080/10618600.2017.1317263 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026430416&doi=10.1080%2f10618600.2017.1317263&partnerID=40&md5=178a066587b4a9c63a6eed305259e88a 0,pseudo likelihood method besag remained popular method estimating markov random field large lattice despite various documented deficiencies partly remains computationally tractable method large lattices introduce novel method estimate markov random fields defined regular lattice method takes advantage conditional independence structures recursively decomposes large lattice smaller sublattices approximation made decomposition completely avoids need compute troublesome normalizing constant computational complexity n n number pixels lattice making computationally attractive large lattices show simulations proposed method performs well even compared methods using exact likelihoods supplementary material article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/10618600.2017.1307117 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026419157&doi=10.1080%2f10618600.2017.1307117&partnerID=40&md5=424d6a247a9b369b6b5456c0cf569c64 0,complexity metropolisâ€“hastings mh algorithm arises requirement likelihood evaluation full dataset iteration one solution proposed speed algorithm delayed acceptance approach acceptance decision proceeds two stages first stage estimate likelihood based random subsample determines likely draw accepted second stage uses full data likelihood decide upon final acceptance evaluating full data likelihood thus avoided draws unlikely accepted propose precise likelihood estimator incorporates auxiliary information full data likelihood operating sparse set data prove resulting delayed acceptance mh efficient caveat approach full dataset needs evaluated second stage therefore propose substitute evaluation estimate construct state dependent approximation thereof use first stage results algorithm use smaller subsample leveraging recent advances pseudo marginal mh pmmh ii provably within mâˆ’ true posterior â© american statistical association institute mathematical statistics interface foundation north america
10.1080/01621459.2017.1328358 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047367446&doi=10.1080%2f01621459.2017.1328358&partnerID=40&md5=b4c9a0b0002c3e75e6043e709406d8ea 5,perform differential expression analysis high throughput sequencing count data bayesian nonparametric framework removing sophisticated ad hoc pre processing steps commonly required existing algorithms propose use gamma beta negative binomial process takes account different sequencing depths using sample specific negative binomial probability dispersion parameters detect differentially expressed genes comparing posterior distributions gene specific negative binomial dispersion probability parameters model parameters inferred borrowing statistical strength across genes samples extensive experiments simulated real world rna sequencing count data show proposed differential expression analysis algorithms clearly outperform previously proposed ones terms areas receiver operating characteristic precision recall curves supplementary materials article available online â© american statistical association
10.1080/10618600.2017.1316280 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026410934&doi=10.1080%2f10618600.2017.1316280&partnerID=40&md5=b2ef485df779e4b378cc09cb5f5a34b4 3,univariate multivariate ordinal responses often assumed arise latent continuous parametric distribution covariate effects enter linearly introduce bayesian nonparametric modeling approach univariate multivariate ordinal regression based mixture modeling joint distribution latent responses covariates modeling framework enables highly flexible inference ordinal regression relationships avoiding assumptions linearity additivity covariate effects standard parametric ordinal regression models computational challenges arise identifiability constraints estimation parameters requiring nonstandard inferential techniques key feature nonparametric model achieves inferential flexibility avoiding difficulties particular establish full support nonparametric mixture model fixed cut points relate discretization latent continuous responses ordinal responses practical utility modeling approach illustrated application two datasets econometrics example involving regression relationships ozone concentration multirater agreement problem supplementary materials technical details theoretical results computation available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/07350015.2015.1137757 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018178230&doi=10.1080%2f07350015.2015.1137757&partnerID=40&md5=28be38edd9adc4f1aa26cc86e9324560 1,article develops new markov switching vector autoregressive var model stochastic correlation contagion analysis financial markets correlation log volatility dynamics driven two independent markov chains thus allowing different effects volatility spill overs correlation shifts various degrees intensity outline suitable bayesian inference procedure based markov chain monte carlo algorithms apply model major asian pacific cross rates u dollar find strong evidence supporting existence contagion effects correlation drops crises closely line stylized facts outlined contagion literature comparison model closest competitors time varying parameter var reveals model better predictive ability supplementary materials article available online â© american statistical association
10.1080/03610918.2017.1280830 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020163044&doi=10.1080%2f03610918.2017.1280830&partnerID=40&md5=5c76cf7851607e6b1ac3e652fff81afd 0,number nonstationary models developed estimate extreme events function covariates quantile regression qr model statistical approach intended estimate conduct inference conditional quantile functions article focus simultaneous variable selection parameter estimation penalized quantile regression conducted comparison regularized quantile regression model b splines bayesian framework regularization based penalty aims favor parsimonious model especially case large dimension space prior distributions related penalties detailed five penalties lasso ridge scad scad scad considered equivalent expressions bayesian framework regularized quantile estimates compared maximum likelihood estimates respect sample size markov chain monte carlo mcmc algorithms developed hierarchical model simulate conditional posterior distribution quantiles results indicate scad lasso best performance quantile estimation according relative mean biais rmb relative mean error rme criteria especially case heavy distributed errors case study annual maximum precipitation charlo eastern canada pacific north atlantic climate index covariate presented â© taylor francis group llc
10.1080/10618600.2017.1330206 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031090874&doi=10.1080%2f10618600.2017.1330206&partnerID=40&md5=90b1a441461d36eda1fd87d4eea0053f 0,multiset sampler shown effective algorithm sample complex multimodal distributions multiset sampler requires parameters target distribution divided two parts parameters interest nuisance parameters propose new self multiset sampler smss extends multiset sampler distributions without nuisance parameters also generalize method distributions unbounded infinite support numerical results show smss generalization substantial advantage sampling multimodal distributions compared ordinary markov chain monte carlo algorithm popular variants supplemental materials article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/15598608.2017.1299058 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017408331&doi=10.1080%2f15598608.2017.1299058&partnerID=40&md5=38f9784b668c591c4edc1d9a6d5f5c4d 2,medical studies monotone partial likelihood frequently encountered analysis time event data using cox model example binary covariate subjects classified two groups event interest occur zero event subjects one groups resulting partial likelihood monotone consequently covariate effects difficult estimate article develop bayesian frequentist approaches using data dependent jeffreys type prior handle monotone partial likelihood problem first carry depth examination conditions monotone partial likelihood characterize sufficient necessary conditions propriety jeffreys type prior study several theoretical properties jeffreys type prior cox model addition propose two variations jeffreys type prior shifted jeffreys type prior jeffreys type prior based first risk set efficient markov chain monte carlo algorithm developed carry posterior computation perform extensive simulations examine performance parameter estimates demonstrate applicability proposed method analyzing real data seer prostate cancer study â© grace scientific publishing llc
10.1080/01621459.2016.1255636 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033691180&doi=10.1080%2f01621459.2016.1255636&partnerID=40&md5=b72ab08a1f69d064b7da2c2ebae38343 1,natural bayesian approach mixture models unknown number components take usual finite mixture model symmetric dirichlet weights put prior number componentsâ€”that use mixture finite mixtures mfm commonly used method inference mfms reversible jump markov chain monte carlo nontrivial design good reversible jump moves especially high dimensional spaces meanwhile samplers dirichlet process mixture dpm models relatively simple easily adapted new applications turns fact many essential properties dpms also exhibited mfmsâ€”an exchangeable partition distribution restaurant process random measure representation stick breaking representationâ€”and crucially mfm analogues simple enough used much like corresponding dpm properties consequently many powerful methods developed inference dpms directly applied mfms well simplifies implementation mfms substantially improve mixing illustrate real simulated data including high dimensional gene expression data used discriminate cancer subtypes supplementary materials article available online â© american statistical association
10.1080/00480169.2017.1391723 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032833544&doi=10.1080%2f00480169.2017.1391723&partnerID=40&md5=f8b1895c3437346a2350fdc50869eb9a 0,aims determine sensitivity se specificity sp pregnancy diagnosis using transrectal ultrasonography elisa pregnancy associated glycoprotein pag milk lactating dairy cows seasonally calving herds approximately â€“ days start herdâ€™s breeding period methods paired results used pregnancy diagnosis using transrectal ultrasonography elisa pag milk carried approximately days start breeding period respectively cows four herds victoria australia bayesian latent class model used estimate proportion cows pregnant se sp test covariances test results pregnant non pregnant cows prior probability estimates defined using beta distributions expected proportion cows pregnant se sp test covariances tests markov chain monte carlo iterations identified posterior distributions unknown variables posterior distributions parameter described using medians probability e credible intervals pri posterior median estimates se sp test used estimate positive predictive negative predictive values across range pregnancy proportions results estimate proportion pregnant pri = â€“ pregnancy diagnosis using transrectal ultrasonography se sp pri = â€“ pri = â€“ respectively elisa se sp pri = â€“ pri = â€“ respectively estimated covariance test results pri = â€“ pri = â€“ pregnant non pregnant cows respectively pregnancy diagnosis results using transrectal ultrasonography higher positive predictive value lower negative predictive value results elisa across range pregnancy proportions assessed conclusions clinical relevance pregnancy diagnosis using transrectal ultrasonography elisa pag milk similar se differed predictive values pregnancy diagnosis seasonally calving herds around â€“ days start breeding period using elisa expected result higher negative predictive value lower positive predictive value pregnancy diagnosis using transrectal ultrasonography thus elisa higher proportion cows negative results non pregnant relative results transrectal ultrasonography lower proportion cows positive results pregnant â© new zealand veterinary association
10.1002/andp.201700214 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044290374&doi=10.1002%2fandp.201700214&partnerID=40&md5=78bc02cafc30816c7346ff319173b744 0,inception modern frontiers applied statistics markov chain monte carlo one ubiquitous successful methods statistical computing development method time fueled increasingly difficult problems also novel techniques adopted physics history markov chain monte carlo reviewed inception metropolis method contemporary state art hamiltonian monte carlo focusing evolving interplay statistical physical perspectives method â© wiley vch verlag gmbh co kgaa weinheim
10.1117/12.2293588 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047350507&doi=10.1117%2f12.2293588&partnerID=40&md5=a7fcb2dfd5ea643b6475db7a3b13f54c 0,image guided diagnostics therapy comprise decisions concerning treatment intervention based registered image data patients many clinical settings therefore knowledge reliability registration result crucial paper tackle issue estimating registration uncertainty based bayesian analysis e examining posterior distribution parameters describing underlying transformations intractability posterior distributions allows approximation usually realized monte carlo sampling methods conventional markov chain monte carlo mcmc algorithms require large number posterior samples ensure robust estimates inflicts high computational burden contribution work embedding mcmc approach cost reducing multilevel framework multilevel mcmc fits multi resolution framework usually applied image registration work evaluate performance method using b spline transformation framework e b spline coefficients parameters estimate demonstrate correctness comparison ground truth posterior distribution evaluate efficiency examination cost reduction show reliability uncertainty estimator brain mri images â© copyright spie downloading abstract permitted personal use
10.1016/j.advwatres.2017.11.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034570705&doi=10.1016%2fj.advwatres.2017.11.011&partnerID=40&md5=b74719038d48c02654016e286330a727 3,particle filters pfs received increasing attention researchers different disciplines including hydro geosciences effective tool improve model predictions nonlinear non gaussian dynamical systems implication dual state parameter estimation using pfs hydrology evolved since pf sir sampling importance resampling pf mcmc markov chain monte carlo effective robust framework evolutionary pf approach based genetic algorithm ga mcmc called epfm framework prior distribution undergoes evolutionary process based designed mutation crossover operators ga merit approach particles move appropriate position using ga optimization number effective particles increased means mcmc whereby particle degeneracy avoided particle diversity improved study usefulness effectiveness proposed epfm investigated applying technique conceptual highly nonlinear hydrologic model four river basins located different climate geographical regions united states synthetic real case studies demonstrate epfm improves state parameter estimation effectively reliably compared pf mcmc â© elsevier ltd
10.1007/978-981-10-8108-8_38 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042080306&doi=10.1007%2f978-981-10-8108-8_38&partnerID=40&md5=0e60ad43d93bd2324912623802b4b4db 0,novel framework particle filter named bidirectional markov chain monte carlo particle filter bmcmcpf proposed estimate articulated human movement state action category jointly owing reason regard action category estimated state framework firstly motion models every possible action built via autoregressive modeling captured motion data minimum distance meanwhile dynamic model observation model also get coupled tracking recognition achieve synchronously state estimation completed using bidirectional marko chain monte carlo sampling bmcmcpf improve tracking performance global optimization property also smooth jointâ€™s movement trajectories ensure motion coordination experimental results humaneva datasets show effectiveness bmcmcpf unknown motion modality solving tracking problem â© springer nature singapore pte ltd
10.1007/978-3-319-68385-0_12 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032705319&doi=10.1007%2f978-3-319-68385-0_12&partnerID=40&md5=023f8dfa60faf8bbec4c6dad9cdfc584 0,paper present three different approaches feature selection starting naã¯ve markov chain monte carlo random walk algorithm refined methods like simulated annealing genetic algorithms typical textual data thousands dimensions feature space makes feature selection crucial phase final classification classification legal documents eight categories performed via simple document similarity measure based term frequency nearest neighbour concept average success rate random walk algorithm performed better simulated annealing genetic algorithms also matched accuracy support vector machines although methods commonly used selecting appropriate features fields use text categorisation satisfactorily investigated knowledge first work investigates use legal domain generic text classification framework enhanced using active learning methodology selection training samples rather following passive learning approach â© springer international publishing ag
10.1137/17M1144301 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053525284&doi=10.1137%2f17M1144301&partnerID=40&md5=8516088afd463b46279151fde6b98371 0,markov chain monte carlo mcmc widely used approximate expectation statistic given probability measure pi finite set asymptotic variance typical approach evaluating performance mcmc methods paper provide lower bound worst case analysis asymptotic variance general markov chains invariant probability pi reversible well nonreversible ones construct optimal transition matrix achieves lower bound fact statistic f evaluated mcmc constructed optimal transition matrix produces smaller asymptotic variance independent sampling â© society industrial applied mathematics
10.2514/1.J055947 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043253515&doi=10.2514%2f1.J055947&partnerID=40&md5=a9ffe682af2d74fe1f34fa8711e225e2 0,tail modelingis anefficient method used reliability estimationofhighly safe structures classical tail modeling basedonperforming limit state functionevaluations throughasampling scheme selectingathreshold valuetospecify tail part cumulative distribution function fitting proper model tail part estimating reliability approach limit state function calculations belong tail part mostly discarded majority limit state evaluations wasted paper markov chain monte carlo method metropolis hastings algorithm used draw samples tail part accurate reliability index prediction achieved commonly used proposal distribution formula modified using scale parameter optimal value scale parameter obtained various numerical example problems varying number random variables approximate relationship obtained optimal value scale parameter number random variables approximate relationship tested reliability prediction horizontal axis wind turbine observed work well also found proposed approach accurate classical tail modeling number variables less equal four larger number random variables none two approaches found superior another copyright â© gamze bayrak erdem acar published american instituteof aeronautics astronautics inc permission
10.1504/IJCSM.2018.091733 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047367230&doi=10.1504%2fIJCSM.2018.091733&partnerID=40&md5=a7f0cae6a2d6e2aa632c51dc51d06373 0,sequential monte carlo smc methods also known particle filter provide way solve state estimation problem nonlinear non gaussian state space models ssm numerical approximation particle smoothing one retrospective state estimation method based particle filtering paper propose new particle smoother basic idea easy leads forward backward procedure metropolis hastings algorithm used resample filtering particles goodness new scheme assessed using nonlinear ssm concluded new particle smoother suitable state estimation complicated dynamical systems copyright â© inderscience enterprises ltd
10.2514/1.G002296 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039853757&doi=10.2514%2f1.G002296&partnerID=40&md5=8963d27af91fef88acdb712ff9d96374 1,paper presents new approach estimate observed space object shape also inferring attributes inertial attitude surface parameters adaptive hamiltonian markov chain monte carlo estimation approach employed uses light curve data process inversion estimate shape attributes main advantage approach previous ones estimate attributes simultaneously whereas previous approaches typically rely priori knowledge one estimate particular attribute also unlike previous approaches new approach shown work well relatively high dimensions non gaussian distributions light curve inversion problem simulation results involving singleand multiple faceted objects shown good results obtained cases â© copyright american institute aeronautics astronautics inc rights reserved
627.849095281649 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051540699&partnerID=40&md5=4e78e977526d995c1046cada2f83a8aa 0,performance test important part commissioning procedure natural gas transmission pipeline construction common natural gas pipeline always experience unsteady injection withdrawal situations different meter stations makes estimation pipeline parameters difficult due uncertainty dynamics natural gas flow markov chain monte carlo mcmc method introduced paper find pipeline parameters enable best match performance testing data parameters determined using method include specific gravity gas effective roughness pipeline black powder mass concentration average particle size influence black powder gas pipeline pressure loss included based experience commissioned gas pipeline method presented paper consists three major steps data collection data uncertainty modeling mcmc simulation determine likelihood parameter synchronized pressure temperature flow rate data compressor stations mainline block valves metering stations collected dcs basis input benchmarking variation gas pressure temperature flow rate meter stations statistically analyzed derive probability distribution fluctuations addition probability distribution uncertainty reliability flow meters pressure temperature transmitters modeled based published data specific gravity black powder concentration average size variation added uncertainties final step estimate specific gravity effective pipeline roughness black power concentration sizes based mcmc simulations real long distance gas pipeline performance test result presented example show method used instead identifying single parameter pipeline roughness proposed method helps provide estimate multiple parameters based data results show better matching measurement data hydraulics model prediction consideration physical aspects â© copyright psig inc
10.1615/Int.J.UncertaintyQuantification.2018021551 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048193047&doi=10.1615%2fInt.J.UncertaintyQuantification.2018021551&partnerID=40&md5=1abcebae8b076d3145e02f24224a778b 0,paper consider computing expectations respect probability laws associated certain class stochastic systems order achieve task one must resort numerical approximation expectation also biased discretization associated probability concerned situation discretization required multiple dimensions instance space time contexts known multi index monte carlo mimc method haji ali nobile tempone numer math pp â€“ improve independent identically distributed sampling accurate approximation probability law nontrivial modification multilevel monte carlo mlmc method method reduce work obtain given level error relative sampling even mlmc paper consider case probability laws complex sampled independently example bayesian inverse problem evaluation likelihood requires solution partial differential equation model needs approximated finite resolution develop modification mimc method allows one use standard markov chain monte carlo mcmc algorithms replace independent coupled sampling certain contexts prove variance theorem simplified estimator shows using mimcmc method preferable sense sampling accurate approximation appropriate assumptions method numerically illustrated bayesian inverse problem associated stochastic partial differential equation path measure conditioned observations â© begell house inc
10.3233/978-1-61499-843-3-159 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043576869&doi=10.3233%2f978-1-61499-843-3-159&partnerID=40&md5=7d3b3c8c1dfea9a4ed94ffc7ff4de6e9 0,calibration individual based models ibms successful modeling complex ecological dynamical systems often performed ad hoc bayesian inference used parameter estimation uncertainty quantification successful application realistic scenarios hindered complex stochastic nature ibms computationally expensive techniques particle filter pf provide marginal likelihood estimates multiple model simulations particles required get sample state distribution conditional observed data particle ensembles sampled data observation time requiring particle destruction replication lead increase algorithmic complexity present spux python implementation parallel particle markov chain monte carlo pmcmc algorithm mitigates high computational costs distributing particles multiple computational units adaptive load balancing techniques used mitigate computational work imbalances introduced sampling framework performance investigated significant speed ups observed simple predator prey ibm model â© authors ios press
10.1111/gean.12135 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028765512&doi=10.1111%2fgean.12135&partnerID=40&md5=716fe9f5cd617ec4e06a59206ad76699 0,spatial econometric specifications pose unique computational challenges bayesian analysis making difficult estimate models efficiently literature main focus extending bayesian analysis increasingly complex spatial models stochastic efficiency commonly used markov chain monte carlo mcmc samplers received less attention comparison specifically bayesian methods analyze effective sample size samplers provide large effective size thoroughly considered literature thus compare three mcmc techniques familiar metropolis within gibbs sampling slice within gibbs sampling hamiltonian monte carlo latter two methods common domains widely encountered bayesian spatial econometrics assess methods across four different scenarios estimate spatial autoregressive parameter mixed regressive spatial autoregressive specification spatial lag model find shelf implementations newer high yield simulation techniques require significant adaptation viable find effective sizes often significantly smaller nominal sizes addition find stopping simulation early may understate posterior credible interval widths effective sample size small broadly suggest sample information stopping rules deserve attention applied basic bayesian spatial econometric research â© ohio state university
10.1186/s12859-017-2003-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042509162&doi=10.1186%2fs12859-017-2003-3&partnerID=40&md5=7ffb2a1c1ed33de451750d2b5c692ecb 0,background running multiple chain markov chain monte carlo mcmc provides efficient parallel computing method complex bayesian models although efficiency approach critically depends length non parallelizable burn period simulated data discarded practice burn period set arbitrarily often leads performance far iterations required addition accuracy genomic predictions improve mcmc reaches equilibrium results automatic tuning burn length running multiple chain mcmc proposed context genomic predictions using bayesa bayescï€ models performance parallel computing versus sequential computing tunable burn mcmc versus fixed burn mcmc assessed using simulation data sets well applying methods genomic predictions chinese simmental beef cattle population results showed tunable burn parallel mcmc greater speedups fixed burn parallel mcmc greater speedups relative sequential single chain mcmc nevertheless genomic estimated breeding values gebvs genomic prediction accuracies highly comparable various computing approaches applied genomic predictions four quantitative traits chinese simmental population beef cattle genotyped illumina bovine k snp beadchip tunable burn multiple chain bayescï€ tbm bayescï€ outperformed tunable burn multiple chain bayescï€ tbm bayesa genomic best linear unbiased prediction gblup terms prediction accuracy although differences necessarily caused computational factors intrinsic statistical models per se conclusions automatically tunable burn multiple chain mcmc provides accurate cost effective tool high performance computing bayesian genomic prediction models algorithm generally applicable high performance computing complex bayesian statistical model â© author
10.2298/TSCI1804673T https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052440492&doi=10.2298%2fTSCI1804673T&partnerID=40&md5=46f5c8bfbafc3fca7d0c28fef22e9288 0,thermal problem always modeled using integral equation paper uses monte carlo method based simulation continuous markov chain solve fredholm integral equations second kind examples given show efficiency present work â© society thermal engineers serbia
704.5276150743085 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054593969&partnerID=40&md5=69b01ecb1b99d2abb99d7e660ea86b14 0,ensemble kalman filter enkf markov chain monte carlo mcmc popular methods obtain posterior distribution unknown parameters reservoir model however millions simulation runs may required mcmc accurate sampling posterior subsurface flow problems highly nonlinear non gaussian similarly enkf formulated basis linear gaussian assumptions may also require large number realizations correctly map solution space unknown model parameters ultimately resulting high computational cost data driven meta surrogate proxy models provide alternative solution alleviate issue high computational cost since models accurate numerical solutions partial differential equations pde implementation may add uncertainty forecast model literature effect uncertainty forecast model data assimilation well studied especially field scale reservoir models work propose robust assisted history matching workflow using polynomial chaos expansion pce based forecast model proposed forecast model relies reducing parameter space using karhunen loeve kl expansion preserves two point statistics field random variables kl expansion orthogonal polynomials corresponding prior probability density function pdf form set input parameters pce non intrusive probabilistic collocation method pcm used compute pce coefficients pce forecast model used enkf mcmc calculate likelihood samples place high fidelity full physics simulation runs case study performed using field scale model reservoir located near fort mcmurray northern alberta canada performance enkf mcmc assessed forecast model uncertainty using rigorous qualitative quantitative analysis posterior distribution characterization results clearly depict although enkf provided reliable mean variance estimates model parameters mcmc outperformed former even uncertainty associated pce metamodel inaccurate initial assumptions model parameters successfully handled mcmc although longer burn period furthermore characterization posterior demonstrated reduced uncertainty estimation model parameters using mcmc compared enkf practical implications proposed approach performance assessment forecast model uncertainty consequential designing accurate computationally efficient reservoir characterization optimization workflows hence improved decision making reservoir management â© european association geoscientists engineers eage rights reserved
10.1007/s11222-018-9828-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051651404&doi=10.1007%2fs11222-018-9828-0&partnerID=40&md5=108b936ccb89ddf08fd165afda6518ce 0,bayesian analysis often concerns evaluation models different dimensionality necessary example model selection mixture models facilitate evaluation transdimensional markov chain monte carlo mcmc relies sampling discrete indexing variable estimate posterior model probabilities however little attention paid precision estimates switches occur models transdimensional mcmc output precision may low assessment based assumption independent samples misleading propose new method estimate precision based observed transition matrix model indexing variable assuming first order markov model method samples posterior stationary distribution allows assessment uncertainty estimated posterior model probabilities model ranks bayes factors moreover method provides estimate effective sample size mcmc output two model selection examples show proposed approach provides good assessment uncertainty associated estimated posterior model probabilities â© author
10.1137/17M1134640 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049791282&doi=10.1137%2f17M1134640&partnerID=40&md5=e71098878079ee5690b78353eaa207cf 0,introduce new framework efficient sampling complex probability distributions using combination transport maps metropolis hastings rule core idea use deterministic couplings transform typical metropolis proposal mechanisms e g random walks langevin methods non gaussian proposal distributions effectively explore target density approach adaptively constructs lower triangular transport map approximation knothe rosenblatt rearrangement using information previous markov chain monte carlo mcmc states via solution optimization problem optimization problem convex regardless form target distribution solved efficiently without gradient information target probability distribution target distribution instead represented via samples sequential updates enable efficient parallelizable adaptation map even large numbers samples show approach uses inexact truncated maps produce adaptive mcmc algorithm ergodic exact target distribution numerical demonstrations range parameter inference problems show order magnitude speedups standard mcmc techniques measured number effectively independent samples produced per target density evaluation per unit wallclock time â© u government
10.1093/pasj/psx150 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042215259&doi=10.1093%2fpasj%2fpsx150&partnerID=40&md5=b7ad1a2cc70bbdc2021be536187710b7 0,fit spectral energy distributions seds gev tev bl lac objects frame leptonic one zone synchrotron self compton ssc model investigate physical properties objects use markov chain monte carlo mcmc method obtain basic parameters magnetic field b break energy relativistic electron distribution î³â€²b electron energy spectral index based modeling results support following scenarios gev tev bl lac objects sources large doppler factors implying radiation mechanism considered compared flat spectrum quasars fsrqs gev tev bl lac objects weaker magnetic fields larger doppler factors cause ineffective cooling shift seds higher bands jet powers around ã— erg compared radiation power ã— erg indicating small fraction jet power transformed emission power bl lacs large doppler factors jet components two substructures e g fast core slow sheath gev tev bl lacs kelvin helmholtz instabilities suppressed higher magnetic fields leading micro variability intro day variability optical bands combined sample fsrqs anti correlation peak luminosity lpk peak frequency î½pk obtained favoring blazar sequence scenario addition anti correlation jet power pjet break lorentz factor î³b also supports blazar sequence â© author
10.1214/17-BA1084 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054672211&doi=10.1214%2f17-BA1084&partnerID=40&md5=310215d0a97e9bdbb2c2749f9f1c761d 1,discuss principles guide design efficient metropolis hastings proposals well behaved target distributions without deeply divided modes illustrate developing evaluating novel proposal kernels using variety target distributions efficiency measured variance ratio relative independent sampler first principle introduce negative correlation mcmc sample reduce positive correlation propose something new propose something different explains singlemoded proposals gaussian random walk poorer uniform random walk turn poorer bimodal proposals avoid values close current value evaluate three new bimodal proposals called box airplane strawhat find similar performance earlier bactrian kernels suggesting general shape proposal matters specific distributional form propose mirror kernel generates new values around mirror image current value side target distribution effectively opposite current value introduces negative correlations leading many cases efficiency second principle applicable multidimensional targets sequence well designed one dimensional proposals efficient single dimensional proposal thirdly suggest variable transformation explored general strategy designing efficient mcmc kernels apply principles high dimensional gaussian target strong correlations logistic regression problem molecular clock dating problem illustrate practical utility â© international society bayesian analysis
10.2514/6.2018-1975 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044351687&doi=10.2514%2f6.2018-1975&partnerID=40&md5=061066afa67f3e2c6ee6385919defd1e 0,lack observability inherent linearized dynamics model angles relative navigation two satellites close proximity well established numerous studies showing infinite set possible relative orbits satisfy observations work seeks probabilistic method angles orbit determination study problem using full nonlinear formulation lack range observability problem makes gaussian approximations poor representation solution probability density motivates higher fidelity approaches typical markov chain monte carlo approaches probability distribution sampling order achieve hamiltonian monte carlo sampling theoretical probability distribution possible solutions explored known successful high dimensional problems technique performed several angles measurement cases increasingly difficult observability including close proximity coplanar cases observed tuned correctly hamiltonian monte carlo sampling successfully resolve probability distributions possible deputy states showing increasingly non gaussian behavior observability limited additionally hamiltonian monte carlo achieves much efficiently traditional markov chain monte carlo techniques â© american institute aeronautics astronautics inc aiaa rights reserved
10.1137/17M1112595 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046769002&doi=10.1137%2f17M1112595&partnerID=40&md5=01af8c5d8d22360fd798c9c4d6afa53a 1,article consider static bayesian parameter estimation partially observed diffusions discretely observed work assumption one must resort discretizing underlying diffusion process instance using eulerâ€“maruyama method given assumption show one use markov chain monte carlo mcmc particularly particle mcmc c andrieu doucet r holenstein j r stat soc ser b stat methodol â€“ implement new approximation multilevel ml monte carlo mc collapsing sum identity approach comprises constructing approximate coupling posterior density joint distribution parameter hidden variables two different discretization levels correcting importance sampling method variance weights independent length observed data set utility method prescribed level mean square error cost mlmc method provably less sampling posterior associated precise discretization however method comprises using known efficient simulation methodologies theoretical results illustrated inference parameters two prototypical processes given noisy partial observations process first ornsteinâ€“uhlenbeck process second general langevin equation â© society industrial applied mathematics
10.1016/j.automatica.2017.09.025 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034062676&doi=10.1016%2fj.automatica.2017.09.025&partnerID=40&md5=9ea92170f72cd244bfa7b5ec7f8ff495 0,paper considers problem initial uncertainty forecasting deterministic nonlinear continuous time dynamical systems via particle ensembles popular monte carlo method simple implement faces fundamental issues particular clear well propagated particles continue represent true state uncertainty future times paper evaluates performance monte carlo forecasting analyzing context markov chain monte carlo mcmc theory propagated ensemble viewed realization markov chain time instant generated associated instantaneous transition kernel shown special class nonlinear systems zero divergence propagated kernel detailed balance true state probability density function guarantees statistical consistency monte carlo ensemble truth times systems hand guarantee possible systems non zero divergence â© elsevier ltd
10.1137/17M1149250 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049488912&doi=10.1137%2f17M1149250&partnerID=40&md5=9b511a0dbfb0b0e57057e46d166992f7 1,point spread function psf translation invariant imaging system impulse response always measured directly case high energy x ray radiography psf must estimated images calibration objects indirectly related impulse response psf assumed radial symmetry estimated image opaque straight edge use nonparametric bayesian approach prior probability density psf modeled gaussian markov random field radial symmetry incorporated novel way markov chain monte carlo posterior estimation carried adapting recently developed improvement gibbs sampling algorithm referred partially collapsed gibbs sampling moreover algorithm present proven satisfy invariance respect target density finally demonstrate efficacy methods radiographic data obtained high energy x ray diagnostic system u department energy nevada national security site â© mission support test services llc contractor us doe
10.1016/j.mineng.2017.10.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032302270&doi=10.1016%2fj.mineng.2017.10.017&partnerID=40&md5=a80d0ead7d82549825c0d79da714319b 1,gold dissolution investigated ferric chloride solution one alternative cyanide free leaching media increasing interest effect process variables fe + = â€“ clâˆ’ = â€“ ph = â€“ = â€“ â°c reaction mechanism kinetics studied electrochemically using rotating disk electrode ï‰cyc = â€“ rpm tafel method highest gold dissolution rate â· âˆ’ mol mâˆ’ sâˆ’ achieved â°c fe + = clâˆ’ = ph = ï‰cyc = rpm increase gold dissolution rate observed increase temperature ferric ion concentration chloride concentration gold dissolution rate clear dependency ph redox potential found vary mv vs sce experiments according calculated equilibrium measured open circuit potentials gold suggested dissolve aurous ion au+ form aucl âˆ’ rather auric ion au + form aucl âˆ’ suggested aucl âˆ’ oxidize aucl âˆ’ investigated conditions levich plot calculated activation energies suggested gold dissolution limited mass electron transfer according mechanistic kinetic model developed current work intrinsic surface reaction mainly controls gold dissolution especially higher rotational speeds gt rpm uncertainties model parameters mechanistic kinetic model studied markov chain monte carlo methods â© authors
10.1007/s00521-018-3718-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053494204&doi=10.1007%2fs00521-018-3718-4&partnerID=40&md5=966746dfa4791306426d49bb90d7d7af 0,due risk outsourcing supplier selection critical issue companies considerable evidence shows among criteria selecting supplier quality critical factor process yield index efficient tool assessing process quality supplier although frequentist approach adopted discriminate degrees two yield indices solve supplier selection problem unknown parameters must estimated samples potentially introduce uncertainty statistical testing process instead frequentist inference study proposes using bayesian inference derive posterior distribution ratio two yield indices furthermore markov chain monte carlo technique applied discern empirical posterior distribution ratio aim discriminating degrees two yield indices simulations show proposed method reasonable empirical size tests well terms power â© natural computing applications forum
10.1108/IMDS-10-2016-0423 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041132502&doi=10.1108%2fIMDS-10-2016-0423&partnerID=40&md5=ae0ccd1fbc17f88c6557d7e926755310 0,purpose â€“ purpose paper examine effects atmospherics affective state shoppersâ€™ store behaviour using two approaches structural equation modelling sem e frequentist bayesian approaches shoppersâ€™ affective state tested mediating effect store shopping behaviour design methodology approach â€“ final sample consists respondents drawn shoppers selected apparel stores six popular shopping malls around kuala lumpur malaysia frequentist approach sem common among researchers offers generally analysis relationships multiple latent variables constructs alternatively bayesian sem bsem approach stems diffusion modelâ€™s posterior distributions using markov chain monte carlo technique specifically technique inherently flexible substantive determining parameter estimates compared conventional frequentist approach sem findings â€“ results show mixed effects atmospheric cues retail setting shoppersâ€™ affective state specifically positive direct effect atmospheric cues music store behaviour confirmed atmospheric cues colour store layout found fully mediated affective state bayesian approach able offer distinctive results complementing frequentist approach research limitations implications â€“ although current sample size adequate interesting examine bigger sample size different antecedents store behaviour retailing affect comparison frequentist approach sem bsem practical implications â€“ authors found combination well designed store atmospherics layout store produce pleasurable effects shoppers resulting positive affective state study found results frequentist bayesian approaches complement may beneficial future studies utilise approaches sem originality value â€“ paper met aim compare approaches sem need consider approaches store shopping environment overall authors contend bayesian approach sem potentially viable alternative frequentist sem especially studies conducted dynamic conditions apparel retailing â© emerald publishing limited
10.2514/1.T5094 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039730712&doi=10.2514%2f1.T5094&partnerID=40&md5=414907d33e67d941b809a14335bde8fa 1,work investigates sensitivity direct simulation monte carlo input parameters high temperature hypersonic flow scenario computation hypersonic ionizing particles shocks chips direct simulation monte carlo code simulates rarefied hypersonic shock tube experiment air aprevious model improved include species air charged species collisions reactions order model high temperature interactions appropriately chips used simulate nasa electric arc shock tube data peak radiative heating lunar return scenario global monte carlo sensitivity analysis conducted scenario investigate reaction rates greatest effect simulation results sensitivity reaction rate measured calculating square pearson correlation coefficient mutual information certain quantity interest sensitive parameters identified preparation future markov chain monte carlo calibrations electric arc shock tube data copyright â© american institute aeronautics astronautics inc rights reserved
10.1155/2018/5148085 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051326931&doi=10.1155%2f2018%2f5148085&partnerID=40&md5=f05a240ccd29334c01a78a79c62eac23 0,despite wide application floating car data fcd urban link travel time congestion estimation sparsity observations low penetration rate gps equipped floating cars make difficult estimate travel time distribution ttd especially travel times may multimodal distributions associated underlying traffic states case study develops bayesian approach based particle filter framework link ttd estimation using real time historical travel time observations fcd first link travel times classified different traffic states according levels vehicle delays state transition function represented transition probability matrix markov chain upstream current links historical observations using state transition function importance distribution constructed summation historical link ttds conditional states weighted current link state probabilities sampling strategy developed address sparsity problem observations selecting particles larger weights terms importance distribution gaussian likelihood function finally current link ttd reconstructed generic markov chain monte carlo algorithm incorporating high weighted particles proposed approach evaluated using real world fcd results indicate proposed approach provides good accurate estimations close empirical distributions addition approach different percentage floating cars tested results encouraging even multimodal distributions observations exist â© wenwen qin meiping yun
10.1137/17M1151900 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049477025&doi=10.1137%2f17M1151900&partnerID=40&md5=7bd9ff98f5b5b7a5566f5e1095010bb1 0,consider nonlinear filtering problem whereby signal obeys stochastic navierâ€“stokes equations observed linear mapping additive noise setup relevant data assimilation numerical weather prediction climate modeling similar models used unknown ocean wind velocities present particle filtering methodology uses likelihood informed importance proposals adaptive tempering small number appropriate markov chain monte carlo steps provide detailed design steps show numerical examples crucial terms achieving good performance efficiency â© society industrial applied mathematics
10.1137/16M1087667 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053896504&doi=10.1137%2f16M1087667&partnerID=40&md5=26e0523216ed2dfa7eec5d5cea07e2aa 0,rotor router model deterministic process analogous simple random walk graph discrepancy token configurations rotor router model corresponding random walk investigated contexts motivated general markov chains beyond simple random walks paper investigates generalized model imitates markov chain multiple tokens possibly containing irrational transition probabilities concerned vertexwise discrepancy numbers tokens generalized model corresponding markov chain present upper bound discrepancy terms mixing time markov chain â© society industrial applied mathematics
10.1016/j.cja.2017.08.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039935372&doi=10.1016%2fj.cja.2017.08.020&partnerID=40&md5=437000deeb0801fdf6c4c5ed74fb110d 1,paper investigates bayesian methods aerospace system reliability analysis using various sources test data expert knowledge subsystem system levels four scenarios based available information priors test data system subsystems studied using specific bayesian inference techniques paper proposes bayesian melding method integrating subsystem level priors system level priors system subsystem level reliability analysis system subsystem reliability outcomes compared different scenarios computational challenges posterior inferences using sophisticated bayesian melding method addressed using markov chain monte carlo mcmc adaptive sampling importance sampling sir methods case study simulation results illustrates applications proposed methods provides insights aerospace system reliability analysis using available multilevel information â© chinese society aeronautics astronautics
10.1016/j.eng.2018.06.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054458087&doi=10.1016%2fj.eng.2018.06.006&partnerID=40&md5=2360346aca164d960a3aad1d79270559 0,study develops multivariate eco hydrological risk assessment framework based multivariate copula method order evaluate occurrence extreme eco hydrological events xiangxi river within three gorges reservoir tgr area china parameter uncertainties marginal distributions dependence structure quantified markov chain monte carlo mcmc algorithm uncertainties joint return periods evaluated based posterior distributions probabilistic features bivariate multivariate hydrological risk also characterized results show obtained predictive intervals bracketed observations well especially flood duration uncertainty joint return period â€œandâ€� case increases increase return period univariate flood variables furthermore low design discharge high service time may lead high bivariate hydrological risk great uncertainty â© authors
10.1007/978-3-319-99978-4_17 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053603288&doi=10.1007%2f978-3-319-99978-4_17&partnerID=40&md5=c2bda6db5f3d1043f63d94a130db9899 0,bounded rationality investigates utility optimizing decision makers limited information processing power particular information theoretic bounded rationality models formalize resource constraints abstractly terms relative shannon information namely kullback leibler divergence agentsâ€™ prior posterior policy prior posterior lies anytime deliberation process instantiated sample based evaluations utility function markov chain monte carlo mcmc optimization simple model assumes fixed prior relate abstract information theoretic processing costs number sample evaluations however advanced models also address question learning prior adapted time generated prior proposals become efficient work investigate generative neural networks priors optimized concurrently anytime sample based decision making processes mcmc evaluate approach toy examples â© author
10.1016/j.envsoft.2018.03.008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046668997&doi=10.1016%2fj.envsoft.2018.03.008&partnerID=40&md5=f52c576e98ca07d0d6d0fa3ef7c2b1c8 0,studying empirical phenomenon wildfires distinguish occurrence specific location time burnt area measured study proposes using structured additive regression models based zero one inflated beta distribution studying wildfire occurrence burnt area simultaneously beta distribution affords convenient way studying percentage burnt area cases percentages bounded away zero one inflation zeros ones enables observations without wildfires burnt areas treated special cases structured additive regression allows one include variety covariates simultaneously exploring spatial temporal correlations inferences based efficient markov chain monte carlo simulation algorithm utilizing iteratively weighted least squares approximations proposal densities application proposed methodology large wildfire database covering galicia spain provides essential information improved wildfire management â© elsevier ltd
10.1137/15M1021751 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049428905&doi=10.1137%2f15M1021751&partnerID=40&md5=98baeb8ecef2cd678cd3e61067432e45 0,many scientific engineering problems require one perform bayesian inferences function spaces unknowns infinite dimension problems many standard markov chain monte carlo mcmc algorithms become arbitrarily slow mesh refinement referred dimension dependent work develop independence sampler based mcmc method bayesian inferences functions represent proposal distribution mixture finite number specially parametrized gaussian measures also design efficient adaptive algorithm adjust parameter values mixtures previous samples finally provide numerical examples demonstrate efficiency robustness proposed method even problems multimodal posterior distributions â© society industrial applied mathematics
10.1098/rsif.2018.0283 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053038382&doi=10.1098%2frsif.2018.0283&partnerID=40&md5=e74b8b48ba7ab8adc51d626839b72953 0,methods stochastic dynamical systems theory instrumental understanding behaviours chemical reaction networks crns arising natural systems however considerably less attention given inverse problem synthesizing crns specified behaviour important forward engineering biological systems present method generating discrete state stochastic crns functional specifications combines synthesis reactions using satisfiability modulo theories parameter optimization using markov chain monte carlo first identify candidate crns possibility produce correct computations given finite set inputs optimize parameters crn using combination stochastic search techniques applied chemical master equation improve probability correct behaviour rule spurious solutions addition use techniques continuous time markov chain theory analyse expected termination time crn illustrate approach synthesizing crns probabilistically computing majority maximum division producing known previously unknown networks including novel crn probabilistically computing maximum two species future synthesis techniques used automate design engineered biological circuits chemical systems â© authors
10.1007/978-3-030-01234-2_12 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055096002&doi=10.1007%2f978-3-030-01234-2_12&partnerID=40&md5=08d69e089f3629f0a76a95dd621e5f83 0,propose computational framework jointly parse single rgb image reconstruct holistic configuration composed set cad models using stochastic grammar model specifically introduce holistic scene grammar hsg represent scene structure characterizes joint distribution functional geometric space indoor scenes proposed hsg captures three essential often latent dimensions indoor scenes latent human context describing affordance functionality room arrangement ii geometric constraints scene configurations iii physical constraints guarantee physically plausible parsing reconstruction solve joint parsing reconstruction problem analysis synthesis fashion seeking minimize differences input image rendered images generated representation space depth surface normal object segmentation map optimal configuration represented parse graph inferred using markov chain monte carlo mcmc efficiently traverses non differentiable solution space jointly optimizing object localization layout hidden human context experimental results demonstrate proposed algorithm improves generalization ability significantly outperforms prior methods layout estimation object detection holistic scene understanding â© springer nature switzerland ag
10.1002/asmb.2395 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053444779&doi=10.1002%2fasmb.2395&partnerID=40&md5=215ce3861fff93bc6c525c6ab9e0e718 0,study proposes threshold realized generalized autoregressive conditional heteroscedastic garch model jointly models daily returns realized volatility thereby taking account bias asymmetry realized volatility incorporate threshold realized garch model skew student innovations observation equation view model sharp transition model treat realized volatility proxy volatility nonlinear structure bayesian markov chain monte carlo method model jointly estimate parameters return equation volatility equation measurement equation illustration conduct simulation study apply proposed method us japan stock markets based quantile forecasting volatility estimation find threshold heteroskedastic framework realized volatility successfully models asymmetric dynamic structure also investigate predictive ability volatility comparing proposed model traditional garch model well popular asymmetric garch realized garch models threshold realized garch model skew student innovations outperforms competing risk models sample volatility value risk forecasting â© john wiley sons ltd
10.1007/978-3-030-00111-7_7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054484981&doi=10.1007%2f978-3-030-00111-7_7&partnerID=40&md5=6320c794272381e69a9d844dff338693 0,probabilistic parallel multiset rewriting systems ppmrs model probabilistic dynamic systems consisting multiple inter acting agents objects entities multiple individual actions performed parallel main computational challenge approaches computing distribution parallel actions compound actions formulated constraint satisfaction problem csp unfortunately computing partition function distribution exactly infeasible requires enumerate solutions csp subject combinatorial explosion central technical contribution paper efficient markov chain monte carlo mcmc based algorithm approximate partition function thus compound action distribution proposal function works performing backtracking csp search tree sampling solution remaining partially solved csp demonstrate approach lotka volterra system ppmrs semantics exact compound action computation infeasible approach allows perform simulation studies bayesian filtering ppmrs semantics scenarios previously infeasible â© springer nature switzerland ag
10.1016/j.mbs.2017.10.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032966411&doi=10.1016%2fj.mbs.2017.10.005&partnerID=40&md5=34116b1ec50bb668a0fbd9d78ba7edc9 2,efficiency spatial repellents long lasting insecticide treated nets llins key research topic malaria control insecticidal nets reduce mosquito human contact rate simultaneously decrease mosquito populations however llins demonstrate dissimilar efficiency different species malaria mosquitoes various factors proposed explanation including differences insecticide induced mortality flight characteristics persistence attack present discrete agent based approach enables efficiency llins baited traps insecticide residual sprays irs examined model calibrated hut level experimental data compare efficiency protection two mosquito species anopheles gambiae anopheles arabiensis show data allow unambiguous identification details llins alter vector behavior model calibrations quantify overall impact llins two different mosquito species simulations generalized community scale scenarios systematically demonstrate lower efficiency llins control arabiensis compared gambiae â© author
10.1109/TCOMM.2018.2873393 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054519829&doi=10.1109%2fTCOMM.2018.2873393&partnerID=40&md5=afd1fd3afcfdd4f83c7b3fe6d7f967e5 0,random access considered machinetype communication mtc particular random access scheme pool preambles widely studied similar multichannel aloha support number mtc devices paper study optimal approaches user activity detection random access preambles fading channels since computational complexity grows exponentially number preambles low complexity detector derived using markov chain monte carlo mcmc approaches approximately solve optimal maximum posteriori map detection problem resulting mcmc detector enjoy trade performance complexity complexity obtain sample linearly proportional number preambles performance analysis optimal detection also studied see optimal performance simulation results confirm mcmc detector performs better compressive sensing cs based approaches provide near optimal performance certain conditions reasonable computational complexity ieee
10.1007/978-3-319-75996-8_15 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046257506&doi=10.1007%2f978-3-319-75996-8_15&partnerID=40&md5=94aa0c285140dfc4f3a1b15ad5a1a158 0,error scaling markov chain monte carlo mcmc techniques n samples behaves like âˆšn scaling makes often time intensive reduce error calculated observables particular applications dimensional lattice quantum chromodynamics theory interaction quarks gluons even certain cases infamous sign problem appears mcmc methods fail provide results reliable error estimate therefore highly desirable alternative methods hand show improved error scaling potential overcome sign problem one candidate alternative integration technique used based new class polynomially exact integration rules u n su n derived polynomially exact rules spheres applied rules successfully non trivial zero dimensional model sign problem obtained arbitrary precision results article test possible way apply integration rules spheres case one dimensional u model topological rotor already leads problem high dimensionality â© springer international publishing ag part springer nature
10.1137/16M1060625 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044499487&doi=10.1137%2f16M1060625&partnerID=40&md5=4743515692ddc5dc2bb072b3410a8235 0,present randomized maximum posteriori rmap method generating approximate samples posteriors high dimensional bayesian inverse problems governed large scale forward problems derive rmap approach casting problem computing map point stochastic optimization problem interchanging optimization expectation approximating expectation monte carlo method specific randomized data prior mean rmap reduces randomized maximum likelihood rml approach also viewed iterative stochastic newton method analysis convergence rmap samples carried linear nonlinear inverse problems rmap sample requires solution pde constrained optimization problem solve problems employ state art trust region inexact newton conjugate gradient method sensitivity based warm starts approximate metropolization approach presented reduce bias rmap samples various numerical methods presented demonstrate potential rmap approach posterior sampling nonlinear bayesian inverse problems high dimensions â© society industrial applied mathematics
10.1177/1475921716683360 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037730771&doi=10.1177%2f1475921716683360&partnerID=40&md5=6f848427066e1c668d6adc2eea2da3d7 0,crack identification engineering structures widely investigated researchers literature multiple crack identification however focused rather simple structures like beams often assumed number cracks known practical assumption article multiple crack identification frame structures investigated based experimental vibration data using bayesian model class selection swarm based optimization methods identify number cracks characteristics end first numerical model intact frame updated based natural frequencies intact state using particle swarm inspired multi elitist artificial bee colony algorithm updating intact model structure set numerical models cracked frame different numbers cracks constructed since number cracks known priori bayesian model class selection employed find plausible model class order predict number cracks parameters cracks identified using particle swarm inspired multi elitist artificial bee colony algorithm instead pinpointing one optimal solution obtained large number function evaluations set best solutions whose objective values less âˆ’ recorded regions best solutions concentrated identified see solution differ less number function evaluations employed fully assess effectiveness approach numerical experimental examples utilized results confirm effectiveness proposed method identifying multiple cracks frames using experimental natural frequencies structure effect using natural frequencies accuracy location depth cracks also studied â© â© author
10.1007/978-3-030-01449-0_22 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054878308&doi=10.1007%2f978-3-030-01449-0_22&partnerID=40&md5=8d60f7b37cbc9eab36ff2996e422b710 0,automatic object detection widely investigated problem different fields military urban surveillance availability high resolution vhr optical remotely sensed data motivated design new object detection methods allow recognizing small objects like ships buildings vehicles however challenge always remains increasing accuracy speed object detection methods difficult due complex background therefore development robust flexible models analyze remotely sensed data vehicle detection needed propose paper hierarchical bayesian model automatic vehicle detection experiments performed using real data indicate benefit drawn approach â© springer nature switzerland ag
10.1016/j.jqsrt.2017.09.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032487842&doi=10.1016%2fj.jqsrt.2017.09.014&partnerID=40&md5=4f4424910305c8c52e57b67d2a419e1c 2,chord length sampling cls algorithm powerful monte carlo method models effects stochastic media particle transport generating fly material interfaces seen random walkers trajectories annealed disorder approach formally consists solving approximate levermoreâ€“pomraning equations linear particle transport enables considerable speed respect transport quenched disorder ensemble averaging boltzmann equation respect possible realizations needed however cls intrinsically neglects correlations induced spatial disorder accuracy solutions obtained using algorithm must carefully verified respect reference solutions based quenched disorder realizations disorder described markov mixing statistics comparisons attempted far one dimensional geometries rod slab type work extend results markov media two dimensional extruded three dimensional geometries revisiting classical set benchmark configurations originally proposed adams larsen pomraning extended brantley particular examine discrepancies cls reference solutions scalar particle flux transmission reflection coefficients function material properties benchmark specifications system dimensionality â© elsevier ltd
10.1007/978-3-030-00350-0_29 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054066393&doi=10.1007%2f978-3-030-00350-0_29&partnerID=40&md5=b5ed4573a6aaf2649bfa5e9fd3cf4333 0,identification properties land destinations key factors urban planning decisions especially rapid growing urbanized cities information vital cadaster matters property taxes calculations therefore financial sustainability city work present markov monte carlo simulation model predict changes land destinations first markov chain established identify transition finite state matrix property destinations monte carlo simulation model used predict changes present case study city medellã­n colombia using historical information cadaster office results obtained allow identifying urban areas larger number changes moreover results provide support urban planning decisions related workforce sizing visits sequences identified areas â© springer nature switzerland ag
10.1177/0954409718777834 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047664983&doi=10.1177%2f0954409718777834&partnerID=40&md5=2276a254f35d1575d790e74cc3fe1288 0,track related failures major factor contributing train derailments united states therefore determining failure time critical safety purposes traditionally failure time track geometry modeled using defect data however unless accident due extreme events track geometry fails result underlying degradation process first hitting time referred probability distribution time degradation path first reaches safety threshold paper presents formulation implementation first hitting time railway track geometry degradation using track geometry inspection data underlying degradation path modeled wiener process drift first hitting time follows inverse gaussian distribution results provide robust representation failure time track geometry using degradation data â© imeche
10.2991/ijcis.11.1.49 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045665219&doi=10.2991%2fijcis.11.1.49&partnerID=40&md5=5c491f19e99c993b627f89c947f6b8d6 0,rapid booming reviews valid sentiment analysis model significantly boost review recommendation systemâ€™s capability present constructive information consumers topic probabilistic models already shown many advantages detecting potential structure topics sentiments reviews corpus however reviews presented time dependent data streams respects potential structure unfixed time varying topic number word probability distribution paper novel probabilistic topic modelling framework proposed called line evolutionary sentiment topic modeling oestm capacity achieving optimization aforementioned aspects firstly oestm depends improved non parametric bayesian model estimating best number topics perfectly explain current time slice analyzes latent topics sentiment polarities simultaneously secondly oestm implements birth death inheritance detected topics transfer parameters previous time slices updated time slice experiments show significant improvements achieved proposed model respect state art models â© authors
10.6220/joq.201808_25(4).0002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053402518&doi=10.6220%2fjoq.201808_25%284%29.0002&partnerID=40&md5=26a09e81648d90a5ff8d7346e0e0ebd6 0,paper proposed bayesian regression four commonly used priors test bed methodology evaluating empirical modeling techniques method applied evaluate fine tune several popular bayesian regression formulations provides systematic analysis robustness alternative bayesian regression priors based result concluded stochastic search variable selection ssvs relies mixture normal priors gibbs sampling performed better priors handled regression problems bias multicollinearity design moment better methods illustrate proposed methods applied tuned bayesian regression formulation minimize surface roughness wooden plate â© chinese society quality rights reserved
10.1137/16M1087175 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046685956&doi=10.1137%2f16M1087175&partnerID=40&md5=3b7c505bc0b35200a483277ac0b3ab85 1,random graph null models found widespread application diverse research communities analyzing network datasets including social information economic networks well food webs protein protein interactions neuronal networks popular random graph null models called configuration models defined uniform distributions space graphs fixed degree sequence commonly properties empirical network compared properties ensemble graphs configuration model order quantify whether empirical network properties meaningful whether instead common consequence particular degree sequence work study subtle important decisions underlying specification configuration model investigate role choices play graph sampling procedures suite applications place particular emphasis importance specifying appropriate graph labeling stub labeled vertex labeled consider null model choice closely connects study random graphs study random contingency tables show choice graph labeling inconsequential studies simple graphs significant impact analyses multigraphs graphs self loops importance choices demonstrated series three depth vignettes analyzing three different network datasets many different configuration models observing substantial differences study conclusions different models argue case one possible configuration models appropriate work focuses undirected static networks aims guide study directed networks dynamic networks network contexts suitably studied lens random graph null models â© society industrial applied mathematics
10.1007/978-3-319-94211-7_25 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049664044&doi=10.1007%2f978-3-319-94211-7_25&partnerID=40&md5=f6d759ba7fc4e94a79a4ee0ae2ad316c 0,paper focus constructing new flexible powerful parametric framework visual data modeling reconstruction particular propose bayesian density estimation method based upon mixtures scaled dirichlet distributions consideration bayesian learning interesting several respects allows simultaneous parameters estimation model selection permits also taking uncertainty account introducing prior information parameters allows overcoming learning problems related fitting work three key issues related bayesian mixture learning addressed choice prior distributions estimation parameters selection number components moreover principled metropolis within gibbs sampler algorithm scaled dirichlet mixtures developed finally proposed bayesian framework tested challenging real life application namely visual scene reconstruction â© springer international publishing ag part springer nature
10.1007/978-3-319-77249-3_25 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045988218&doi=10.1007%2f978-3-319-77249-3_25&partnerID=40&md5=23b1b68c81d984f1d266b6318a76c494 0,differential item functioning dif occurs individuals different groups level ability different probabilities answering item correctly paper develop bayesian approach detect dif based credible intervals within framework item response theory models method performed well uniform non uniform dif conditions two parameter logistic model efficacy proposed approach demonstrated simulation studies real data application â© springer international publishing ag part springer nature
10.1109/TNSRE.2017.2769701 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033722631&doi=10.1109%2fTNSRE.2017.2769701&partnerID=40&md5=18b0de42fbe290793c29bd68270b7b65 0,improving balance performance among elderly utmost importance increasing number injuries fatalities caused fall incidences digital games controlled body movements exergames proposed way improve balance among older people however assessment balance performance real time exergaming remains challenging task assessment used provide instantaneous feedback automatically adjust exergame difficulty features potentially increase motivation player thus augmenting effectiveness exergames clear differences balance performance identified older younger people distinguishing older younger adults help identifying measures balance performance used generalized linear models investigate whether assessment balance performance based movement speed improved incorporating curvature movement trajectory analysis indeed results indicated curvature improves performance models five fold cross validation indicated method promising assessment balance performance real time showing classification accuracy finally method valuable exergaming also real time assessment body movements sports rehabilitation medicine â© ieee
10.1002/asmb.2410 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053731638&doi=10.1002%2fasmb.2410&partnerID=40&md5=489b64d82cdac711e3de91a034bb4dd2 0,paper proposes efficient estimation method elliptical copula regression models expressing copula density marginal density functions scale mixtures normals smn implementing models using smn novel allows efficient estimation via bayesian methods innovative algorithm case complex semicontinuous margins also presented utilize facts copulas invariant location scale margins elliptical distributions correlation structure densities represented smn two simulation studies one continuous margins semicontinuous margins highlight favorable performance proposed methods two empirical studies one us excess returns one thai wage earnings illustrate applicability proposals â© john wiley sons ltd
10.1093/gji/ggx428 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042152317&doi=10.1093%2fgji%2fggx428&partnerID=40&md5=9264b98d41ae6a0213be8ddbf3750df5 1,limited illumination insufficient offset noisy data poor starting models pose challenges seismic full waveform inversion present application tree based bayesian inversion scheme attempts mitigate problems accounting data uncertainty using mildly informative prior subsurface structure sample resulting posterior model distribution compressional velocity using trans dimensional trans reversible jump markov chain monte carlo method wavelet transform domain velocity allows us attain rapid convergence stationary distribution posterior models requiring limited number wavelet coefficients define sampled model two synthetic low frequency noisy data examples provided first example simple reflection + transmission inverse problem second uses scaled version marmousi velocity model dominated reflections examples initially started semi infinite half space incorrect background velocity find trans tree based approach together parallel tempering navigating rugged likelihood e misfit topography provides promising easily generalized method solving large scale geophysical inverse problems difficult optimize true model contains hierarchy features multiple scales â© authors published oxford university press behalf royal astronomical society
10.1002/2017WR022148 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040987952&doi=10.1002%2f2017WR022148&partnerID=40&md5=bed897d409d8c77b28ecb869b1c613c2 0,probabilistic inversion within multiple point statistics framework often computationally prohibitive high dimensional problems partly address introduce evaluate new training image based inversion approach complex geologic media approach relies deep neural network generative adversarial network gan type training using training image ti proposed spatial gan sgan quickly generate unconditional realizations key characteristic sgan defines low dimensional parameterization thereby allowing efficient probabilistic inversion using state art markov chain monte carlo mcmc methods addition available direct conditioning data incorporated within inversion several categorical tis first used analyze performance sgan unconditional geostatistical simulation training deep network take several hours training realizations containing millions pixels voxels produced matter seconds makes especially useful simulating many thousands realizations e g mcmc inversion relative cost training per realization diminishes considered number realizations synthetic inversion case studies involving steady state flow transient hydraulic tomography without direct conditioning data used illustrate effectiveness proposed sgan based inversion case inversion rapidly explores posterior model distribution case inversion recovers model realizations fit data close target level visually resemble true model well â© american geophysical union rights reserved
10.1175/JTECH-D-17-0116.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041682127&doi=10.1175%2fJTECH-D-17-0116.1&partnerID=40&md5=b4a134cd16d2442d26ee616d50d71db9 0,study focuses merging modis mapped ssts km spatial resolution amsr e optimally interpolated ssts km resolution new data fusion method developed spatiotemporal hierarchical bayesian model sthbm method implemented markov chain monte carlo technique utilized extract inferential results specified hierarchically decomposing sst spatiotemporal process three subprocesses spatial trend process seasonal cycle process spatiotemporal random effect process spatial scale transformation spatiotemporal variation introduced fusion model data model model parameters respectively suitably selected link functions compared two modern spatiotemporal statistical methods bayesian maximum entropy robust fixed rank kriging sthbm following strength simultaneously meet expression uncertainties data model seamless scale transformation sst spatiotemporal process simulation utilizing multisensors complementation merged data complete spatial coverage high resolution km fine spatial pattern lying modis ssts obtained sthbm merged data assessed local spatial structure overall accuracy local accuracy evaluation results illustrate sthbm provide spatially complete sst fields reasonably good data values acceptable errors merged ssts collect fine spatial patterns lying modis ssts fine resolution accuracy merged ssts modis amsr e ssts contribution accuracy spatial pattern merged ssts original modis ssts stronger original amsr e ssts â© american meteorological society
10.1016/j.jhydrol.2017.07.040 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034116066&doi=10.1016%2fj.jhydrol.2017.07.040&partnerID=40&md5=704a0558298774d368c643676e81ea13 1,recent studies identified importance vegetation processes terrestrial hydrologic systems process based ecohydrological models combine hydrological physical biochemical ecological processes catchments generally complex parametric conceptual hydrological models thus appropriate calibration objectives model uncertainty analysis essential ecohydrological modeling recent years bayesian inference become one popular tools quantifying uncertainties hydrological modeling development markov chain monte carlo mcmc techniques bayesian approach offers appealing alternative traditional multi objective hydrologic model calibrations defining proper prior distributions considered analogous ad hoc weighting often prescribed multi objective calibration study aims develop appropriate prior distributions likelihood functions minimize model uncertainties bias within bayesian ecohydrological modeling framework based traditional pareto based model calibration technique study pareto based multi objective optimization formal bayesian framework implemented conceptual ecohydrological model combines hydrological model hymod modified bucket grassland model bgm simulations focused one objective streamflow lai multiple objectives streamflow lai different emphasis defined via prior distribution model error parameters results show reliable outputs predicted streamflow lai using bayesian multi objective calibration specified prior distributions error parameters based results pareto front ecohydrological modeling methodology implemented provides insight usefulness multiobjective bayesian calibration ecohydrologic systems importance appropriate prior distributions approaches â© elsevier b v
10.1016/j.neuroimage.2017.08.077 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038077897&doi=10.1016%2fj.neuroimage.2017.08.077&partnerID=40&md5=d325cb913446b80dd2622052b9822316 2,previous attempts characterizing spatial specificity blood oxygenation level dependent functional mri bold fmri response estimating point spread function psf conventionally relied retinotopic spatial representations visual stimuli area v consequently estimates confounded width scatter receptive fields v neurons circumvent limits instead using inherent cortical spatial organization ocular dominance columns odcs determine psf gradient echo ge spin echo se bold imaging tesla applying markov chain monte carlo sampling probabilistic generative model imaging odcs quantified psfs best predict spatial structure magnitude differential odcsâ€™ responses prior distributions odc model parameters determined analyzing published data cytochrome oxidase patterns post mortem histology human v neurophysiological ocular dominance indices average psf full widths half maximum obtained differential odcsâ€™ responses following removal voxels influenced contributions macroscopic blood vessels mm se mm ge results provide quantitative basis spatial specificity bold fmri ultra high fields used planning interpretation high resolution differential fmri fine scale cortical organizations â©
10.1016/j.sigpro.2017.07.030 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026450257&doi=10.1016%2fj.sigpro.2017.07.030&partnerID=40&md5=a526611c768c07cc7971f17135754b47 2,bayesian estimation unknown parameters state space dynamical systems received considerable attention past decade handful powerful algorithms introduced paper tackle theoretical analysis recently proposed nonlinear population monte carlo npmc iterative importance sampling scheme whose key features compared conventional importance samplers approximate computation importance weights iws assigned monte carlo samples ii nonlinear transformation iws order prevent degeneracy problem flaws performance conventional importance samplers contribution present paper rigorous proof convergence nonlinear nis scheme number monte carlo samples increases analysis reveals nis approximation errors converge almost surely optimal monte carlo rate mâˆ’ moreover prove achieved even mean estimation error iws remains constant property termed exact approximation markov chain monte carlo literature illustrate theoretical results means computer simulation example involving estimation parameters state space model typically used target tracking â© elsevier b v
10.1364/JOSAA.35.000088 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041720471&doi=10.1364%2fJOSAA.35.000088&partnerID=40&md5=239062c345dee1676a6a89cd4e4bb1cf 1,characterization nanoparticle aggregates observed scattered light leads highly complex inverse problem even forward model complex prohibits use classical likelihood based inference methods study compare four called likelihood free methods based approximate bayesian computation abc requires numeric simulation forward model without need evaluating likelihood particular rejection markov chain monte carlo population monte carlo adaptive population monte carlo apmc compared terms accuracy current model assume nanoparticle aggregates mutually well separated made particles size filippov particle cluster algorithm used generate aggregates discrete dipole approximation used estimate scattering behavior found apmc algorithm superior others terms time acceptance rates although algorithms produce similar posterior distributions using abc techniques utilizing unpolarized light experiments nm wavelength characterization soot aggregates performed less nm deviation nanoparticle radius deviation number nanoparticles forming monodisperse aggregates promising results also observed polydisperse aggregate log normal particle size distribution â© optical society america
10.1190/GEO2017-0009.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037056636&doi=10.1190%2fGEO2017-0009.1&partnerID=40&md5=2834d110fc88de93d4962b694fd99dbc 2,principle equivalence known cause nonuniqueness interpretations direct current dc resistivity data low high resistivity equivalences arise thin geologic layer low high resistivity embedded relative high low resistivity background formation causing strong resistivity thickness correlations equivalences often make impossible resolve embedded layers found equivalence problem significantly reduced combining dc data full decay time domain induced polarization ip measurements applied markov chain monte carlo algorithm invert synthetic dc data models low high resistivity equivalences applying inversion method possible study space equivalent models acceptable fit observed data make full sensitivity analysis model parameters include contrast chargeability model modeled terms spectral cole cole ip parameters invert dc ip data combination results show addition ip data largely resolves dc equivalences furthermore present field example dc ip data measured sand formation embedded clay layer known borehole drilling inversion results show dc data alone resolve clay layer due equivalence problems adding ip data inversion layer resolved â© society exploration geophysicists rights reserved
10.1007/978-3-319-69814-4_43 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034615923&doi=10.1007%2f978-3-319-69814-4_43&partnerID=40&md5=4763843bed5e6c9d7dd9305720daa1cb 0,recently refined markov chain monte carlo techniques bayesian inference combined elegant computationally advantageous specification state space models develop evaluate approach clustering time series fixed income financial instruments approach based upon specification estimation finite mixture model mixture component represented time series generative model specified linear state space form â© springer international publishing ag
10.1016/j.ultras.2017.09.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029480823&doi=10.1016%2fj.ultras.2017.09.002&partnerID=40&md5=fe6c5baa94ec44a06e160f06c99cdd06 1,ultrasonic damage detection characterization commonly used nondestructive evaluation nde aerospace composite components recent years increased development guided wave based methods real materials structures dispersive waves result complicated behavior presence complex damage scenarios model based characterization methods utilize accurate three dimensional finite element models fems guided wave interaction realistic damage scenarios aid defect identification classification work describes inverse solution realistic composite damage characterization comparing wavenumber frequency spectra experimental simulated ultrasonic inspections composite laminate material properties first verified bayesian solution markov chain monte carlo enabling uncertainty quantification surrounding characterization study undertaken assess efficacy proposed damage model comparative metrics experimental simulated output fem parameterized damage model capable describing typical complex damage created impact events composites damage characterized transdimensional markov chain monte carlo solution enabling flexible damage model capable adapting complex damage geometry investigated posterior probability distributions individual delamination petals well overall envelope damage site determined â© elsevier b v
10.1016/j.csda.2017.07.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028697379&doi=10.1016%2fj.csda.2017.07.009&partnerID=40&md5=afadc0259858681e323702c3d3a06088 3,novel distributed particle filter algorithm presented called drift homotopy likelihood bridging particle filter dhlb pf dhlb pf designed surmount degeneracy problem employing multilevel markov chain monte carlo mcmc procedure resampling step particle filtering dhlb pf considers sequence pertinent stationary distributions facilitates mcmc step well explores state space higher degree freedom proposed algorithm tested multi target tracking problem using wireless sensor network fusion center required data processing observations gathered informative sensors sensing useful observations nearby moving targets detection informative sensors typically small portion sensor network taking place using sparsity aware matrix decomposition technique simulation results showcase dhlb pf outperforms current popular tracking algorithms â© elsevier b v
10.1080/17415977.2018.1516767 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053273598&doi=10.1080%2f17415977.2018.1516767&partnerID=40&md5=cb9b692e574bec5813acad0cc2864eb9 0,non invasive monitoring tissuesâ€™ temperatures necessary diagnostic therapeutic applications photoacoustic new hybrid biomedical imaging technique combining high contrast optical properties high spatial resolution ultrasound estimation model parameters temperature dependent used work indirectly measure temperatures tissues solution inverse problem within bayesian framework statistics two dimensional case examined related hyperthermia treatment cancer laser heating near infrared range simulated measurements used inverse analysis markov chain monte carlo method provided accurate estimation spatial distribution gruneisen parameter temperature distribution region interest recovered discrepancies smaller â°c â© â© informa uk limited trading taylor francis group
10.1016/j.ifacol.2018.09.205 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054391788&doi=10.1016%2fj.ifacol.2018.09.205&partnerID=40&md5=57af4530d6501dae1467bd12daa5d24a 0,identification static parameters jump markov nonlinear models jmnms poses key challenge explaining nonlinear abruptly changing behavior dynamical systems paper introduces stochastic approximation expectation maximization algorithm facilitate offline maximum likelihood parameter estimation jmnms method relies construction particle gibbs kernel takes advantage inherent structure model increase efficiency rao blackwellization numerical examples illustrate proposed solution outperforms related approaches â©
10.1002/wics.1452 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053215779&doi=10.1002%2fwics.1452&partnerID=40&md5=40211a74347415ca7f147a5d7ed1e82e 0,algorithms computing nonparametric maximum likelihood estimate univariate log concave density briefly described relevant issues discussed fast algorithms numerically compared small scale simulation study article categorized statistical graphical methods data analysis markov chain monte carlo mcmc statistical graphical methods data analysis density estimation statistical graphical methods data analysis nonparametric methods algorithms computational methods algorithms â© wiley periodicals inc
779.869537940662 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048311195&partnerID=40&md5=778bd3267b9af167374d5eecc9188a3b 0,many systems including space satellites graded repaired easily missions simulation based design techniques often used check conditions induce critical malfunctions ensure sufficient credibility reliability operation however critical conditions low probability occurring e g per trial rarely appear within tractable number simulations propose herein multicanonical markov chain monte carlo mcmc technique extended efficient search rare critical conditions significantly enhance simulation efficiency furthermore demonstrate application proposed technique efficient search stray light space telescope satellite â© siam
295.067901652055 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054244591&partnerID=40&md5=02217d03c9e91443aed8e6be370bf8c3 0,online word mouth wom important aspect consumer firm relationship leading indicator product performance however prior research focuses considerably static view online wom paper attempts explicate dynamics spillover effects online wom u automobile industry employed bayesian approach using markov chain monte carlo mcmc methods model estimation results suggest pressing need extending dynamic view online wom examining spillover effects â© association information systems rights reserved
10.1016/j.petrol.2017.10.055 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033498685&doi=10.1016%2fj.petrol.2017.10.055&partnerID=40&md5=15d846784ec1e1238ea89ca2090486aa 1,study established efficient approach fractured shale reservoir modeling emphasis simplifying automating workflow assisted history matching uncertainty quantification improvement especially notable process history matching since fracture geometry properties directly set parameters history matched resultant approach shows significant reduction computational time maintaining model accuracy also provides automatic method modifying fracture related parameters laborious process traditional workflow forward reservoir model implemented extended embedded discrete fracture model embedded dfm approach fractures arbitrary strike dip angle multiple porosity permeability setting fractures naturally discretized boundary parent matrix grid blocks control volumes fracture segments generated according specific geometry segments three types non neighbor connections generated namely connection fracture segment parent matrix grid blocks connection two intersecting fracture segments different fractures connection two neighbor fracture segments fracture non neighbor connections transmissibility calculated honoring physics flow approach embedded discrete fracture multiple porosity model matrix sub divided three porosity types namely organic matrix kerogen inorganic matrix natural fractures necessary physics included porosity types macro fractures explicitly represented embedded dfm proposed model provides coherent method characterizing organic matrix inorganic matrix micro fractures well hydraulic fractures shale reservoirs offers computationally efficient approach modeling severe heterogeneity due hydraulic natural fractures compared traditional discrete fracture models fewer grid blocks lower levels refinement required compared multiple porosity method proposed model desirable accuracy simulation reservoirs large scale fractures history matching uncertainty quantification stage due low efficiency traditional markov chain monte carlo mcmc method applied reservoir history matching advanced algorithm two stage mcmc employed evaluate uncertainty parameters since upscaling fracture related parameters required reservoir model generated pre processor based proposed parameter maintains adequacy gaussian distribution assumption therefore workflow completely automated incorporating embedded dfm multiple porosity permeability approaches improved model facilitates history matching fractured shale reservoirs cutting total amount grid blocks reducing complexity gridding process well improving accuracy fluid transportation within among different porosity types â©
10.1016/j.cviu.2018.07.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053720331&doi=10.1016%2fj.cviu.2018.07.001&partnerID=40&md5=c379241e9a4b2912abad1c71b9ccd7c0 0,paper approaches problem geometric multi model fitting data segmentation problem proposed solution based sequence sampling hyperedges hypergraph model selection hypergraph clustering steps developed sampling method significantly facilitates solving segmentation problem using new form markov chain monte carlo mcmc method effectively sample hyperedge distribution sample distribution effectively proposed markov chain includes new ways long short jumps perform exploration exploitation structures enhance quality samples greedy algorithm used exploit nearby structure based minimization least kth order statistics cost function unlike common sampling methods require specific prior knowledge distribution models output set samples leads clustering solution final model parameters segment obtained method competes favorably state art terms computation power segmentation accuracy â©
10.12011/1000-6788(2018)01-0164-13 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046818325&doi=10.12011%2f1000-6788%282018%2901-0164-13&partnerID=40&md5=899a48dbbae066b33c6ace4a21774ccd 0,random turnover r staff influences new product r project portfolio scheduling using discrete markov chain describe staff turnover processes multi skilled r staff scheduling object proposed stochastic multi objective constraint optimization model new product r project portfolio scheduling specifically three objectives strategic gains talent cultivation r cycle r costs proposed model solved adaptive pareto sampling algorithm utilizes sampling method markov chain monte carlo calculate objective values deterministic model serial schedule generation scheme obtain pareto set nondominated sorting genetic algorithmii multi objective expected value model model algorithm tested real world case staff scheduling new electric energy saving product r project portfolio chinese company since algorithm converged well obtained pareto set effectively results indicated stochastic model suitable reflect company reality deterministic model practically enterprises use model algorithm make effective decision multi skilled staff scheduling scheme new product r project portfolio stochastic turnover scenario â© editorial board journal systems engineering society china right reserved
10.1016/j.proci.2018.06.190 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050754171&doi=10.1016%2fj.proci.2018.06.190&partnerID=40&md5=29bfd1e0e29ecc098e16ad3028fc1879 0,procedure determining joint uncertainty arrhenius parameters across multiple combustion reactions interest demonstrated approach capable constructing joint distribution arrhenius parameters arising uncertain measurements performed specific target experiments without direct access underlying experimental data method involves constructing ensemble hypothetical data sets summary statistics consistent available information reported experimentalists followed fitting procedure learns structure joint parameter density across reactions using consistent hypothetical data evidence procedure formalized bayesian statistical framework employing maximum entropy approximate bayesian computation methods utilizing efficient markov chain monte carlo techniques explore data parameter spaces nested algorithm demonstrate application method context experiments designed measure rates selected chain reactions h system highlight utility approach revealing critical correlations parameters within single reaction across reactions well maximizing consistency utilizing rate parameter information predictive combustion modeling systems interest â© combustion institute
10.1007/978-3-319-73441-5_26 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041746321&doi=10.1007%2f978-3-319-73441-5_26&partnerID=40&md5=410a00a6a6a5cd6dc9fb850312afa3d5 0,paper focuses minimizing communications monte carlo methods linear algebra thus improving overall performance focus producing set small number covering markov chains much longer usually produced ones approach allows efficient communication pattern enables transmit sampled portion matrix parallel case approach applied quasi monte carlo comparison efficiency new approach case sparse approximate matrix inversion hybrid monte carlo quasi monte carlo methods solving systems linear algebraic equations carried experimental results showing efficiency approach set test matrices presented numerical experiments executed marenostrum iii supercomputer barcelona supercomputing center bsc avitohol supercomputer institute information communication technologies iict â© springer international publishing ag
848.4230176312947 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054570352&partnerID=40&md5=62c509c84769c628de25a1fb48e1c9aa 0,present methodology obtain correct sampling posterior probability density function pdf conditional observations posterior pdf formally expressed using bayes theorem generating correct sampling multimodal posterior pdf challenging task achieved markov chain monte carlo mcmc methods standard mcmc random walk mcmc evaluation acceptance probability proposed state requires forward model run reservoir simulation run forward model run computationally expensive afford generate long markov chains tens thousands states therefore critically important design mcmc converges posterior pdf generating thousand less states two level mcmc procedure sample multimodal posteriors relatively efficiently developed applied first step use distributed gauss newton dgn method generate many modes posterior pdf parallel procedure estimates sensitivity matrices without need adjoint solution gaussian mixture model gmm constructed based distinct modes find first step second step constructed gmm used proposal distribution mcmc algorithm proposal distribution constructed direct approximation target pdf without normalizing constant markov chain constructed converge relatively quickly posterior distribution applications two level mcmc algorithm test problems show proposed two level mcmc far efficient random walk mcmc â© european association geoscientists engineers eage rights reserved
10.1007/978-3-319-91143-4_12 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050315489&doi=10.1007%2f978-3-319-91143-4_12&partnerID=40&md5=907d258e94e308ac53026e3f4198e5cb 0,recent years many statistical inference problems solved using markov chain monte carlo mcmc techniques however necessary derivate analytical form likelihood function although level computing increased steadily limitation caused difficulty misunderstanding computing likelihood function approximate bayesian computation abc method dispenses use likelihood function simulating candidates posterior distributions using algorithm accept reject proposed candidates work presents alternative nonparametric estimation method smoothing empirical distributions random bernstein polynomials via abc method bernstein prior obtained rewriting bernstein polynomial terms k mixtures mixtures beta densities mixing weights study simulation real example presented illustrate method proposed â© springer international publishing ag part springer nature
10.1016/j.radmeas.2017.10.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038883443&doi=10.1016%2fj.radmeas.2017.10.007&partnerID=40&md5=1b94d4a0a1878e1dead78fa93db63c4e 2,optically stimulated luminescence osl commonly used date last exposure grains extracted sediments sunlight however frequent measured grains sufficiently exposed light burial samples said poorly bleached propose new statistical model based bayesian approach analyse osl measurements performed poorly bleached sediment samples data propose mixture model gaussian distributions analyse equivalent doses de distributions model either applied directly observed de values log transformation bayesian analysis requires numerical approximation use jags another gibbs sampler programme run models using markov chain monte carlo simulations apply model synthetic datasets real samples â©
10.1016/j.jsg.2018.05.026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047982819&doi=10.1016%2fj.jsg.2018.05.026&partnerID=40&md5=93d9458ce451034a98c7f48b52bb6b07 1,despite implementation several kinematic mechanical models fault related folding incorporation structural uncertainty geological models structural modeling still deterministic current focus forward modeling unique fit show application trishear inverse modeling global optimization markov chain monte carlo mcmc methods clay model basement involved compressional faulting know total incremental deformation global optimization mcmc methods provide range possible models rather unique fit total inversions give average model deformation incremental inversions physically related model evolution global optimization identifies full range possible models mcmc characterizes expected parameter values uncertainties structural inversions without sound geology meaningless robust stratigraphy geomorphic markers mesoscopic structures analogue mechanical modeling greatly improve inversions â© elsevier ltd
10.1007/978-981-10-7989-4_35 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045317537&doi=10.1007%2f978-981-10-7989-4_35&partnerID=40&md5=2add9d54cec8b31030c68ea78375745c 0,paper presents bayesian mcmc model assess collector shoes slider degradation different materials markov chain monte carlo mcmc method based bayesian decision model put forward built framework case life cycle collector shoes different materials forecast inspection data gathered beijing metro lines winbugs software used predict sliderâ€™s wear rate result shows difference predicted value real one less later one consequently case new metro equipment parts newest method able ensure safety operation metro providing valid device equipment manufacturers maintenance department well purchasing department metro equipment â© springer nature singapore pte ltd
368.5570519965244 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050470798&partnerID=40&md5=c207afa75abe68c5825c875ad3f41e28 0,study investigates factors significantly contribute pedestrians red light running violation signalized intersections data collected eight crosswalks located two signalized intersections nanjing china random parameters logistic regression developed explore potential unobserved heterogeneous effects across observations markov chain monte carlo mcmc simulation based full bayesian approach employed estimate model parameters parameter estimates odds ratio developed used interpret model estimation results show contributing factors significantly influence pedestrians red light running behavior though differ across observations modeling results show age gender group size cell phone use pedestrian signal type pedestrian volume pedestrian signal green ratio statistically significant model variables gender pedestrian signal type pedestrian volume found heterogeneous effects appearing form random parameters statistical model â© american society civil engineers
10.1117/12.2293772 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047847289&doi=10.1117%2f12.2293772&partnerID=40&md5=cbd46280fd91a424db37252c8f6bff18 0,advocated task based measures image quality iq employed evaluate optimize imaging systems task based measures iq quantify performance observer medically relevant task bayesian ideal observer io employs complete statistical information object noise achieves upper limit performance binary signal classification task however computing io performance generally analytically intractable computationally burdensome markov chain monte carlo mcmc techniques employed paper supervised learning convolutional neural networks cnns employed approximate io test statistics signal known exactly background known exactly ske bke binary detection task receiver operating characteristic roc curve area roc curve auc compared produced analytically computed io advantages proposed supervised learning approach approximating io demonstrated â© spie
10.7498/aps.67.20172246 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046884481&doi=10.7498%2faps.67.20172246&partnerID=40&md5=998d4d197bd21c254e9e86075accf9b8 0,relationship sequential structural features intrinsically disordered peptides idps attracted much attention recent decade one essential problem relating sequence structure relationship distribution charged residues affects structure idp work address problem simulations series random peptides composed arginine aspartic acids absinth implicit solvation model structural ensembles generated markov chain monte carlo method replica exchange sampling relations various structural features including gyration radius tail distance distance residues asphericity distribution charged residues analyzed several limit cases parts interactions switched also calculated comparison conversion extended conformations compact structures observed following demixing negatively positively charged residues along sequence cases well mixed charges intra chain electrostatic repulsions attractions balanced results generic flory random coil like conformation differently case well separated charged residues electrostatic attraction residues distant along sequence induces semi compact hairpin like conformation consistent observations pappu group results suggest structural dependence charge distribution sensitive selection amino acid determined patterns charges demonstrates robustness mechanism charge distribution modulates structural features idp system results may broaden understanding sequence structure relation idp system â© chinese physical society
10.1007/978-3-319-59315-9_7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034233721&doi=10.1007%2f978-3-319-59315-9_7&partnerID=40&md5=ac8c340e0fe32434d939d37dcd3f1dbe 0,since advent space based photometric missions corot nasaâ€™s kepler asteroseismology acquired central role understanding stellar physics kepler spacecraft especially still releasing excellent photometric observations contain large amount information yet investigated exploiting full potential data sophisticated robust analysis tools essential constraining stellar structure evolutionary models obtained addition extracting detailed asteroseismic properties many stars yield new insights correlations fundamental stellar properties dynamics brief introduction bayesian notion probability describe code diamonds bayesian parameter estimation model comparison means nested sampling monte carlo nsmc algorithm nsmc constitutes efficient powerful method replacement standard markov chain monte carlo suitable high dimensional multimodal problems typical detailed asteroseismic analyses fitting mode identification individual oscillation modes stars known peak bagging diamonds able provide robust results statistical inferences involving tens individual oscillation modes time preserving considerable computational efficiency identifying solution tutorial present fitting stellar background signal peak bagging analysis oscillation modes red giant star providing example use bayesian evidence assessing peak significance fitted oscillation peaks â© springer international publishing ag
10.1016/j.asr.2017.12.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038836362&doi=10.1016%2fj.asr.2017.12.009&partnerID=40&md5=1fa827a43a3b80fd590ef305be5cfa7a 0,model regular irregular variation ionospheric total electron content stationary non stationary processes respectively apply method developed scinda gps data set observed bahir dar ethiopia â°n â°e use hierarchical bayesian inversion gaussian markov random process priors model prior parameters hyperprior use matã©rn priors via stochastic partial differential equations use scaled inv ï‡ hyperpriors hyperparameters drawing posterior estimates use markov chain monte carlo methods gibbs sampling metropolis within gibbs parameter hyperparameter estimations respectively allows us quantify model parameter estimation uncertainties well demonstrate applicability method proposed using synthetic test case finally apply method real gps data set decompose regular irregular variation components result shows approach used accurate ionospheric disturbance characterization technique quantifies total electron content variability corresponding error uncertainties â© cospar
10.1007/978-3-319-73441-5_30 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041710703&doi=10.1007%2f978-3-319-73441-5_30&partnerID=40&md5=3005789f806e8fbc7c7f4a65e7291735 0,consider diffusion problems partially reflecting boundaries formulated terms elliptic equation solve boundary value problems robin condition propose monte carlo method based randomization integral representation algorithm behaviour analysed application solving model problem â© springer international publishing ag
10.1002/asmb.2232 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013392773&doi=10.1002%2fasmb.2232&partnerID=40&md5=52409fd7f24dea965f5a1862ad5f549a 0,article describes statistical analyses pertaining marketing data large multinational pharmaceutical firm describe models monthly new prescription counts written physicians firm focal drug competing drugs functions physician specific time varying predictors modeling patterns discrete valued time series specifically time series counts based large datasets focus much recent research attention first provide brief overview bayesian approaches employed modeling multivariate count time series using markov chain monte carlo methods discuss flexible level correlated model framework enables us combine different marginal count distributions build hierarchical model vector time series counts accounting association among components response vector well possible overdispersion employ integrated nested laplace approximation inla fast approximate bayesian modeling using r inla package r inla org enhance computational speed first build model physician use features estimated trends time varying parameters order cluster physicians groups fit aggregate models physicians within cluster three stage analysis provide useful guidance pharmaceutical firm marketing actions copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1007/978-3-319-91947-8_18 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048050201&doi=10.1007%2f978-3-319-91947-8_18&partnerID=40&md5=d32536d687ca8eff9713fe3807bd622e 1,template based information extraction generalizes standard token level binary relation extraction sense attempts fill complex template comprising multiple slots basis information given text approach presented paper templates possible fillers defined given ontology information extraction task consists filling slots within template previously recognized entities literal values cast task structure prediction problem propose joint probabilistic model based factor graphs account interdependence slot assignments inference implemented heuristic building markov chain monte carlo sampling main contribution investigate impact soft constraints modeled single slot factors measure preferences individual slots ranges fillers well pairwise slot factors modeling compatibility fillers two slots instead relying expert knowledge acquire soft constraints approach directly captured model learned training data show types factors effective improving information extraction real world data set full text papers biomedical domain pairwise factors shown particularly improve performance extraction model + points precision leading f score individual templates â© springer international publishing ag part springer nature
10.1117/12.2309466 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046436250&doi=10.1117%2f12.2309466&partnerID=40&md5=2834ef760661170a6cd631cb81d00c79 0,machine vision typical heuristic methods extract parameterized objects raw data points hough transform ransac bayesian models carry promise optimally extract parameterized objects given correct definition model type noise hand category solvers bayesian models markov chain monte carlo methods naive implementations mcmc methods suffer slow convergence machine vision due complexity parameter space towards blocked gibbs split merge samplers developed assign multiple data points clusters paper introduce new split merge sampler triadic split merge sampler perform steps two three randomly chosen clusters two advantages first reduces asymmetry split merge steps second able propose new cluster composed data points two different clusters advantages speed convergence demonstrate line extraction problem show triadic split merge sampler outperforms conventional split merge sampler although new mcmc sampler demonstrated machine vision context application extend general domain statistical inference â© copyright spie
10.1111/risa.12988 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044323201&doi=10.1111%2frisa.12988&partnerID=40&md5=1b8b46a381cf423708c076ea5bb56e53 0,harbor seals iliamna lake alaska small isolated population one two freshwater populations harbor seals world yet little known abundance risk extinction bayesian hierarchical models used estimate abundance trend population observational models developed aerial survey harvest data included effects time year time day survey counts underlying models abundance trend based leslie matrix model used prior information vital rates literature developed three scenarios variability priors used part sensitivity analysis models fitted using markov chain monte carlo methods population production rate implied vital rate estimates per year similar average annual harvest rate period growth population appears relatively stable around individuals population viability analysis assessing risk quasi extinction defined reduction animals next years ranged depending prior scenario although moderately low risk include genetic catastrophic environmental events may occurred population past results applied cautiously â© society risk analysis
10.3788/OPE.20182601.0161 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044670447&doi=10.3788%2fOPE.20182601.0161&partnerID=40&md5=47bc4cf9f53bad53b2a3fee0355b6f12 0,decompose asymmetric full waveform lidar data unknown number components full waveform lidar decomposition method proposed based skew normal distribution reversible jump markov chain monte carlo rjmcmc algorithm automatically determine numbers components first energy function used describe differences actual waveform ideal waveform obeyed skew normal distribution likelihood function defined gibbs distribution second parameter models ideal waveform established using prior distribution bayesian paradigm followed build ideal waveform model third rjmcmc algorithm designed determine numbers components decompose waveform proposed algorithm used decompose icesat glas waveform data various typical regions experimental results indicate cross correlation true data result proposed method fit skewed waveform data normal waveform data also accurately determine number components comparison methods realize accurate decomposition full waveform lidar data decomposition result consistent corresponding elevation information â© science press right reserved
10.1002/qre.2409 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055116954&doi=10.1002%2fqre.2409&partnerID=40&md5=56289270a400caa3dceb0a08a233a6fb 0,consider change point detection estimation sequences functional observations setting often arises quality process characterized observations called profiles monitoring profiles changes structure used ensure stability process time interest phase ii profile monitoring grown methods approach problem bayesian perspective propose wavelet based bayesian methodology bases inference posterior distribution change point without placing restrictive assumptions form profiles obtaining analytic form posterior distribution allow proposed method run online without using markov chain monte carlo mcmc approximation wavelets effective tool estimating nonlinear signals noise contaminated observations enable us flexibly distinguish sustained changes profiles inherent variability process analyze observed profiles wavelet domain consider two possible prior distributions coefficients corresponding unknown change sequence priors previously applied nonparametric regression setting yield tuning free choices hyperparameters present additional considerations controlling computational complexity time effects performance proposed method significantly outperforms relevant frequentist competitor simulated data â© john wiley sons ltd
10.1117/12.2320450 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053888142&doi=10.1117%2f12.2320450&partnerID=40&md5=eba1cef4d32cee9c9839dfcb8c90ec26 0,night target tracking usually fails due various reasons insufficient light appearance change motion blur illumination variation deformation infrared ir visible video data provides comple mentary information utilized suitably efficiently explore novel framework combining correlation filter based visible tracking markov chain monte carlo mcmc based ir tracking overcome challenges framework two types videos asynchronous frame rate visible video several times faster ir video visible video first used location scale estimation solving ridge regression problem efficiently correlation filter domain recording ir data use uniquely designed feature shape context descriptor best location scale estimation ir video target using mcmc particle filter use candidate region location scale fusion rules final target tracking update meanwhile build accurately labeled ir visible target tracking dataset experiments result shows performance proposed approach better state art trackers night target tracking approach significantly improve tracking performance drift â© copyright spie downloading abstract permitted personal use
10.1177/1748006X17751494 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042380381&doi=10.1177%2f1748006X17751494&partnerID=40&md5=05b3867306e0b87af3a4c257b01cec34 0,lifetime evolution mechanical equipment complicated structure harsh operating environment accurately expressed due dynamics failure mechanism however performance monitoring equipment information characterizing failure process sensed data used assess failure time online remaining useful life existence nonlinearity non gaussian real systems online assessment unscented kalman filter combined particle filter studied instead standard particle filter importance sampling modified update states iteratively meanwhile markov chain monte carlo performed resampling improve prediction accuracy modeling stateâ€“space model developed quantify relationship information online observation underlying degradation unscented particle filter investigated realize assessment remaining useful life particular sufficient statistic method presented obtain joint recursive estimation system state model parameters stateâ€“space model unknown time invariant ones end article acoustic emission signals milling cutter illustrated case study cutter online remaining useful life estimate milling cutter example demonstrates effectiveness proposed method online estimate provides useful insights regarding necessity online updating assessment â© imeche
10.1177/0954410018781464 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048781175&doi=10.1177%2f0954410018781464&partnerID=40&md5=ced2eaeb04b05b3782dc1db337fcee88 0,paper presents approach solve combined size shape design optimization problems using recently developed subset simulation optimization continuous discrete design variables except componentwise metropolisâ€“hasting algorithm recently developed adaptive conditional sampling algorithm also employed alternative approach generating new conditional samples candidate designs simulation level enhances accuracy stability optimization process besides double criterion sorting algorithm used handle design constraints integrate generation conditional samples markov chain monte carlo simulation inverse transform method employed deal discrete design variables totally four numerical examples considered including bar truss bar truss bar truss truss type landing gear unmanned aerial vehicle optimal designs obtained subset simulation optimization using either componentwise metropolisâ€“hasting algorithm adaptive conditional sampling algorithm succeed substantially reducing weights truss type structures design constraints terms member stress euler buckling nodal displacement computational results indicate proposed method taken alternative tool structural optimization design truss structures involving combined size shape design â© â© imeche
10.1080/00295639.2018.1512790 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053869379&doi=10.1080%2f00295639.2018.1512790&partnerID=40&md5=00ac7d98ca375289292dd7be34bd5df4 0,two fluid model based multiphase computational fluid dynamics mcfd considered one promising tools investigate two phase flow boiling system engineering purposes mcfd solver requires closure relations make conservation equations solvable wall boiling closure relations example provide predictions wall superheat heat partitioning accuracy closure relations significantly influences predictive capability solver paper study validation uncertainty quantification vuq wall boiling closure relations mcfd solver performed work three purposes identify influential parameters quantities interest qois boiling system sensitivity analysis sa evaluate parameter uncertainty bayesian inference support multiple data sets quantitatively measure agreement solver predictions data sets widely used kurul podowski wall boiling closure relation studied paper several statistical methods used including morris screening method global sa markov chain monte carlo inverse bayesian inference confidence interval validation metric vuq results indicate current empirical correlations based wall boiling closure relations achieved satisfactory agreement wall superheat predictions however closure relations also demonstrate intrinsic inconsistency fail give consistently accurate predictions qois well developed nucleate boiling regime â© â© american nuclear society
10.1016/j.ress.2017.09.029 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030669828&doi=10.1016%2fj.ress.2017.09.029&partnerID=40&md5=b01c53d0339a78a276391261568464f6 5,nuclear reactor fuel performance simulation fission gas release fgr swelling involve treatment several complicated interrelated physical processes inevitably depend uncertain input parameters however uncertainties associated input parameters known â€œexpert judgmentâ€� paper inverse uncertainty quantification uq bayesian framework applied bison code fgr model based risã time series experimental data inverse uq seeks statistical descriptions uncertain input parameters consistent available measurement data always captures uncertainties estimates rather merely determining best fit values kriging metamodel applied greatly reduce computational cost markov chain monte carlo sampling performed dimension reduction fgr time series data using principal component analysis also projected original fgr time series measurement data onto pc subspace â€œtransformed experiment dataâ€� forward uncertainty propagation based posterior distributions shows agreement bison simulation risã time series measurement data greatly improved posterior distributions uncertain input factors used replace expert specifications future uncertainty sensitivity analysis â© elsevier ltd
10.2514/6.2018-3775 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051289751&doi=10.2514%2f6.2018-3775&partnerID=40&md5=968b4d028f334adad0149548a5adc8fa 0,paper presents statistical inference method impedance eduction flow duct facility impedance recast random variable bayesâ€™ theorem used obtain posterior probability density real imaginary parts thus expressing knowledge uncertainty one impedance value given certain experimental data uncertainty evolutionary markov chain monte carlo technique selected explore probability space surrogate model based method snapshots employed speed calculations linearized euler equations solved using two dimensional discontinuous galerkin scheme accounting presence grazing flow inference process first validated published nasa git results acoustic pressure measurements wall opposite liner used inputs procedure applied educe impedance conventional sdof liner oneraâ€™s b acoustic bench laser doppler velocimetry technique used measure two components acoustic velocity fields liner â© american institute aeronautics astronautics inc rights reserved
10.1016/j.ifacol.2018.09.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053821995&doi=10.1016%2fj.ifacol.2018.09.010&partnerID=40&md5=2659501294664123e6f18d69e11550ec 0,distinguishing feature systems biology interrogation models means making predictions generating deeper understanding systems study however using given data set address specific question unique provably correct model formulation apply rarely known instead large selection alternative formulations varying scopes ensues combinatorial composition entities scenario computational methods allow us make statistically valid inferences predictions accounting uncertainty model formulation desired investigate bayesian model averaging bma accounts model uncertainty considering ensemble candidate models instead single model instance show computational tractability bma perform model uncertainty analysis realistically sized reaction network domain metabolic flux analysis featuring ensemble millions models made possible using markov chain monte carlo mcmc method tailored handle parameter model structure uncertainty simultaneously investigate computational burden solving multi model problem super model created includes reactions models multi model problem computational burden multi model problem compared conventional mcmc inference single super model comparison yields surprising insight multi model problem computationally less expensive single super model problem furthermore demonstrate example hand bma yields valid structural network inferences â©
10.1155/2018/1450683 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049110001&doi=10.1155%2f2018%2f1450683&partnerID=40&md5=62c9fc7e278274692ecc3f9b962c8c4d 0,key issue assessment tunnel face stability reliable evaluation required support pressure tunnel face variations tunnel excavation paper bayesian framework involving markov chain monte carlo mcmc simulation implemented estimate uncertainties limit support pressure probabilistic analysis three dimensional face stability tunnel river presented friction angle cohesion considered random variables uncertainties friction angle cohesion effects tunnel face stability prediction evaluated using bayesian method three dimensional model tunnel face stability river based limit equilibrium theory adopted probabilistic analysis results show posterior uncertainty bounds friction angle cohesion much narrower prior ones implying reduction uncertainty cohesion friction significantly reduces uncertainty limit support pressure uncertainty encompassed strength parameters greatly reduced mcmc simulation conducting uncertainty analysis mcmc simulation exhibits powerful capability improving reliability accuracy computational time calculations â© weiping liu et al
10.1016/j.swevo.2018.09.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053310178&doi=10.1016%2fj.swevo.2018.09.001&partnerID=40&md5=e91094e1480d60690818b39ee6b1b525 0,state art global optimization techniques adapt search range direction objective function differential evolution algorithms perform adaptation implicitly leading contour fitting property empirically observed lacks theoretical grounding paper formalize contour fitting notion derive analytical model links differential mutation operator adaptation range direction search analysis uses differential mutation evolutionary algorithm dmea optimizes multidimensional gaussian objective function analysis able make several observations firstly normally distributed population remains normal consecutive iterations moreover parameters population distribution updated explicit algebraic formulas furthermore scaling factor critical value population reaches stable state finally covariance matrix population stable state proportional covariance matrix gaussian objective function analytical results explaining contour fitting property confirmed simulation study although work focuses theoretical analyses proposed de prop mutation dmea algorithm maintain population diversity therefore lead optimization means saddle crossing become basis adaptive markov chain monte carlo sampling schemes element strategy adaptive differential evolution variants latter approach tested cec benchmark found significantly improve performance sade algorithm â© elsevier b v
10.2436/20.8080.02.66 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049174062&doi=10.2436%2f20.8080.02.66&partnerID=40&md5=f08b9d29866ad327589e002e840258f9 0,paper proposed bayesian analysis time series presence random change point autoregressive terms development model motivated data set related monthly number asthma medications dispensed public health services ribeirã preto southeast brazil pronounced increase trend observed specific change point posterior decrease end series order obtain estimates parameters interest bayesian markov chain monte carlo mcmc simulation procedure using gibbs sampler algorithm developed bayesian model autoregressive terms order fits well data allowing estimate change point july probably reflecting results new health policies previously adopted programs directed toward patients asthma results imply present model useful analyse monthly number dispensed asthma medications used describe broad range epidemiological time series data change point present â© institut estadistica de catalunya rights reserved
790.3854964159576 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041237875&partnerID=40&md5=090d4df9946a00c288a954f9f966852e 0,complex approach risk assessment crucial especially deal offshore greenfield development plan hovering verge profitability paper describes algorithm outputs application modern simulation technologies assessment risks associated development one caspian offshore fields carried risk assessment based multi realization calculations including geomodeling reservoir simulation integrated modeling fluid flow wells gathering system several types variables affecting geovolumes fluid flow used estimate uncertainties neighboring hydrocarbon field pre fasila formation development years included model hydrodynamic connection studied field question markov chain monte carlo technique applied get posterior distribution future reservoir production calculation resulted conclusion two offshore platforms installed middle south eastern parts field conclusion respects risk defined two main sources uncertainty impact varies different parts field applied approach enables quantitative risk assessment made acceptable time thus helps make transparent informed decisions improves project management efficiency copyright society petroleum engineers
10.1007/978-3-319-93713-7_16 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049009241&doi=10.1007%2f978-3-319-93713-7_16&partnerID=40&md5=f8ff547a1461ab2a1fe1e0b1abc93654 0,new monte carlo algorithm solving singular linear systems equations introduced fact consider convergence resolvent operator rî» construct algorithm based mapping spectral parameter î» approach applied systems singular matrices matrices show fairly high accuracy obtained â© springer international publishing ag part springer nature
9.08364072742418 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046441194&partnerID=40&md5=a48956caa81193874d73bf2740b9ec5c 2,develop opposing left turn traffic conflict model signalized intersections traffic conflict data traffic volume data extracted hours video data signalized intersections vancouver computer vision techniques given impacts traffic flow status traffic conflicts traffic flow status divided scenarios based v c indicator traffic conflict model based multivariate poisson lognormal distribution multiple scenarios traffic conflict model based poisson lognormal distribution single scenario developed posterior distribution models parameters derived bayesian estimation method based markov chain monte carlo simulation model parameters estimated using deviance information criterion dic models expectation variance goodness fit precision models compared results show goodness fit multivariate poisson lognormal based traffic conflict model superior single poisson lognormal based traffic conflict model precision multivariate poisson lognormal based traffic conflict model scenarios twice times twice times larger single poisson lognormal based traffic conflict model conflicting volumes different impacts traffic conflicts different traffic flow status results elasticity analysis show increase traffic flow movement may increase opposing left turn conflict frequency traffic scenario respectively given left turn traffic flow remains accordingly increase traffic flow left turn may increase opposing left turn conflict frequency traffic scenario respectively given traffic flow remains â© editorial department china journal highway transport right reserved
10.1080/00295639.2018.1499279 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051918828&doi=10.1080%2f00295639.2018.1499279&partnerID=40&md5=03a22656f6ef2d87047cf1ad661b9dfa 0,framework best estimate plus uncertainty methodology uncertainties involved model predictions must quantified prove investigated design reasonable acceptable uncertainties predictions usually calculated propagating input uncertainties simulation model requires knowledge model code input uncertainties example means variances distribution types etc however best estimate system thermal hydraulic codes trace parameters empirical correlations may large uncertainties unknown code users uncertainties therefore simply ignored described expert opinion paper issue missing uncertainty information physical model parameters thermal hydraulic code trace addressed inverse uncertainty quantification iuq using steady state void fraction experimental data organisation economic co operation development nuclear energy agency psbt pressurized water reactor sub channel bundle tests benchmark iuq process formulated bayesian perspective yield posterior distributions uncertain inputs gaussian process emulator employed significantly reduce computational burden involved sampling posteriors using markov chain monte carlo method posterior distributions used forward uncertainty quantification sensitivity analysis quantify influences parameters quantities interest results demonstrate effectiveness iuq framework practical nuclear engineering example show necessity quantifying reducing uncertainty physical model parameters future work â© â© american nuclear society
10.4271/2018-01-1103 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045512323&doi=10.4271%2f2018-01-1103&partnerID=40&md5=eca0765104e2c4839d98092e9378a52f 0,paper presents approach comparing alternative repairable systems calculating value information obtained testing specified number systems specifically approach presented determine value information comes field testing specified number systems order appropriately estimate reliability metric associated respective repairable systems reliability repairable system measured failure rate support decision making effort failure rate translated expected utility based utility curve represents risk tolerance decision maker algorithm calculates change expected value decision sample size change value decision represents value information obtained testing approach uses bayesian probability model allows decision maker incorporate subjective priors reliability performance design alternatives dependency modeled using copulas couple marginal prior distributions alternatives single joint prior procedure presented paper uses markov chain monte carlo simulation mcmc determine posterior probability density resulting expected utility decision approach considers design alternatives based failure rate metric e g number failures per unit fpu number failures per unit time utilizes archimedean copulas couple dependent marginals describe priors design alternative failure per unit behavior paper extension paper assessing value information multiple correlated design alternatives capser nikolaidis presented approach determining optimal sample sizes assessing correlated non repairable design alternatives based prior estimate joint failure probability â© sae international rights reserved
10.1093/GJI/GGY302 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054872776&doi=10.1093%2fGJI%2fGGY302&partnerID=40&md5=8229ce801c53e0dffc36e58fb4b98461 0,single point source oversimplified representation medium large earthquakes finite fault models many cases parameterize inversion due lack sufficient near field data multiple point source solutions fill gap two representations propose markov chain monte carlo multiple point source inversion scheme combination advantage cut paste technique cuts seismogram pnl surface portions allows different time shifts segment align data synthetics apply approach mw foreshock kumamoto earthquake sequence using strong motion observations within km able perform inversion relatively high frequency ranges hz pnl hz surface waves confidence velocity model built mw path calibration event results show rupture mainly composed three subevents total duration total mw strikes three subevents agree well surface fault mapping futagawa fault intersects hinagu fault â° difference strike solution shows first subevent dips southeast second third subevents located km north km southwest first subevent dip northwest focal mechanism first subevent shows remarkable agreement first motion solution fault geometry also shows well consistence relocated aftershocks delineate se dipping fault around first subevent two nw dipping faults north south respectively corresponding second third subevent sum moment tensor subevents different geometry also rake angles shows strong compensated linear vector dipole clvd component per cent local crustal model full moment tensor inversion using regional long period waveform data also detects strong clvd component earthquake contrast using prem model results almost pure double couple solution short precisely resolved rupture process intricate fault geometry strong clvd component strong motion data highlights importance extracting relatively high frequency information waveformdata accurate velocity model seismic source analyses large earthquakes â© author published oxford university press behalf royal astronomical society
10.1016/j.radphyschem.2018.06.024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049553832&doi=10.1016%2fj.radphyschem.2018.06.024&partnerID=40&md5=9c964a1113932015957447a1606bff7a 1,apply bayesian techniques determine location intensity gamma radiation source urban environment using count rates taken distributed detector network simplified model radiation transport process used construct statistical model detector count rates presence randomly varying background markov chain monte carlo used generate samples bayesian posterior density used inform search interdiction efforts also present modification traditional metropolis sampling algorithm allows us incorporate fixed parameter uncertainties building macroscopic cross sections account effects posterior distribution method applied test problem based real urban geometry different levels uncertainty building cross sections results show uncertainty estimated source location modest even large degree uncertainty building cross sections â©
459.4883625888745 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051627635&partnerID=40&md5=82e194be90611ab16f870ede95f7ce07 0,since lwd deep azimuthal resistivity service first introduced decade ago followed ultra deep azimuthal resistivity years ago new service spotlight drawn great attention operators azimuthal propagation resistivity tools use concept multi spacings multi frequencies multi components measurements acquired tool much richer conventional omni directional propagation resistivity applications new service widely ranged well placement reservoir mapping geo stopping landing fault detection salt edge detection etc however due complexity measurement physics tool response characteristics data processing inversion without well understanding uncertainty service operators sufficient confidence use service much expected promote understanding technology clear many questions surfing around industry paper systematically study sensitivity quantify uncertainty azimuthal propagation resistivity technology various formation model sensitivity measurements dip angle anisotropy layer boundaries formation resistivity essential assess capability technology practical applications reservoir boundary mapping formation evaluation well placement group studies conducted evaluate sensitivity several common situations including homogeneous isotropy formation homogeneous anisotropy formation layered formation information content measurements proper use measurements clearly demonstrated depth detection dod two layer formation presented format â€œpicassoâ€� plot studied common practice produce â€œpicassoâ€� plot based noise threshold measurement always realistic reflects quality measurements rather quality error bar distance boundary b resulting inversion processing b error based dod investigated paper comparison two methods reveals commonly used noise based dod considerably overestimated set formation models proposed spwla resistivity special interest group rtsig chapter used quantify uncertainty bed boundary position formation resistivity dip angle novel statistical analysis trans dimensional markov chain monte carlo tmcmc method probability maps boundary interface distribution resistivity profile extracted statistical characteristics posterior probability distribution ppd exercise statistical solver formation models recommended spwla rtsig demonstrates uncertainty quantification techniques crucial assess azimuthal propagation resistivity technology field example subsea gas well wheatstone liquefied natural gas project western australia used confirm importance uncertainty quantification evaluating capacity azimuthal propagation resistivity measurements copyright held jointly society petrophysicists well log analysts spwla submitting authors
10.1007/978-3-319-95165-2_22 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049978878&doi=10.1007%2f978-3-319-95165-2_22&partnerID=40&md5=dcf2f36f727d836cbb08bcdbaa2149d3 0,subsurface characterization using history matching algorithm subsurface properties reconstructed set limited data focus characterization permeability field aquifer using markov chain monte carlo mcmc algorithms reliable procedures reconstruction mcmc method serial nature due markovian property moreover calculation likelihood information mcmc computationally expensive subsurface flow problems running long mcmc chain long period makes method less attractive characterization subsurface contrast several shorter mcmc chains substantially reduce computation time make framework suitable subsurface flows however convergence mcmc chains carefully studied paper consider multi mcmc chains singleâ€“phase flow problem analyze chains aiming reliable characterization â© springer international publishing ag part springer nature
10.1049/iet-rsn.2017.0235 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040184706&doi=10.1049%2fiet-rsn.2017.0235&partnerID=40&md5=63e446552a2f83d30229167f5910cbee 0,study deals problem joint delay doppler estimation practically motivated scenario passive bistatic radar surveillance channel polluted direct path signal residual new joint delay doppler maximum likelihood estimator mle based markov chain monte carlo mcmc proposed mcmc method allows one compute mle computationally efficient manner proposed estimator based upon generating random variates using markov chain whose stationary distribution approximates likelihood function guarantees convergence global maximum contrast recently proposed modified cross correlation estimator expectation maximisation based mle avoids grid search may lead straddle loss initialisation dependent iteration may lead convergence problems simulation results indicate proposed estimator achieves significant performance improvement existing methods â© institution engineering technology
10.1007/s11222-017-9722-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010735053&doi=10.1007%2fs11222-017-9722-1&partnerID=40&md5=42d16fd03b90b903224cb9ef19cb701b 0,present sequential monte carlo algorithm markov chain trajectories proposals constructed reverse time advantageous paths conditioned end rare set reverse time proposal distribution constructed approximating ratio greenâ€™s functions nagasawaâ€™s formula conditioning arguments used interpret ratios low dimensional conditional sampling distributions coordinates process given others hence difficulty designing smc proposals high dimension greatly reduced empirically method outperforms adaptive multilevel splitting algorithm three examples estimating overflow probability queueing model probability diffusion follows narrowing corridor initial location infection epidemic model network â© springer science+business media new york
10.1093/COMNET/CNX024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044219998&doi=10.1093%2fCOMNET%2fCNX024&partnerID=40&md5=e3750053658fa0dc5aa95aec3d005012 1,spreading processes ubiquitous natural artificial systems studied via plethora models depending specific details phenomena study disease contagion rumour spreading among important processes due practical relevance however despite similarities current models address spreading dynamics separately article propose general spreading model based discrete time markov chains model includes transitions plausible disease contagion process rumour propagation show model covers traditional spreading schemes also contains features relevant social dynamics apathy forgetting lost recovering interest model evaluated analytically obtain spreading thresholds early time dynamical behaviour contact reactive processes several scenarios comparison monte carlo simulations shows markov chain formalism highly accurate excels computational efficiency round work showing proposed framework applied study spreading processes occurring social networks â© authors published oxford university press rights reserved
8.694870083156392 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050285932&partnerID=40&md5=5c20f7014880203ade4fd2f491a8bfb7 0,study discuss effects observational error phase velocity shallow phase velocity profile numerical case uncertainty wave velocity profile obtained inversion phase velocity using markov chain monte carlo uncertainty wave velocity profile used estimate variability nonlinear soil amplification variability linear amplification also estimated comparison nonlinear one find nonlinear amplification less variability linear response decrease shear modulus increase damping nonlinear amplification â© european association geoscientists engineers eage rights reserved
10.1007/978-3-319-77404-6_63 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045409316&doi=10.1007%2f978-3-319-77404-6_63&partnerID=40&md5=98958ea74b0b27e4044f370a904d8358 0,counting perfect matchings played central role theory counting problems permanent corresponding bipartite graphs shown p complete compute exactly valiant fully polynomial randomized approximation scheme fpras presented jerrum sinclair vigoda using markov chain monte carlo mcmc approach however remained open question whether exists fpras counting perfect matchings general graphs fact unresolved whether markov chain defined jsv rapidly mixing general paper show prove torpid mixing weighting scheme hole patterns jsv chain first step toward overcoming obstacle introduce new algorithm counting matchings based gallaiâˆ’edmonds decomposition graph give fpras counting matchings graphs sufficiently close bipartite particular obtain fixed parameter tractable algorithm counting matchings general graphs parameterized greatest â€œorderâ€� factor critical subgraph â© springer international publishing ag part springer nature
10.1111/geb.12666 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038123927&doi=10.1111%2fgeb.12666&partnerID=40&md5=c834d376b900f36051824a78e2f87dd0 3,aim species distribution models important tools used study distribution abundance organisms relative abiotic variables dynamic local interactions among species community affect abundance abundance single species may equilibrium environment spreading invasive species species range shifting climate change innovation develop methods incorporating temporal processes spatial joint species distribution model presence absence ordinal abundance data model non equilibrium conditions via temporal random effect temporal dynamics vector autoregressive process allowing intra interspecific dependence co occurring species autoregressive term captures abundance species enhance inhibit subsequent abundance subsequent abundance species community well suited â€˜community modulesâ€™ approach strongly interacting species within food web r code provided fitting multispecies models within bayesian framework ordinal data number locations time points covariates ordinal categories main conclusions model ordinal abundance data two invasive insects hemlock woolly adelgid elongate hemlock scale share host tree undergoing northwards range expansion eastern u period â€“ accounting range expansion high inter annual variability abundance led improved estimation speciesâ€“environment relationships erroneously concluded winter temperatures affect scale abundance accounted range expansion scale autoregressive component revealed weak evidence commensalism adelgid may predisposed hemlock stands subsequent infestation scale residual spatial dependence indicated unmeasured variable additionally affected scale abundance robust modelling approach provide similar insights community modules co occurring species â© john wiley sons ltd
10.1111/cgf.13585 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054602663&doi=10.1111%2fcgf.13585&partnerID=40&md5=1ab781dd0d2387f19f97aa536456d818 0,present system generate procedural environment produces desired crowd behaviour instead altering behavioural parameters crowd automatically alter environment yield desired crowd behaviour novel inverse approach useful crowd simulation virtual environments urban crowd planning applications approach tightly integrates extends space discretization crowd simulator inverse procedural modelling extend crowd simulation goal exploration e agents initially unaware goal locations variable appealing sign usage several acceleration schemes use markov chain monte carlo quickly explore solution space yield interactive design applied method variety virtual real world locations yielding one order magnitude faster crowd simulation performance related methods several fold improvement crowd indicators â© authors computer graphics forum â© eurographics association john wiley sons ltd
10.1016/j.procs.2018.08.180 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053155539&doi=10.1016%2fj.procs.2018.08.180&partnerID=40&md5=d5a00a331d11b466a93733608e8e209f 0,spatio temporal analysis widely used describe geo referenced data contain information space time many important response variables predictors models usually presented maps represent spatial dependence temporal correlation time time spatio temporal models presented paper designed hierarchical fashion estimated inla integrated nested laplace approximation current estimation method bayesian analysis inla based latent gaussian posterior distribution provides great computational benefit solve convergence issue mcmc markov chain monte carlo algorithm model poverty data set using classical dynamic space time interaction spatio temporal models investigate poverty relationship socio economics predictors using r inla package deviance information criteria models best fit selection conclude dynamical non parametric proper model ecological regressions â© authors published elsevier ltd
10.1137/16M1107401 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049453677&doi=10.1137%2f16M1107401&partnerID=40&md5=59020629cbcb66b4e3c21a87e750c318 0,propose algorithm efficient robust sampling posterior probability distribution bayesian inference problems algorithm combines local search capabilities manifold metropolis adjusted langevin transition kernels advantages global exploration population based sampling algorithm transitional markov chain monte carlo tmcmc langevin diffusion process determined either hessian fisher information target distribution appropriate modifications nonâ€“positive definiteness present method shown superior population based algorithms sampling probability distributions gradients available shown handle otherwise unidentifiable models demonstrate capabilities advantages method computing posterior distribution parameters pharmacodynamics model glioma growth drug induced inhibition using clinical data â© society industrial applied mathematics
10.1007/978-3-319-77249-3_28 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045965513&doi=10.1007%2f978-3-319-77249-3_28&partnerID=40&md5=cdcb87efc608fc1e99d0d8933ec568ef 0,study simulation based method computing joint maximum likelihood estimates cognitive diagnosis model parameters proposed central theme approach reduce complexity models focus critical elements particular approach analogous joint maximum likelihood estimation taken latent attribute vectors regarded structural parameters parameters removed integration approach joint distribution latent attributes specified reduces number parameters model markov chain monte carlo algorithm used simultaneously evaluate optimize likelihood function streamlined approach performed well traditional methods models dina affords opportunity fit complicated models methods may feasible â© springer international publishing ag part springer nature
10.1137/16M1108716 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045045191&doi=10.1137%2f16M1108716&partnerID=40&md5=78d38a28c34f29d823622eff8d312634 0,propose two algorithms simulating continuous time markov chains presence metastability show algorithms correctly estimate ergodicity assumption stationary averages process algorithms based idea parallel replica method use parallel computing order explore metastable sets efficiently algorithms require assumptions markov chains beyond ergodicity presence identifiable metastability particular assumption reversibility simpler illustration algorithms assume synchronous architecture used throughout paper present error analyses well numerical simulations multiscale stochastic reaction network models order demonstrate consistency method efficiency â© society industrial applied mathematics
10.1007/978-3-319-91938-6_11 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049182096&doi=10.1007%2f978-3-319-91938-6_11&partnerID=40&md5=0ed4a72947a6f3ee00f361b6214dc4a7 0,extensive literature using probabilistic models hidden markov models analysis biological sequences models clear theoretical basis many heuristics developed reduce time memory requirements dynamic programming algorithms used inference nevertheless mirroring shift natural language processing bioinformatics increasingly seeing higher accuracy predictions made recurrent neural networks rnn shift exemplified basecalling oxford nanopore technologiesâ€™ sequencing platform continuous time series current measurements mapped string nucleotides current basecallers applied connectionist temporal classification ctc method originally developed speech recognition focused task decoding rnn output single read wish extend method general task consensus basecalling multiple reads exploit gains accelerated algorithms sequence analysis recurrent neural networks areas advanced parallel past decade end develop dynamic programming algorithm consensus decoding pair rnns show readily optimized use alignment envelope express decoding notation finite state automata show pair rnn decoding compactly represented using automata operations additionally introduce set markov chain monte carlo moves consensus basecalling multiple reads â© springer international publishing ag part springer nature
10.6052/j.issn.1000-4750.2017.01.0075 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050101512&doi=10.6052%2fj.issn.1000-4750.2017.01.0075&partnerID=40&md5=53d50463dfd95f38f3c69779c0e233a6 0,traditional models shear strength reinforced concrete rc beams generally deterministic models exhibit low computational accuracy large numerical fluctuation due fact take account aleatory physical uncertainties various parameters geometry material properties boundary conditions well epistemic model uncertainties modelling based modified compression field theory mcft critical crack angle model considering influence shear span ratio deterministic model shear strength rc beams established first subsequently probabilistic model shear strength rc beam developed using bayesian theory markov chain monte carlo mcmc take account influences epistemic aleatory uncertainties finally applicability efficiency proposed probabilistic model validated comparing experimental data traditional deterministic models analysis results show proposed probabilistic model good accuracy adaptability model describe probabilistic distribution characteristics shear strength rc beams also provide benchmark calibrate confidence level traditional deterministic models provide efficient way determine characteristic values shear strength rc beams different confidence levels â© engineering mechanics press right reserved
10.1016/j.compenvurbsys.2018.09.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053935382&doi=10.1016%2fj.compenvurbsys.2018.09.003&partnerID=40&md5=d22f537f2a1ac93ed3717680024edbeb 0,social physical processes often exhibit macro level geographic smoothness â€“ implying positive spatial dependence â€“ micro level discontinuities â€“ suggesting implicit step changes boundaries data however simultaneous treatment two features unified statistical model poses great challenges study extends innovative locally adaptive spatial auto regressive modelling approach multi level modelling framework order explore multiple scale geographical data develops bayesian locally adaptive spatial multi level model takes account horizontal global spatial dependence local step changes well vertical group dependency effect imposed multiple scale data structure heart correlation structures spatial units implied spatial weights matrix learned along model parameters using iterative estimation algorithm rather assumed invariant exogenous bayesian markov chain monte carlo mcmc sampler implementing new spatial multi level model derived developed methodology applied infer neighbourhood quality using property transaction data examine potential correlates neighbourhood quality liverpool results reveal complex fragmented geography neighbourhood quality besides overall smoothness trend boundaries delimiting neighbourhood quality scattered across liverpool socio economics built environment locational characteristics statistically significantly associated neighbourhood quality â© authors
174.2715065189435 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051522665&partnerID=40&md5=622b17c2c196328da09a0d51328c16c0 0,availability spatial spatio temporal data widely increased allow researcher describe potential geographical pattern including information space time interraction many scientific fields bayesian method deal spatial spatio temporal data extensively approach markov chain monte carlo mcmc however models complex designed hierarchical fashion mcmc algorithms may extremely slow even become computationally unfeasible integrated nested laplace approximation inla algorithm current development r inla package r designed deal fundamental limitation mcmc computation paperpurpose investigate socioeconomic information e population density expectation years ofschooling construction overpriced index effect number poor people east java province indonesia using bayes spatial model investigation result expectation years schooling greatesteffect reducing number poor people spatial pattern also investigate timedependency poor people data years using classical dynamic space timeinteraction bayes spatio temporal models paper computational aspect efficiently solvedwith r inla resulting dynamic bayes spatio temporal best model based smallest devianceinformation criteria â© ieom society international
10.1002/stc.2258 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053530647&doi=10.1002%2fstc.2258&partnerID=40&md5=39503428f97337325213fbaafb6d7d71 0,paper presents bayesian model updating methodology dynamical systems geometric nonlinearities based nonlinear normal modes nnms extracted broadband vibration data model parameters calibrated minimizing selected metrics identified model predicted nnms first approach deterministic formulation adopted parameters updated minimizing nonlinear least squares objective function probabilistic approach based bayesian inference next investigated transitional markov chain monte carlo implemented sample joint posterior probability distribution nonlinear model parameters bayesian model calibration advantage quantify parameter uncertainty provide estimation model evidence model class selection two formulations evaluated applied numerical cantilever beam geometrical nonlinearity nnms beam derived simulated broadband data nonlinear subspace identification numerical continuation accuracy model updating results studied respect level measurement noise number available datasets modeling errors â© john wiley sons ltd
10.1137/16M1088417 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046726232&doi=10.1137%2f16M1088417&partnerID=40&md5=f43fa7466e2412f91839314941136cf2 0,parameter estimation problems one computes posterior distribution uncertain parameters defined jointly prior distribution model noisy data markov chain monte carlo mcmc often used numerical solution problems alternative mcmc importance sampling exhibit near perfect scaling number cores high performance computing systems samples drawn independently however finding suitable proposal distribution challenging task several sampling algorithms proposed past years take iterative approach constructing proposal distribution investigate applicability algorithms applying two realistic challenging test problems one subsurface flow one combustion modeling specifically implement importance sampling algorithms iterate mean covariance matrix gaussian multivariate proposal distributions implementation leverages massively parallel computers present strategies initialize iterations using â€œcoarseâ€� mcmc runs gaussian mixture models â© society industrial applied mathematics
10.1190/GEO2017-0075.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037054481&doi=10.1190%2fGEO2017-0075.1&partnerID=40&md5=b066c0fb98115fd8794987e70cc1395d 2,consider problem fluid identification fracture detection unconventional reservoir tight gas sand shale gas characterization begin simplification stiffness parameters derivation linearized reflection coefficient azimuthal elastic impedance ei accuracy simplification confirmed application gas bearing fractured rocks low porosity small fracture density developed modified fluid factor sensitive fluid type less influenced porosity two step inversion workflow evaluated based derived linearized reflection coefficient azimuthal ei including damped least squares inversion azimuthal ei constrained initial model bayesian markov chain monte carlo inversion modified fluid factor dry fracture weaknesses stability accuracy examined synthetic data conclude modified fluid factor dry fracture weaknesses stably determined presence moderate data error noise stability approach confirmed fractured tight gas sand field data set within observe geologically reasonable parameters lamã© constants modified fluid factor dry fracture weaknesses determined conclude inversion workflow underlying assumptions form realistic predictions discriminations reservoir fracture fluid parameters â© society exploration geophysicists
10.1016/j.imavis.2017.11.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034856672&doi=10.1016%2fj.imavis.2017.11.004&partnerID=40&md5=12c5e15442f09f0b3ea3ca42dc0f17bd 0,paper present novel tracking system based edge based object proposal data association called object proposal association object proposal method accurately detects localizes objects image searching object like regions assumption object represented closed boundary search closed boundaries image present new edge fields efs technique using technique method extract high quality edges obtain accurate boundaries image efs technique consists blurring thresholding steps former helps extract high quality edges latter prevents method losing image details blurring method extracts object like regions associate regions previous frame current frame purpose using markov chain monte carlo data association mcmcda algorithm find pairs similar regions across two frames experimental results demonstrate object proposal method competitive state art object proposal methods pascal voc dataset tracking method also competitive state art tracking methods object tracking benchmark dataset â© elsevier b v
10.1007/978-3-319-91436-7_2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049896614&doi=10.1007%2f978-3-319-91436-7_2&partnerID=40&md5=4bbd962b0a0634b5ee7d5ece01063ce2 0,survey basic ideas results randomized quasi monte carlo rqmc methods discuss practical aspects give numerical illustrations rqmc improve accuracy compared standard monte carlo mc estimating integral interpreted mathematical expectation rqmc estimators unbiased variance converges faster rate certain conditions mc estimators function sample size variants rqmc also work simulation markov chains function approximation optimization solving partial differential equations etc introductory survey look rqmc point sets sequences constructed measure uniformity work high dimensional integrals work simulating markov chains large number steps â© springer international publishing ag part springer nature
10.1080/13504851.2018.1512740 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053262490&doi=10.1080%2f13504851.2018.1512740&partnerID=40&md5=15ae135412072bb22c8058e79583dc7d 0,distribution asset returns often proved heavy tailed paper based fama french five factor model multivariate distribution develop convenient explicit bayesian approach test asset pricing developed test statistic product markov chain monte carlo mcmc outputs hence convenient practice simulation studies demonstrate effectiveness finite sample performance proposed approach finally fama french data used testing efficiency financial markets result shows market efficiency rejected â© â© informa uk limited trading taylor francis group
10.1137/16M1078471 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053600147&doi=10.1137%2f16M1078471&partnerID=40&md5=59fa967d1bc6e4a49a7fd918bd48bd80 0,problem identifying planted assignment given random k satisfiability k sat formula consistent assignment exhibits large algorithmic gap planted solution becomes unique identified given formula n log n clauses distributions clauses best known efficient algorithms require nk clauses propose study unified model planted k sat captures well known special cases instance described planted assignment ïƒ distribution clauses k literals define distribution complexity largest r distribution r wise independent â‰¤ r â‰¤ k distribution planted assignment main result unconditional lower bound tight logarithmic factors statistical query algorithms kearns j acm pp â€“ v feldman e grigorescu l reyzin vempala xiao j acm pp â€“ matching known upper bounds show implemented using statistical algorithm since known approaches problems distributions statistical analogues spectral markov chain monte carlo gradient based convex optimization etc lower bound provides rigorous explanation observed algorithmic gap proof introduces new general technique analysis statistical query algorithms also points geometric paring phenomenon space planted assignments describe consequences lower bounds feigeâ€™s refutation hypothesis u feige proceedings acm symposium theory computing pp â€“ lower bounds general convex programs solve planted k sat bounds also extend planted k csp models particular provide concrete evidence security goldreichâ€™s one way function associated pseudorandom generator used sufficiently hard predicate goldreich preprint ia cr â© society industrial applied mathematics
10.1029/2018TC005207 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055029064&doi=10.1029%2f2018TC005207&partnerID=40&md5=524e918764f161701606673bb1550b4e 0,low temperature thermochronometry widely used measure timing rate slip normal faults rates often derived suites footwall thermochronometer samples regression age versus structural depth fails account trajectories samples fault slip demonstrate rotating fault blocks regression age depth data susceptible significant errors identification initiation rate faulting advection heat topographic growth influence thermal histories exhumed particles range geologically reasonable fault geometries rates effects produce apatite u th ages comparable derived rotation fixed isotherms apply fixed isotherm model published data pine forest range east range nevada incorporating field thermochronologic constraints markov chain monte carlo model modeled parameters pine forest range described narrow ranges geologically reasonable values compared slip rates â€“ â km myr initiation faulting ca â€“ â derived visual inspection model predicts average slip rate â km myr onset faulting ca â€“ â east range fault block model suggests faulting began â extension rate â km myr slowed extension rate â km myr â absence preserved partial retention zone east range sample set limits well model predict fault block geometry published article u government work public domain usa
223.46043856063957 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051633534&partnerID=40&md5=5ebf4cdd8d132d9b2eb9f4b1244cc0d9 0,show statistical methods enable use portable industrial scanners sparse measurements suitable fast site whole core x ray computerized tomography ct opposed conventional medical devices dense measurements approach accelerates informed first stage general assessment core samples end show novel industrial tomographic measurement principle feasible rock sample imaging conjunction suitable forms priors bayesian inversion algorithms assess performance inversion gaussian cauchy total variation tv priors consider discrete form conditional mean cm estimators via markov chain monte carlo mcmc algorithms noise contaminated measurements benchmark reliability whole core imaging sparse radiograms via bayesian inversion study include x ray ct numerical simulations synthetic measurement based whole core samples end consider tomographic measurements fine medium grained sandstone core samples igneous rich pebbles miocene shimokita peninsula japan fractured welded tuff big bend national park texas bayesian inversion results show radiograms natural fractures aperture less mm wide detectable additionally images show approximately spherical concretions mm diameter show achieve similar results filtered back projection fbp techniques require hundreds radiograms possible conventional medical laboratory scanners paper shows bayesian inversion whole core x ray ct capable imaging coarse sedimentary features faster simplified measurement principles aid efficient operational petrophysical decisions planning core analysis copyright held jointly society petrophysicists well log analysts spwla submitting authors
10.1111/rssb.12237 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019544964&doi=10.1111%2frssb.12237&partnerID=40&md5=fa2d76c234c1a57c07e0c5375ab83939 0,present novel inference methodology perform bayesian inference spatiotemporal cox processes intensity function depends multivariate gaussian process dynamic gaussian processes introduced enable evolution intensity function discrete time novelty method lies fact discretization error involved despite non tractability likelihood function infinite dimensionality problem method based markov chain monte carlo algorithm samples joint posterior distribution parameters latent variables model particular choice dominating measure obtain likelihood function shown crucial devise valid markov chain monte carlo algorithm models defined general flexible way amenable direct sampling relevant distributions careful characterization components models also enable inclusion regression covariates temporal components explain variability intensity function components may subject relevant interaction space time real simulated examples illustrate methodology followed concluding remarks â© royal statistical society
28.80864343492029 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046161669&partnerID=40&md5=cec362e5ac7eaec34620d059e5ab913f 0,understanding evolution cancer important development appropriate cancer therapies task challenging tumors evolve heterogeneous cell populations unknown number genetically distinct subclones varying frequencies conventional approaches based bulk sequencing limited addressing challenge clones observed directly single cell sequencing holds promise resolving heterogeneity tumors however advantage comes cost elevated noise due limited amount dna material present cell extensive dna amplification required prior sequencing present sciî¦ first single cell specific variant caller combines single cell genotyping reconstruction cell lineage tree sciî¦ leverages fact somatic cells organism related via phylogenetic tree mutations propagated along tree branches inference scheme starts initial identification possible mutation loci performs joint phylogenetic inference variant calling via posterior sampling first step likely mutated loci identified using posterior probability observing least one mutated cell specific locus order sciî¦ models nucleotide counts using beta binomial distribution especially useful single cell setting since beta binomial distribution described pã³lya urn model turn close approximation multiple displacement amplification commonly used amplify genomic material single cell second step identified loci used infer tumor phylogeny account dropout events modeling likelihood observing mutation cell weighted mixture likelihoods homozygous reference genotype heterozygous genotype homozygous alternative genotype model infer tumor phylogeny consists three parts genealogical tree mutation attachments edges parameters model tree search space grows superexponentially number cells employ markov chain monte carlo scheme traverse tree space mutation assignment learn parameters model using relationship cells able reliably call mutations single cell even experiments high dropout rates missing data show sciî¦ outperforms existing methods simulated data apply different real world datasets availability https github com cbg ethz sciphi â© springer international publishing ag part springer nature
10.1515/snde-2017-0114 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054848873&doi=10.1515%2fsnde-2017-0114&partnerID=40&md5=553115ee64b9514fc2a7960f0ecd2191 0,literature time series models threshold effects makes assumption constant threshold value different periods however time homogeneity assumption tends restrictive owing fact threshold value triggers regime switching possibly time varying study herein proposes threshold model threshold value assumed latent variable following autoregressive ar process newly proposed model estimated using markov chain monte carlo mcmc algorithm bayesian framework monte carlo simulations presented assess effectiveness bayesian approaches illustration model made application regime sensitive taylor rule employing u data â© walter de gruyter gmbh berlin boston
10.1007/978-3-319-61566-0_39 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026294120&doi=10.1007%2f978-3-319-61566-0_39&partnerID=40&md5=dec9b5070ee00578c22d4dafcb86b920 0,propose hardware architecture solving combinatorial optimization problems implemented fpga hardware minimizes energy ising model state variables fully connectable bit weights ease restrictions mapping problems onto ising model system uses hardware bit sieve engine performs markov chain monte carlo search parallel evaluation energy increment prior bit selection achieving speedup guaranteeing convergence engine implemented arria gx fpga solves city traveling salesman problems times faster simulated annealing running ghz intel xeon e v processor â© springer international publishing ag
10.15672/HJMS.2017.441 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046349601&doi=10.15672%2fHJMS.2017.441&partnerID=40&md5=b7137ae37edfefd9d77f59bec00f8b09 0,paper developed slice sampler algorithm generalized pareto distribution gpd model two simulation studies shown performance peaks given threshold pot gpd density function various simulated data sets results compared another commonly used markov chain monte carlo mcmc technique called metropolis hastings algorithm based results slice sampler algorithm provides closer posterior mean values shorter quantile based credible intervals compared metropolis hastings algorithm moreover slice sampler algorithm presents higher level stationarity terms scale shape parameters compared metropolis hastings algorithm finally slice sampler algorithm employed estimate turn risk values investment malaysian gold market â© hacettepe university rights reserved
10.18637/jss.v083.i11 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042686753&doi=10.18637%2fjss.v083.i11&partnerID=40&md5=8dc889deb3bdb55cf7ac4eae4bd7c996 1,present r package epinet provides tools analyzing spread epidemics populations assume relationships among individuals population modeled contact network described exponential family random graph model disease studied spreads across edges network infectious susceptible individuals use susceptible exposed infectious removed compartmental model describe progress disease within host describe functionality package consists routines perform simulation plotting inference main inference routine utilizes bayesian approach markov chain monte carlo algorithm demonstrate use package two examples one involving simulated data one using data actual measles outbreak â© american statistical association rights reserved
10.1016/j.ecosta.2018.03.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046161118&doi=10.1016%2fj.ecosta.2018.03.003&partnerID=40&md5=1b9a339feb79be08d956da44a5b11bb0 0,single equicorrelation structure among several daily asset returns promising attractive reduce number parameters multivariate stochastic volatility models however assumption may realistic number assets may increase example portfolio optimizations solution oversimplification multiple block equicorrelation structure proposed high dimensional financial time series common correlations within group asset returns assumed different correlations different groups allowed realized volatilities realized correlations also jointly modelled obtain stable accurate estimates parameters latent variables leverage effects using state space representation efficient estimation method markov chain monte carlo simulation described empirical studies using u daily stock returns data show proposed model outperforms competing models portfolio performances â© ecosta econometrics statistics
10.1016/j.patrec.2018.07.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050076279&doi=10.1016%2fj.patrec.2018.07.005&partnerID=40&md5=8787bdb2980091ce83450b8f9d787700 0,graph matching powerful tool computer vision distance measure machine learning however many factors influences accuracy matching outliers key problem process matching paper novel approach proposed handle graph matching problem based markov chain monte carlo framework constructing target distribution proposed perform process sampling maximize graph matching objective process method effectively save matching pairwise one one matching constraints also avoid effect outliers deformation corresponding experiments synthetic graphs real images view based model retrieval demonstrate superiority proposed method â© elsevier b v
10.18517/ijaseit.8.2.3506 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046535847&doi=10.18517%2fijaseit.8.2.3506&partnerID=40&md5=185d475c0085d459ec8e3879fb9c69c2 0,situations observations extreme current extreme value recorded kind data called record values many applications lot fields paper bayesian estimators using squared error linex loss functions generalized inverted exponential distribution parameters considered depending upper record values upper record ranked set sampling bayes estimates credible intervals derived considering independent gamma priors parameters markov chain monte carlo mcmc method developed due lack explicit forms bayes estimates simulation study implemented compute compare performance estimators sampling schemes respect relative absolute biases estimated risks width credible intervals â© ijaseit
10.1007/s11009-018-9676-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054853188&doi=10.1007%2fs11009-018-9676-6&partnerID=40&md5=4a1e1c77b324e5959e001466d186823d 0,article presents different estimation procedure inverse lindley distribution type hybrid censored data obtained parameter estimate classical bayesian paradigm classical set method maximum likelihood ml maximum product spacings mps estimates obtained along asymptotic confidence interval bayesian estimation implemented assumption squared error loss function alternative bayesian procedure also proposed incorporating sample information spacings function instead likelihood function bayes estimates computed using markov chain monte carlo mcmc technique due implicit nature highest posterior density hpd intervals based mcmc samples evaluated compared terms simulated risks real data guinea pigs infected tuberculosis analysed justify suitability afore said estimation techniques specified censoring scheme â© springer science+business media llc part springer nature
10.1111/stan.12143 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047838423&doi=10.1111%2fstan.12143&partnerID=40&md5=f34fe1bd5ab05e33852597f0ee43c627 0,paper introduce threshold stochastic volatility model explanatory variables bayesian method considered estimating parameters proposed model via markov chain monte carlo mcmc algorithm gibbs sampling metropolis hastings sampling methods used drawing posterior samples parameters latent variables simulation study accuracy mcmc algorithm sensitivity algorithm model assumptions robustness posterior distribution different priors considered simulation results indicate mcmc algorithm converges fast posterior distribution robust different priors model assumptions real data example analyzed explain asymmetric behavior stock markets â© authors
10.1111/rssc.12213 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012938924&doi=10.1111%2frssc.12213&partnerID=40&md5=a1858ba96b6947d170a2b4ba89cfd5d3 1,recent advances molecular biology allow quantification transcriptome scoring transcripts differentially equally expressed two biological conditions although two tasks closely linked available inference methods treat separately primary model used estimate expression output post processed using differential expression model paper issues simultaneously addressed proposing joint estimation expression levels differential expression unknown relative abundance transcript either equal two conditions hierarchical bayesian model builds bitseq framework posterior distribution transcript expression differential expression inferred using markov chain monte carlo sampling shown model proposed enjoys conjugacy fixed dimension variables thus full conditional distributions analytically derived two samplers constructed reversible jump markov chain monte carlo sampler collapsed gibbs sampler latter found perform better cluster representation aligned reads transcriptome introduced allowing parallel estimation marginal posterior distribution subsets transcripts reasonable computing time fixed prior probability differential expression clusterwise sampler marginal posterior distributions raw sampler general prior structure also employed algorithm proposed benchmarked alternative methods using synthetic data sets applied real rna sequencing data source code available line https github com mqbssppe cjbitseq â© authors journal royal statistical society series c applied statistics published john wiley sons ltd behalf royal statistical society
10.1137/16M1084080 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046042349&doi=10.1137%2f16M1084080&partnerID=40&md5=bb1d138201f383597ba922021389accb 1,performing bayesian inference via markov chain monte carlo mcmc exceedingly expensive posterior evaluations invoke evaluation computationally expensive model system pdes recent work j amer statist assoc pp described framework constructing refining local approximations models mcmc simulation posterior adapted approximations harness regularity model reduce computational cost inference preserving asymptotic exactness markov chain describe two extensions work first prove samplers running parallel collaboratively construct shared posterior approximation ensuring ergodicity associated chain providing novel opportunity exploiting parallel computation mcmc second focusing metropolis adjusted langevin algorithm describe proposal distribution successfully employ gradients relevant information extracted approximation investigate practical performance approach using two challenging inference problems first subsurface hydrology second glaciology using local approximations constructed via parallel chains successfully reduce run time needed characterize posterior distributions problems days hours months days respectively dramatically improving tractability bayesian inference â© society industrial applied mathematics american statistical association
10.1177/0962280217754231 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043466873&doi=10.1177%2f0962280217754231&partnerID=40&md5=ed9c50ac7d9da8d0b7c5ee6c9bb19a07 0,present computational framework select accurate precise method measurement certain quantity access true value measurand typical use case several image analysis methods applied measure value particular quantitative imaging biomarker images accuracy measurement method characterized systematic error bias modeled polynomial true values measurand precision random error modeled gaussian random variable contrast previous works random errors modeled jointly across methods thereby enabling framework analyze measurement methods based similar principles may correlated random errors furthermore posterior distribution error model parameters estimated samples obtained markov chain monte carlo analyzed estimate parameter values unknown true values measurand framework validated six synthetic one clinical dataset containing measurements total lesion load biomarker neurodegenerative diseases obtained four automatic methods analyzing brain magnetic resonance images estimates bias random error good agreement corresponding least squares regression estimates reference â© author
10.1007/s11222-016-9719-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001837165&doi=10.1007%2fs11222-016-9719-1&partnerID=40&md5=ac527b0c21900651f9836b9f05db59bf 1,integro difference equations ides provide flexible framework dynamic modeling spatio temporal data choice kernel ide model relates directly underlying physical process modeled affect model fit predictive accuracy introduce bayesian non parametric methods ide literature means allow flexibility modeling kernel propose mixture normal distributions ide kernel built spatial dirichlet process mixing distribution model kernels shapes change location allows ide model capture non stationarity respect location reflect changing physical process across domain address computational concerns inference leverage use hermite polynomials basis representation process ide kernel incorporate hamiltonian markov chain monte carlo steps posterior simulation method example synthetic data demonstrates model successfully capture location dependent dynamics moreover using data set ozone pressure show spatial dirichlet process mixture model outperforms several alternative models ide kernel including state art ide literature gaussian kernel location dependent parameters â© springer science+business media new york
10.1016/j.matcom.2018.06.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050163861&doi=10.1016%2fj.matcom.2018.06.007&partnerID=40&md5=be37acc033c8da1c6031e5b44704065e 0,reversible jump algorithm useful markov chain monte carlo method introduced green allows switches subspaces differing dimensionality therefore model selection although method increasingly used key areas e g biology finance remains challenge implement paper focus simple sampling context order obtain theoretical results lead optimal tuning procedure considered reversible jump algorithm consequently easy implementation key result weak convergence sequence stochastic processes engendered algorithm represents main contribution paper knowledge first weak convergence result reversible jump algorithm sampler updating parameters according random walk result allows retrieve well known rule finding optimal scaling also leads answer question â€œwith probability parameter update proposed comparatively model switch iteration â€� â©
10.1214/17-BA1069 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050962301&doi=10.1214%2f17-BA1069&partnerID=40&md5=16d7adab6718d9543d05bd8aa17fc94c 3,introduce computationally efficient bayesian model predicting high dimensional dependent count valued data setting poisson data model latent gaussian process model become de facto model however model difficult use high dimensional settings data may tabulated different variables geographic regions times computational difficulties exacerbated acknowledging count valued data naturally non gaussian thus many current approaches bayesian inference require one carefully calibrate markov chain monte carlo mcmc technique avoid mcmc methods require tuning developing new conjugate multivariate distribution specifically introduce multivariate log gamma distribution provide substantial methodological development independent interest including results regarding conditional distributions marginal distributions asymptotic relationship multivariate normal distribution full conditional distributions gibbs sampler incorporate dependence variables regions time points multivariate spatio temporal mixed effects model mstm used demonstrate methodology use data obtained us census bureau longitudinal employer household dynamics lehd program particular approach motivated lehd quarterly workforce indicators qwis constitute current estimates important us economic variables â© international society bayesian analysis
10.2427/12777 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045329234&doi=10.2427%2f12777&partnerID=40&md5=80cf21275264ffa6827faf7f92373439 0,background previous models based limited number clinical parameters used far failed exhibit high accuracy prediction asthma persistence children number significance factors used proposed model play cardinal role prediction accuracy different models may lead different significant variables addition accuracy model medicine really important since accurate prediction illness persistence may improve prevention treatment intervention children risk aim study evaluate model effectively accurately predict asthma persistence children methods data asthmatic children analyzed new method predicting asthma outcome using principal component analysis pca combination bayesian logistic regression approach implemented markov chain monte carlo mcmc use pca required due multicollinearity among explanatory variables results method using appropriate models seems predict asthma accuracy sensitivity specificity respectively conclusion approach predicts asthma high accuracy gives steadier results terms positive negative patients provides better information influence factor demographic symptoms etc asthma prediction â© prex p rights reserved
10.1504/IJOR.2018.093506 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050805680&doi=10.1504%2fIJOR.2018.093506&partnerID=40&md5=26cad99203b0d3de3a2a69d68f3c7197 0,paper consider planning terminal locations intermodal transportation systems given number potential locations aim find appropriate number terminals provide economically efficient operation multiple service pairs needed simultaneously problem also inherent task determine optimal route paths service pair np hard problem present markov chain monte carlo mcmc based two layer method find suboptimal solution lower layer routing service pairs given particular location planning solved table based heuristic method considers efficiency fairness upper layer mapping cost function stationary distribution optimal planning solved based mcmc method integrates advantages simulated annealing slice sampling finally effectiveness heuristic mcmc based method demonstrated computer experiments copyright â© inderscience enterprises ltd
10.1007/s13171-018-0136-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053228839&doi=10.1007%2fs13171-018-0136-8&partnerID=40&md5=94c4babe421212a9f7f83b85e1105968 0,regression models size shape analysis developed model specified euclidean space landmark coordinates statistical models space known top space ambient space often easier practitioners understand alternative models quotient space size shapes consider bayesian linear size shape regression model response variable given labelled configuration matrix covariates represent quantities gender age important parameterize model identifiable use lq decomposition intercept term model purpose gamma priors inverse variance error term matrix fisher priors random rotation matrix flat priors regression coefficients used markov chain monte carlo algorithms used sampling posterior distribution particular using combinations metropolis hastings updates gibbs sampler proposed bayesian methodology illustrated application forensic facial data three dimensions investigate main changes growth describing relative movements landmarks gender time â© author
10.1007/978-3-319-70942-0_6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037863623&doi=10.1007%2f978-3-319-70942-0_6&partnerID=40&md5=48a2972c3ec8b833c28b61b80bdaa483 0,paper evaluates performances value risk var expected shortfall well volatility forecasts class risk models specifically focusing garch integrated garch asymmetric garch models gjr garch exponential garch smooth transition garch models models incorporate four error probability distributions gaussian studentâ€™s skew studentâ€™s generalized error distribution ged employ bayesian markov chain monte carlo sampling methods estimation forecasting present backtesting measures var expected shortfall forecasts implement two loss functions evaluate volatility forecasts empirical results based p u japanâ€™s nikkei var forecasting study reveals level smooth transition model second order logistic function skew studentâ€™s error compares favorably terms violation rates markets volatility predictive abilities egarch model ged error best model markets â© springer international publishing ag
10.1002/sim.8010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055176992&doi=10.1002%2fsim.8010&partnerID=40&md5=fd6a160000b9394fbc323c50007974fb 0,models excess mortality random effects used estimate regional variation relative net survival cancer patients statistical inference models based markov chain monte carlo mcmc methods computationally intensive therefore feasible routine analyses cancer register data study assessed performance integrated nested laplace approximation inla monitoring regional variation cancer survival poisson regression model excess mortality including spatially correlated unstructured random effects fitted data patients diagnosed ovarian breast cancer finland follow using period approach five year calendar time windows estimated standard deviations associated variation hospital districts ii municipalities within hospital districts posterior estimates based inla approach compared based mcmc simulation estimates variation parameters similar two approaches variation within hospital districts dominated total variation municipalities proportion average variation within hospital districts posterior interval total variation ovarian breast cancer respectively estimation regional variation inla approach accurate fast easy implement using r inla package â© john wiley sons ltd
10.1177/0962280218754928 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043706966&doi=10.1177%2f0962280218754928&partnerID=40&md5=d1a9e882e8eae06c5f53cd500cf967d6 0,meta analysis interventions usually relies randomized controlled trials however dominant source information comes single arm studies results randomized controlled trials lack generalization due strict inclusion exclusion criteria vital synthesize sources evidence one challenge synthesizing sources single arm studies usually less reliable randomized controlled trials due selection bias confounding factors paper propose bayesian hierarchical framework purpose bias reduction efficiency gain framework three methods proposed bivariate generalized linear mixed effects models hierarchical power prior model hierarchical commensurate prior model design difference potential biases considered models within hierarchical power prior hierarchical commensurate prior models offer downweight single arm studies flexibly hierarchical commensurate prior model recommended primary method evidence synthesis accuracy robustness illustrate methods applying models two motivating datasets evaluate performance simulation studies finish discussion advantages limitations methods well directions future research area â© author
10.1016/B978-0-444-63964-6.00005-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049934939&doi=10.1016%2fB978-0-444-63964-6.00005-2&partnerID=40&md5=a4f2207b30e824a8ea00bda19c7fafc3 0,previous work reduced order population pharmacokinetic pk model used within bayesian inference framework predict individualized patient dosing regimens shown reduced order model adequate individualized dosing gabapentin given minimum number plasma samples given patient however purely empirical model explain patients different dosing needs accordingly work couple advanced compartment transit oral absorption model full physiologically based pk model parameterized using two level hierarchical bayesian approach coupled model provides capability understand variable oral absorption also disposition drug proposed model based strategy individualized dosing applied dosing gabapentin using retrospective data literature computations show standard starting regimen mg every h likely result efficacious dosing substantial proportion patients additionally proposed approach able incorporate urine data seamless way inform extent absorption without assuming data perfect mechanistic absorption model elucidated uncertainty absorption plays role variability exposure seen across patient population also suggested apparent absorption site likely full upper gi localized segment due transit times required fit data study model implementation markov chain monte carlo computations performed using cmdstan package â© elsevier b v
10.1007/978-3-319-96661-8_30 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051738688&doi=10.1007%2f978-3-319-96661-8_30&partnerID=40&md5=8c1c6ad13b00227ba48f4efcf02e4a37 0,new tasks trivial learn others almost impossible determines easy learn arbitrary task similar prior beliefs new visual scenes colors perception new stimuli priors structure new tasks shapes learning generalization abilities quantifying visual priors led major insights visual system works quantifying priors tasks remains formidable goal even clear define task focus tasks natural mapping graphs develop method quantify humansâ€™ priors â€œtask graphsâ€� combining new modeling approaches markov chain monte carlo people mcmcp process whereby agent learns data generated another agent recursively show method recovers priors accurately standard mcmc sampling approach additionally propose novel low dimensional â€œsmoothâ€� sense graphs differ fewer edges given similar probabilities parametrization probability distributions graphs allows accurate recovery prior better generalization also created online experiment platform gamifies mcmcp algorithm allows subjects interactively draw task graphs use platform collect human data several navigation social interactions tasks show priors tasks non trivial structure deviating significantly null models insensitive graphical information priors also notably differ navigation social domains showing fewer differences cover stories within domain finally extend framework general case quantifying priors exchangeable random structures â© springer nature switzerland ag
10.1137/16M1066865 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043458602&doi=10.1137%2f16M1066865&partnerID=40&md5=fddb24616f3da38375e5060caa1b9ec9 0,goal solve certain dynamic programming equations associated given markov chain x using regression based monte carlo algorithm specifically assume model x known full detail root sample x xm process available stratification space suitable choice probability measure î½ design new resampling scheme allows us compute local regressions basis functions stratum combination stratification resampling allows us compute solution dynamic programming equation possibly large dimensions using relatively small set root paths assess accuracy algorithm establish nonasymptotic error estimates l î½ numerical experiments illustrate good performance even = âˆ’ root paths â© society industrial applied mathematics
10.1016/bs.host.2018.07.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051678126&doi=10.1016%2fbs.host.2018.07.001&partnerID=40&md5=43a8849f673cbe56113da9c4be643feb 0,chapter focus exploring basic ideas bayesian markov networks associated inferential procedures classical bayesian paradigm chapter draws heavily article friedman et al end chapter conceptual well hands exercises provided better understanding subject matter author welcomes constructive criticism suggestions readers book â© elsevier b v
10.1190/GEO2017-0239.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038098118&doi=10.1190%2fGEO2017-0239.1&partnerID=40&md5=43bfd6d6089d1c3166da51d11a15a4a8 2,seismic reservoir characterization focuses prediction reservoir properties based available geophysical petrophysical data inverse problem generally includes continuous properties petrophysical elastic attributes discrete properties lithology fluid classes developed joint probabilistic inversion methodology prediction petrophysical elastic properties lithology fluid classes combined statistical rock physics bayesian seismic inversion elastic attributes depend continuous petrophysical variables porosity clay content discrete lithology fluid classes nonlinear rock physics relationship together seismic model relates elastic attributes velocities density seismic response reflectivity traveltime amplitudes advantage integrated approach inversion method accounts uncertainty associated step modeling workflow lithology fluid classes assigned markov random field prior model capture vertical continuity vertical sorting lithology fluid classes rock fluid properties general gaussian spatially coupled gaussian mixture prior model based lithology fluid classes constructed forward geophysical operator includes lithology fluid dependent rock physics model linearized seismic model based convolution seismic wavelet reflectivity coefficient series solution inverse problem consists posterior distributions petrophysical elastic properties lithology fluid classes proposed efficient markov chainmonte carlo algorithm sample posterior models assess uncertainty methodology demonstrated seismic cross section survey norwegian sea shows promising results consistent well log data measured well location well reliable prediction uncertainties â© society exploration geophysicists rights reserved
10.1007/s13253-018-0335-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054196470&doi=10.1007%2fs13253-018-0335-8&partnerID=40&md5=87b47c1357d8e740eefdb56f28fbfb7f 0,capture mark reencounter studies pollockâ€™s robust design combines methods open populations methods closed populations open population features robust design allow estimation rates death permanent emigration closed population features enhance estimation population sizes describe similar design use removal data data collection occurs secondary sampling occasions clustered within primary sampling periods primary sampling periods intervals brief enough duration safely assumed population unchanged births deaths immigration emigration population change movement occurs primary sampling periods model provides basis inference population size changes population size movement rates among sample locations primary sampling periods movement rates modeled functions distance time capture probabilities modeled function effort apply model data obtained attempting eradicate introduced population veiled chameleons chamaeleo calyptratus island maui hawaii supplementary materials accompanying paper appear online â© international biometric society
10.1016/j.eneco.2018.03.032 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049300505&doi=10.1016%2fj.eneco.2018.03.032&partnerID=40&md5=ee1f6fd972479b0600bdcb2316cc8ddb 0,crude oil markets quite volatile risky past decades due large fluctuations oil prices contribute current debate testing existence leverage effect considering daily spot returns wti brent crude oil markets studying direct impact leverage effect measures risk var cvar specifically model spot crude oil returns using stochastic volatility sv models various distributions errors find introduction leverage effect traditional sv model normally distributed errors capable adequately estimating risk conservative oil suppliers wti brent markets tends overestimate risk speculative oil suppliers results also show financial regulatorsâ€™ model choice supply demand side affected introduction leverage focusing instead firm internal risk management results show introduction leverage useful firms demand side oil use var risk management particularly worried magnitude losses exceeding var wanting minimize opportunity cost capital using logic firms supply side better considering leverage effect â© elsevier b v
10.3844/jcssp.2018.1115.1125 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052861202&doi=10.3844%2fjcssp.2018.1115.1125&partnerID=40&md5=3099b28c659f6b44195dce287344a173 0,bayesian network structure learning considered complex task number possible structures grows exponentially number variables two main methods used bayesian network structure learning conditional independence method structure created consistently independence tests performed data heuristic search method explores structure space hybrid algorithms combine aforementioned methods study propose combination common metrics used evaluate bayesian structures fuzzy system idea different metrics evaluate different properties structure proposed fuzzy system used metric evaluate bayesian networks structures heuristic search algorithm based monte carlo markov chains algorithm evaluated within context synthetic databases comparison algorithms processing time results shown despite increase processing time proposed method improved structure learning process â© ademar crotti junior beatriz wilges silvia modesto nassar
10.3233/JIFS-171491 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051373996&doi=10.3233%2fJIFS-171491&partnerID=40&md5=d50f27b9239fc13b12e3053207dbc035 0,aim paper introducing method based fuzzy time failure fttf improve reliability analysis complex engineering systems based fault tree analysis method focuses quantitative part fault trees either static dynamic analysis compute failure probabilities fttf model developed estimate reliability system solve aforetime methods problems presented fttf model able figure construction consist static dynamic gates fttf distributions integrated fuzzy monte carlo simulation fmcs techniques analyzing possibilistic functions associated fuzzy probability distributions basic event using fuzzy algorithm gates fttf generated top event ttf evaluated case studies used demonstrate priority method exact evaluation compared solving methods like bn analytical solution markov chain traditional fuzzy fault tree modeling much less effort higher accuracy finally model implemented emergency detection system eds useful system aerospace space applications â© ios press authors
10.1007/s10955-017-1912-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033437799&doi=10.1007%2fs10955-017-1912-x&partnerID=40&md5=80646aacedd25cec0a97f5b30de31517 0,consider coupling past implementation randomâ€“cluster heat bath process study random running time coupling time focus hypercubic lattices embedded tori dimensions one three cluster fugacity least one make number conjectures regarding asymptotic behaviour coupling time motivated rigorous results one dimension monte carlo simulations dimensions two three amongst findings observe generic parameter values distribution appropriately standardized coupling time converges gumbel distribution standard deviation coupling time asymptotic explicit universal constant multiple relaxation time perhaps surprisingly observe results hold criticality coupling time closely mimics coupon collectorâ€™s problem also critical point provided cluster fugacity value transition becomes discontinuous finally consider analogous questions single spin ising heat bath process â© springer science+business media llc part springer nature
10.1016/j.strusafe.2017.10.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032802354&doi=10.1016%2fj.strusafe.2017.10.011&partnerID=40&md5=493afe803a268e70056f6d7787e704cc 1,paper presents new probabilistic site characterization approach soil classification property estimation using sounding data multiple cone penetration tests cpts project site hidden markov random field hmrf model based bayesian clustering approach developed describe heterogeneity properties statistically homogeneous soil layers also correlation spatial distributions different soil layers latter well considered existing cpt interpretation methods monte carlo markov chain based expectation maximization mcmc em algorithm adopted calibrate established hmrf model subsurface soil rock stratification pertinent soil properties estimated probabilistic manner proposed cpt interpretation approach validated demonstrated using series numerical examples including using real cpt data shown proposed method able accurately identify soil layers pinpoint boundaries provide reasonable estimates associated soil properties addition comparative studies show combining analysis cpt data multiple soundings rather interpreting separately significantly enhance accuracy interpretation simplify subsequent task interpreting stratigraphic profiles â© elsevier ltd
10.1509/jm.15.0523 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045886719&doi=10.1509%2fjm.15.0523&partnerID=40&md5=a7accc46a8ec06d06028e82b1a6c714a 2,authors study specialized personal incentives spis cash rewards granted salespeople meeting interim performance goals within regular sales quota period monthly quarterly etc firms often institute multiple spis authors able investigate whether different sales achievement trajectories differential impacts salespeople period end sales performance authors find steadily growing sales trajectory sales period strongly associated period end success sales trajectory relatively flat early sharp spike later period furthermore although salespeople high performance prior month e high performance state may able draw superior selling strategies compared salespeople experience boost sales performance current month earning spis notably authors also find although earning spis benefits salespeople u shaped relationship salesperson performance state month end sales performance specific number spis earned probability meeting exceeding month end quotas boosted salespeople low high performance states salespeople medium performance state â© american marketing association
10.1007/s11538-018-0518-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055290535&doi=10.1007%2fs11538-018-0518-z&partnerID=40&md5=de84667fc268cea1595caff87821bbf1 0,study apply bayesian paradigm parameter identification well studied semi linear reactionâ€“diffusion system activator depleted reaction kinetics posed stationary well evolving domains provide mathematically rigorous framework study inverse problem finding parameters reactionâ€“diffusion system given final spatial pattern stationary domain parameters finite dimensional evolving domain consider problem identifying evolution domain e time dependent function whilst others considered inverse problems using optimisation techniques bayesian approach provides rigorous mathematical framework incorporating prior knowledge uncertainty observation parameters resulting approximation full probability distribution parameters given data furthermore using previously established results prove well posedness results inverse problem using well posedness forward problem although numerical approximation full probability computationally expensive parallelised algorithms make problem solvable using high performance computing â© author
10.1002/ecs2.2060 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041241370&doi=10.1002%2fecs2.2060&partnerID=40&md5=7a153b916821111f83a14e11e7efcebb 1,plant functional traits research revealed many interesting important patterns among morphological physiological life history traits environment exemplified trade offs groups traits embodied leaf wood economics spectra inferences empirical studies often constrained correlative nature analyses availability trait data focus easily measured traits however empirical studies fundamental modeling endeavors aiming enhance understanding functional traits scale affect example community dynamics ecosystem productivity take complementary approach utilizing individual based model tree growth mortality allometrically constrained growth carbon allocation acgca model investigate theoretical trait space tts north american trees model includes parameters representing allometric physiological anatomical traits overlapping leaf wood economics spectra traits using bayesian approach fit acgca model individual tree heights diameters usfs forest inventory analysis fia dataset constraints literature based priors fitting model million fia recordsâ€”aggregated across individuals species sitesâ€”produced posterior distribution traits leading realistic growth explored multidimensional posterior distribution tts evaluate traitâ€“trait relationships emerging acgca model compare empirical patterns reported literature three notable bivariate correlations among possible trait pairs contained tts however stepwise regressions uncovered complicated structure subset traitsâ€”related photosynthesis e g radiation use efficiency maintenance respiration â€”exhibited strong multivariate trade offs half traitsâ€”mostly related allometries construction costsâ€”varied independently traits interestingly specific leaf area related several rarely measured root traits trade offs contained tts generally reflect mass balance related carbon allocation engineering mostly related allometries trade offs represented acgca model point potentially important traits explored field studies e g root traits branch senescence rates â© fell et al
10.1214/18-EJS1435 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047801825&doi=10.1214%2f18-EJS1435&partnerID=40&md5=10e8f8d8968b34a7b93d306ee4eb6d3c 0,informative sampling design leads selection units whose inclusion probabilities correlated response variable interest inference population model performed resulting observed sample without adjustment biased population generative model one approach produces asymptotically unbiased inference employs marginal inclusion probabilities form sampling weights used exponentiate likelihood contribution pseudo likelihood used form pseudo posterior distribution conditions posterior consistency restrict applicable sampling designs pairwise inclusion dependencies asymptotically limit many sampling designs excluded restriction example multi stage design samples individuals within households viewing household population dependence among individuals attenuate propose targeted approach paper inference focused pairs individuals sampled units example substance use one spouse shared household conditioned substance use spouse formulate pseudo likelihood weights based pairwise second order probabilities demonstrate consistency removing requirement asymptotic independence replacing restrictions higher order selection probabilities approach provides nearly automated estimation procedure applicable model specified data analyst demonstrate method national survey drug use health â© institute mathematical statistics rights reserved
10.1111/twec.12665 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046405702&doi=10.1111%2ftwec.12665&partnerID=40&md5=60a6850912329c25af3638b4c6f85004 0,paper structurally estimates dynamic discrete choice model exporting importing model provides framework analyse determinants firm decision export import allowing current decision affect future productivity considering panel danish manufacturing firms period simple description data reveals considerable firm heterogeneity significant export import activity premia frequent incidence simultaneous exporting importing high persistence scope firm trading structural estimation model shows marked difference demand elasticities export markets characterised elastic demand tougher competition lower markup domestic market estimates also indicate firms larger capital holding paying higher wages cost efficient even controlling productivity additionally estimates imply substantial sunk fixed costs exporting importing consistent hypothesis self selection productive firms trading also exists positive correlation size costs scale firm operation moreover exporting importing improve firm productivity therefore learning effects drive self selection process â© john wiley sons ltd
10.1214/18-EJS1479 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053883800&doi=10.1214%2f18-EJS1479&partnerID=40&md5=0868f65602880223cfbfee3e334681a1 0,faced high frequency streams data clustering raises theoretical algorithmic pitfalls introduce new adaptive online clustering algorithm relying quasi bayesian approach dynamic e time dependent estimation unknown changing number clusters prove approach supported minimax regret bounds also provide rjmcmc flavored implementation called pacbo see https cran r project org web packages pacbo index html give convergence guarantee finally numerical experiments illustrate potential procedure â© institute mathematical statistics rights reserved
10.1016/j.spasta.2018.08.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053718334&doi=10.1016%2fj.spasta.2018.08.007&partnerID=40&md5=24692881fc589215b9749d78f7f40e80 0,propose bayesian spatial model time event data allow censoring mechanism depend covariates spatial structure survival model incorporates cure rate fraction assumes time event follows weibull distribution covariates race stage grade marital status age diagnosis linked scale parameter right censoring primary concern consider joint logistic regression model death versus censoring indicator allowing dependence covariates including spatial structure via use random effects apply models examine prostate cancer data surveillance epidemiology end results seer registry displays marked spatial variation â© elsevier b v
10.1177/0962280218784757 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049887579&doi=10.1177%2f0962280218784757&partnerID=40&md5=5438087c885324c7f5199dca079c287b 0,traditional joint models longitudinal time event outcome linear mixed model assuming normal random errors used model longitudinal process however many circumstances normality assumption violated linear mixed model appropriate sub model joint models addition linear mixed model models conditional mean longitudinal outcome appropriate clinical interest lies making inference prediction median lower upper ends longitudinal process end quantile regression provides flexible distribution free way study covariate effects different quantiles longitudinal outcome robust deviation normality also outlying observations article present advocate linear quantile mixed model longitudinal process joint models framework development motivated large prospective study huntingtonâ€™s disease primary clinical interest utilizing longitudinal motor scores early covariates predict risk developing huntingtonâ€™s disease develop bayesian method based locationâ€“scale representation asymmetric laplace distribution assess performance extensive simulation study demonstrate linear quantile mixed model based joint models approach used making subject specific dynamic predictions survival probability â© author
10.1016/bs.host.2018.08.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053149918&doi=10.1016%2fbs.host.2018.08.001&partnerID=40&md5=0f4afefd6c4427f48d5efcf306a98834 0,acquisition time series data supported recent popularization genomic sequencing revealed dynamic nature microbial community recent advances analyzing community dynamics microbial species cover applying existing traditional methods also developing new methods chapter introduces traditional novel mathematical statistical approaches analyze community dynamics microbial species former part introduce data fitting methods link time series data community dynamics mechanistic modeling data driven approaches later part specifically introduce traditional new methods analyze time series data community dynamics based reconstruction attractors â© elsevier b v
10.1111/1556-4029.13926 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054565760&doi=10.1111%2f1556-4029.13926&partnerID=40&md5=c0b1ea6b9e2336d765d4b1759c77e1f1 0,completion third molar roots played important role ascertaining whether individuals may legal threshold age often taken â years study demonstrates root apex completion third molar relatively uninformative regarding threshold age â years sample males mean age attainment root apex completion third mandibular molars â years paper also considers legal age threshold problem cases third mandibular molar completely formed outlines use parametric models bayesâ€™ factors evaluate dental evidence statistically appropriate ways attempts resolve confusion age within stage versus age attainment likelihood ratios versus diagnostic tests prior odds case versus prior density age distribution â© american academy forensic sciences
10.18637/jss.v086.i07 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053285199&doi=10.18637%2fjss.v086.i07&partnerID=40&md5=de3e5c5bcdaea6952d4f31aeb5c81e2a 0,probabilistic bayesian inferences typically want compute properties posterior distribution describing knowledge unknown quantities context particular dataset assumed prior information marginal likelihood also known â€œevidenceâ€� key quantity bayesian model selection diffusive nested sampling algorithm variant nested sampling powerful tool generating posterior samples estimating marginal likelihoods effective solving complex problems including many posterior distribution multimodal strong dependencies variables dnest open source mit licensed multi threaded implementation algorithm c++ along associated utilities including â€˜rjobjectâ€™ class template finite mixture models ii python package allowing basic use without c++ coding paper demonstrate dnest usage examples including simple bayesian data analysis finite mixture models approximate bayesian computation â© american statistical association rights reserved
10.1080/15598608.2018.1489919 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052097024&doi=10.1080%2f15598608.2018.1489919&partnerID=40&md5=5fc357c2ad08099c2da342c9f71db8d7 0,poisson negative binomial distributions frequently used fit count data limitation poisson distribution mean variance assumed equal assumption far realistic many practical applications negative binomial distribution used cases overdispersion given variance higher mean two parameter double poisson distribution introduced efron may considered useful alternative poisson negative binomial distributions given account overdispersion underdispersion article obtain maximum likelihood bayesian estimates double poisson distribution also extend proposed methodology situation excess zeros sample applications double poisson distribution considered assuming simulated real data sets â© â© grace scientific publishing llc
10.1111/rssa.12266 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017102370&doi=10.1111%2frssa.12266&partnerID=40&md5=3e333af4befc4c2dc4817f56ede97e6b 2,objective analysis explore temporal spatial variation teen birth rates tbrs across counties usa using hierarchical bayesian models prior examination spatiotemporal variation tbrs limited reliance large scale geographies states potential instability tbrs smaller geographical scales counties implemented hierarchical bayesian models spaceâ€“time interaction terms spatially structured unstructured random effects produce smoothed county level tbr estimates allowing examination spatiotemporal patterns trends tbrs smaller geographic scale across usa results may help highlight us counties tbrs higher lower inform efforts reduce birth rates adolescents usa published article u government work public domain usa
10.1016/j.spinee.2017.06.036 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026286858&doi=10.1016%2fj.spinee.2017.06.036&partnerID=40&md5=ec91aaa8e310e3695ddd9c7164005f6a 3,background context anterior cervical discectomy fusion acdf cervical disc replacement cdr acceptable surgical options treatment cervical myelopathy radiculopathy date limited economic analyses assessing relative cost effectiveness two level acdf versus cdr purpose purpose study determine year cost effectiveness two level acdf versus cdr study design study design secondary analysis prospectively collected data patient sample patients prestige cervical disc investigational device exemption ide study underwent either two level cdr two level acdf included study outcome measures outcome measures cost quality adjusted life years qalys materials methods markov state transition model used evaluate data two level prestige cervical disc ide study data item short form health survey converted utilities using short form sf algorithm costs calculated payer perspective qalys used represent effectiveness probabilistic sensitivity analysis psa performed using monte carlo simulation results base case analysis assuming year old person failed appropriate conservative care generated year cost cdr acdf cervical disc replacement acdf generated qalys respectively incremental cost effectiveness ratio icer calculated qaly cdr monte carlo simulation validated base case scenario cervical disc replacement average cost confidence interval ci â€“ average effectiveness ci â€“ anterior cervical discectomy fusion average cost ci â€“ average effectiveness ci â€“ icer calculated qaly respect cdr using qaly willingness pay wtp cdr cost effective strategy selected time simulation conclusions two level cdr acdf cost effective strategies years neither strategy found cost effective icer greater qaly wtp threshold assumptions used analysis strongly validated results psa â© elsevier inc
10.1111/rssb.12289 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052365098&doi=10.1111%2frssb.12289&partnerID=40&md5=149b92ad1793de2298d37555cb011acc 0,introduce class generative network models insert edges connecting starting terminal vertices random walk network graph within taxonomy statistical network models class distinguished permitting location new edge depend explicitly structure graph nonetheless statistically computationally tractable limit infinite walk length model converges extension preferential attachment modelâ€”in sense motivated alternatively asking preferential attachment approximation theoretical properties including limiting degree sequence studied analytically entire history graph observed parameters estimated maximum likelihood final graph available history imputed using markov chain monte carlo methods develop class sequential monte carlo algorithms generally applicable sequential network models may interest right model parameters recovered single graph generated model applications data clarify role random walk length length scale interactions within graph â© royal statistical society
10.26633/RPSP.2018.10 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052016154&doi=10.26633%2fRPSP.2018.10&partnerID=40&md5=72f7b99220c7dda6e18c64af65f23c46 0,objective evaluate cost effectiveness integral model ambulatory treatment patients presented acute coronary syndrome methods economic evaluation made quasi experimental intervention study included patients aged years presented acute coronary syndrome intervention group n = received integral model ambulatory treatment based managed care disease management control group n = received conventional cardiovascular rehabilitation one year follow presentation cardiovascular events hospitalizations evaluated probabilistic markov model developed study perspective applied within general system health social security colombia including direct health costs time horizon years discounts costs effectiveness measure effectiveness quality adjusted life years qalys probabilistic multivariate sensitivity analysis performed using montecarlo simulation results year follow direct costs related value paid average usd control group usd intervention group probabilistic sensitivity analysis simulations located quadrant corresponding incremental negative costs positive incremental effectiveness evaluated intervention lower cost effective simulations average annual savings per patient usd per qaly observed conclusions integral model ambulatory treatment implemented patients suffered acute coronary syndrome found less expensive effective compared conventional care considering dominant alternative recommended model care population â© pan american health organization rights reserved
10.1016/j.ifacol.2018.08.015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052646695&doi=10.1016%2fj.ifacol.2018.08.015&partnerID=40&md5=72663c20a953b2f0503738c533d23a6d 0,work propose stratified sampling method statistically check probabilistic computation tree logic pctl formulas discrete time markov chains sequential probability ratio test distinct previous statistical verification methods using independent monte carlo sampling algorithm uses stratified samples negatively correlated thus give lower variance experiments demonstrate new algorithm uses smaller number samples given confidence level several benchmark examples â©
10.1016/j.csda.2018.08.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052750838&doi=10.1016%2fj.csda.2018.08.004&partnerID=40&md5=f8202863c6581ed77426db53d8611048 0,latent variable hidden markov models lvhmms important statistical methods exploring possible heterogeneity data explaining pattern subjects moving one group another time classic subject time homogeneous assumptions transition matrices transition model well emission distribution observed process may inappropriate interpret heterogeneity subject level end general extension lvhmm proposed address heterogeneity multivariate longitudinal data subject level occasion level main modeling strategy observed time sequences first grouped different clusters within cluster observed sequences formulated via latent variable hidden markov model local heterogeneity occasion level characterized distribution related latent states global heterogeneity subject level identified finite mixture model compared existing methods appeal underlying proposal capacity accommodating non homogeneous patterns state sequences emission distributions across subjects simultaneously result proposal provides comprehensive framework exploring various kinds relevance among multivariate longitudinal data within bayesian paradigm markov chains monte carlo mcmc method used implement posterior analysis gibbs sampler used draw observations related full conditionals posterior inferences carried based simulated observations empirical results including simulation studies real example used illustrate proposed methodology â© elsevier b v
10.1177/0962280218766964 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045035017&doi=10.1177%2f0962280218766964&partnerID=40&md5=32b187c5689934e428b1dd8f16222779 0,hidden markov models stochastic models observations assumed follow mixture distribution parameters components governed markov chain unobservable issues related estimation poisson hidden markov models observations coming mixture poisson distributions parameters component poisson distributions governed state markov chain unknown transition probability matrix explained methods applied data vibrio cholerae counts reported every month year span christian medical college vellore india using viterbi algorithm best estimate state sequence obtained hence transition probability matrix mean passage time states estimated confidence interval mean passage time estimated via monte carlo simulation three hidden states estimated markov chain labelled â€˜lowâ€™ â€˜moderateâ€™ â€˜highâ€™ mean counts estimated average duration stay months respectively environmental risk factors studied using markov ordinal logistic regression analysis significant association found disease severity levels climate components â© author
10.13031/aea.12420 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046097768&doi=10.13031%2faea.12420&partnerID=40&md5=b368d2b2bcc60c2b2f2c82d864a73056 0,prediction agricultural machinery fatigue life increasing importance machine developers must produce durable reliable machines globalized market different local operating conditions mathematical tools model simulate variable loading agricultural machines necessary fatigue life prediction modeling based measured loads real world operations article loads four rotor rake recorded grass swathing markov chains used model transitions machine operating conditions field swathing headland turning sequences turning points present load signals markov transition probabilities trained using recoded data fatigue life predicted via executing monte carlo simulations based trained markov models differences accumulated fatigue damage predicted simulations measured data mean value standard deviation equal respectively evaluation trained model new data present training dataset recorded swathing different grass field resulted fatigue damage difference mean standard deviation equal respectively fatigue damage difference reasonable region considering fatigue life affected high amplitude individual cycles â© american society agricultural biological engineers
10.1093/aje/kwx201 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040629195&doi=10.1093%2faje%2fkwx201&partnerID=40&md5=9064cda444dc9d32cbfd0112695c7b38 0,seasonal influenza epidemics occur year round tropics complicating planning vaccination programs built individual level longitudinal model baseline antibody levels time infection subsequent rise decay antibodies postinfection using influenza h n pdm data sources singapore noncommunity cohort real time polymerase chain reaction confirmed infections least serological sample collected participant may october n = community cohort serological samples collected may october n = model hierarchical account interval censoring interindividual variation model parameters estimated via reversible jump markov chain monte carlo algorithm using custom designed r https www r project org c++ https isocpp org code infection antibody levels peaked weeks half life weeks followed slower decrease year approximately preinfection levels third wave seropositivity rate population level antibody titer dropped level end first pandemic wave results analysis consistent hypothesis population level effect individuals waxing waning antibodies influences influenza seasonality tropics â© author
10.1016/j.procs.2018.04.074 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051263570&doi=10.1016%2fj.procs.2018.04.074&partnerID=40&md5=6695dbe505d0fd67fba622c5b7ff98d3 0,transportation modeling simulation play important role planning management emergency evacuation often indispensable preparedness timely response extreme events occurring highly populated areas reliable robust agent based evacuation models great importance support evacuation decision making nevertheless models rely numerous hypothetical causal relationships evacuation behavior variety factors including socio economic characteristics storm intensity understanding impacts factors evacuation behaviors e g destination route choices crucial preparing optimal evacuation plans paper aims contribute literature integrating well calibrated behavior models agent based evacuation simulation model context hurricane evacuation specifically discrete choice models developed estimate evacuation behaviors based large scale survey data northern new jersey monte carlo markov chain mcmc sampling method used estimate evacuation propensity destination choices whole population finally evacuation million residents study area simulated using agent based simulation built matsim agent based modeling framework proposed paper provides integrated methodology evacuation simulation specific consideration agents behaviors simulation results need validated verified using real world evacuation data â© authors published elsevier b v
10.1007/s00165-018-0470-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054536367&doi=10.1007%2fs00165-018-0470-6&partnerID=40&md5=7cf87516fe0d5e5883d7a1ba74b4d5d3 0,computation steady state probabilities important aspect analysing biological systems modelled probabilistic boolean networks pbns small pbns efficient numerical methods compute steady state probabilities pbns exist based markov chain state transition matrix however large pbns numerical methods suffer state space explosion problem since state space size exponential number nodes pbn fact use statistical methods monte carlo methods remain feasible approach address problem large pbns methods usually rely long simulations pbn since slow simulation impede analysis efficiency simulation procedure becomes critical intuitively parallelising simulation process ideal way accelerate computation recent developments general purpose graphics processing units gpus provide possibilities massively parallelise simulation process work propose trajectory level parallelisation framework accelerate computation steady state probabilities large pbns use gpus maximise computation efficiency gpu develop dynamical data arrangement mechanism handling different size pbns gpu specially propose reorder split method handle large dense pbns besides develop specific way storing predictor functions pbn state pbn gpu memory moreover introduce strongly connected component scc based network reduction technique accelerate computation speed experimental results show gpu based parallelisation gains approximately fold speedup real life pbn compared state art sequential method â© british computer society
10.1097/EDE.0000000000000761 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044314160&doi=10.1097%2fEDE.0000000000000761&partnerID=40&md5=baad9228f7cc2596d4f05cb7e5155723 3,background considerable scientific interest associations protracted low dose exposure ionizing radiation occurrence specific types cancer methods associations ionizing radiation site specific solid cancer mortality examined among nuclear workers employed france united kingdom united states workers monitored external radiation exposure follow encompassed million person years radiation mortality associations estimated using maximum likelihood method using markov chain monte carlo method latter used fit hierarchical regression model stabilize estimates association results analysis included deaths attributable solid cancer common lung prostate colon cancer using maximum likelihood method quantify associations radiation dose site specific cancer obtained positive point estimates oral esophagus stomach colon rectum pancreas peritoneum larynx lung pleura bone connective tissue skin ovary testis thyroid cancer addition obtained negative point estimates cancer liver gallbladder prostate bladder kidney brain estimated coefficients exhibited substantial imprecision employing hierarchical model stabilization little impact estimated associations commonly observed outcomes less frequent cancer types stabilized estimates tended take less extreme values greater precision estimates obtained without stabilization conclusions results provide evidence regarding associations low dose radiation exposure cancer â© wolters kluwer health inc
10.1371/journal.pone.0191822 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041032228&doi=10.1371%2fjournal.pone.0191822&partnerID=40&md5=9ac2cc218b88cae8cf6ecf254eb6a28d 0,objective evaluate intravoxel incoherent motion ivim diffusion weighted imaging dwi dynamic contrast enhanced dce magnetic resonance imaging mri sequences quantitative characterization anal fistula activity methods retrospective study approved institutional review board one hundred two patients underwent mri clinical suspicion anal fistula forty three patients demonstrable anal fistulas met inclusion criteria quantitative analysis included measurement dce ivim parameters reference standard clinical activity based medical records statistical analyses included bayesian analysis markov chain monte carlo multivariable logistic regression receiver operating characteristic analyses results brevity enhancement defined time difference wash wash longer active inactive fistulas p = regression coefficients multivariable logistic regression analysis revealed brevity enhancement increased normalized perfusion area curve decreased presence active fistulas p = p = respectively cross validation logistic regression model included quantitative perfusion parameters dce ivim performed significantly better ivim p area curves distinguishing patients active inactive fistulas confidence interval ci model ivim ci model ivim brevity enhancement ci model ivim dce parameters conclusion inclusion brevity enhancement measured dce mri improved assessment anal fistula activity ivim dwi â© lefrancois et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1177/0021998317704708 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040068349&doi=10.1177%2f0021998317704708&partnerID=40&md5=8b13041c3ea90d91c2e0c525ffea73b0 0,paper presents probabilistic first ply failure analysis composite laminates using high fidelity multi scale approach called saf micromechanics based approach static failure end square hexagonal representative unit cells composites developed calculate constituent stresses help bridging matrix macro micro stresses referred stress amplification factor matrix separate failure criteria applied constituents fiber matrix interface order calculate damage state successful implementation saf requires strength properties constituents difficult expensive characterize experimentally limiting use saf early design stages structure obstacle overcome integrating bayesian inference approach saf academic sample problem cantilever beam used first demonstrate calibration procedure bayesian inference calibrates saf first ply failure model parameters posterior distributions prior probability density functions drawn lamina test data posterior statistics used calculate probabilistic first ply failure range different laminates â© â© author
10.1007/978-3-030-00928-1_76 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054096938&doi=10.1007%2f978-3-030-00928-1_76&partnerID=40&md5=9ae5d4c8c34ac5ae9d6d4105c36ec4f6 0,typical segmentation methods produce single optimal solution fail inform confidence uncertainty object boundaries ii alternate close optimal solutions estimate uncertainty methods intend sample segmentations associated posterior model using markov chain monte carlo mcmc sampling perturbation models however guarantee sampling true posterior deviating significantly practice propose novel method guarantees exact mcmc sampling finite time multi label segmentations generic bayesian markov random field mrf models exact sampling propose fillâ€™s strategy extend generic mrf models via novel bounding chain algorithm results simulated data clinical brain images classic problems show uncertainty estimates gain accuracy state art â© springer nature switzerland ag
10.1109/LCOMM.2017.2756833 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030777097&doi=10.1109%2fLCOMM.2017.2756833&partnerID=40&md5=a7c3af6055a337ef2fef39489c13d4e4 3,letter discuss multiple links equal weights buffer size based relay selection schemes cooperative wireless networks general relay selection factor defined includes weight link first metric link quality priority second metric different cases weight markov chain based theoretical framework employed evaluate outage probability delay throughput system proposed scheme evaluated symmetric asymmetric channel conditions link quality based second selection metric achieves lower outage probability link priority based selection shows significant improvements terms delay throughput theoretical results validated extensive monte carlo simulations â© ieee
10.1667/RR14852.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042348439&doi=10.1667%2fRR14852.1&partnerID=40&md5=55be5e1dba29e3224a4bd77cc08cdee1 0,serandour et al reported vitro experiment involving rat plasma samples obtained intravenous intake plutonium citrate different amounts dtpa added plasma samples percentage low molecular weight plutonium measured dtpa dosage three orders magnitude greater recommended î¼mol kg plutonium apparently form chelate data modeled assuming three competing chemical reactions molecules bind plutonium time dependent second order kinetics reactions calculated intended eventually become part complete biokinetic model dtpa action actinides laboratory animals humans probability distribution ratio stability constants reactants calculated using markov chain monte carlo calculations substantiate inclusion reactions needed order agreement known stability constants â© radiation research society
10.1214/17-BA1088 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054607918&doi=10.1214%2f17-BA1088&partnerID=40&md5=36205cb28a20c223bdefcbede1931b9b 1,propose two new sequential monte carlo smc smoothing methods general state space models unknown parameters first modification particle learning smoothing pls algorithm carvalho johannes lopes polson adjustment backward resampling weights second called refiltering two stage method combines sequential parameter learning particle smoothing algorithms illustrate methods three benchmark models using simulated data apply stochastic volatility model daily p index returns financial crisis show new methods outperform existing smc approaches refiltering competitive smoothing approaches based markov chain monte carlo mcmc particle mcmc â© international society bayesian analysis
10.1371/journal.pone.0189531 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040003858&doi=10.1371%2fjournal.pone.0189531&partnerID=40&md5=abf4d31bda0fab39aff14f6a89f1a9ec 0,background tuberculosis tb elderly remains challenge intermediate disease burden areas like hong kong given higher tb burden elderly limited impact current case finding strategy patient initiated pathway proactive screening approaches high risk group optimal increasingly need targeted economic evaluations study examined whether circumstance screening strategies cost effective compared screening strategy elderly admission residential care homes methods decision analytic process based markov model adopted evaluate cost effectiveness four strategies screening ii tb screening cxr iii tb screening xpert represent screening tb symptomatic elderly chest x ray xpertâ® mtb rif respectively iv ltbi tb screening represents screening latent active tb infection quantiferonâ® tb gold tube chest x ray target population hypothetical cohort year old people using health service provider perspective time horizon years outcomes direct medical costs life years quality adjusted life years qalys measured incremental cost effectiveness ratio icer results base case analysis screening cost saving tb screening cxr dominated tb screening xpert ltbi tb screening resulted life years qalys accrued icers ltbi tb screening us us per qaly gained compared screening tb screening xpert respectively willingness pay threshold us per qaly gained ltbi tb screening cost effective probability annual ltbi reactivation greater acceptability ltbi tb screening greater iterations monte carlo simulation probabilities screening tb screening cxr tb screening xpert ltbi tb screening cost effective respectively conclusions screening latent active tb infection hong kong elderly people admission residential care homes appears highly effective cost effective key findings may next key factor bring tb endemic elderly population among intermediate tb burden areas â© li et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1016/j.matcom.2016.07.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997208447&doi=10.1016%2fj.matcom.2016.07.010&partnerID=40&md5=63dd0bd6458cafd241ecd83bbecc10f5 1,review array rqmc method variants sorting strategies convergence results interested convergence rate measures discrepancy states given step chain function sample size n also convergence rate variance sample average cost function state given step viewed estimator expected cost summarize known convergence rate results show empirical results suggest much better convergence rates proved also compare different types multivariate sorts match chains rqmc points including sort based hilbert curve â© international association mathematics computers simulation imacs
10.1515/sagmb-2017-0046 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048416379&doi=10.1515%2fsagmb-2017-0046&partnerID=40&md5=88b8dd795a52b7bee46b86f9e30fb1c3 0,increasing availability population level allele frequency data across one related populations necessitates development methods efficiently estimate population genetics parameters strength selection acting population data existing methods problem setting wright fisher diffusion model primarily likelihood based rely numerical approximation likelihood computation bootstrapping assessment variability resulting estimates requiring extensive computation recent work provided method obtaining exact samples general wright fisher diffusion processes enabling development methods bayesian estimation setting develop implement bayesian method estimating strength selection based wright fisher diffusion data sampled single time point method utilizes latest algorithms exact sampling devise markov chain monte carlo procedure draw samples joint posterior distribution selection coefficient allele frequencies demonstrate assumptions initial allele frequencies accurate method performs well simulated data empirical data set hypoxia flies find evidence strong positive selection region chromosome l previously identified discuss possible extensions method general settings commonly encountered practice highlighting advantages bayesian approaches inference setting â© walter de gruyter gmbh berlin boston
10.1002/2017JB014847 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040242470&doi=10.1002%2f2017JB014847&partnerID=40&md5=104de12aaf6973e4f78b5c0dcdcb160c 3,using markov chain monte carlo mcmc inversion technique mullet et al reassess validity conventionally accepted values grain size exponent diffusion creep olivine aggregates systematic comprehensive analysis individual experimental runs taken three widely cited studies reveals data tightly constrain grain size exponent flow law parameter diffusion dislocation creep analysis indicates large data uncertainties cause inversion results deviate significantly true values covariance grain size stress exponents even resolving grain size exponent difficult versatility mcmc inversion technique however exploited improve situation identifying optimal conditions future experimental studies uncertainties grain size stress exponents highly correlated example increasing range grain size variation help better constrain exponents simultaneously â© american geophysical union rights reserved
10.1016/j.vaccine.2018.01.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040335726&doi=10.1016%2fj.vaccine.2018.01.007&partnerID=40&md5=717a0a207cb067a5fe7134289a068d86 0,background current recommendations dengue vaccination world health organization depend seroprevalence levels serological status populations individuals however seroprevalence estimation may difficult due diversity factors thus estimation models using data epidemiological surveillance systems alternative procedure achieve goal objective estimate expected dengue seroprevalence children selected areas argentina using simple model based data passive epidemiological surveillance systems methods markov model using simulated cohort individuals age years developed parameters regarding reported annual incidence dengue proportion inapparent cases expansion factors outpatient hospitalized cases considered transition probabilities proportion immune population years age taken proxy expected seroprevalence considering age targeted vaccination model used evaluate expected seroprevalence misiones salta provinces buenos aires city three settings showing different climatic favorability dengue results estimates seroprevalence group year old children misiones ci salta ci located northeastern northwestern argentina respectively buenos aires city central argentina showed likely seroprevalence ci according deterministic sensitivity analyses parameter showing highest influence results probability inapparent cases conclusions model allowed estimation dengue seroprevalence settings information available particularly misiones expected seroprevalence higher wide range scenarios thus province vaccination strategy directed seropositive children years analyzed including considerations safety cost effectiveness budget impact â© elsevier ltd
10.7507/1672-2531.201707008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050722310&doi=10.7507%2f1672-2531.201707008&partnerID=40&md5=f554c54779be1e05bef0c6836cf80a09 0,health economics analysis become increasingly important recent years essential master use relevant software conduct research health economics treeage pro software widely used healthcare decision analysis carry decision analysis cost effectiveness analysis monte carlo simulation powerful functionlity outstanding visualization build markov disease transition models analyze markov processes according disease models accomplish decision analysis decision trees influence diagrams paper introduces cost effectiveness analysis based markov model examples explains main graphs â© west china university medical science rights reserved
10.1016/j.acvd.2017.03.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029698719&doi=10.1016%2fj.acvd.2017.03.010&partnerID=40&md5=8779ca76a5e82d240d1ee7418fa71e61 1,background patient education programmes pep recommended patients heart failure specifically assessed heart failure preserved ejection fraction hfpef aim assess effectiveness structured pep reducing cause mortality patients hfpef methods patients hfpef selected odin cohort designed assess pep effectiveness patients hf whatever ejection fraction included followed baseline sociodemographic clinical biological therapeutic characteristics collected inclusion patients invited participate pep consisted educational diagnosis education sessions final evaluation education focused hf pathophysiology medication symptoms worsening hf dietary recommendations management exercise propensity score matching cox models performed results patients hfpef participated pep patients participated pep younger â± vs â± years standardized difference stdiff = âˆ’ less often women vs stdiff = âˆ’ presented often hypercholesterolaemia vs stdiff smoking vs stdiff alcohol abuse vs stdiff ischaemic hf vs stdiff also presented better clinical cardiovascular variables propensity score matching baseline characteristics balanced except hypertension postmatch stdiff pep associated lower cause mortality pooled hazard ratio confidence interval â€“ p = association remained significant adjustment hypertension adjusted pooled hazard ratio confidence interval â€“ p = conclusions investigation structured pep associated lower cause mortality patient education might considered effective treatment patients hfpef â© elsevier masson sas
10.1111/jfb.13520 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037671980&doi=10.1111%2fjfb.13520&partnerID=40&md5=e14d6237fb71f74f12a291286728795a 0,current study activity latency explore well correlation traits examined individually marked juvenile gadus morhua â° c concluded individual rank order traits maintained across temperature level change differed individuals â© fisheries society british isles
10.1016/j.artmed.2017.12.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038819556&doi=10.1016%2fj.artmed.2017.12.003&partnerID=40&md5=e5a33dcfd88fab6bd6c44eb1825830af 1,health care practitioners analyse possible risks misleading decisions need estimate quantify uncertainty predictions examined â€œgoldâ€� standard screening patient conditions predicting survival probability based logistic regression modelling used trauma care clinical purposes quality audit methodology based theoretical assumptions data uncertainties models induced within approach exposed number problems providing unexplained fluctuation predicted survival low accuracy estimating uncertainty intervals within predictions made bayesian method theory capable providing accurate predictions uncertainty estimates adopted study using decision tree models approach tested large set patients registered us national trauma data bank outperformed standard method terms prediction accuracy thereby providing practitioners accurate estimates predictive posterior densities interest required making risk aware decisions â© elsevier b v
10.7334/psicothema2017.92 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040839700&doi=10.7334%2fpsicothema2017.92&partnerID=40&md5=be4e0c1eab26c5345bd1f2dc2ef7f056 0,background negative symptoms represent main cause disability schizophrenia recently grouped two general dimensions avolition diminished emotional expression includes affective flattening alogia aim study explore response two symptoms set behavioral interventions based contingency management performed interdisciplinary context method behaviors interest monitored evaluations treatment performed schizophrenic inpatients persistent negative symptoms program included group double sessions aimed developing facial expression verbal communication nursing care plan generalize strengthen behaviors synergistically results appreciable differences facial expression less clear alogia clinical evaluation using panss n find notable differences group level nursing assessment using noc indicators conclusions although difficult modify negative symptoms insensitive influence behavioral interventions specific psychological interventions address negative symptoms priority focus attention care need promoted developed particularly considering crucial role context progression â© psicothema
10.3923/ijp.2018.151.163 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041293521&doi=10.3923%2fijp.2018.151.163&partnerID=40&md5=e64c1b3b915d5b3b4921d4c3a3f08d56 0,statins inhibit cholesterol synthesis blocking hydroxy methylglutaryl coenzyme reductase liver thereby ameliorating hypercholesterolemia thus determine statins best efficacy meta analysis performed compare effects statins hypercholesterolemia comprehensive literature searches established cochrane library pubmed embase studies performed randomize controlled trials rcts cohort studies case control studies efficacy different statin drugs dose hypercholesterolemia published february study qualities assessed according cochrane collaboration recommendations non programming software aggregate data drug information system addis version used perform bayesian network meta analysis compare treatments using markov chain monte carlo mcmc method overall rcts studies including patients met inclusion criteria total cholesterol tc levels significantly reduced p using mg pitavastatin pit using mg pravastatin pra mg simvastatin sim mg atorvastatin ato similarly triglyceride tg levels reduced using mg pit using mg pra p mg sim p mg sim p reduced apolipoprotein b apo b levels observed using mg ato mg pra p rosuvastatin ros significantly reduced tc tg levels p administered mg ros treatments ameliorated percentage changes low density lipoprotein cholesterol drugs p increased high density lipoprotein cholesterol levels effectively mg ato p mg pra p mg sim p increases apo levels differ treatments p among present statin drug regimens mg pit mg ros highest efficacy hypercholesterolemia â© qingzan kong et al
10.1016/j.molmet.2017.10.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033388114&doi=10.1016%2fj.molmet.2017.10.007&partnerID=40&md5=1e58882248d39ac7429ad22d57923d32 0,objectives body fatness widely assumed regulated lipostatic set point system evolved response trade offs risks mortality increasing fatness makes risk starvation lower increases risk predation yet models available aim work evaluate using mathematical modeling whether set point systems likely evolve alternatives methods modeled trade mortality risks using simple mathematical model generates optimum level fatness presumed driver evolution set point mimicked likely errors optimum level derive variation component parameters mortality curves using markov chain monte carlo mcmc simulation bayesian inference using gibbs sampling bugs results error propagation generated simulations showed even small errors model parameters magnified enormously location optimum fatness level model parameters coefficients variation coefficient variation optimum level fatness situation set point centered mathematical optimum component curves correct level fatness minimizes mortality hence maximizes fitness less occasions conclusions set point regulation body fatness hence highly unlikely evolve realistic level variation parameters define mortality risks using mcmc modeling show dual intervention point system likely evolve mathematical simulation work important implications interpret molecular work concerning regulation adiposity â©
10.7150/jca.24690 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048330856&doi=10.7150%2fjca.24690&partnerID=40&md5=beadba5088bb323f8d0031386028110b 1,objective increasing recognition diagnosis treatment prostate cancer pca choice better prostate biopsy strategy confused patients clinical surgeons hence network meta analysis conducted clarify question methods current network meta analysis twenty eligible randomized controlled trials rcts participants comprehensively identified pubmed embase web science databases july pooled odds ratio credible interval cri calculated markov chain monte carlo methods bayesian network meta analysis conducted using r software help package gemtc version results six different pca biopsy strategies four clinical outcomes ultimately analyzed study although efficacy different pca biopsy strategies ors corresponding cris yet reached statistical differences cumulative rank probability indicated overall pca detection rate best worst fus gb plus trus gb fus gb ceus mri gb trus gb tpus gb terms clinically significant pca detection ceus fus gb fus gb plus trus gb higher whereas trus gb tpus gb relatively lower significant detection rate meanwhile tpus gb trus gb higher insignificant pca detection rate trus guided biopsy general trend biopsy cores higher overall pca detection rate targeted biopsy yield comparable even better effect fewer cores compared traditional random biopsy conclusion taken together comprehensive consideration four clinical outcomes outcomes shed light fus gb fus gb plus trus gb showed superiority compared puncture methods detection pca moreover tpus trus gb easily associated diagnosis treatment pca addition targeted biopsy obviously effective traditional random biopsy subsequent rcts larger sample sizes required validate findings â© ivyspring international publisher
10.1007/s11276-018-1821-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053178807&doi=10.1007%2fs11276-018-1821-1&partnerID=40&md5=52ca82f7082a9ccf57e6ddc8eabfd4a1 0,paper present analytical framework performance evaluation radio resource allocation rra orthogonal frequency division multiple access ofdma networks focus quality service qos guaranteed traffic whose capacity terms number active user connections depends usersâ€™ qos requirements channel conditions rra algorithm required qos guaranteed restricting number admitted calls turn requires accurate estimate qos metrics capacity supported rra new call arrives estimates ofdma networks variable usually obtained time consuming offline computer simulations mathematical frameworks hand yield timely accurate results however earlier known works analytical modelling rra either consider single channel random traffic arrivals multiple channels full buffer data traffic contrast develop queueing theoretic framework considering randomly arriving qos guaranteed traffic variable rate multi channel multi class ofdma network framework used online leading better dynamic call admission control characterize rra algorithm using scheduler control parameter regulate call blocking probability providing predefined qos constraints model rra variable service rate multi server multi class finite buffer queueing system verify derived qos metrics using extensive monte carlo discrete event simulations â© springer science+business media llc part springer nature
10.1115/MSEC2018-6638 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054964869&doi=10.1115%2fMSEC2018-6638&partnerID=40&md5=09306478b03fef4a30e82f60e31050f1 0,critical element rotating machines remaining useful life rul prediction rolling bearings plays essential role realizing predictive preventative machine maintenance modern manufacturing physics defect e g spall initiation propagation describes bearing service life generally divided three stages normal operation defect initiation accelerated performance degradation transition among stages embedded variations monitored data e g vibration paper presents multi mode particle filter mmpf aimed automatically detect transition among three life stages accurately characterize bearing performance degradation integrating physical models stochastic modeling method mmpf set linear non linear modes also called degradation functions first defined according physical empirical knowledge well statistical analysis measured data e g vibration modes subsequently refined particle filtering pf based bearing performance tracking process mode corresponds individual performance scenario finitestate markov chain switches among modes reflecting transition service life stages case studies performed two run failure experiments indicate developed technique effective tracking evolution bearing performance degradation predicting remaining useful life rolling bearings copyright â© asme
10.14419/ijet.v7i3.15.17522 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051646789&doi=10.14419%2fijet.v7i3.15.17522&partnerID=40&md5=beb6688ac25a20bd8e6916abd9850db9 0,paper discussed monte carlo simulation technique determine optimal placement phasor measurement unit pmu power system whilst ensuring observability system addition information force outage rate system calculated using markov chain technique represents level risk security transmission line happened unscheduled unexpected failure repair system subsequently reliability model transmission line developed using ieee bus system results obtained monte carlo simulation technique demonstrate optimal pmu placement desired reliability wide area monitoring system wams well number location covered contingencies system â© authors
949.4167702710866 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053891521&partnerID=40&md5=29ae46155969972170803aa374311c7e 0,article likelihood bayesian estimations partially accelerated constant stress life test model compared using type ii censored data pareto distribution second kind posterior means posterior variances obtained squared error loss function using lindley approximation procedure furthermore highest posterior density credible intervals model parameters based gibbs sampling technique presented illustration simulation studies provided shown bayesian approach via gibbs sampling procedure statistical precision parameter estimation improved consequently required number failures reduced savings time cost achieved markov chain monte carlo mcmc technique reducing total testing time total number failures without sacrificing much statistical power inference often desired industrial applications â© international journal industrial engineering
10.1016/j.csda.2018.08.025 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054553886&doi=10.1016%2fj.csda.2018.08.025&partnerID=40&md5=167c4bff5f3342b024a9ba9861de3e72 0,high dimensional data emerging various domains sparse logistic regression models gained much interest researchers variable selection plays key role improving prediction accuracy enhancing interpretability built models bayesian variable selection approaches enjoy many advantages high selection accuracy easily incorporating many kinds prior knowledge bayesian methods generally make inference posterior distribution markov chain monte carlo mcmc techniques however become intractable high dimensional situations due large searching space address issue novel variational bayesian method variable selection high dimensional logistic regression models presented proposed method based indicator model covariate equipped binary latent variable indicating whether important bernoulli type prior adopted latent indicator variable specification hyperparameter bernoulli prior provide two schemes determine optimal value novel model achieve sparsity adaptively identify important variables make predictions one efficient variational bayesian approach employed make inference posterior distribution experiments conducted synthetic publicly available data show new method outperforms competitive popular counterparts â© elsevier b v
10.1080/17415977.2018.1505883 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052084541&doi=10.1080%2f17415977.2018.1505883&partnerID=40&md5=c936aec3b15b140b7e9dd70b4d5b8aea 0,work reconstruction location time domain multiple forces acting linear elastic structure achieved bayesian approach solve inverse problem bayesian solution inverse problem provided form posterior probability density function unknown forces determined markov chain monte carlo method gibbs algorithm posterior density integrating likelihood prior information considered particular case linear elastic structure measurements affected additive random noise two particular cases analysed unperturbed uncertain model representing structure unperturbed model used identify single force model uncertain compressed sensing technique used provide adequate sparse representation inverse problem wavelet basis sparse representation possibility achieving automatic location forces investigated requires identify degrees freedom along identified actions vanishing also possibility force identification less sensors forces studied proposed approach illustrated validated numerical examples proposed approach compared classical approach force identification based tikhonov regularization associated gcv criterion â© â© informa uk limited trading taylor francis group
10.4149/gpb_2018005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052133720&doi=10.4149%2fgpb_2018005&partnerID=40&md5=3f99c4610b29b4411a4e23a4a48e7920 0,one commonly used approaches biophysical modeling muscle contractile apparatus spatially explicit discrete lattice models monte carlo simulation models allow reproduce structural features actin myosin interaction muscle contractile system accurately limitation models low computational efficiency stochasticity certain circumstances work introduces deterministic approximation stochastic model considers pair rigid contractile filaments interaction approximation background discreetness spacing cross bridges binding sites due property cross bridges divided discrete groups strain considered statistically using set ordinary differential equations deterministic model computationally efficient operates average values within given approach isotonic contraction simulated comparison monte carlo simulation demonstrates approximation reproduces results stochastic model large number cross bridges also within deterministic model mechanism essential conditions oscillations appearance isotonic transient response relations parameters geometrical ones filaments lattice examined theoretical experimental results compared proposed approach also applied approximation continuous huxley based models solutions advantage existing numerical methods greater numerical stability â© slovak academy sciences rights reserved
10.1002/minf.201700130 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041219226&doi=10.1002%2fminf.201700130&partnerID=40&md5=ebee7117dbc3e1c20dc423de04ace2c3 0,consider lead discovery active search space labelled graphs particular extend recent data driven adaptive markov chain approach evaluate focused drug design problem search antagonist î±v integrin target protein belongs group argâˆ’glyâˆ’asp integrin receptors group integrin receptors thought play key role idiopathic pulmonary fibrosis chronic lung disease significant pharmaceutical interest silico proxy binding affinity use molecular docking score experimentally determined î±vî² protein structure search driven probabilistic surrogate activity molecules space process evolves algorithm observes activity scores previously designed molecules hypothesis activity refined algorithm guaranteed converge probability best hypothesis priori specified hypothesis space empirical evaluations approach achieves large structural variety designed molecular structures docking score better desired threshold novel molecules suggested active surrogate model provoke significant interest perspective medicinal chemistry warrant prioritization synthesis moreover approach discovered active compounds known active previous biological assays â© wiley vch verlag gmbh co kgaa weinheim
10.1029/2018WR023366 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054557187&doi=10.1029%2f2018WR023366&partnerID=40&md5=80a328c87c1b8ae8ec7430c9e7330675 0,intensity duration frequency idf curves one common rainfall statistical models used hydrologic design analysis projects uncertainties related elaboration idf curves nevertheless seldom evaluated past article recall existing link idf formulation properties rainfall series simple scaling multifractal structure assuming properties valid idf curves formulation product dimensionless e reduced distribution function annual maximum rainfall intensities depths duration dependent scaling factor parameters evaluated integrated way e based unique pooled sample peak intensities range durations â min â hr use likelihood based bayesian markov chain monte carlo statistical inference methods evaluation provides consistent uncertainties parameters idf relation corresponding rainfall quantiles methodology tested via local analysis large data set rain gauge records spread north central part algeria â km various climatic regimes integrated approach undoubtedly consistent estimates annual maximum rainfall fitted single durations furthermore credibility intervals significantly reduced also integrated approach appears robust unlike traditional method based single durations generally provides rational quantile estimates even short observed series available significant advantage engineering applications â© american geophysical union rights reserved
10.1137/16M1090466 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044504789&doi=10.1137%2f16M1090466&partnerID=40&md5=fd14023ca86684f83d93c276d8302fb1 0,approximate bayesian computation abc methods gained popularity last decade expand horizon bayesian parameter inference methods range models analytical formula likelihood function might difficult even impossible establish majority abc methods rely choice set summary statistics reduce dimension data however noted abc literature lack convergence guarantees induced absence vector sufficient summary statistics assures intermodel sufficiency set competing models hinders use usual abc methods applied bayesian model selection assessment paper present novel abc model selection procedure dynamical systems based recently introduced multilevel markov chain monte carlo method self regulating abc subsim hierarchical state space formulation dynamic models show formulation makes possible independently approximate model evidence required assessing posterior probability competing models also show abc subsim provides estimate model evidence simple product also gives posterior probability model function tolerance level allows abc model choices made previous studies understood illustrate performance proposed framework abc model updating model class selection applying two problems bayesian system identification single degree freedom bilinear hysteretic oscillator three story shear building masing hysteresis subject seismic excitation â© society industrial applied mathematics
10.1214/17-AOS1629 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054717605&doi=10.1214%2f17-AOS1629&partnerID=40&md5=f318cbd702fc6960024d3371b8c6c852 1,paper introduces new way compact continuous probability distribution f set representative points called support points points obtained minimizing energy distance statistical potential measure initially proposed szã©kely rizzo interstat â€“ testing goodness fit energy distance two appealing features first distance based structure allows us exploit duality powers euclidean distance fourier transform theoretical analysis using duality show support points converge distribution f enjoy improved error rate monte carlo integrating large class functions second minimization energy distance formulated difference convex program manipulate using two algorithms efficiently generate representative point sets simulation studies support points provide improved integration performance monte carlo specific quasi monte carlo method two important applications support points highlighted way quantify propagation uncertainty expensive simulations b method optimally compact markov chain monte carlo mcmc samples bayesian computation â© institute mathematical statistics
10.15866/iree.v13i3.14413 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052236962&doi=10.15866%2firee.v13i3.14413&partnerID=40&md5=d3a798f757c7ac065ba98fad2d0b5e75 0,agriculture food processing industries demand lot energy applied small agriculture farms isolated electric power grid use electrical heat energy makes significant business cost economies result decision electrical heat energy provided agriculture farms isolated electric power grid economical reliable way crucial importance business life quality electrical heat energy need investigated farms scattered bosnia mountains sites away electric power grid besides energy needs aspects energy solutions farms researched environmental technical economical nature reliability offered solutions analysis carried using hybrid algorithm based analytical hierarchy process techno economic analysis â© praise worthy prize r l rights reserved
10.7717/peerj.5140 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049448400&doi=10.7717%2fpeerj.5140&partnerID=40&md5=77632243945056b98f46057ad7ed84a3 0,time resolved phylogenetic methods use information time sample collection estimate rate evolution originally models used estimate evolutionary rates quite simple assuming lineages evolve rate assumption commonly known molecular clock richer complex models since introduced capture phenomenon substitution rate variation among lineages two well known model extensions local clock wherein lineages clade share common substitution rate uncorrelated relaxed clock wherein substitution rate lineage independent lineages constrained fit parametric distribution introduce model extension called flexible local clock flc provides flexible framework combine relaxed clock models local clock models evaluate flexible local clock simulated real datasets show provides substantially improved fit influenza dataset implementation model available download https www github com ment flc â© fourment darling
10.1155/2018/1543034 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045724326&doi=10.1155%2f2018%2f1543034&partnerID=40&md5=ca28fb7b31d6ec8df8c8cfd1c71d55b4 0,background treatment schizophrenia first second generation antipsychotics associated elevated prolactin levels may increase risk prolactin related adverse events methods randomized controlled trials rcts included recent systematic review considered analysis bayesian network meta analysis used compare changes prolactin levels pediatric patients diagnosed schizophrenia schizophrenia spectrum disorders treated second generation antipsychotics sgas results five rcts including patients combined evaluated changes prolactin pediatric patients weeks treatment risperidone quetiapine aripiprazole olanzapine paliperidone overall study population treatment risperidone associated highest increase mean prolactin levels compared sgas patients treated risperidone mg day found experience greatest increases ng ml cri prolactin levels followed risperidone mg day paliperidone mg day paliperidone mg day conclusions study shows differences sgas ability cause hyperprolactinemia clear evidence safety concerns risperidone paliperidone treatment adolescent schizophrenia patients copyright â© chakrapani balijepalli et al
10.7717/peerj.4723 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047517702&doi=10.7717%2fpeerj.4723&partnerID=40&md5=9d47593a8670c12f6808549887e93f25 0,colobanthus apetalus member genus colobanthus one genera large family caryophyllaceae groups annual perennial herbs rarely shrubs widely distributed around globe mainly holarctic genus colobanthus consists species including colobanthus quitensis extremophile plant native maritime antarctic complete chloroplast cp genomes useful phylogenetic studies species identification study next generation sequencing ngs used identify cp genome c apetalus complete cp genome c apetalus length bp gc content quadripartite structure large single copy lsc bp small single copy ssc bp separated inverted repeats irs bp cp genome contains genes including unique genes genes duplicated irs group unique genes features protein coding genes trna genes four rrna genes five conserved chloroplast open reading frames orfs total forward repeats palindromic repeats five reverse repeats three complementary repeats detected addition simple sequence repeat ssr analysis revealed mono di tri tetra penta hexanucleotide ssrs rich detailed comparison c apetalus c quitensis cp genomes revealed identical gene content order phylogenetic tree built based sequences protein coding genes shared eleven sequenced representatives caryophyllaceae c apetalus revealed c apetalus c quitensis form clade closely related silene species agrostemma githago moreover genus silene appeared polymorphic taxon results study expand knowledge evolution molecular biology caryophyllaceae â© androsiuk et al
10.1080/17513758.2017.1401677 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041770077&doi=10.1080%2f17513758.2017.1401677&partnerID=40&md5=7fc006c0e1ed7368a1143176044fa01f 1,erlang differential equation models epidemic processes provide realistic disease class transition dynamics susceptible exposed e infectious removed r categories ubiquitous seir model latter one end spectrum erlang seminr models â‰¥ concatenated e compartments n â‰¥ concatenated compartments discrete time models however computationally much simpler simulate fit epidemic outbreak data continuous time differential equations also much readily extended include demographic types stochasticity formulate discrete time deterministic analogs erlang models stochastic extension based time go distributional principle depending distributions used e g discretized erlang gamma beta uniform distributions demonstrate formulation represents discretization erlang epidemic models generalizations thereof consider challenges fitting seminr models discrete time analog data recent outbreak ebola liberia demonstrate latter performs much better former although confining fits strict seir formulations reduces numerical challenges sacrifices best fit likelihood scores least â© author
10.11909/j.issn.1671-5411.2018.05.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049683076&doi=10.11909%2fj.issn.1671-5411.2018.05.001&partnerID=40&md5=a966f1cdcb27759c8c8303126d753e2e 0,abstract available
10.1002/asmb.2371 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050940648&doi=10.1002%2fasmb.2371&partnerID=40&md5=146baca24b384a39d46c42a6aaaae43b 0,paper studies lasting effects common credit events influence default probability distribution prices multiname credit derivatives based joint defaults model common credit events used generate simultaneous defaults extend model allow impacts last longer default intensity entity heightened significantly impact still influence time later effect fades away incorporating lasting effects helps generate higher default correlation consistent today highly correlated financial markets proposed model either formulated markov chain implemented monte carlo simulation order calculate default probability distributions multiname derivatives prices numerical results demonstrate strong influences lasting effects provide justification incorporation â© john wiley sons ltd
10.1248/yakushi.17-00159 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040451128&doi=10.1248%2fyakushi.17-00159&partnerID=40&md5=dc378f5dac5c771f6d0adc0b70270dd6 0,evaluated four representative chemotherapy regimens unresectable advanced recurrent kras wild type colorectal cancer mfolfox mfolfox +bevacizumab bmab cetuximab cmab panitumumab pmab employed decision analysis method combination clinical economic evidence health outcomes regimens analyzed basis overall progression free survival data drawn literature randomized controlled clinical trials mentioned drugs total costs regimens calculated basis direct costs obtained medical records patients diagnosed unresectable advanced recurrent colorectal cancer yamagata university hospital yamagata prefecture central hospital cost effectiveness analyzed using markov chain monte carlo mcmc method study designed viewpoint public medical care mcmc analysis revealed expected life months expected cost months yen mfolfox months yen mfolfox +bmab months yen mfolfox +cmab months yen mfolfox +pmab incremental costs per effectiveness ratios per life month mfolfox yen mfolfox +bmab yen mfolfox +cmab yen mfolfox +pmab compared conventional mfolfox regimen molecular targeted drug regimens provide better health outcomes cost increases accordingly mfolfox +pmab cost effective regimen among surveyed study â© pharmaceutical society japan
10.1209/0295-5075/121/10008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044192494&doi=10.1209%2f0295-5075%2f121%2f10008&partnerID=40&md5=f0706526efb39ddd670e394b352317be 2,analyze convergence irreversible event chain monte carlo algorithm continuous spin models presence topological excitations two dimensional xy model show local nature markov chain dynamics leads slow decay vortexantivortex correlations spin waves decorrelate quickly using frã©chet description maximum vortex antivortex distance quantify contributions topological excitations equilibrium correlations show vary dynamical critical exponent z âˆ¼ critical temperature z âˆ¼ limit zero temperature confirm event chain algorithm fast relaxation corresponding z = spin waves harmonic approximation xy model mixing times describing approach towards equilibrium least favorable initial state however remain much larger equilibrium correlation times low temperatures also describe respective influence topological monopole antimonopole excitations spin waves event chain dynamics three dimensional heisenberg model â© epla
10.1051/0004-6361/201731450 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040469598&doi=10.1051%2f0004-6361%2f201731450&partnerID=40&md5=8e339e7104f905dd5d09a10590ab2def 0,aims present results deep spatially extended ctio decam g r photometry reaching âˆ¼ mag oldest main sequence turn covering âˆ¼ deg around sextans dwarf spheroidal galaxy aim use dataset study structural properties sextans overall stellar population member stars different evolutionary phases well search possible signs tidal disturbance milky way indicate departure dynamical equilibrium methods performed accurate quantitative structural analysis date sextans stellar components applying bayesian monte carlo markov chain methods individual stars positions surface density maps built statistically decontaminating sample matched filter analysis colour magnitude diagram analysed departures axisymmetry results sextans found significantly less spatially extended centrally concentrated early studies suggested statistically significant distortions signs tidal disturbances found surface brightness limit âˆ¼ mag arcsec v band identify overdensity central regions may correspond previously reported kinematic substructure agreement previous findings old metal poor stars blue horizontal branch stars cover much larger area stars evolutionary phases bright blue stragglers bss less spatially extended faint ones however different spatial distribution bright faint bss appears consistent general age metallicity gradients found sextans stellar component compatible sextans bss formed evolution binaries necessarily due presence central disrupted globular cluster suggested literature provide structural parameters various populations analysed make publicly available photometric catalogue point sources well catalogue literature spectroscopic measurements updated membership probabilities â© eso
10.1007/s00542-018-4070-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050931118&doi=10.1007%2fs00542-018-4070-4&partnerID=40&md5=16d8183b6f7fe2566a8d1709608ca752 0,flexible interconnection controller fic type power electronic device based insulated gate bipolar transistors igbt modules applied electrical distribution systems realize flexible control power flow reliability device plays important role reliable continuous operation active distribution system paper reliability model fic consists three modular multilevel converters mmcs proposed considering uncertainty current loading first structure operating modes fic analyzed based fault tree analysis reliability model single terminal mmc established next considering impact random current loading igbt modulesâ€™ reliability monte carlo simulation used obtain loading expectation correction factor thus equivalent reliability model igbt module built furthermore state space model fic established analytical method based markov chain used solve taking improved three ieee node feeder groups testing system equivalent reliability indices igbt module well converter reliability three terminals mmc obtained via simulation based probabilities average durations ficâ€™s eight states calculated verify proposed model â© springer verlag gmbh germany part springer nature
10.4310/SII.2018.v11.n4.a9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054681514&doi=10.4310%2fSII.2018.v11.n4.a9&partnerID=40&md5=247af221c9c444f00158e20e5e2c1736 0,propose two new methods sampling undirected loopless multigraphs fixed degree first sequential importance sampling method proposal based asymptotic approximation total number multigraphs fixed degree multigraphs associated importance weights used approximate null distribution test statistics additionally estimate total number multigraphs second markov chain monte carlo method samples multigraphs based similar moves used sample contingency tables fixed margins apply methods number examples demonstrate excellent performance â© international press boston inc
10.1214/18-BA1101 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054632269&doi=10.1214%2f18-BA1101&partnerID=40&md5=996a89cd9a749efb16e76106c6231b8c 0,markov equivalence class contains directed acyclic graphs dags encoding conditional independencies represented completed partially directed acyclic graph cpdag also named essential graph eg approach problem model selection among noncausal sparse gaussian dags directly scoring egs using objective bayes method specifically construct objective priors model selection based fractional bayes factor leading closed form expression marginal likelihood eg next propose markov chain monte carlo mcmc strategy explore space egs using sparsity constraints illustrate performance method simulation studies well real dataset method provides coherent quantification inferential uncertainty requires minimal prior specification shows competitive learning structure data generating eg compared alternative state art algorithms â© international society bayesian analysis
893.9006342644999 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049773915&partnerID=40&md5=65f93a9100b101a9a89a14158790273e 0,study examined variation eight autosomal microsatellite markers explored genetic diversity measure population structuring eurasian woodcock scolopax rusticola hungary spring tested whether subpopulations identified sample also examined whether individuals occurred closer space timewere alsomore similar genetic terms analysed samples free ranging birds collected legal hunting mid february end april different parts country bayesian clustering method markov chain monte carlo simulation used infer probable number genetic clusters without priori definition populations second approach discriminant analysis principal components order identify clusters individuals without population geneticmodels additionally fitted general linear model genetic distance samples dependent variable temporal days geographical meters distances interactions factors independent variables found high genetic diversity lowlevel population structuring samples moreover results support assumptions woodcocks occurring different places different times hungary also belong different breeding populations â© university helsinki rights reserved
10.7717/peerj.4333 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041327577&doi=10.7717%2fpeerj.4333&partnerID=40&md5=bcaff929f373280f696393dc639a046d 1,background winter rarely reported norovirus nov genotype gii found increased frequency norovirus outbreaks east asia surpassing gii nov infections gii genotype detected three decades world aim study examine evolutionary dynamics gii last four decades methods nov gii sequences complete nearly complete vp loaded genbank phylogenetic analyses conducted results maximum likelihood analysis showed gii genotype divided four different clades clades strains detected cause outbreaks separated clades c mean amino acid distance bayesian markov chain monte carlo analyses indicated rate nucleotide substitution per sites ã— nucleotide substitutions site year time themost recent common ancestor p subdomain gii highly variable amino acids variations including two insertions positions one deletion position clades c one insertion position clade variations existed epitopes b corresponding gii human histo blood group antigens binding site p subdomain conclusion novelgii strains caused outbreaks may two new variants evolvement hbgas binding site epitopes p subdomain might contribute novel gii strains predominance regions â© sang yang
10.1016/j.bpj.2018.09.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054088301&doi=10.1016%2fj.bpj.2018.09.005&partnerID=40&md5=51ce7c7840fcb8152d366f696b2af3b5 0,state art single particle tracking spt techniques generate long trajectories high temporal spatial resolution offers possibility mechanistically interpreting particle movements behavior membranes end number statistical techniques developed partition spt trajectories states distinct diffusion signatures allowing statistical analysis diffusion state dynamics switching behavior develop confinement model within hidden markov framework switches phases free diffusion confinement harmonic potential well using markov chain monte carlo algorithm fit model automated partitioning individual spt trajectories two phases achieved allows us analyze confinement events demonstrate utility algorithm previously published interferometric scattering microscopy data set gold nanoparticle tagged ganglioside gm lipids tracked model membranes performed comprehensive analysis confinement events demonstrating heterogeneity lifetime shape size events confinement size shape highly conserved within trajectories observations suggest heterogeneity confinement events caused individual nanoparticle characteristics binding site environment individual nanoparticle heterogeneity ultimately limits ability interferometric scattering microscopy resolve molecule dynamics order tag size homogeneous tags potentially allow resolution taken limit deconvolution methods wider context presented harmonic potential well confinement model potential detect characterize wide variety biological phenomena hop diffusion receptor clustering lipid rafts â© biophysical society
10.1002/jmv.25296 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053736791&doi=10.1002%2fjmv.25296&partnerID=40&md5=f5aee34c8ad0176550358b01d6573c63 0,hepatitis e virus hev infection bulgaria endemic demonstrated seroprevalence antibody virus general population high prevalence clinical cases registered study deep bayesian phylogenetic analysis performed provide information genetic diversity spread hev genotypes bulgaria three different data sets hev virus built genotyping maximum likelihood method evolutionary rate estimated bayesian markov chain monte carlo approach demographic history investigation selective pressure analysis evolutionary rate genotype e ã— âˆ’ substitution site year highest posterior density hpd ã— âˆ’ ã— âˆ’ root time recent common ancestor bayesian maximum clade credibility tree hev e genotype corresponded hpd bulgarian sequences mainly clustered main clade clade monophyletic clade included bulgarian genotype e sequences demographic history showed slight growth followed sort bottleneck peak new growth selection pressure analysis show sites positive pressure statistically significant sites negative selection molecular epidemiological surveillance bayesian phylogeny hev virus contribute trace way human infection contact swine source directly heating meat improving public health control â© wiley periodicals inc
10.1371/journal.pone.0202545 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053669712&doi=10.1371%2fjournal.pone.0202545&partnerID=40&md5=a985720f0a171ed40de47c04e29d4b0c 1,integrated model assessing status productivity antarctic krill euphausia superba hereafter krill configured estimate different subsets potentially estimable parameters alternative configurations fixed parameters estimated given configuration pre specified values model fitted forty years fisheries survey data krill subarea statistical reporting area around antarctic peninsula used commission conservation antarctic marine living resources ccamlr number estimated parameters gradually increased across model configurations configurations estimated parameters fitted data better order parameters estimated became important finding best fit twenty two configurations estimating parameters able obtain invertible hessian matrix subsequently used estimate parameter uncertainty parameter uncertainties calculated using asymptotic approximation around maximum likelihood estimates often larger uncertainties based markov chain monte carlo sampling parameters diagnostics applied mcmc samples best model configuration obtained invertible hessian indicated highly parameterized configurations reach stationary distributions parameter configuration best fitting model passed mcmc diagnostics aic bic scores indicated essentially support relative best model alternative models also passed mcmc diagnostics simulated data using configurations operating models showed configurations passed self tests spawning biomass recruitment small negative bias due model penalties fishing mortality estimates years highest fishing mortalities cross tests configurations estimated different parameters often differed operating model values â© public library science rights reserved
459.7483065458403 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050612203&partnerID=40&md5=875360e137ab58f10d12eac7dc867ef8 0,paper proposes novel methodology evaluating travel time reliability urban road network using latest advances evolutionary game theory mcmc markov chain monte carlo proposed method following notable features obtains stationary distribution traffic flow patterns stems stochastic day day dynamics population rational users ii distribution consistent traditional sue stochastic user equilibrium terms traffic flow iii estimate percentile travel time od pair practical size network paper provide numerical example using sioux falls network â© hong kong society transportation studies limited rights reserved
10.1007/s11235-018-0491-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050196954&doi=10.1007%2fs11235-018-0491-8&partnerID=40&md5=94ec1ce4e4a4d0c656b2326bd7b5878d 0,energy harvesting eh body sensor nodes bsns operate independently system emerging solution multiple replacements battery operated bsns deployment stored energy bsn falls minimum level due uncertain energy harvesting process therefore node unable transmit occurred events base station stores storage buffer sb queue due queue overflow sb bsn unable store occurred events therefore lost health monitoring system loss emergency critical information bad impact quality service network essential estimate duration occur event loss order take precautions prior control nodes critical situations medical applications calculate duration event loss occurs sb absorbing discrete time markov chain dtmc model evaluate performance eh bsn temporal death also derive closed form expression event loss duration reduces computational complexity conventional dtmc model analytical results validated monte carlo simulation using matlab â© springer science+business media llc part springer nature
10.29220/CSAM.2018.25.1.029 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044024184&doi=10.29220%2fCSAM.2018.25.1.029&partnerID=40&md5=c2ba93b2d8640f7daff535924043893f 0,combine integer valued garch model generalized regime switching model propose dynamic count time series model model adopts markov chains time varying dependent transition probabilities model dynamic count time series called generalized regime switching integer valued garch grs ingarch models derive recursive formula conditional probability regime markov chain given past information terms transition probabilities markovchain poisson parameters ingarch process addition also study forecasting poisson parameter well cumulative impulse response function model measure persistence volatility monte carlo simulation conducted see performances volatility forecasting behaviors cumulative impulse response coefficients well conditional maximum likelihood estimation consequently real data application given â© korean statistical society korean international statistical society
10.1016/j.csda.2017.08.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029393305&doi=10.1016%2fj.csda.2017.08.005&partnerID=40&md5=c223e7223a6e6cad6dc26c75e0fbbdd8 0,efficient flexible bayesian approach proposed dual semiparametric regression model models mean function semiparametrically estimates distribution error term nonparametrically using weighted dirichlet process mixture wdpm bayesian approach developed assumption distributions response variables unknown wdpm approach especially useful real applications heterogeneous error distributions come mixture distributions mean function unknown functions estimated using natural cubic smoothing splines error terms several different wdpms proposed using different weights depend distances covariates marginal likelihoods derived computation marginal likelihood wdpm provided efficient markov chain monte carlo mcmc algorithms also provided bayesian approaches based different wdpms compared parametric error model dirichlet process mixture dpm error model terms bayes factor using simulation study suggesting better performance bayesian approach based wdpm advantage proposed bayesian approach also demonstrated using credit rating data â© elsevier b v
10.1137/17M1110535 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045069326&doi=10.1137%2f17M1110535&partnerID=40&md5=8ac9152414d41851e887c2b77147988c 1,paper present strategy accelerating posterior inference unknown inputs time fractional diffusion models many inference problems posterior may concentrated small portion entire prior support much efficient build simulate surrogate significant region posterior end construct coarse model using generalized multiscale finite element method gmsfem solve least squares problem coarse model regularizing levenberg marquart algorithm intermediate distribution built based approximate sampling distribution bayesian inference use gmsfem least squares stochastic collocation method obtain reduced coarse model based intermediate distribution increase sampling speed markov chain monte carlo dreamzs algorithm used explore surrogate posterior density based surrogate likelihood intermediate distribution proposed method lower generalized polynomial chaos order gives approximate posterior accurately surrogate model directly based original prior numerical examples time fractional diffusion equations carried demonstrate performance proposed method applications bayesian inversion â© society industrial applied mathematics
10.1061/(ASCE)HE.1943-5584.0001583 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032219421&doi=10.1061%2f%28ASCE%29HE.1943-5584.0001583&partnerID=40&md5=a4fd0de53670456967e1d7ddabbe3c28 0,variations precipitation extremes relatively small spatial scales urban areas significantly different larger regions understanding variations critical urban infrastructure design operation urban climatology sparse spatial data lead uncertainties estimates spatial precipitation study bayesian hierarchical model used obtain spatial distribution return levels precipitation extremes urban areas quantify associated uncertainty generalized extreme value gev distribution used modeling precipitation extremes spatial component introduced parameters gev latent spatial process considering geographic climatologic covariates markov chain monte carlo algorithm used sampling parameters gev distribution latent process model applicability methodology demonstrated data telemetric rain gauge stations bangalore city india case study inferred elevation mean monsoon precipitation predominant covariates annual maximum precipitation variation seasonal extremes also examined study monsoon maximum precipitation observed geographic covariates dominate whereas summer maximum precipitation elevation mean summer precipitation predominant covariates significant variation spatial return levels extreme precipitation observed city â© american society civil engineers
10.1007/s00477-018-1617-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055260777&doi=10.1007%2fs00477-018-1617-y&partnerID=40&md5=884a9cd140dfa7038bcacecc13ef37bd 0,rapid growth nanotechnology industry nanomaterials emerging pollutant gradually released subsurface environments become great concerns simulating transport nanomaterials groundwater important approach investigate predict impact nanomaterials subsurface environments currently number transport models used simulate process outputs models inconsistent due conceptual model uncertainty however performances different models simulating nanoparticles transport groundwater rarely assessed bayesian framework previous researches primary objective study porous media column experiment conducted observe transport titanium dioxide nanoparticles nano tio ten typical transport models consider different chemical reaction processes used simulate transport nano tio observed nano tio breakthrough curves data used calibrate models transport model parameter uncertainty evaluated using markov chain monte carlo dream zs algorithm used sample parameter probability space moreover bayesian model averaging bma method used incorporate conceptual model uncertainty arising different chemical reaction based transport models results indicate two sites nonequilibrium sorption models well reproduce retention nano tio transport porous media linear equilibrium sorption isotherm first order degradation mobile immobile models fail describe nano tio retention transport bma method instead provide reliable estimations predictive uncertainty compared using single model â© springer verlag gmbh germany part springer nature
10.1155/2018/3187807 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049321653&doi=10.1155%2f2018%2f3187807&partnerID=40&md5=16be4eb47666a809516a27e2938f3d24 0,media coverage reduces transmission rate infective susceptible individuals reflected suitable nonlinear functions mathematical modeling disease focus estimating parameters transmission rate based stochastic sir epidemic model media coverage order reduce computational load newton raphson algorithm markov chain monte carlo mcmc technique incorporated maximum likelihood estimation simulations validate estimation results necessity model media coverage modeling contagious diseases â© changguo li et al
10.1016/B978-0-444-64241-7.50252-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050611520&doi=10.1016%2fB978-0-444-64241-7.50252-4&partnerID=40&md5=5c1b3b45c3717059d25bee8463fe6c57 0,contribution employs simulation based approach assessing accuracy computational efficiency different strategies estimation probability distributions applied ode dae systems specifically two bayesian markov chain monte carlo approaches compared fast new pdf estimation strategy based projection techniques two case studies analyzed confirm new pdf estimation strategy offers good trade accuracy computational efficiency thus excellent time critical pdf estimation tasks â© elsevier b v
10.1155/2018/8134132 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053049325&doi=10.1155%2f2018%2f8134132&partnerID=40&md5=f86f60515f66244f99eae9aaeed18d6d 0,consider bayesian approach assessing hypotheses equivalence two arm trials binary data discuss development likelihood prior posterior distributions parameters interest examine suitability normal approximation posterior distribution obtained via taylor series expansion bayesian inference carried using markov chain monte carlo mcmc methods illustrate methods using actual data arising two arm clinical trials preventing mortality myocardial infarction â© cynthia kpekpena saman muthukumarana
10.1285/i20705948v11n2p655 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055165370&doi=10.1285%2fi20705948v11n2p655&partnerID=40&md5=cb5d2c559d3f5a83b6409bfca1a83043 0,context survival lifetime analysis introduce paper bayesian maximum likelihood approaches bivariate basu dhar geometric model presence covariates cure fraction distribution useful model bivariate discrete lifetime data bayesian estimation posterior summaries interest obtained using standard markov chain monte carlo methods openbugs software maximum likelihood estimates parameters interest computed using maxlik package r software illustrations proposed approaches given two real data sets â© universitã del salento
10.4310/SII.2018.v11.n2.a4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043349294&doi=10.4310%2fSII.2018.v11.n2.a4&partnerID=40&md5=b3611d138bee2d09dd44f272dbf41e17 1,multivariate nonlinear mixed effects model mtnlmm shown promising robust tool analyzing multiple longitudinal trajectories following arbitrary growth patterns presence outliers possible missing responses owing intractable likelihood function model devise fully bayesian estimating procedure account uncertainties model parameters random effects missing responses via markov chain monte carlo method posterior predictive inferences future values missing responses also investigated conduct simulation study demonstrate feasibility bayesian sampling schemes proposed techniques illustrated applications two case studies â© international press boston inc
10.1007/978-3-319-99465-9_4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053832988&doi=10.1007%2f978-3-319-99465-9_4&partnerID=40&md5=8ecdf12f4c1f6df698d4afb4eeccff4e 0,chapter introduces classical frequentist bayesian inference applied analyzing diffraction profiles methods compared contrasted methods applied modelling single diffraction profiles full profile refinement crystallographic structures bayesian method markov chain monte carlo algorithms used sample distribution model parameters allowing construction posterior probability distributions provide parameter estimates quantifiable uncertainties present application method single peak fitting lead zirconate titanate crystal structure refinement national institute standards technology silicon standard reference material â© springer nature switzerland ag
10.17713/ajs.v47i1.578 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041334692&doi=10.17713%2fajs.v47i1.578&partnerID=40&md5=bcbca2656d726f1e5ffab03bb2b2d56f 0,paper deals estimation procedure inverse weibull distribution progressive type ii censored samples removals follow beta binomial probability law estimate unknown parameters maximum likelihood bayes estimators obtained progressive censoring scheme mentioned bayes estimates obtained using markov chain monte carlo mcmc technique considering square error loss function compared corresponding mleâ€™s expected total time test obtained considered censoring scheme finally real data set analysed check validity study â© austrian statistical society rights reserved
10.1515/snde-2017-0062 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046625671&doi=10.1515%2fsnde-2017-0062&partnerID=40&md5=67ce91b23ccd917890b3abd0448ea7c8 0,paper propose study effective bayesian subset selection method two threshold variable autoregressive ttv ar models usual complexity model selection increased capturing uncertainty two unknown threshold levels two unknown delay lags using markov chain monte carlo mcmc techniques driven stochastic search identify best subset model large number possible choices simulation experiments show proposed method works well applied application hang seng index successfully distinguish best subset ttv ar model â© walter de gruyter gmbh berlin boston
10.1214/16-BA1043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039871540&doi=10.1214%2f16-BA1043&partnerID=40&md5=a30f8afd9883d2e693ba0bb01e94a52b 1,bayesian item response models used modeling educational testing internet ratings data typically statistical analysis carried using markov chain monte carlo methods however may computationally feasible real time data continuously arrive online parameter estimation needed develop efficient algorithm based deterministic moment matching method adjust parameters real time proposed online algorithm works well two real datasets achieving good accuracy considerably less computational time â© international society bayesian analysis
10.1214/17-BA1083 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054697234&doi=10.1214%2f17-BA1083&partnerID=40&md5=89b0f3d63808f121f1cc1dff7bb4f3c4 1,introduce normal inverse gamma summation operator combines bayesian regression results different data sources leads simple split merge algorithm big data regressions summation operator also useful computing marginal likelihood facilitates bayesian model selection methods including bayesian lasso stochastic search variable selection markov chain monte carlo model composition etc observations scanned one pass sampler iteratively combines normal inversegamma distributions without reloading data simulation studies demonstrate algorithms efficiently handle highly correlated big data real world data set employment wage also analyzed â© international society bayesian analysis
10.1029/2018JB016079 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054831528&doi=10.1029%2f2018JB016079&partnerID=40&md5=208188419077a9bad1a7e28ee25e5cd5 0,different geophysical observables sensitive volume possible invert simultaneously jointly constrain different physical properties question addressed study determine structures e g interfaces common different properties ones separated present algorithm resolving level spatial coupling physical properties enable common separate structures model new approach called structure decoupling sd algorithm based bayesian trans dimensional adaptive parameterization models display full spectra spatial coupling physical properties fully coupled models identical model geometries imposed across inverted properties completely decoupled models independent parameterization used property apply algorithm three geophysical inverse problems using synthetic field data synthetic cases compare sd algorithm standard markov chain monte carlo reversible jump markov chain monte carlo approaches use either fully coupled fully decoupled parameterizations case coupled structures sd algorithm behave differently methods assume common interfaces case decoupled structures sd approach demonstrated correctly retrieve portion profiles physical properties share structure application new algorithm field data demonstrates ability decouple structures common stratification supported data â© authors
10.1137/17M1153157 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054970164&doi=10.1137%2f17M1153157&partnerID=40&md5=926a27c08850fa8a70138de4db7ca27b 0,introducing inequality constraints gaussian processes lead realistic uncertainties learning great variety real world problems consider finite dimensional gaussian model maatouk bay math geosci pp satisfy inequality conditions everywhere either boundedness monotonicity convexity contributions threefold first extend approach order deal sets linear inequalities second explore different markov chain monte carlo mcmc methods approximate posterior distribution third investigate theoretical numerical properties constrained likelihood covariance parameter estimation according experiments artificial real data framework together hamiltonian monte carlo sampler provides efficient results data fitting uncertainty quantification copyright â© siam asa
10.1137/17M1137218 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054967728&doi=10.1137%2f17M1137218&partnerID=40&md5=051a96953d3488c102618c22df9351bc 0,bayesian inverse problems posterior distribution used quantify uncertainty reconstructed solution fully bayesian approaches prior parameters assigned hyperpriors markov chain monte carlo algorithms often used draw samples posterior distribution however implementations algorithms computationally expensive present computationally efficient scheme sampling high dimensional gaussian distributions ill posed bayesian linear inverse problems approach uses metropolis hastings independence sampling proposal distribution based low rank approximation prior preconditioned hessian show dependence acceptance rate number eigenvalues retained discuss conditions acceptance rate high demonstrate proposed sampler using metropolis hastings within gibbs sampling numerical experiments image deblurring computerized tomography nmr relaxometry copyright â© siam asa
10.1007/978-3-030-00129-2_15 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053934038&doi=10.1007%2f978-3-030-00129-2_15&partnerID=40&md5=62954dba3da849b287a3db8af7d2c787 0,accurate noise modelling important training deep learning reconstruction algorithms noise models well known traditional imaging techniques noise distribution novel sensor may difficult determine priori therefore propose learning arbitrary noise distributions paper proposes fully connected neural network model map samples uniform distribution samples explicitly known probability density function training jensen shannon divergence distribution modelâ€™s output target distribution minimized experimentally demonstrate model converges towards desired state provides alternative existing sampling methods inversion sampling rejection sampling gaussian mixture models markov chain monte carlo model high sampling efficiency easily applied probability distribution without need analytical numerical calculations â© springer nature switzerland ag
10.1504/IJKBD.2018.094896 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054136953&doi=10.1504%2fIJKBD.2018.094896&partnerID=40&md5=f23d46241d852e337797f4cfc1328265 0,computer generated model illustrates advantages virtual silico techniques derived data smes service industries enables business owner consultant identify organisation three dimensional landscape draw quantitative conclusions fruitful future directions travel plus high resulting benefits costs due along journey â€˜ready goâ€™ landscape map immense value academics practitioners alike easily applicable anyone create three dimensional fold discuss implications growth development specific clients markov chain monte carlo modelling presented put simply throwing virtual balls basic fold show predict outcomes knowledge engineering projects results shown adding multiskilled innovators adding network input external environments costing management control effectively explaining ipr adds extraneous value copyright â© inderscience enterprises ltd
10.1002/sim.7916 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052374881&doi=10.1002%2fsim.7916&partnerID=40&md5=6ed32f815e552cc87715e45d79ee5dff 0,paper propose semiparametric failure time model analyze multivariate censored data latent variables proposed model generalizes conventional accelerated failure time model accommodate latent risk factors measured multiple observed variables factor analysis incorporate additive nonparametric functions observed latent risk factors examine functional effects multivariate failure times interest bayesian approach along bayesian p splines markov chain monte carlo techniques developed estimate unknown parameters functions empirical performance proposed methodology evaluated simulation study application study risk factors two diabetes complications presented â© john wiley sons ltd
10.1027/1614-2241/a000147 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049162218&doi=10.1027%2f1614-2241%2fa000147&partnerID=40&md5=0536840c0211196efd73fb29a1a2f933 0,circular data different linear data analysis also requires methods different conventional methods study bayesian embedding approach estimating circular regression models investigated means simulation studies terms performance efficiency flexibility new markov chain monte carlo mcmc sampling method proposed contrasted existing method empirical example regression model predicting teachers scores interpersonal circumplex used throughout performance efficiency better newly proposed sampler reasonable good situations furthermore method general deemed flexible additional research done provides overview circular data looks like practice investigates interpretation circular effects examines might conduct way hypothesis testing model checking embedding approach â© hogrefe publishing
10.1007/s10763-018-9917-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050752738&doi=10.1007%2fs10763-018-9917-8&partnerID=40&md5=7c99a076da26bb6ef76e580644770605 0,study critically examines digital divides comprising access use information technology two spheres schools home affect student achievement confucian heritage cultures chcs sample comprised students schools seven chcs participated program international student assessment pisa markov chain monte carlo multiple imputation hierarchical linear modeling hlm latent class analysis lca employed analysis results showed home school use benefited student mathematics achievement students overall least resources academically successful results indicate importance understanding nuanced effects digital divides different contexts â© ministry science technology taiwan
10.1016/j.sste.2018.05.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048020824&doi=10.1016%2fj.sste.2018.05.001&partnerID=40&md5=70c7a07b3900fb5c75fb186afcb8934f 0,hospital length stay los often used indicator hospital efficiency resource utilization los nonnegative presence zeros typically positively skewed long right tail may adequately modelled traditional distributions lognormal developed zero augmented accelerated frailty model modeling extreme skewness presence zeros levels utilization health services may vary geographically conditional autoregressive priors used provide spatial smoothing across neighboring hospital health districts random effect terms linked investigate capacity longer los consistently higher lower health district level modeling inference used bayesian approach via markov chain monte carlo simulation techniques demonstrated proposed model modeling los patients admitted due chronic lower respiratory disease saskatchewan canada â© elsevier ltd
10.4310/SII.2018.v11.n3.a12 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054672429&doi=10.4310%2fSII.2018.v11.n3.a12&partnerID=40&md5=76c93079b1b896df6e0088f07dc0b697 0,analysis scientific data often interest learn features feature interactions relevant prediction task present selective bayesian forest classifier strikes balance predictive power interpretability simultaneously performing classification feature selection feature interaction detection visualization builds parsimonious yet flexible models using tree structured bayesian networks samples ensemble models using markov chain monte carlo build feature selection capability dividing trees two groups according relevance outcome interest method performed competitively compared top classification algorithms simulated data sets real data sets terms classification accuracy often outperformed methods terms feature selections interaction visualizations â© international press boston inc
10.1016/j.sste.2018.08.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053104917&doi=10.1016%2fj.sste.2018.08.002&partnerID=40&md5=012043669ee8fd3ea0945dde25ccf74f 0,emerging epidemic public health officials must move quickly contain spread information obtained statistical disease transmission models often informs development containment strategies inference procedures bayesian markov chain monte carlo allow researchers estimate parameters models computationally expensive work explore supervised statistical machine learning methods fast inference via supervised classification focus deep learning apply methods simulated epidemics two populations swine farms iowa find random forest performs well denser population outperformed deep learning model sparser population â© elsevier ltd
696.5791516387612 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051487450&partnerID=40&md5=f136fcb27bc5b8a1eeb919de423e1b14 0,proceedings contain papers topics discussed include centrifugal compressors transient surge analysis need hot gas bypass line comprehensive model predicting efficiency dra liquid pipelines effect placing relief system outside flow path crude oil pipeline system evaluation probabilistic leak detection testing approach cpm systems mitigation slugging phenomena offshore oil export lines modeling mitigation acoustic induced vibration aiv piping systems modeling heavy crude modeling rapid transients natural gas pipelines operational experience introduction light oil heavy oil pipeline system optimization gas networks transient conditions performance testing data interpretation using markov chain monte carlo methods natural gas transmission pipeline compressor station
10.26802/jaots.2018.12216 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051342130&doi=10.26802%2fjaots.2018.12216&partnerID=40&md5=77025ce3a3b4f657cf691fe34a2797d1 0,mma multiple model analysis used determine diffusion modeling uncertainties groundwater solutes arising different grid scales series seepage field models constructed using mcmc adaptive metropolis algorithm markov chain monte carlo method based large hydro geological test dataset next optimal seepage model selected simulate solute diffusion determine uncertainties arising different grid scales effect solute diffusion calculations due numerical dispersion reduced numerical simulations still influenced chosen time steps spatial scales simulated example show increased scale resolution lead accurate results finally show simulated solute accuracy controlled seepage velocity time step size simulation model grid scale â© walter de gruyter gmbh rights reserved
10.1017/asb.2017.21 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030717499&doi=10.1017%2fasb.2017.21&partnerID=40&md5=5a8a95d6813e682537f08b43366402c2 0,age period cohort models used life general insurance parameterized actuaries used several methods avoid cubic splines regularization statistical approach avoiding parameterization reduce estimation predictive variances compared mle markov chain monte carlo mcmc estimation regularization accomplished use mean zero priors degree parsimony optimized numerically efficient sample cross validation provides consistent framework comparing variety regularized mcmc models built cubic splines linear splines limiting case non regularized estimation apply multiple trend model hunt blake â© astin bulletin
10.1285/i20705948v11n2p463 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055152861&doi=10.1285%2fi20705948v11n2p463&partnerID=40&md5=6ba15f17dcfa2d1cde55c5768a324cc2 0,recent years use copulas grown rapidly especially survival analysis paper introduce bivariate modified weibull distribution derived farlie gumbel morgenstern fgm copula function commonly used model weak linear dependences considering presence non censored data censored data extensive simulation study developed check performance maximum likelihood method estimating parameters proposed model maximum like lihood bayesian approaches estimation model parameters presented bayesian analysis posterior distributions parameters estimated using markov chain monte carlo mcmc methodology example considering real data set introduced illustrate proposed methodology â© universitã del salento
10.1504/IJTGM.2018.092487 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049063241&doi=10.1504%2fIJTGM.2018.092487&partnerID=40&md5=3c5ce46be807f9bf9531e16dbc8a7976 0,paper based bayesian inference explore two purposes first specific objective proposed consider empirical analysis employing panel bayesian vector autoregressive pbvar model secondly empirical study aimed analyse driven factor tourism demands service sectors adapting granger causality bayesian test technically simulated computation called markov chain monte carlo mcmc approach employed investigate researchâ€™s findings yearly time series data tourism growth tourist arrivals economic growth service sectors asean countries singapore thailand malaysia observed â€“ empirical results study deeply clarify linkage tourism demands economy asean countries give recommendations assure suitable tourism policy appropriately activated copyright â© inderscience enterprises ltd
10.1162/COLI_a_00326 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054024956&doi=10.1162%2fCOLI_a_00326&partnerID=40&md5=79645774ff52b73de8795f560202179a 0,orthographic similarities across languages provide strong signal unsupervised probabilistic transduction decipherment closely related language pairs existing decipherment models however well suited exploiting orthographic similarities propose log linear model latent variables incorporates orthographic similarity features maximum likelihood training computationally expensive proposed log linear model address challenge perform approximate inference via markov chain monte carlo sampling contrastive divergence results show proposed log linear model contrastive divergence outperforms existing generative decipherment models exploiting orthographic features model scales large vocabularies preserves accuracy low resource contexts â© association computational linguistics
10.1140/epjc/s10052-017-5479-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042845258&doi=10.1140%2fepjc%2fs10052-017-5479-0&partnerID=40&md5=4957238f6286e82349e2ff001ea1c478 0,cosmological redshift drift lead next step high precision cosmic geometric observations becoming direct irrefutable test cosmic acceleration order test viability possible properties effect also called sandageâ€“loeb sl test generate model independent mock data set order compare constraining power future mock data sets type ia supernovae sne baryon acoustic oscillations bao performance data sets analyzed testing several cosmological models markov chain monte carlo mcmc method independently well combining data sets final results show general sl data sets allow remarkable constraints matter density parameter today î©m every tested model showing also great complementarity sne bao data regarding dark energy parameters â© author
10.1111/tops.12315 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038122348&doi=10.1111%2ftops.12315&partnerID=40&md5=a27292f2a67f543ae3bdd4fcf069b089 1,cognitive architectures often applied data individual experiments paper develop act r reader model much larger set data eye tracking corpus data shown resulting model good fit data considered low level processes unlike previous related works prominently engelmann vasishth engbert kliegl model achieves fit estimating free parameters act r using bayesian estimation markov chain monte carlo mcmc techniques rather relying mix manual selectionâ +â default values method used paper generalizable beyond particular model data set used act r models copyright â© cognitive science society inc
92.58184439297156 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044994797&partnerID=40&md5=c43f6cde8d2ef838bc9f7b442687c10d 0,paper follow idea using invariant loss function decision theoretic approach point estimation bayesian mixture models presented although using approach called label switching longer problem difficult assess uncertainty propose simple accessible way assessing uncertainty using leaving idea jackknife method compute bayes estimates called jackknife bayes estimates use visualize uncertainty bayesian point estimates paper primarily related simulation based point estimation using markov chain monte carlo mcmc samples hence mcmc methods particular gibbs sampling metropolis hastings method used approximate posterior mixture models also present use importance sampling reduced posterior mixture distribution corresponding leaving observation â© mathematical association thailand rights reserved
10.1016/j.gfj.2018.07.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052972964&doi=10.1016%2fj.gfj.2018.07.002&partnerID=40&md5=a97e8d02a5f779281dc614fb35f21174 0,using firm level panel data paper examines whether cost capital coc differs significantly u based multinational corporations mncs u domestic corporations dcs results suggest u based mncs higher coc u dcs industry importantly influences coc study also finds significant time effect coc time effect follows trend u economic growth rate using bayesian markov chain monte carlo approach estimate jointly cost equity cost debt capital structure find higher cost capital mncs due mainly higher cost equity greater use equity financing cost debt financing differ significantly mncs versus dcs â© elsevier inc
10.1214/17-AOS1649 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054759831&doi=10.1214%2f17-AOS1649&partnerID=40&md5=c70da9099d8e4d5a63f9c780abd24bbc 1,contrastive divergence cd algorithm achieved notable success training energy based models including restricted boltzmann machines played key role emergence deep learning idea algorithm approximate intractable term exact gradient log likelihood function using short markov chain monte carlo mcmc runs approximate gradient computationally cheap biased whether cd algorithm provides asymptotically consistent estimate still open questions paper studies asymptotic properties cd algorithm canonical exponential families special cases energy based model suppose cd algorithm runs mcmc transition steps iteration iteratively generates sequence parameter estimates î tâ‰¥ given data sample xi n i= âˆ¼ pî conditions commonly obeyed cd algorithm practice prove existence bounded limit point time average âˆ’ = î â†’ âˆž consistent estimate true parameter î proof based fact î tâ‰¥ homogenous markov chain conditional data sample xi n i= chain meets fosterâ€“lyapunov drift criterion converges random walk around maximum likelihood estimate range random walk shrinks zero rate n sample size n â†’ âˆž â© institute mathematical statistics
10.1080/10618600.2018.1482765 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053268730&doi=10.1080%2f10618600.2018.1482765&partnerID=40&md5=9c74e8d1fb2f23480a04a55d66b24bb9 0,develop efficient bayesian inference one factor copula model two significant contributions existing methodologies first approach leads straightforward inference dependence parameters latent factor inference former available frequentist alternatives second develop reversible jump markov chain monte carlo algorithm averages models constructed different bivariate copula building blocks approach accommodates combination discrete continuous margins extensive simulations compare computational monte carlo efficiency alternative proposed sampling schemes preferred algorithm provides reliable inference parameters latent factor model space potential methodology highlighted empirical study binary measures socio economic deprivation collected east timorese households importance conducting inference latent factor motivated constructing poverty index using estimates factor compared linear gaussian factor model model average improves sample fit relationships poverty index observed variables uncovered approach diverse allow richer precise understanding dependence overall deprivation individual measures well â© â© american statistical association institute mathematical statistics interface foundation north america
10.1002/bimj.201600206 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031421931&doi=10.1002%2fbimj.201600206&partnerID=40&md5=a760a844f3667d4b9b433388eb709fe6 1,paper development probabilistic network diagnosis acute cardiopulmonary diseases presented detail panel expert physicians collaborated specify qualitative part directed acyclic graph defining factorization joint probability distribution domain variables univariate conditional distributions quantitative part set parametric models defining univariate conditional distributions estimated following bayesian paradigm particular exploited original reparameterization beta categorical logistic regression models elicit joint prior distribution parameters medical experts updated conditioning dataset hospital records via markov chain monte carlo simulation refinement iteratively performed probabilistic network provided satisfactory concordance index values several acute diseases reasonable diagnosis six fictitious patient cases probabilistic network employed perform medical diagnosis total diseases acute chronic basis patient findings â© wiley vch verlag gmbh co kgaa weinheim
10.1093/mnras/stx2304 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045895593&doi=10.1093%2fmnras%2fstx2304&partnerID=40&md5=1d453535f465613bc6f60abcd983ec0e 4,present novel algorithm based bayesian method tilted ring analysis disc galaxy velocity fields compared conventional algorithms based chi squared minimization procedure new bayesian based algorithm suffers less local minima model parameters even highly multimodal posterior distributions moreover bayesian analysis implemented via markov chain monte carlo sampling requires broad ranges posterior distributions parameters makes fitting procedure fully automated feature essential performing kinematic analysis large number resolved galaxies expected detected neutral hydrogen h surveys square kilometre array pathfinders called bayesian automated tiltedring fitter dbat implements bayesian fits tilted ring models order derive rotation curves galaxies explore dbat performance artificial hi data cubes built based representative rotation curves intermediate mass massive spiral galaxies b australia telescope compact array hi data local volume hi survey find dbat works best well resolved galaxies intermediate inclinations â° â° complementing techniques better suited modelling inclined galaxies â© authors
10.1080/10618600.2018.1482761 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053562527&doi=10.1080%2f10618600.2018.1482761&partnerID=40&md5=e3e6ab97c0c6591908fd1f7ddb4e4873 0,fitting hierarchical bayesian models spatially correlated datasets using markov chain monte carlo mcmc techniques computationally expensive complicated covariance structures underlying spatial processes together high dimensional parameter space mean number calculations required grows cubically number spatial locations mcmc iteration necessitates need efficient model parameterizations hasten convergence improve mixing associated algorithms consider partially centred parameterizations pcps lie continuum known centered cp noncentered parameterizations ncp introducing weight matrix remove conditional posterior correlation fixed random effects hence construct pcp achieves immediate convergence three stage model based multiple gaussian processes known covariance parameters covariance parameters unknown dynamically update parameterization within sampler pcp outperforms cp ncp leads fully automated algorithm demonstrated two simulation examples effectiveness spatially varying pcp illustrated practical dataset nitrogen dioxide concentration levels supplemental materials consisting appendices datasets computer code reproduce results available online â© â© author published license taylor francis
10.1093/mnras/stx2433 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042700422&doi=10.1093%2fmnras%2fstx2433&partnerID=40&md5=834605c06b7ef1dc8b61aa670adc419f 3,apply analytic markov chain monte carlo model sample active galactic nucleus agn driven biconical outflows identified sample active galaxies double peaked narrow emission lines z sloan digital sky survey find best described asymmetric bicones nested bicones symmetric bicones geometry kinematics models find moderate luminosity agn outflows large energetic biconical outflows axes randomly oriented respect photometric major axis galaxy implying randomly oriented clumpier torus collimate outflow torus also allows radiation escape equatorially find per cent outflows energetic enough drive two staged feedback process host galaxies outflows geometrically intersect photometric major axis galaxy per cent outflow host galaxies significantly redder significantly lower specific star formation rates compared matched sample active galaxies â© author
10.1093/MNRAS/STX2464 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040258364&doi=10.1093%2fMNRAS%2fSTX2464&partnerID=40&md5=85195d5d9ff06fc749d398376bc46f41 3,developed novel markov chain monte carlo chemical painting technique explore possible radial vertical metallicity gradients thick disc progenitor analysis match n body simulation data apache point observatory galactic evolution experiment survey assume thick disc constant scaleheight completed formation early epoch time radial mixing stars taken place assumptions find initial radial metallicity gradient thick disc progenitor negative either flat even positive explain current negative vertical metallicity gradient thick disc study suggests thick disc built inside upside fashion older smaller thicker populations metal poor case star forming discs different epochs thick disc formation allowed different radial metallicity gradients including negative one helps explain variety slopes observed high redshift disc galaxies scenario helps explain positive slope metallicity rotation velocity relation observed galactic thick disc hand radial mixing flattens slope existing gradient â© authors
10.1016/j.epidem.2018.08.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052987683&doi=10.1016%2fj.epidem.2018.08.004&partnerID=40&md5=ff7ea578efc133c91ccbf944677d94f9 0,dengue dynamics shaped complex interplay several factors including vector seasonality interaction four virus serotypes inapparent infections however paucity quality data allow taken account mathematical models order explore separately importance factors models combined surveillance data local scale cluster study rural province kampong cham cambodia serotypes asymptomatic infections documented formulate several mechanistic models one relying different set hypotheses explicit vector dynamics transmission via asymptomatic infections coexistence several virus serotypes models confronted observed time series using bayesian inference markov chain monte carlo model selection performed using statistical information criteria coherence epidemiological characteristics reproduction numbers incidence proportion dynamics susceptible classes assessed model analyses transmission dynamics rural endemic setting highlight two strain models interacting effects better reproduce long term data difficult parameterize relying incidence cases hand considering available data incorporating vector asymptomatic components seems limited added value seasonality underreporting already accounted â© authors
10.1093/MNRAS/STY2062 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055162888&doi=10.1093%2fMNRAS%2fSTY2062&partnerID=40&md5=0e06152ef1a2c96b5a855ba23125ca93 0,cosmic distance duality relation ddr connects angular diameter distance luminosity distance simple formula da z + z dl z = important relation cosmology therefore testing validity ddr great importance paper test possible violation ddr using available local data including type ia supernovae sne ia galaxy clusters baryon acoustic oscillations bao write modified ddr da z + z dl z = î· z consider two different parameterizations î· z namely î· z = + î· z î· z = + î· z + z luminosity distance sne ia compared angular diameter distance galaxy clusters bao redshift two different cluster data used e elliptical clusters spherical clusters parameter î· obtained using markov chain monte carlo methods found î· strictly constrained elliptical clusters + bao data best fitting values î· = â± î· = â± first second parametrizations respectively however spherical clusters + bao data strictly constrain î· due large intrinsic scatter case studied evidence violation ddr found â© author
10.1214/17-BA1089 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054617184&doi=10.1214%2f17-BA1089&partnerID=40&md5=848ea89ae157e3b70894493780799453 1,regular vine copulas flexible class dependence models bayesian methodology model selection inference yet fully developed propose sparsity inducing otherwise non informative priors present novel proposals enable reversible jump markov chain monte carlo posterior simulation bayesian model selection inference method first jointly estimate posterior distribution trees regular vine copula represents substantial improvement existing frequentist bayesian strategies select one tree time known induce bias simulation study demonstrates feasibility strategy shows combines superior selection reduced computation time compared bayesian tree tree selection real data example forecast daily expected tail loss portfolio nine exchange traded funds using fully bayesian multivariate dynamic model built around bayesian regular vine copulas illustrate model viability financial analysis risk estimation â© international society bayesian analysis
10.1504/IJEBR.2018.089689 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041750373&doi=10.1504%2fIJEBR.2018.089689&partnerID=40&md5=0d82573e0e8c7642a4f524244b80858b 0,paper presents variant mixed logit model form panel like error components mixed logit relies multinomial logit formulation weighted logit formula opposed usual conditional logit representation uses model evaluate consistency consumersâ€™ preferences health insurance jointly modelling stated health insurance preferences revealed health insurance choices respondents medical expenditure panel survey meps estimation implemented within bayesian paradigm using markov chain monte carlo mcmc methods results suggest meps respondents present stable preferences health insurance fact respondents initially express health insurance worth cost found less likely privately insured less likely publicly insured hand initially expressing health insurance worth cost found likely privately insured likely publicly insured copyright â© inderscience enterprises ltd
10.1093/mnras/sty2140 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054734358&doi=10.1093%2fmnras%2fsty2140&partnerID=40&md5=512a781b5adc00b16afddf27ff1c02a8 0,present umbrella sampling us technique show used sample extremely low probability areas posterior distribution may required statistical analyses data approach sampling target likelihood split sampling multiple biased likelihoods confined within individual umbrella windows show us algorithm efficient highly parallel easily used existing markov chain monte carlo mcmc samplers method allows user capitalize intuition define umbrella windows increase sampling accuracy along specific directions parameter space alternatively one define umbrella windows using approach similar parallel tempering provide public code implements us standalone python package present number tests illustrating power us method sampling low probability areas posterior show ability allows considerablymore robust sampling ofmultimodal distributions compared standard sampling methods also present application method real world example deriving cosmological constraints using supernova type ia data show us sample posterior accurately â‰ˆ ïƒ credible region î©m î©î› plane computational effort affine invariant mcmc sampling implemented emcee code samples posterior reliably â‰ˆ ïƒ â© author
615.1280532741631 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046085294&partnerID=40&md5=7e53cfd67c633ebe43663a5da1dd6ac8 0,literature several macroeconomic economic factors gdp inflation rate unemployment exchange rate identified influence level non performing loan ratio npl banking sector macroeconomic variables industry production index stock exchange index oil price also well documented strong explanatory power npls study examine effects macroeconomic variables exchange rates tl= tl â‚¬ industrial production index ipi stock exchange index bist oil price npl ratio focus estimating parameters related variables non performing loan ratio model via frequentist approach bayesian analysis bayesian method provide uninformative informative priors likelihood function determines posterior distributions parameters using markov chain monte carlo mcmc algorithm sample estimates parameters posterior distributions results analysis show mentioned macroeconomic variables examined study significant effects non performing loan ratio â© world scientific engineering academy society rights reserved
10.1093/mnras/stx2109 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042586837&doi=10.1093%2fmnras%2fstx2109&partnerID=40&md5=788aa3e68e915a7aa1fa13a775cb3679 5,variability light curves spotted rotating stars often non sinusoidal quasiperiodic spots move stellar surface finite lifetimes causing stellar flux variations slowly shift phase strictly periodic sinusoid therefore accurately model rotationally modulated stellar light curve physical models stellar surfaces many drawbacks preventing effective inference highly degenerate high dimensional parameter spaces work test appropriate effective model gaussian process quasi periodic covariance kernel function highly flexible model allows sampling posterior probability density function periodic parameter marginalizing kernel hyperparameters using markov chain monte carlo approach test effectiveness method infer rotation periods simulated stellar light curves demonstrating gaussian process method produces periods accurate sinefitting periodogram autocorrelation function method also demonstrate works well real data inferring rotation periods kepler stars previously measured periods provide table rotation periods many altogether kepler objects interest posterior probability density function samples method delivers posterior probability density functions enable hierarchical studies involving stellar rotation particularly involving population modelling inferring stellar ages obliquities exoplanet systems characterizing star planet interactions code used implement method available online â© author
10.18637/jss.v083.i01 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042469222&doi=10.18637%2fjss.v083.i01&partnerID=40&md5=2cd9deddcfa58d2f55063d6d570a4405 0,paper introduces r package meta diag implementing bayesian bivariate meta analyses diagnostic test studies package meta diag purpose built front end r package inla inla offers full bayesian inference large set latent gaussian models using integrated nested laplace approximations meta diag extracts features needed bivariate meta analysis presents intuitive way allows user straightforward model specification offers user specific prior distributions newly proposed penalized complexity prior framework supported builds prior intuitions behaviors variance correlation parameters accurate posterior marginal distributions sensitivity specificity well hyperparameters covariates directly obtained without markov chain monte carlo sampling univariate estimates interest odds ratios well summary receiver operating characteristic sroc curve common graphics directly available interpretation interactive graphical user interface provides user full functionality package without requiring r programming package available comprehensive r archive network cran https cran r project org package=meta diag usage illustrated using three real data examples â© american statistical association rights reserved
10.1002/pst.1888 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051062880&doi=10.1002%2fpst.1888&partnerID=40&md5=8ee60574275ce29bb889005c1d720b1b 0,article focuses objectives analysis efficacy long term extension studies chronic diseases defining discussing estimands interest studies evaluating performance several multiple imputation methods may useful estimating estimands specifically estimands defined clinical utility inferential ramifications discussed performance several multiple imputation methods approaches evaluated using simulated data results suggested interest binary outcome derived underlying continuous measurement preferable impute underlying continuous value subsequently dichotomized rather directly impute binary outcome results also demonstrated multivariate gaussian models markov chain monte carlo imputation sequential regression minimal bias anticipated confidence interval coverage even settings ordinal data departures normality concern approaches illustrated using long term extension study psoriasis â© john wiley sons ltd
10.1007/s10596-018-9769-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053181646&doi=10.1007%2fs10596-018-9769-x&partnerID=40&md5=919914974269ad6dde28f2c2836a3042 0,methane gas hydrates increasingly become topic interest potential future energy resource significant economical environmental risks associated extraction hydrate reservoirs variety multiphysics models developed analyze prospective risks benefits models generally large number empirical parameters known priori traditional optimization based parameter estimation frameworks may ill posed computationally prohibitive bayesian inference methods increasingly found effective estimating parameters complex geophysical systems methods often viable cases computationally expensive models high dimensional parameter spaces recently methods developed effectively reduce dimension bayesian inverse problems identifying low dimensional structures informed data active subspaces one generally applicable methods performing dimension reduction paper bayesian inference parameters state art mathematical model methane hydrates based experimental data triaxial compression test gas hydrate bearing sand performed efficient way utilizing active subspaces active subspaces used identify low dimensional structure parameter space exploited generating cheap regression based surrogate model implementing modified markov chain monte carlo algorithm posterior densities means match experimental data approximated computationally efficient way â© springer nature switzerland ag
10.1137/15M1033162 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046039781&doi=10.1137%2f15M1033162&partnerID=40&md5=1fe3de1abe08f53866e61338a9bdfdfa 0,making good predictions physical system using computer code requires inputs carefully specified inputs called control variables reproduce physical conditions whereas inputs called parameters specific computer code often uncertain goal statistical calibration consists reducing uncertainty help statistical model links code outputs field measurements bayesian setting posterior distribution parameters typically sampled using markov chain monte carlo methods however impractical code runs highly time consuming way circumvent issue consists replacing computer code gaussian process emulator sampling surrogate posterior distribution based calibration subject error strongly depends numerical design experiments used fit emulator assumption code discrepancy aim reduce error constructing sequential design means expected improvement criterion numerical illustrations several dimensions assess efficiency sequential strategies â© society industrial applied mathematics american statistical association
10.1080/01621459.2018.1473776 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052073228&doi=10.1080%2f01621459.2018.1473776&partnerID=40&md5=09812cdd5d40c801b68080a57084a510 0,key challenge modern bayesian statistics perform scalable inference posterior distributions address challenge variational bayes vb methods emerged popular alternative classical markov chain monte carlo mcmc methods vb methods tend faster achieving comparable predictive performance however theoretical results around vb article establish frequentist consistency asymptotic normality vb methods specifically connect vb methods point estimates based variational approximations called frequentist variational approximations use connection prove variational bernsteinâ€“von mises theorem theorem leverages theoretical characterizations frequentist variational approximations understand asymptotic properties vb summary prove vb posterior converges kullbackâ€“leibler kl minimizer normal distribution centered truth corresponding variational expectation parameter consistent asymptotically normal applications theorem derive asymptotic properties vb posteriors bayesian mixture models bayesian generalized linear mixed models bayesian stochastic block models conduct simulation study illustrate theoretical results supplementary materials article available online â© â© american statistical association
10.7566/JPSJ.87.054004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046033756&doi=10.7566%2fJPSJ.87.054004&partnerID=40&md5=1a9097c379be2bece9013f402c59f6c3 0,study unlearning mixed states hopfield model extensive loading case firstly focus case several embedded patterns correlated whereas rest uncorrelated secondly study case ii patterns divided clusters way patterns cluster correlated two different clusters correlated using replica method derive saddle point equations order parameters ansatz replica symmetry equations also derived self consistent signal noise analysis case cases ii find correlation patterns large network loses ability retrieve embedded patterns depending parameters confused memory mixed state and=or spin glass state emerges unlearning mixed state network acquires ability retrieve embedded patterns parameter regions find delete mixed state retrieve embedded patterns coefficient unlearning chosen appropriately perform markov chain monte carlo simulations find simulation theoretical results agree reasonably well except spin glass solution parameter region due replica symmetry breaking furthermore find existence many correlated clusters reduces stabilities embedded patterns mixed states â© physical society japan
10.3159/TORREY-D-17-00012.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041058605&doi=10.3159%2fTORREY-D-17-00012.1&partnerID=40&md5=194d8ab429e6838e6c7d5969ec23f2c0 0,population structure invasive species determined species specific breeding strategies region specific conditions events history invasion context investigate role human land use policy gene flow within population widespread invasive tree ailanthus altissima predicted genetic diversity elevated urban environments reduced exurban human mediated dispersal allow propagules break geographic isolation six populations altissima divided evenly among urban exurban suburban sites surveyed using set eight microsatellite loci total individuals sampled populations assessed partitioning genetic variation gene flow sites genetic cluster estimation effective population size based genetic variation also modeled using bayesian markov chain monte carlo simulations despite strong propensity clonal growth microsatellite data revealed evidence clonal reproduction population level gene flow sites found independent geographic distance instead gene flow correlated level human traffic site genetic diversity found generally increase correlation human development however reduced admixture managed sites suggests land management practices effective inhibiting gene flow managed sites â© copyright torrey botanical society
824.1452762321835 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051558141&partnerID=40&md5=55463a6845268644df657172d863fa2d 0,probit models spatial dependencies first studied mcmillen em algorithm developed produce consistent maximum likelihood estimates models spatial autoregressive probit model spatial dependent structure adds complexity estimation parameters lesage smith use bayesian estimation via markov chain monte carlo methods sample sequentially complete set conditional distributions parameters klier mcmillen proposed linearized version gmm estimator avoids infeasible problem inverting n n matrices employing large samples show standard gmm reduces nonlinear two stage least squares problem martinetti geniaux proposed approximate likelihood estimation based full maximization likelihood approximate multivariate normal distribution function use extensive simulation methods show best estimation method handle sample sizes many observations various value coefficient spatial lag provided spatial weight matrix inconvenient sparse form large data sets observation neighbours observations â© ieom society international
10.1080/10618600.2018.1459303 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052067282&doi=10.1080%2f10618600.2018.1459303&partnerID=40&md5=ba6b289d4b839c55e5b98e0d3a4f3d4c 0,performance markov chain monte carlo mcmc algorithms like metropolis hastings random walk mhrw highly dependent choice scaling matrix proposal distributions popular choice scaling matrix adaptive mcmc methods use empirical covariance matrix ecm previous samples however choice problematic dimension target distribution large since ecm converges slowly computationally expensive use propose two algorithms improve convergence decrease computational cost adaptive mcmc methods cases precision inverse covariance matrix target density well approximated sparse matrix first algorithm online estimation cholesky factor sparse precision matrix second estimates sparsity structure precision matrix combining two algorithms allows us construct precision based adaptive mcmc algorithms used black box methods densities unknown dependency structures construct precision based versions adaptive mhrw adaptive metropolis adjusted langevin algorithm demonstrate performance methods two examples supplementary materials article available online â© â© american statistical association institute mathematical statistics interface foundation north america
691.6148226696008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047349519&partnerID=40&md5=983bf2bcdf8844c3d93691465808f129 0,proceedings contain papers topics discussed include sulcal depth based cortical shape analysis normal healthy control schizophrenia groups skull segmentation mr scans using higher order shape model based convolutional restricted boltzmann machines constructing statistically unbiased cortical surface templates using feature space covariance segmentation anatomical structures cardiac cta using multi label v net iterative convolutional neural networks automatic vertebra identification segmentation ct images visualization coronary artery calcium dual energy chest radiography using automatic rib suppression radiation dose reduction digital breast tomosynthesis dbt means deep learning based supervised image processing left ventricle segmentation ultrasound combining structured random forests active shape models automatic fast ct liver segmentation using sparse ensemble machine learned contexts multilevel markov chain monte carlo approach uncertainty quantification deformable registration self reference based registration detection motion artifacts spatiotemporal image data novel framework local extraction extra axial cerebrospinal fluid mr brain images regional autonomy changes resting state functional mri patients hiv associated neurocognitive disorder
10.1007/s11009-018-9670-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053930994&doi=10.1007%2fs11009-018-9670-z&partnerID=40&md5=2f0cb1b8ef3f9791f0ddea3cf3901de1 0,k nearest neighbours k nn popular classification regression algorithm yet one main limitations difficulty choosing number neighbours present bayesian algorithm compute posterior probability distribution k given target point within data set efficiently without use markov chain monte carlo mcmc methods simulationâ€”alongside exact solution distributions within exponential family central idea data points around target generated probability distribution extending outwards appropriate though unknown number neighbours data projected onto distance metric choice transform choice k change point detection problem efficient solution recursively compute probability last change point move towards target thus de facto compute posterior probability distribution k applying approach classification regression uci data sets compare favourably importantly removing need simulation able compute posterior probability k exactly rapidly example computational time ripley data set milliseconds compared hours using mcmc approach â© author
10.1080/01621459.2018.1476244 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052155485&doi=10.1080%2f01621459.2018.1476244&partnerID=40&md5=31764d5f836137e9111f4b3e1878af96 0,voxel functional magnetic resonance imaging fmri time courses complex valued signals giving rise magnitude phase data nevertheless studies use magnitude signals thus discard half data potentially contain important information methods make use complex valued fmri cv fmri data shown lead superior power detecting active voxels compared magnitude methods particularly small signal noise ratios snrs present new bayesian variable selection approach detecting brain activation voxel level cv fmri data develop models complex valued spike slab priors activation parameters able combine magnitude phase information present complex valued em variable selection algorithm leads fast detection voxel level cv fmri slices also consider full posterior inference via markov chain monte carlo mcmc model performance illustrated extensive simulation studies including analysis physically based simulated cv fmri slices finally use complex valued bayesian approach detect active voxels human cv fmri healthy individual performed unilateral finger tapping designed experiment proposed approach leads improved detection activation expected motor related brain regions produces fewer false positive results methods cv fmri supplementary materials article available online â© â© american statistical association
10.3847/1538-4357/aa9b7e https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040326811&doi=10.3847%2f1538-4357%2faa9b7e&partnerID=40&md5=6031fd22f0c10abdf9a1733075b20cf7 2,model simultaneous quasi simultaneous multi band spectral energy distributions seds sample blazars radio core shift measurements one zone leptonic model markov chain monte carlo technique adopted sed fitting low synchrotron peaked lsp blazars seed photons broad line blr molecular torus considered respectively external compton process find sed fitting seed photons torus better utilizing blr photons suggest î³ ray emitting region may located outside blr assuming magnetic field strength î³ ray emitting region constrained sed fitting follows magnetic field distribution derived radio core shift measurements e b r â‰ƒ b pc r pc r distance central engine magnetic field strength pc calculate location î³ ray emitting region rî³ blazars find rî³ âˆ¼ ã— rsâ‰ƒ rblr rs schwarzschild radius blr size estimated broad line luminosities using empirical correlations obtained using reverberation mapping methods â© american astronomical society
10.1007/978-3-319-75408-6_41 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047780529&doi=10.1007%2f978-3-319-75408-6_41&partnerID=40&md5=f0f8b41d22958732d779af0049bd4735 0,determining trade individual criteria often obvious especially attributes different nature juxtaposed e g health money difficulty stems lack adequate market experience strong ethical component valuing goods resulting inherently imprecise preferences fuzzy sets used model willingness pay accept wtp wta quantify imprecision support decision making process preferences need estimated based available data paper show estimate membership function fuzzy wtp wta decision makersâ€™ preferences collected via survey likert based questions apply proposed methodology data set wtp wta health mathematical model contains two elements parametric representation membership function mathematical model translated likert options model parameters estimated bayesian approach using markov chain monte carlo results suggest slight wtp wta disparity wta fuzzy wtp model fragile single respondents lexicographic preferences e willing accept trade offs health money â© springer international publishing ag part springer nature
10.1093/imammb/dqx010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052222190&doi=10.1093%2fimammb%2fdqx010&partnerID=40&md5=8ead552019f3ae8f0738010091c16dcb 0,consider extensions previous models patient level nosocomial infection several ways provide specification likelihoods new models specify new update steps required stochastic integration provide programs implement methods obtain parameter estimates model choice statistics previous susceptible infected models extended allow latent period initial exposure pathogen patient becoming infectious possibility decolonization allow multiple facilities acute care hospitals long term care facilities nursing homes multiple units wards within facility patient transfers units facilities tracked accounted models direct importation colonized individual one facility unit another might inferred allow constant transmission rates rates depend number colonized individuals unit facility rates depend proportion colonized individuals statistical analysis done bayesian framework using markov chain monte carlo methods obtain sample parameter values joint posterior distribution cross validation deviance information criterion widely applicable information criterion approaches model choice fit naturally framework implemented three illustrate methods considering model selection issues parameter estimation data methicilin resistant staphylococcus aureus surveillance tests year veterans administration hospital comprising seven wards â© authors
10.1093/MNRAS/STY2015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055158105&doi=10.1093%2fMNRAS%2fSTY2015&partnerID=40&md5=d24cc6b11316cd9d1fbcdcf31bb889db 0,uncertainty quantification critical missing component radio interferometric imaging become increasingly important big data era radio interferometry emerges statistical sampling approaches perform bayesian inference like markov chain monte carlo mcmc sampling principle recover full posterior distribution image uncertainties quantified however massive data sizes like anticipated square kilometre array difficult impossible apply mcmc technique due inherent computational cost formulate bayesian inference problems sparsity promoting priors motivated compressive sensing recover maximum posteriori map point estimators radio interferometric images convex optimization exploiting recent developments theory probability concentration quantify uncertainties post processing recovered map estimate three strategies quantify uncertainties developed highest posterior density credible regions ii local credible intervals cf error bars individual pixels superpixels iii hypothesis testing image structure forms uncertainty quantification provide rich information analysing radio interferometric observations statistically robust manner ourmap based methods approximately times faster computationally state theart mcmc methods addition support highly distributed parallelized algorithmic structures first time map based techniques provide means quantifying uncertainties radio interferometric imaging realistic data volumes practical use scale emerging big data era radio astronomy â© author
10.29220/CSAM.2018.25.1.043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044041996&doi=10.29220%2fCSAM.2018.25.1.043&partnerID=40&md5=969457fe80fa5bb4c5fe21325eb88695 0,paper considers use classical bayesian inference methods analyze data generated variables whose natural behavior modeled using asymmetric distributions presence left censoring approach used lã©vy distribution presence left censored data covariates distribution good alternative model data asymmetric behavior many applications lifetime data instance especially engineering applications health research observations large comparison ones standard distributions commonly used model asymmetry data like exponential weibull log logistic appropriate fitted data inferences parameters proposed model classical inference approach obtained using maximum likelihood estimators mles approach usual asymptotical normality mles based fisher information measure bayesian approach posterior summaries interest obtained using standard markov chain monte carlo simulation methods available software like sas numerical illustration presented considering data thyroglobulin levels present group individuals differentiated cancer thyroid â© korean statistical society korean international statistical society
10.1515/phys-2018-0062 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052003425&doi=10.1515%2fphys-2018-0062&partnerID=40&md5=beefa6353434fe878b077c056c50475f 0,method judge shale gas flow regimes based digital core analysis proposed work firstly three dimensional shale digital cores anonymous shale formation sichuan basin reconstructed markov chain monte carlo mcmc algorithm based two dimensional scanning electron microscope sem images voxel based method proposed calculate characteristic length three dimensional shale digital core knudsen number three dimensional shale digital cores calculated ratio molecular mean free path characteristic length used judge flow regimes different reservoir conditions results indicate shale gas flow regimes mainly located slip flow transition flow region furthermore adsorption obvious influence free gas flow regimes adsorption exists organic pores three dimensional inorganic pores organic pores haynesville shale formation reconstructed mcmc algorithm based two dimensional sem images characteristic lengths three dimensional inorganic pores three dimensional organic pores calculated gas flow regimes organic pores inorganic pores judged â© w song et al published de gruyter
10.1002/sta4.184 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046788371&doi=10.1002%2fsta4.184&partnerID=40&md5=b461500da7914260cec25f0d211295a3 0,geostatistics inference spatial covariance parameters gaussian process often critical scientists understanding structural dependence data finite sample inference customarily proceeds either using posterior distributions fully bayesian approach via resampling subsampling techniques frequentist setting resampling methods particular bootstrap become attractive modern age big data unlike bayesian models require sequential sampling markov chain monte carlo naturally lend parallel computing resources however spatial bootstrap involves expensive cholesky decomposition decorrelate data manuscript develop highly scalable parametric spatial bootstrap uses sparse cholesky factors parameter estimation decorrelation proposed bootstrap rapid inference spatial covariances brisc algorithm requires linear memory computations embarrassingly parallel thereby delivering substantial scalability simulation studies highlight accuracy computational efficiency approach analysing large satellite temperature data brisc produces inference closely matches delivered state art bayesian approach several times faster r package brisc available download github https github com arkajyotisaha brisc available cran soon â© john wiley sons ltd
10.1093/mnras/sty2160 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054755960&doi=10.1093%2fmnras%2fsty2160&partnerID=40&md5=3a03eec0e3c897b84fe3c3cd39e54860 1,standardmodel cosmology lambda cold darkmatter î›cdm simplest model matches current observations relies two hypothetical components wit dark matter dark energy future galaxy surveys cosmic microwave background cmb experiments independently shed light components joint analysis includes cross correlations necessary extract much information possible observations paper carry multiprobe analysis based pseudo spectra test publicly available data sets use cmb temperature anisotropies cmb lensing observations planck well spectroscopic galaxy quasar samples sdss iii boss taking advantage large areas covered surveys build likelihood simultaneously analyse auto cross spectra cmb lensing tracer overdensity maps running markov chain monte carlo assess constraining power combined analysis add cmbtemperature anisotropies likelihood obtain constraints cosmological parameters h ï‰b ï‰c ln ns zre galaxy biases demonstrate joint analysis additionally constrain total mass neutrinos âˆ‘mv well dark energy equation state w total eight cosmological parameters impossible either data sets considered separately finally discuss limitations analysis related e g theoretical precision models particularly non linear regime â© author
10.1016/j.cegh.2018.02.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044162659&doi=10.1016%2fj.cegh.2018.02.009&partnerID=40&md5=c983203d75ff603c75991df2b230f224 0,background aimed compare treatments esophageal cancer association risk disease recurrence compare frequentist bayesian methods data analysis methods web science medline scopus cochrane library embase searched assessed statistical heterogeneity assumption consistency assessed using loop specific design treatment interaction methods markov chain monte carlo method used obtain pooled estimates effect size bayesian approach random effect model used report pooled risk ratios rr results study reported confidence interval ci credible interval cri results included randomized controlled trials rcts reported local recurrence esophageal cancer rr local recurrence surgery plus paclitaxel cisplatin radiotherapy spcrt compared surgery alone ci rr spcrt compared surgery plus cisplatin vindesine scv ci compared cisplatin fluorouracil radiotherapy plus surgery cfrts spcrt better treatment rr = ci conclusions network meta analysis indicated spcrt compared surgery alone treatments better treatment terms ranking spcrt radiotherapy plus surgery rts first second treatments network seems precision frequentist better bayesian approach however results ranking treatments frequentist bayesian approaches â©
10.1111/rssc.12220 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016420357&doi=10.1111%2frssc.12220&partnerID=40&md5=68af52e08fb4dc4dbd933f45620cf190 2,many randomized controlled trials report one primary outcome result multivariate meta analytic methods assimilation treatment effects systematic reviews randomized controlled trials received increasing attention literature methods show promise respect bias reduction efficiency gain compared univariate meta analysis however methods multivariate meta analysis focused pairwise treatment comparisons e number treatments current methods mixed treatment comparisons meta analysis e number treatments focused univariate recently bivariate outcomes broaden application propose framework mixed treatment comparisons meta analysis multivariate two outcomes correlations multivariate outcomes within studies accounted copulas joint modelling multivariate random effects respectively consider bayesian hierarchical model using markov chain monte carlo methods estimation important feature framework proposed allows borrowing information across correlated outcomes show via simulation approach reduces effect outcome reporting bias variety missing outcome scenarios apply method systematic review randomized controlled trials pharmacological treatments alcohol dependence tends report multiple outcomes potentially subject outcome reporting bias â© royal statistical society
10.1111/rssc.12298 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050888680&doi=10.1111%2frssc.12298&partnerID=40&md5=f4948a9109ae975b1dbd3e16c5403d84 0,ranking sportsmen whose careers took place different eras often contentious issue topic much debate focus cricket examine conclusions may drawn ranking test batsmen using data batting scores first test onwards overlapping nature playing careers exploited form bridge past present players compared simultaneously rather relative contemporaries natural variation runs scored batsman modelled additive log linear model year age cricket specific components used extract innate ability individual cricketer incomplete innings handled via censoring zero inflated component incorporated model allow excess frailty start innings innings innings variation runs scored batsman leads uncertainty ranking position bayesian approach used fit model realizations posterior distribution obtained deploying markov chain monte carlo algorithm posterior summaries innate player ability used assess uncertainty ranking position contrasted rankings determined via posterior mean runs scored posterior predictive checks show model provides reasonably accurate description runs scored â© royal statistical society blackwell publishing ltd
10.1007/s11222-018-9826-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051553582&doi=10.1007%2fs11222-018-9826-2&partnerID=40&md5=540cc3c110eaf81f30e4e49b02b1e67b 0,well known markov chain monte carlo mcmc methods scale poorly dataset size popular class methods solving issue stochastic gradient mcmc sgmcmc methods use noisy estimate gradient log posterior reduces per iteration computational cost algorithm despite number results suggesting stochastic gradient langevin dynamics sgld probably popular methods still computational cost proportional dataset size suggest alternative log posterior gradient estimate stochastic gradient mcmc uses control variates reduce variance analyse sgld using gradient estimate show log concavity assumptions target distribution computational cost required given level accuracy independent dataset size next show different control variate technique known zero variance control variates applied sgmcmc algorithms free postprocessing step improves inference algorithm reducing variance mcmc output zero variance control variates rely gradient log posterior explore variance reduction affected replacing noisy gradient estimate calculated sgmcmc â© author
10.1111/jomf.12527 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052496054&doi=10.1111%2fjomf.12527&partnerID=40&md5=8bd8fe8a987a34dcc82a43191070014e 0,objective study assesses whether parenthood influences repartnering women men explores repartnering associated parental status prospective partners background previous research demonstrated whether gender differences repartnering conditional presence children study aims better disentangle specific gender differentials repartnering probabilities conditional parenthood child custody status method analytical sample consists women men reported least one partnership dissolution british understanding society survey multilevel event history models markov chain monte carlo simulations used estimate probabilities finding new partner b finding new childless partner new partner children results results suggest mothers lesser extent fathers less likely repartner childless counterparts among parents child custody emerges distinct gender gap mothers exhibit significantly lower rate repartnering fathers finally coresident single parents relatively less likely repartner childless individuals single fathers frequently form two parent stepfamilies mothers conclusion suggests presence gender divide repartnering especially apparent child custody taken account presence children also reduces possibility forming unions childless individuals â© national council family relations
522.6035206722654 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032707507&partnerID=40&md5=9a82a9919f79312cdcb884d843a43f8f 0,proceedings contain papers special focus conference intelligent systems technologies applications topics include markov chain monte carlo methods evolutionary algorithms automatic feature selection legal documents adaptive soft set based diagnostic risk prediction system weighted bipartite graph model recommender system using entropy based similarity measure automated quiz generator temporal modelling bug numbers open source software applications using lstm direct demodulator amplitude modulated signals using artificial neural network real time detection atrial fibrillation short time single lead ecg traces using recurrent neural networks stylolit stylometry location indicative terms based geographic location estimation using convolutional neural networks energy efficient fuzzy based data fusion tree based clustering algorithm wireless sensor networks emg pattern classification using neural networks crime women state level analysis using hierarchical k means clustering techniques zero pronouns resolution sanskrit texts semantic analysis using pairwise sentence comparison word embeddings illuminant color inconsistency powerful clue detecting digital image forgery survey fast block based copy move forgery detection approach using image gradient modified k means operation based deterministic extended visual cryptography using complementary cover images empirical comparison different key frame extraction approaches differential evolution based algorithms breast cancer diagnosis prognosis using machine learning techniques performance assessment framework computational models visual attention biologically inspired foraging decision making distributed cognitive radio networks pam based radar counter measures hostile environments
10.3923/ajsr.2018.376.382 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048624986&doi=10.3923%2fajsr.2018.376.382&partnerID=40&md5=8334a7c636184ca75b2b8125f18ac44b 0,background objective weibull distribution widely used model analyze data survival time bayesian estimation approach received much attention contention estimation methods study examined performance bayesian estimator using conjugate prior information estimating parameters weibull distribution censored survival data dengue fever df materials methods simulated weibull distributed survival dataset performance conjugate estimator estimating weibull distribution parameters checked applying df survival dataset makassar indonesia statistical analysis simulation data collected df data analyzed summary tables markov chain monte carlo method via gibbs sampling algorithm performed using r version win bugs results based simulation study mean posterior means weibull distribution parameter estimates still reasonably accurate fitting weibull models df survival time dataset using conjugate prior distribution age factor substantially described df patients survival times positive effect estimated survival time conclusion choose sample size censoring level estimates generated conjugate prior depend data also parameters prior distribution amount uncensored data must one order obtain estimate greater zero results estimated parameters weibull model using conjugate prior either simulated survival data df data good â© sri astuti thamrin et al
10.1016/j.prevetmed.2017.10.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033441699&doi=10.1016%2fj.prevetmed.2017.10.009&partnerID=40&md5=0fadfebddd4bdf5ece7ab8229f97bfde 0,paratuberculosis johne disease jd chronic infectious disease causing intractable diarrhea cattle leads less productivity decreased milk yield lower daily weight gain control measure jd cattle national serological surveillance conducted japan since conduct modeling studies useful evaluate effectiveness control measures jd reliable parameter values length time infection start fecal shedding antibody expression especially important parameters japanese cattle population assumed different countries higher prevalence jd experimental infection settings therefore must estimated cattle population japan data national surveillance conducted tokachi district hokkaido prefecture used study using data jd diagnostic tests cattle tokachi district testing histories infected animals estimated number tested cattle positive cattle age month fecal antibody tests deterministic mathematical model jd development infection fecal shedding antibody expression infected cattle constructed obtain probability testing positive applied fecal antibody tests given age likelihood obtained estimated test results best values parameters obtained using markov chain monte carlo method fifty five percent infected cattle projected transient shedding period estimated start months infection last months persistent shedding projected occur infected cattle estimated begin â€“ months infection following persistent shedding antibody expression estimated start months later values useful developing models evaluate status jd infection effectiveness control measures japanese cattle population â© elsevier b v
10.1093/mnras/stx2443 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040256870&doi=10.1093%2fmnras%2fstx2443&partnerID=40&md5=8f8ac49cef4d522ac2a420f65873abdb 14,light recent planck downward revision electron scattering optical depth discovery faint active galactic nuclei agn population z gt reassess actual contribution quasars cosmic reionization aim extend previous markov chain monte carlo based data constrained semi analytic reionization model study role quasars global reionization history find quasars alone reionize universe models high agn emissivities high redshift models still allowed recent cosmic microwave background data observations related hi reionization however predict extended early ii reionization ending z â‰³ much slower evolution mean ii ly î± forest opacity actual observation suggests thus constrain model ii ly î± forest data agn dominated scenario found clearly ruled ïƒ limits data seems favour standard two component picture quasar contributions become negligible z â‰³ non zero escape fraction per cent needed early epoch galaxies models mean neutral hydrogen fraction decreases z = z = helium becomes doubly ionized much later time z find models well good agreement observed thermal evolution igm opposed models high agn emissivities â© author
10.3847/1538-4357/aa9c81 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040250094&doi=10.3847%2f1538-4357%2faa9c81&partnerID=40&md5=2fe383317e76faf703fbd6a886f0a326 1,present new measurement lyî± forest power spectrum lt z lt using keck hires vlt uves high resolution high signal noise ratio quasar spectra developed custom pipeline measure power spectrum uncertainty fully accounts finite resolution noise corrects bias induced masking missing data damped lyî± absorption systems metal absorption lines measurement results unprecedented precision small scale modes k gt km inaccessible previous sdss boss analyses well known high k modes highly sensitive thermal state intergalactic medium contamination narrow metal lines significant concern quantify effect metals small scale power find modest effect modes k lt km result masking metals restricting k lt km impact completely mitigated present end end bayesian forward modeling framework whereby mock spectra noise resolution masking data generated lyî± forest simulations mock spectra used build custom emulator enabling us interpolate sparse grid models perform markov chain monte carlo fits results agree well boss scales lt km measurements overlap combination percent level low k precision boss high k measurements results powerful new data set precisely constraining thermal history intergalactic medium cosmological parameters nature dark matter power spectra covariance matrices provided electronic tables â© american astronomical society rights reserved
10.1111/ane.13025 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053729753&doi=10.1111%2fane.13025&partnerID=40&md5=ae1706a8a1bca60e0c7f0b378aba112d 0,second third generation aeds directly compared controlled release carbamazepine cbz cr initial monotherapy new onset focal epilepsy conversely head head trials performed aim study estimate comparative efficacy tolerability antiepileptic monotherapies adults newly diagnosed focal epilepsy network meta analysis nma randomized double blinded parallel group monotherapy studies comparing aed cbz cr adults newly diagnosed untreated epilepsy focal onset seizures identified outcome measures seizure freedom â months occurrence treatment emergent adverse events teaes treatment withdrawal due teaes mixed treatment comparisons conducted bayesian nma using markov chain monte carlo methods effect sizes calculated odds ratios ors credible intervals cris four trials included involving participants cbz cr comparative aeds monotherapy aeds compared cbr cr levetiracetam lev zonisamide zns lacosamide lcm eslicarbazepine acetate esl statistical differences month seizure freedom teaes occurrence lev zns lcm esl cbz cr analysis drug withdrawal due teaes lcm treatment associated significantly lower discontinuation rate cbz cr cri lev zns lcm esl effective initial monotherapy treatments adult patients newly diagnosed focal epilepsy represent suitable alternatives cbz cr â© john wiley sons published john wiley sons ltd
10.1289/EHP1289 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041418759&doi=10.1289%2fEHP1289&partnerID=40&md5=e155d5d018fbf6be2d79c2c3dd492fcb 2,background benchmark dose bmd modeling important step human health risk assessment used default approach identify point departure risk assessment probabilistic framework doseâ€“response assessment proposed advocated various institutions organizations therefore reliable tool needed provide distributional estimates bmd important quantities doseâ€“ response assessment objectives developed online system bayesian bmd bbmd estimation compared results software u environmental protection agencyâ€™s epaâ€™s benchmark dose software bmds methods system built bayesian framework featuring application markov chain monte carlo mcmc sampling model parameter estimation bmd calculation makes bbmd system fundamentally different currently prevailing bmd software packages addition estimating traditional bmds dichotomous continuous data developed system also capable computing model averaged bmd estimates results total dichotomous continuous data sets extracted u epaâ€™s integrated risk information system iris database similar databases used testing data compare estimates bbmd bmds programs results suggest bbmd system may outperform bmds program number aspects including fewer failed bmd bmdl calculations estimates conclusions bbmd system useful alternative tool estimating bmd additional functionalities bmd analysis based recent research importantly bbmd potential incorporate prior information make doseâ€“response modeling reliable provide distributional estimates important quantities doseâ€“response assessment greatly facilitates current trend probabilistic risk assessment â© public health services us dept health human services rights reserved
10.1017/ice.2017.241 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038252824&doi=10.1017%2fice.2017.241&partnerID=40&md5=ac03dcb37d71eadffe232d5d101f8184 0,background extended spectrum î² lactamase producing enterobacteriaceae esbl e emerging worldwide contact precautions recommended known esbl e carriers control spread esbl e within hospitals objective study quantified acquisition esbl e rectal carriage among patients dutch hospitals given application contact precautions methods data used cluster randomized studies isolation strategies esbl e som study performed dutch hospitals r gnosis study data limited collected dutch hospital perianal cultures obtained either ward based prevalence surveys som admission twice weekly thereafter r gnosis studies contact precautions applied known esbl e carriers estimates acquisition esbl e based results admission discharge cultures patients hospitalized days studies markov chain monte carlo mcmc model applied patients hospitalized r gnosis results absolute risk acquisition esbl e rectal carriage ranged esbl e acquisition rate acquisitions per patient days addition acquisitions attributable patient dependent transmission per admission reproduction number conclusions low esbl e acquisition rate study demonstrates possible control nosocomial transmission esbl low endemic non icu setting escherichia coli prevalent esbl e standard contact precautions applied known esbl e carriers â© society healthcare epidemiology america
10.1002/ecs2.2046 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040547401&doi=10.1002%2fecs2.2046&partnerID=40&md5=4730218cd6f7eef800bfde86d83b86b6 0,leaf area index lai often used quantify plant production evapotranspiration terrestrial ecosystem models tems study evaluated lai simulation north america using data assimilation technique process based tem well situ satellite data first optimized parameters related lai tem using markov chain monte carlo method ameri flux site level regional lai data advanced high resolution radiometer parameterized model verified observed monthly lai major ecosystem types site level simulated lai compared well observed data sites harvard forest r = university michigan biological station r = howland forest r = morgan monroe state forest r = shidler tallgrass prairie r = donaldson r = root mean square error rmse modeled satellite based monthly lai north america period simulated average monthly lai recent three decades increased region average alaska canada conterminous united states respectively consistent satellite data model performed well wet tundra boreal forest temperate coniferous forests temperate deciduous forests grasslands xeric shrublands rmse lt alpine tundra xeric woodlands rmse gt spring fall lai higher region suggesting leaf phenology earlier onset later senescence average lai increased april september respectively study provides way quantify lai ecosystem models improve future carbon water cycling studies â© qu zhuang
10.1186/s13071-017-2588-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042625734&doi=10.1186%2fs13071-017-2588-4&partnerID=40&md5=74cd011a350825b4b8d287e741f57811 0,background dengue remains important public health problem timor leste several major epidemics occurring last years aim study identify dengue clusters high geographical resolution determine association local environmental characteristics distribution transmission disease methods notifications dengue cases occurred january december obtained ministry health timor leste population suco third level administrative subdivision obtained population housing census spatial autocorrelation dengue incidence explored using moran statistic local indicators spatial association lisa getis ord statistics multivariate zero inflated poisson zip regression model developed conditional autoregressive car prior structure posterior parameters estimated using bayesian markov chain monte carlo mcmc simulation gibbs sampling results analysis used data cases dengue incidence highly seasonal large peak january patients â‰¥ years found credible interval cri less likely infected years females cri likely suffer dengue compared males dengue incidence increased cri â°c increase mean temperature cri mm increase precipitation significant residual spatial clustering accounting climate demographic variables conclusions dengue incidence highly seasonal spatially clustered positive associations temperature precipitation demographic factors factors explained observed spatial heterogeneity infection â© author
10.1016/j.jaip.2018.08.036 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054453175&doi=10.1016%2fj.jaip.2018.08.036&partnerID=40&md5=b7330d48cb7e4ebb67efa6607139a368 0,background interaction il receptor eosinophils increases activation maintenance eosinophils blocking interaction reduces asthma symptoms patients eosinophilic phenotype reslizumab binds il benralizumab targets il receptor î± subunit compared head head trials objective indirectly compare reslizumab benralizumab similar patient populations using network meta analysis methods systematic literature review conducted network meta analysis performed eligible studies using markov chain monte carlo simulation method bayesian statistical framework results eleven studies identified evaluated clinically relevant doses outcomes similar time points control population differences subgroups selected base case efficacy analysis benralizumab subgroup blood eosinophil levels greater equal cells î¼l n = reslizumab subgroup global initiative asthma step previous exacerbations greater equal eosinophils î¼l n = safety analyzed full population n = reslizumab significantly improved asthma control questionnaire acq asthma quality life questionnaire aqlq scores compared benralizumab every weeks reasonably high posterior probabilities reslizumab superior benralizumab every weeks every weeks acq score aqlq score fev clinical asthma exacerbations conclusions indirect comparison suggests reslizumab may efficacious benralizumab patients eosinophilic asthma global initiative asthma step elevated blood eosinophil levels benralizumab â‰¥ î¼l reslizumab â‰¥ î¼l exacerbations previous year â© american academy allergy asthma immunology
10.1007/s00168-015-0705-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944570061&doi=10.1007%2fs00168-015-0705-x&partnerID=40&md5=9237c84ec9b15389d36139fcab7a7837 2,applications spatial probit regression models appeared literature incorrectly interpreted estimates models spatially dependent choices frequently arise various modeling scenarios including situations involving analysis regional voting behavior decisions states cities change tax rates relative neighboring jurisdictions decisions households move stay particular location use county level voting results presidential election illustrative example issues arise drawing inferences spatial probit model estimates although voting example holds particular intuitive appeal allows us focus interpretive issues numerous situations considerations come play past work regarding bayesian markov chain monte carlo estimation spatial probit models lesage pace introduction spatial econometrics taylor francis new york used well derivations lesage et al j r stat soc ser stat soc â€“ regarding proper interpretation partial derivative impacts changes explanatory variables probability voting candidate case conventional probit models effects arising changes explanatory variables depend nonlinear way levels variables non spatial probit regressions common way explore nonlinearity relationship calculate â€œmarginal effectsâ€� estimates using particular values explanatory variables e g mean values quintile intervals motivation practice consideration impact changing explanatory variable values varies across range values encompassed sample data given nonlinear nature normal cumulative density function transform non spatial probit model relies know changes explanatory variable values near mean may different impact decision probabilities changes low high values spatial probit regression models effects impacts changes explanatory variables highly nonlinear addition since spatial models rely observations represent location region located map levels explanatory variables viewed varying space discuss important implications proper interpretation spatial probit regression models context election application â© springer verlag berlin heidelberg
10.1159/000493951 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054994407&doi=10.1159%2f000493951&partnerID=40&md5=d10cffba4381285fa6778b2922803ee6 0,background aims urothelial cancer uc chemotherapy sensitive tumor achieved remarkable progresses therapeutic paradigm particularly advanced metastatic stages however clinicians patients confused comes choosing optimal chemotherapy hence article aimed conduct comprehensive comparison different chemotherapy regimens advanced metastatic uc terms survival benefits adverse events methods online databases pubmed embase web science searched systematically comprehensively randomized controlled trials rcts september pooled hazard ratios hrs odds ratios ors credible interval cri calculated markov chain monte carlo methods effectiveness safety included regimens conducted provide hierarchy means rank probabilities help r software gemtc package surface cumulative ranking curve sucra also incorporated analysis ranking corresponding chemotherapy regimens results ten different chemotherapy regimens involved article predominantly trials first line setting eight clinical outcomes ultimately analyzed study terms overall response rate orr overall survival os progression free survival pfs time progression ttp rank probabilities sucra indicated paclitaxel cisplatin gemcitabine pcg superior gemcitabine cisplatin gc methotrexate vinblastine doxorubicin cisplatin mvac traditional first line treatment advanced metastatic uc case orr pfs ttp gc+sorafenib also displayed superiority comparison gc mvac despite survival benefits pcg gc+sorafenib presented relatively higher incidence adverse events conclusion results revealed adding paclitaxel sorafenib first line gc yield better survival benefit also worsen adverse events advanced metastatic uc clinically physicians weigh merits approaches maximize survival benefits eligible patients â© author published karger ag basel
10.1093/milmed/usx015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044634522&doi=10.1093%2fmilmed%2fusx015&partnerID=40&md5=8c29bde341ea1982fa2131e0284cef2f 0,background tobacco use major concern military health system department defense dod dod health related behavior survey reported active duty personnel current smokers higher national estimate civilian population overall estimated tobacco use costs dod billion year related medical care increased hospitalization lost days work among others methods study evaluated future health outcomes tricare prime beneficiaries aged yr n = million including active duty retired military members dependents potential economic impact initiatives dod may take effort transform military tobacco free environment analysis simulated future smoking status risk developing smoking related diseases associated medical costs individual using markov chain monte carlo microsimulation model data sources included tricare administrative data national data centers disease control prevention mortality data national cancer institute cancer registry data well relative risks diseases obtained literature review findings found prevalence active smoking among tricare prime population decrease status quo scenario however comprehensive tobacco control initiative includes price increase tighter clean air policy intensified media campaign implemented prevalence smoking decrease near percentage points reduction smoking prevalence represents additional quitters translates total lifetime medical cost savings present value million million attributable tricare savings discussion comprehensive tobacco control policy within dod significantly decrease prevalence lifetime medical cost tobacco use smoking prevalence among prime beneficiaries reach healthy people goal additional measures lifetime savings mount billion achieve future savings dod needs pay close attention program design implementation issues additional tobacco control initiatives â© association military surgeons united states
10.1007/978-3-319-70942-0_10 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037824086&doi=10.1007%2f978-3-319-70942-0_10&partnerID=40&md5=c13fe16d7fa0f30002982cb6c6db4209 0,finding effective methods compute estimate posterior distributions model parameters paramount importance bayesian statistics fact bayesian inference extraordinarily popular applications births efficient algorithms like monte carlo markov chain practicality posterior distributions depends heavily combination likelihood functions prior distributions certain cases closed form formulas posterior distributions attained paper based theory distortion functions calibration like method calculate explicitly posterior distributions three crucial models namely normal poisson bernoulli introduced paper ends applications stock market â© springer international publishing ag
899.4808875646561 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053018955&partnerID=40&md5=7aae97762cfea7d045a3c55ce474ac5c 0,background growth analyses yellowtail snapper neglect consideration model parameter uncertainty goals paper explore model uncertainty using three models von bertalanffy logistic gompertz well akaike criterion model selection also estimate growth parameters uncertainty using maximum likelihood estimation approach different assumptions error variance bayesian methods methods models fitted length age data organisms caught antã³n lizardo veracruz regarding bayesian methods prior distribution asymptotic length built based data gathered literature used monte carlo markov chains mcmc methods fit logistic model results akaike criterion results suggest logistic model provided best fit observed data lowest aic = parameter estimates included asymptotic length lâˆž = â± growth rate k = â± age curve inflection point = â± regarding bayesian analysis mcmc simulations suggest probable value asymptotic length cm interval probability probable value growth rate interval probability last probable value age curve inflection point years range probability conclusions maximum likelihood estimation mle bayesian framework considered basic statistical techniques evaluation individual growth species interest provide robust analysis available information species opportunity incorporate analysis sustainable management practices â© universidad autonoma metropolitana rights reserved
10.1080/21645515.2018.1515455 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053877092&doi=10.1080%2f21645515.2018.1515455&partnerID=40&md5=52d69c2223d2b8897bec5a271c517b9b 0,live attenuated japanese encephalitis chimeric virus vaccine je cv imojevâ® sanofi pasteur elicits robust antibody response children wanes time clinical efficacy based correlate protection je infection defined neutralizing antibody levels equal greater threshold dil information duration persistence je antibody response threshold needed constructed statistical models using year persistence data randomised clinical trial nct children â€“ â years old primed inactivated je vaccine received booster dose je cv je naã¯ve toddlers â€“ â months received je cv single dose primary vaccination models constructed using bayesian monte carlo markov chain approach implemented openbugs v antibody persistence predicted â years following je cv vaccination findings piecewise model phases children classic linear model toddlers presented children predicted median antibody titers thâ€“ th percentile range â€“ dil remained threshold seroprotection â years following booster je cv vaccination predicted median duration protection â years toddlers â years je cv primary vaccination median antibody titers predicted wane around level required seroprotection â€“ dil booster dose je cv children predicted provide long term protection je data useful facilitate decisions implementation recommendations future vaccination strategies â© â© sanofi pasteur published license taylor francis group llc
10.2495/ST180241 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054623014&doi=10.2495%2fST180241&partnerID=40&md5=ac6faea82103c12b7763c999665fc637 0,paper intended clarifying forecasting dynamic structural components inside relationship tourism income economic cycling parameters quarterly time series variables thailand tourism revenues gross domestic products collected period simulation methods using marko chain monte carlo approach mcmc metropolis hasting algorithm mh bayesian seasonal unit root testing b hegy markov switching bayesian var msbvar bayesian dynamic stochastic general equilibrium modelling b dsge empirically results estimated msbvar model strongly confirm business cycles thailand tourism divided two stages based business cycle facts high season low season periods results b dsge model outcomes represent capital labour factors tourism sectors high seasonal moments positive thailand economic expansions explained anxiety increments tourism revenues lead systematically boot employments economy system tourism policies implemented extending high season moments long possible conversely results dynamic simulated model show low seasonal periods negatively cause fluctuations economic system especially sudden shut labour sectors therefore training programs skilled labour improving service sectors technology adaptations intensively activated accordingly changing low season periods high seasonal moments main purpose policy makers focus â© wit press
10.1049/iet-com.2018.0039 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055089518&doi=10.1049%2fiet-com.2018.0039&partnerID=40&md5=cd1b9e22a1ddbcb04903a482eae138ef 0,authors propose efficient spectrum sharing scheme cooperative cognitive radio networks energyconstrained secondary transmitter st first scavenges radio frequency rf energy received primary signals st assists primary transmission obtain opportunity spectrum access specifically st forward primary signal signal adopting alamouti coding technique superposition scheme harvested energy sufficient primary data decoded correctly st otherwise st continue harvest rf energy authors use discrete markov chain model processes charging discharging battery moreover two different joint decoding interference cancellation schemes employed receivers restore desired data closed form expressions outage probabilities primary secondary systems derived aiming minimise outage probability secondary system guaranteeing primary transmission optimal power allocation factor st determined monte carlo simulation numerical results demonstrate proposed scheme effectively improve transfer performance secondary system realising transfer requirement primary system â© institution engineering technology
10.1016/j.scitotenv.2017.07.201 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026255020&doi=10.1016%2fj.scitotenv.2017.07.201&partnerID=40&md5=2ecf0c0960e406164ade32a25a7dc8ad 6,understanding uncertainty spatial modelling environmental variables important provides end users reliability maps past decades bayesian statistics successfully used however conventional simulation based markov chain monte carlo mcmc approaches often computationally intensive study performance novel bayesian inference approach called integrated nested laplace approximation stochastic partial differential equation inla spde evaluated using independent calibration validation datasets various skewed non skewed soil properties compared linear mixed model estimated residual maximum likelihood reml lmm found inla spde equivalent reml lmm terms model performance similarly robust sparse datasets e â€“ samples comparison inla spde able estimate posterior marginal distributions model parameters without extensive simulations concluded inla spde potential map spatial distribution environmental variables along posterior marginal distributions environmental management drawbacks identified inla spde including artefacts model response due use triangle meshes longer computational time dealing non gaussian likelihood families â© elsevier b v
10.1002/sim.7505 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037544487&doi=10.1002%2fsim.7505&partnerID=40&md5=18c31b8649c6f39266218d5aaffd6232 0,traditional chinese medicine tcm complex mixture containing many different ingredients thus statistical analysis traditional chinese medicine data becomes challenging one needs handle association among observed data across different time points across different ingredients multivariate response paper builds stage bayesian hierarchical model analyzing multivariate response pharmacokinetic data usually dimensionality parameter space huge leads parameter estimation difficulty take hybrid markov chain monte carlo algorithms obtain posterior bayesian estimation corresponding parameters model simulation study real data analysis show theoretical model markov chain monte carlo algorithms perform well especially correlation among different ingredients calculated accurately copyright â© john wiley sons ltd
10.1002/sim.7456 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037547018&doi=10.1002%2fsim.7456&partnerID=40&md5=a7ae6f6966261235b8d1197b78b79fda 1,major challenge monitoring risks socially deprived areas developed countries economic epidemiological social data typically underreported thus statistical models take data quality account produce biased estimates deal problem counts suspected regions usually approached censored information censored poisson model considered censored regions must precisely known priori reasonable assumption practical situations introduce random censoring poisson model rcpm accounts uncertainty count data reporting processes consequently region able estimate relative risk event interest well censoring probability facilitate posterior sampling process propose markov chain monte carlo scheme based data augmentation technique run simulation study comparing proposed rcpm competitive models different scenarios considered rcpm censored poisson model applied account potential underreporting early neonatal mortality counts regions minas gerais state brazil data quality known poor copyright â© john wiley sons ltd
10.1002/2017GL076101 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039757485&doi=10.1002%2f2017GL076101&partnerID=40&md5=4e56b653854b8b320621ee6b843ca5a1 3,climate projections continue marred large uncertainties originate processes need parameterized clouds convection ecosystems rapid progress within reach new computational tools methods data assimilation machine learning make possible integrate global observations local high resolution simulations earth system model esm systematically learns quantifies uncertainties propose blueprint esm outline parameterization schemes learn global observations targeted high resolution simulations example clouds convection matching low order statistics esms observations high resolution simulations illustrate learning algorithms esms simple dynamical system shares characteristics climate system discuss opportunities proposed framework presents challenges remain realize â© american geophysical union rights reserved
10.1142/9789813232105_0006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045310094&doi=10.1142%2f9789813232105_0006&partnerID=40&md5=94cdab49d6c73235830cee12c969cffe 1,applications require substantial computational resources today avoid use heavily parallel machines embracing opportunities parallel computing especially possibilities provided new generation massively parallel accelerator devices gpus intel xeon phi even fpgas enables applications studies inaccessible serial programs outline opportunities challenges massively parallel computing monte carlo simulations statistical physics focus simulation systems exhibiting phase transitions critical phenomena covers range canonical ensemble markov chain techniques well generalized ensembles multicanonical simulations population annealing examples discussed simulations spin systems many methods general moderate modifications allow applied lattice lattice problems including polymers particle systems discuss important algorithmic requirements highly parallel simulations challenges random number generation cases outline number general design principles parallel monte carlo codes perform well â© world scientific publishing co pte ltd rights reserved
10.1142/9789813232105_0004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045337492&doi=10.1142%2f9789813232105_0004&partnerID=40&md5=224ec29b94c105ffbfb69715d346c7ed 0,last two decades computer simulations generalized ensembles based markov chain monte carlo sampling multicanonical wang landau parallel tempering replica exchange methods emerged strong numerical tool investigations statistical physics macromolecular systems many studies focused coarse grained models polymers lattice continuum phase diagrams polymer chains bulk interaction surfaces extensively studied also aggregation behavior solution investigated chapter first theoretical background simulations described employed algorithms explained performance assessed implementations algorithms parallel computers also briefly discussed illustration concepts overview polymer systems investigated multicanonical parallel tempering simulations given focusing recent studies coarse grained models â© world scientific publishing co pte ltd rights reserved
10.1186/s12711-017-0369-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040197047&doi=10.1186%2fs12711-017-0369-3&partnerID=40&md5=f46eed694c38d69e767bd36df2ca940a 3,background non linear bayesian genomic prediction models bayesa b c r involve iteration mostly markov chain monte carlo mcmc algorithms computationally expensive especially whole genome sequence wgs data analyzed singular value decomposition svd genotype matrix facilitate genomic prediction large datasets used estimate marker effects prediction error variances pev computationally efficient manner developed implemented evaluated direct non iterative method estimation marker effects bayesc genomic prediction model methods bayesc model assumes priori markers normally distributed effects probability uppi ï€ effect probability uppi ï€ marker effects pev estimated using svd posterior probability marker non zero effect calculated posterior probabilities used obtain marker specific effect variances subsequently used approximate bayesc estimates marker effects linear model computer simulation study conducted compare alternative genomic prediction methods single reference generation used estimate marker effects subsequently used generations forward prediction accuracies evaluated results svd based posterior probabilities markers non zero effects generally lower mcmc based posterior probabilities regions opposite occurred resulting clear signals qtl rich regions accuracies breeding values estimated using svd mcmc based bayesc analyses similar across generations forward prediction intermediate number generations forward prediction accuracies obtained bayesc model tended slightly higher accuracies obtained using best linear unbiased prediction snp effects snp blup model reducing marker density wgs data k snp blup tended yield highest accuracies least short term conclusions based svd genotype matrix developed direct method calculation bayesc estimates marker effects although svd mcmc based marker effects differed slightly prediction accuracies similar assuming svd marker genotype matrix already performed reasons e g snp blup computation times bayesc predictions comparable snp blup â© author
10.1002/cpe.4245 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027989229&doi=10.1002%2fcpe.4245&partnerID=40&md5=6900ec604a3e38793c29c5de8ee7289f 2,paper study issue improving performance markov chain monte carlo method solve local pagerank problem general purpose graphics processing unit environment large number dangling vertices cause large storage space dangling vertices thus slow markov chain procession propose reordering strategy compress storage space reduce computational complexity markov chain procession performance study parallelizing optimizing proposed algorithm based gpu reordering strategy ã— faster compared basic method graphs high proportion dangling vertices according investigation issue variance random walks determines number random walks computation thus introduce low discrepancy sequences enhance performance moreover low discrepancy sequences organized load chip shared memory accelerate fetching wise warp scheduling bank conflict schema series experiments conducted evaluate optimization efficiency compared fetching data chip global memory shared memory based strategy ã— speedup ratio performance experiments indicate size shared memory significant impact parallelism proposed method well copyright â© john wiley sons ltd
10.1109/TCBB.2017.2786239 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039791634&doi=10.1109%2fTCBB.2017.2786239&partnerID=40&md5=772ad908850995b5a113ae0a6c7a5378 3,association mapping genetic diseases attracted extensive research interest recent years however methodologies introduced far suffer spurious inference associated sites due population inhomogeneities paper introduce statistical framework compensate shortcoming equipping current methodologies state art clustering algorithm widely used population genetics applications proposed framework jointly infers disease associated factors hidden population structures regard markov chain monte carlo mcmc procedure employed assess posterior probability distribution model parameters implemented proposed framework software package whose performance extensively evaluated number synthetic datasets compared well known existing methods structure shown extreme scenarios formula tex tex formula improvement inference accuracy achieved moderate increase computational complexity ieee
10.1109/SSPD.2017.8233232 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047562066&doi=10.1109%2fSSPD.2017.8233232&partnerID=40&md5=98a5d5ea310e6b6eb0d236638fcd06f6 1,blind source separation bss number sources present measured speech mixtures unknown focus work therefore automatically estimate number sources binaural speech mixtures collapsed gibbs sampling cgs markov chain monte carlo mcmc technique used obtain samples joint distribution speech mixtures chinese restaurant process crp within framework dirichlet process dp exploited cluster samples different components finally estimate number speakers accuracy proposed method different reverberant environments evaluated real binaural room impulse responses brirs speech signals timit database experimental results confirm accuracy robustness proposed method â© ieee
10.1515/rnam-2017-0034 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037128821&doi=10.1515%2frnam-2017-0034&partnerID=40&md5=f23333bc2d765747928224fd49c0ef08 0,issues finite computational cost vector weighted monte carlo algorithms studied paper relative estimation linear functionals solutions systems nd kind integral equations universal modification weight vector collision estimator branching chain trajectory relative elements matrix weight constructed proved computational cost constructed algorithm finite case basic functionals bounded results numerical calculations presented case use modified weight estimator problems radiation transfer theory allowance polarization â© walter de gruyter gmbh berlin boston
10.1002/sim.7444 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034864373&doi=10.1002%2fsim.7444&partnerID=40&md5=b4ecb0259cc2ceebed3a251ee1512e03 0,modeling correlated biomarkers jointly shown improve efficiency parameter estimates leading better clinical decisions paper employ joint modeling approach unique diabetes dataset blood glucose continuous urine glucose ordinal measures disease severity diabetes known correlated postulated joint model assumes outcomes distributions exponential family hence modeled multivariate generalized linear mixed effects model associated correlated shared random effects markov chain monte carlo bayesian approach used approximate posterior distribution draw inference parameters proposed methodology provides flexible framework account hierarchical structure highly unbalanced data well association outcomes results indicate improved efficiency parameter estimates blood glucose urine glucose modeled jointly moreover simulation studies show estimates obtained joint model consistently less biased efficient separate models copyright â© john wiley sons ltd
10.1145/3175684.3175700 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046662673&doi=10.1145%2f3175684.3175700&partnerID=40&md5=1e5fa821117621a78f6ae1806df0e802 0,black box variational inference bbvi recently proposed estimation method parameters statistical models bbvi order magnitude faster markov chain monte carlo mcmc computation bbvi similar maximum posteriori estimation addition point estimation given latter bbvi also estimate another important statistic e range parameters assuming normal distribution parameters bbvi minimizes kl divergence normal distribution statistical models however parameters normal distributed estimation might precise similarly outliers allowed fat tail distributions suitable model parameters paper discusses problems cauchy student distribution variational distribution inspired lasso paper replaces normal laplace distribution implement bbvi experiment linear regression shows non ideal condition e g outlier data bbsi based laplace provides stable correct estimation ï¿½ association computing machinery
10.1109/CHILECON.2017.8229662 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042689297&doi=10.1109%2fCHILECON.2017.8229662&partnerID=40&md5=89555048dcd56edd00d1e9900f757a50 0,interferometry problem addresses estimation unknown quantity exploiting interference among measurements different sources measurements obtained fourier domain sparse contaminated noise propose parametric sum basis model observations together bayesian approach reconstructing interferometry images main contributions construction model complex valued noise source implementation approximate inference method train model using markov chain monte carlo quantitative comparison called dirty algorithm proposed approach outperformed considered baseline â© ieee
10.13465/j.cnki.jvs.2017.23.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044126443&doi=10.13465%2fj.cnki.jvs.2017.23.014&partnerID=40&md5=77ea16d9f99a2fa896b840e26b1d692f 0,order reflect real vibration characteristics rod fastening rotors high pressure spool hps aero engine fe finite element model modal characteristics confirmation method based bayesian theory proposed elastoplastic slip model non linear hysteretic behavior introduced determine regions uncertain parameters according model likelihood function modal data characteristics built using bayesian theory bayesian updating procedure implemented using multi level markov chain monte carlo mcmc algorithm addition adaptive hierarchical sparse grid collocation asgc method used construct stochastic surrogate model posterior probability distribution calculation uncertain parameters reduced amount computation mcmc large fe models like hps real example aero engine high pressure rotor given results using modal characteristics confirmation method compared test data shown proposed method determine regions varying law hps feature frequencies effectiveness verified â© editorial office journal vibration shock right reserved
10.1016/j.physa.2017.07.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026400641&doi=10.1016%2fj.physa.2017.07.012&partnerID=40&md5=754d5fdd1cdca9386012419a5a9b6709 1,propose dynamic economic model networks agents friends enemies one another decentralized relationship model agents decide whether change relationships minimize imbalanced triads model single parameter call social temperature captures degree agents care social balance relationships show global structure relationship configuration converges unique stationary distribution using stationary distribution characterize maximum likelihood estimator social temperature parameter since estimator computationally challenging calculate real social network datasets provide simple simulation algorithm verify performance real social network datasets â© elsevier b v
10.1007/s00181-017-1364-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038112055&doi=10.1007%2fs00181-017-1364-9&partnerID=40&md5=f4286c5cb55795733fcce88f12691626 0,paper generalize stochastic frontier model allow heterogeneous technologies inefficiencies structured way allows learning adapting propose general model various special cases organized around idea switching transition one technology construct threshold stochastic frontier models suggest bayesian inferences general model proposed special cases using gibbs sampling data augmentation new techniques applied satisfactory results panel world production functions using switching transition variables human capital age capital stock representing input quality well time trend capture structural switching â© springer verlag gmbh germany part springer nature
10.1016/j.energy.2017.05.193 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020911964&doi=10.1016%2fj.energy.2017.05.193&partnerID=40&md5=8224ba420137fd828ee3ea944c51532a 1,paper presents solution thermoacoustic inverse problem using bayesian approach using probabilistic information disturbance data method takes account uncertainty measurements parameter identification variables measurements estimated parameters treated random variables solution task expected value numerically generated markov chain appropriate probability distribution work thermoacoustic inverse problem heat release rate identified basis information obtained pressure measurements walls combustion chamber problem discussed formulated method used solution presented apart bayesian approach marcov chain monte carlo algorithm used obtaining markov chain numerical way also presented verify methodology two numerical examples formulated thermoacoustic inverse problem solved obtained results presented â© elsevier ltd
10.1103/PhysRevD.96.123011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040172755&doi=10.1103%2fPhysRevD.96.123011&partnerID=40&md5=4497ddfe9c518eb2ea759ab90e10e111 2,models gravitational waveforms play critical role detecting characterizing gravitational waves gws compact binary coalescences waveforms numerical relativity nr highly accurate computationally expensive produce directly used bayesian parameter estimation tools like markov chain monte carlo nested sampling propose gaussian process regression gpr method generate reduced order model waveforms based existing accurate e g nr simulations using training set simulated waveforms gpr approach produces interpolated waveforms along uncertainties across parameter space proof concept use training set imrphenomd waveforms build gpr model parameter space mass ratio q equal aligned spin ï‡ =ï‡ using regular equally spaced grid imrphenomd training waveforms q ï‡ gpr mean approximates imrphenomd space mismatches ã— approach principle use training waveforms directly numerical relativity beyond interpolation waveforms also present greedy algorithm utilizes errors provided gpr model optimize placement future simulations fiducial test case find using greedy algorithm iteratively add simulations achieves gpr errors âˆ¼ order magnitude lower errors using latin hypercube square training grids â© american physical society
10.23919/RPIC.2017.8214311 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046465841&doi=10.23919%2fRPIC.2017.8214311&partnerID=40&md5=891fe12673ef37bb4d98e8088d081a73 0,article analyzes performance combining information scanning electron microscopy sem micrographs static light scattering sls measurements retrieving called particle size distribution psd corresponding data fusion formulated bayesian inverse problem implemented using emblematic monte carlo markov chain mcmc technique metropolis hastings mh algorithm furthermore actual psd assumed exactly represented log normal distribution order reduce additional processing errors prior statistics corresponding sem micrographs achieved means jackknife procedure used resampling technique monte carlo based statistical tools also employed assess quality priors likelihood term bayesian approach computed considering independent normal measurements generated simplified sls model local monodisperse approximation lma also used forward linear model finally experimental example analyzed using priors generated proposed procedure parametrization resulting estimations compared achieved previous article discussed â© comisiã³n permanente rpic
10.1109/IROS.2017.8206336 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041959396&doi=10.1109%2fIROS.2017.8206336&partnerID=40&md5=2db4589124cce7cff5fe9643589b4da1 0,human robot collaborative tasks incorporating qualitative information provided humans greatly enhance robustness efficacy robot state estimation introduce algorithmic framework model qualitative information quantitative constraints states approach named sequentially constrained hamiltonian monte carlo integrates hamiltonian dynamics sequentially constrained monte carlo sampling able generate samples satisfy arbitrarily complex non smooth discontinuous constraints turn allows us support wide range qualitative information evaluate approach constrained sampling qualitatively quantitatively several classes constraints schmc significantly outperforms metropolis hastings algorithm standard markov chain monte carlo mcmc method hamiltonian monte carlo hmc method terms accuracy sampling satisfying constraints quality approximation compared sequentially constrained monte carlo scmc supports similar kinds constraints schmc approach faster convergence rates lower parameter sensitivity â© ieee
10.23919/ICCAS.2017.8204399 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044462711&doi=10.23919%2fICCAS.2017.8204399&partnerID=40&md5=66ba035bb773e334cad380e3e85c8159 0,article examines volatility spillover effects among usa five east asian stock markets using multivariate stochastic volatility regime switching model five east asian stock markets china hong kong japan korea singapore respectively choose representative stock index area empirical analysis indices daily data suggest multivariate stochastic volatility regime switching model performs better different market condition study found significant volatility spillover china usa exist significant volatility spillover among east asian markets â© institute control robotics systems icros
10.1080/01457632.2016.1262721 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017420646&doi=10.1080%2f01457632.2016.1262721&partnerID=40&md5=026362cc47e10594d8c801c71d044378 2,knowledge tissues properties noninvase monitoring internal temperature required novel medical diagnostic therapeutic techniques example hyperthermia therapy cancer local heating must accurately controlled order promote necrosis cancerous cells thermoablation induce apoptosis adjuvant treatment chemotherapy radiotherapy without thermally affecting healthy cells photoacoustic imaging also called optoacoustic imaging new biomedical technique based laser generated ultrasound combines high contrast optical imaging high spatial resolution ultrasound since parameters appearing mathematical formulation photoacoustic problem temperature dependent estimation used indirect temperature measurement present work sound speed absorption coefficient parameter includes thermal expansion coefficient laser energy density specific heat estimated inverse analysis aiming identification tissue temperature forward problem solved analytically using laplace transform inverse problem solved markov chain monte carlo method within bayesian framework results obtained simulated measurements reveal capabilities proposed technique parameter temperature estimation â© taylor francis group llc
10.1080/00949655.2017.1370649 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029513935&doi=10.1080%2f00949655.2017.1370649&partnerID=40&md5=08b5af55d4fee196cfc0a3734d58255f 1,paper study identification bayesian regression models ordinal covariate subject unidirectional misclassification xia gustafson bayesian regression models adjusting unidirectional covariate misclassification j stat â€“ obtained model identifiability non binary regression models binary covariate subject unidirectional misclassification current paper establish moment identifiability regression models misclassified ordinal covariates two categories based forms observable moments computational studies conducted confirm theoretical results apply method two datasets one medical expenditure panel survey meps translational research investigating underlying disparities acute myocardial infarction patients health status triumph â© informa uk limited trading taylor francis group
10.3758/s13428-017-0986-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037739851&doi=10.3758%2fs13428-017-0986-3&partnerID=40&md5=9081de397702e0f730330735bbf49f33 1,many behavioral research areas multivariate generalizability theory mg theory typically used investigate reliability certain multidimensional assessments however traditional mg theory estimationâ€”namely using frequentist approachesâ€”has limits leading researchers fail take full advantage information mg theory offer regarding reliability measurements alternatively bayesian methods provide information frequentist approaches offer article presents instructional guidelines implement mg theory analyses bayesian framework particular bugs code presented fit commonly seen designs mg theory including single facet designs two facet crossed designs two facet nested designs addition concrete examples closely related selected designs corresponding bugs code simulated dataset provided demonstrate utility advantages bayesian approach article intended serve tutorial reference applied researchers methodologists conducting mg theory studies â© psychonomic society inc
10.1080/00949655.2017.1376063 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029487015&doi=10.1080%2f00949655.2017.1376063&partnerID=40&md5=b58089c028c802fd224073060fcc321b 0,vector k positive coordinates lies k dimensional simplex sum coordinates vector constrained equal sampling distributions efficiently simplex difficult constraint paper introduces transformed logit scale proposal markov chain monte carlo naturally adjusts step size based position simplex enables efficient sampling simplex even simplex high dimensional includes coordinates differing orders magnitude implementation method shown saltsamplerr package comparisons made simpler sampling schemes illustrate improvement performance method provides simulation typical calibration problem also demonstrates utility method â© work authored employee los alamos national security llc
10.1080/02664763.2016.1267120 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006870986&doi=10.1080%2f02664763.2016.1267120&partnerID=40&md5=a36c08496ebb44ddfe77bea47ca83413 0,multivariate regression models e regression models left hand side regression equation denotes matrix dependent variables long developed however statistical analysis empirical data usually restricted multivariable regression methods one dependent variable within framework hierarchical bayesian methods present study illustrates multivariate regression models offer new possibilities information synthesis theory testing survey data analysis ii sensitive results different specifications prior distributions end large representative survey utilized specify two multivariate hierarchical bayesian regression models n = calculated two different prior distribution specifications estimation procedures implementation r described convergence predictive power analysis model presented advantages disadvantages multivariate regression methods discussed general results obtained prior specification extent similar although differences observed regarding model complexity efficiency predictive power concluded methods facilitate development testing complex research hypotheses promising alternatives efficient data analysis large survey data sets â© informa uk limited trading taylor francis group
10.1002/sim.7371 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021739344&doi=10.1002%2fsim.7371&partnerID=40&md5=24885136c4e0f50a543c72b00aca2939 0,lipgene su vi max study like many others recorded high dimensional continuous phenotypic data categorical genotypic data lipgene su vi max focuses need account phenotypic genetic factors studying metabolic syndrome mets complex disorder lead higher risk type diabetes cardiovascular disease interest lies clustering lipgene su vi max participants homogeneous groups sub phenotypes jointly considering phenotypic genotypic data determining variables discriminatory novel latent variable model elegantly accommodates high dimensional mixed data developed cluster lipgene su vi max participants using bayesian finite mixture model computationally efficient variable selection algorithm incorporated estimation via gibbs sampling algorithm approximate bic mcmc criterion developed select optimal model two clusters sub phenotypes â€˜healthyâ€™ â€˜at riskâ€™ uncovered small subset variables deemed discriminatory notably includes phenotypic genotypic variables highlighting need jointly consider factors â years lipgene su vi max data collected participants underwent analysis diagnose presence absence mets two uncovered sub phenotypes strongly correspond year follow disease classification highlighting role phenotypic genotypic factors mets emphasising potential utility clustering approach early screening additionally ability proposed approach define uncertainty sub phenotype membership participant level synonymous concepts precision medicine nutrition copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.3847/1538-4357/aa9990 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038814722&doi=10.3847%2f1538-4357%2faa9990&partnerID=40&md5=47a7f564440bf8c01e81626355f6cc73 1,class protostars thought represent early stage lifetime protoplanetary disks still embedded natal envelope measure disk masses class protostars taurus molecular cloud constrain initial mass budget forming planets disks use radiative transfer modeling produce synthetic protostar observations fit models multi wavelength data set using markov chain monte carlo fitting procedure fit models simultaneously new combined array research millimeter wave astronomy mm observations sensitive wide range spatial scales expected protostellar disks envelopes able distinguish component well broadband spectral energy distributions compiled literature find median disk mass mo average massive taurus class ii disks median disk mass âˆ¼ mo decrease disk mass explained dust grains grown factor grain size indicating class ii stage myr significant amount dust grain processing occurred however evidence significant dust processing occurred even class stage likely initial mass budget higher value quoted â© american astronomical society rights reserved
10.1007/s10586-017-1400-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037617285&doi=10.1007%2fs10586-017-1400-8&partnerID=40&md5=57ea07cf01a352e8ca12c8723e3b9c29 0,multi users interference direct sequence ultra wideband ds uwb communication hotspot research wireless communication paper using wavelet coefficient transform signal ds uwb communication establish tree based hierarchy shrinkage bayesian compressive sensing hsbcs framework multi users interference models noise model generalization markov chain monte carlo mcmc multi user interference algorithm use hsbcs framework proposed suppress noise presence multi user interference ds uwb communications target paper detect noise suppression performance multi user interference ds uwb communications including normal mean square error nmse performance peak signal noise ratio psnr performance using hsbcs framework simulation results show nmse psnr performance tree based hsbcs algorithm better algorithms tree structure otherwise users increasing error probability performance mcmc multiuser interference algorithm presence multiuser interference use hsbcs framework lowest gradually approach zero â© springer science+business media llc part springer nature
10.1186/s12859-017-1920-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043287122&doi=10.1186%2fs12859-017-1920-5&partnerID=40&md5=d8795f98a6f74ff5c6366c6144aa23f7 0,background recent years protein protein interaction ppi networks well recognized important resources elucidate various biological processes cellular mechanisms paper address problem predicting protein complexes ppi network problem two difficulties one related small complexes contains two three components relatively difficult identify due simpler internal structure unfortunately complexes sizes dominant major protein complex databases cyc another difficulty model overlaps predicted complexes evaluate different predicted complexes sharing common proteins cyc databases include protein complexes thus critical model overlaps predicted complexes identify simultaneously results paper propose sampling based protein complex prediction method rocsampler regularizing overlapping complexes exploits part whole scoring function regularization term overlaps predicted complexes distribution sizes predicted complexes implemented rocsampler matlab executable file windows available site http imi kyushu u ac jp om software rocsampler conclusions applied rocsampler five yeast ppi networks shown superior existing methods implies design scoring functions including regularization terms effective approach protein complex prediction
10.1063/1.5016667 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037843872&doi=10.1063%2f1.5016667&partnerID=40&md5=0bfcd23e288c0d3744c2f5b365696eb6 0,bayesian mixture modeling requires stages identification number appropriate mixture components thus obtained mixture models fit data data driven concept reversible jump markov chain monte carlo rjmcmc combination reversible jump rj concept markov chain monte carlo mcmc concept used researchers solve problem identifying number mixture components known certainty number application rjmcmc using concept birth death split merge six types movement w updating î updating z updating hyperparameter î² updating split merge components birth death blank components development rjmcmc algorithm needs done according observed case purpose study know performance rjmcmc algorithm development identifying number mixture components known certainty number bayesian mixture modeling microarray data indonesia results study represent concept rjmcmc algorithm development able properly identify number mixture components bayesian normal mixture model wherein component mixture case microarray data indonesia known certain number â© author
10.1002/jcc.25065 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032189034&doi=10.1002%2fjcc.25065&partnerID=40&md5=86681c8925bccfd1c207e39d52331d02 0,four pseudorandom number generators compared physical quantum based random number generator using nist suite statistical tests quantum based random number generator successfully pass measured effect five random number generators various calculated properties different markov chain monte carlo simulations two types systems tested conformational sampling small molecule aqueous solution liquid methanol constant temperature pressure results show poor quality pseudorandom number generators produce results deviate significantly obtained quantum based random number generator particularly case small molecule aqueous solution setup contrast widely used mersenne twister pseudorandom generator bit linear congruential generator scrambler produce results statistically indistinguishable obtained quantum based random number generator â© wiley periodicals inc â© wiley periodicals inc
10.1109/MLSP.2017.8168171 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042280281&doi=10.1109%2fMLSP.2017.8168171&partnerID=40&md5=909c8b369d2a68921336c49191ec2af6 0,paper consider parameter estimation latent spatiotemporal gaussian processes using particle markov chain monte carlo methods particular use spectral decomposition covariance function obtain high dimensional state space representation gaussian processes assumed observed nonlinear non gaussian likelihood develop rao blackwellized particle gibbs sampler sample state trajectory show sample hyperparameters possible parameters likelihood proposed method evaluated spatio temporal population model predictive performance evaluated using leave one cross validation â© ieee
10.1051/matecconf/201713900175 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039444965&doi=10.1051%2fmatecconf%2f201713900175&partnerID=40&md5=c278fed768dfdfacf83d49256b008cb6 0,view current social background power system becoming complicated current research situation related fields paper discusses common methods power system risk assessment including method hierarchy analysis markov chain model monte carlo method fuzzy comprehensive evaluation related research progress advantages disadvantages four methods enumerated respectively considered power system evaluated synthetically practical application effective risk assessment method adopted rationally â© authors published edp sciences
10.3389/fnins.2017.00669 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037053927&doi=10.3389%2ffnins.2017.00669&partnerID=40&md5=180c32f2cfe920fd7816ceb8e8745abf 2,develop integrative bayesian predictive modeling framework identifies individual pathological brain states based selection fluoro deoxyglucose positron emission tomography pet imaging biomarkers evaluates association states clinical outcome consider data study temporal lobe epilepsy tle patients subsequently underwent anterior temporal lobe resection modeling framework looks observed profiles regional glucose metabolism pet phenotypic manifestation latent individual pathologic state assumed vary across population modeling strategy adopt allows identification patient subgroups characterized latent pathologies differentially associated clinical outcome interest also identifies imaging biomarkers characterizing pathological states subjects data application identify subgroup tle patients high risk post surgical seizure recurrence anterior temporal lobe resection together set discriminatory brain regions used distinguish latent subgroups show proposed method achieves high cross validated accuracy predicting post surgical seizure recurrence â© chiang guindani yeh dewar haneef stern vannucci
10.3389/fmicb.2017.02399 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037662654&doi=10.3389%2ffmicb.2017.02399&partnerID=40&md5=9d2fc4236d75e857eecb3dc0a1b279df 2,human norovirus hunov leading cause viral gastroenteritis worldwide gii predominant genotype unlike genotypes gii created various variants escaped previously acquired immunity host caused repeated epidemics however molecular evolutionary differences among gii variants including recently discovered strains elucidated thus conducted series bioinformatic analyses using numerous globally collected full length gii major capsid vp gene sequences strains compare evolutionary patterns among gii variants time scaled phylogenetic tree constructed using bayesian markov chain monte carlo mcmc method showed common ancestor gii vp gene diverged gii gii genotype emerged formed seven clusters including known variants evolutionary rate gii strains estimated ã— substitutions site year evolutionary rates probably differed among variants well domains protruding p shell p domains osaka variant strains probably contained nucleotide substitutions variant conformational epitopes located shell p domains although contained p domain previously established associated attachment host factors antigenicity found positive selection sites whole gii genotype existed shell p domains den haag b new orleans sydney variants positive selection p domain amino acid substitutions overlapped putative epitopes located around epitopes p domain effective population sizes present strains increased stepwise den haag b new orleans sydney variants results suggest hunov gii rapidly evolved decades created various variants altered evolutionary rate antigenicity â© motoya nagasawa matsushima nagata ryo sekizuka yamashita kuroda morita suzuki sasaki katayama kimura
10.1142/S1793525319500262 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038396101&doi=10.1142%2fS1793525319500262&partnerID=40&md5=cc0cf3a7decfee82a9946a7dfaa45901 0,show uniform probability measure supported specific set piecewise linear loops nontrivial free homotopy class multi punctured plane overwhelmingly concentrated around loops minimal lengths approach based extending mogulskiiâ€™s theorem closed paths useful result independent interest addition show measure sampled using standard markov chain monte carlo techniques thus providing simple method approximating shortest loops â© world scientific publishing company
10.3390/ijerph14121497 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036652198&doi=10.3390%2fijerph14121497&partnerID=40&md5=ce447930c826dc4455990700058e9667 1,aircraft noise increases risk cardiovascular diseases mental illness allowable limit sound vicinity airport decibels db averaged hour â€˜day nightâ€™ period dnl united states evaluate trade cost health benefits changing regulatory dnl level db db using markov model study used laguardia airport lga case study compliance db allowable limit aircraft noise sound insulation required residential homes within db db dnl markov model built assess cost effectiveness installing sound insulation one way sensitivity analyses monte carlo simulation conducted test uncertainty model incremental cost effectiveness ratio installing sound insulation residents exposed airplane noise lga qaly gained credible interval cost saving life saving qaly gained changing regulatory standard noise exposure around airports db db comes good value â© authors licensee mdpi basel switzerland
10.1016/j.jappgeo.2017.10.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033713903&doi=10.1016%2fj.jappgeo.2017.10.004&partnerID=40&md5=ea65c357b58db382013b83385cdc754f 2,study developed efficient bayesian inversion framework interpreting marine seismic amplitude versus angle controlled source electromagnetic data marine reservoir characterization framework uses multi chain markov chain monte carlo sampler hybrid differential evolution adaptive metropolis adaptive metropolis samplers inversion framework tested estimating reservoir fluid saturations porosity based marine seismic controlled source electromagnetic data multi chain markov chain monte carlo scalable terms number chains useful computationally demanding bayesian model calibration scientific engineering problems demonstration approach used efficiently accurately estimate porosity saturations representative layered synthetic reservoir results indicate seismic amplitude versus angle controlled source electromagnetic joint inversion provides better estimation reservoir saturations seismic amplitude versus angle inversion especially parameters deep layers performance inversion approach various levels noise observational data evaluated â€” reasonable estimates obtained noise levels sampling efficiency due use multiple chains also checked found almost linear scalability â©
10.1109/TWC.2017.2750667 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030650321&doi=10.1109%2fTWC.2017.2750667&partnerID=40&md5=7098e384240a6c7ed8f3d4c74223f462 1,introduce revised derivation bitwise markov chain monte carlo mcmc multiple input multipleoutput mimo detector new approach resolves previously reported high snr stalling problem mcmc without need hybridization another detector method adding heuristic temperature scaling factors another common problem mcmc algorithms unknown convergence time making predictable fixed length implementations problematic insufficient number iterations used slowly converging example output log likelihood ratios unstable overconfident therefore develop method identify rare slowly converging runs mitigate degrading effects soft output information improves forward error correcting code performance removes symptomatic error floor bit error rate plots next pseudo convergence identified novel way visualize internal behavior gibbs sampler effective efficient pseudo convergence detection escape strategy suggested finally new excited mcmc x mcmc detector shown near maximuma posteriori performance even challenging realistic highly correlated channels maximum mimo sizes modulation rates supported ac wifi specification ã— mimo quadrature amplitude modulation â© ieee
10.1007/JHEP12(2017)001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037670141&doi=10.1007%2fJHEP12%282017%29001&partnerID=40&md5=482dbaf37aaeec42817e413b12d7889d 0,given markov chain monte carlo algorithm introduce distance two configurations quantifies difficulty transition one configuration configuration argue distance takes universal form class algorithms generate local moves configuration space explicitly calculate distance langevin algorithm show certainly desired expected properties distance show distance multimodal distribution gets dramatically reduced large value introduction tempering method also argue original distribution highly multimodal large number degenerate vacua anti de sitter like geometry naturally emerges extended configuration space â© author
10.1140/epjd/e2017-80181-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039547031&doi=10.1140%2fepjd%2fe2017-80181-y&partnerID=40&md5=65659d7e8fbea161d0269e6c1ef742c3 0,abstract new simple monte carlo method introduced study electrostatic screening surrounding ions proposed method based generally used markov chain method sample generation sample pristine correlation samples main novelty pairs ions gradually added sample provided energy ion within boundaries determined temperature size ions proposed method provides reliable results demonstrated screening ion plasma water graphical abstract figure available see fulltext â© edp sciences sif springer verlag gmbh germany part springer nature
290.66592313811645 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040666086&partnerID=40&md5=5000a1b7616979f44bbc5bf27671a8a5 0,present wright fisher indian buffet process wf ibp probabilistic model time dependent data assumed generated unknown number latent features model suitable prior bayesian nonparametric feature allocation models features underlying observed data exhibit dependency structure time specifically establish new framework generating dependent indian buffet processes poisson random field model population genetics used way constructing dependent beta processes inference model complex describe sophisticated markov chain monte carlo algorithm exact posterior simulation apply construction develop nonparametric focused topic model collections time stamped text documents test full corpus nips papers published â© valerio perrone paul jenkins dario spano yee whye teh
10.1109/TFUZZ.2016.2617377 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038853498&doi=10.1109%2fTFUZZ.2016.2617377&partnerID=40&md5=7dea03bf63bb5d863414d1fffe8fe93c 0,paper takagi sugeno kang tsk fuzzy classifier casted bayesian inference framework new fuzzy classifier called bayesian tsk fuzzy classifier b tsk fc proposed accordingly proposed classifier constructed learning antecedent consequent parameters involved fuzzy rules simultaneously result introduction bayesian inference proposed b tsk fc distinguished follows unlike existing tsk fuzzy classifiers antecedent consequent parameters fuzzy rules learnt decoupled manner antecedent parameters learnt input space antecedent parameters fuzzy rules b tsk fc learnt developing fuzzy clustering method input output space consequent parameters fuzzy rules learnt accordance maximum margin separation principle thereby resulting form intrinsic link input output spaces achieve improved classification performance better interpretability dirichlet prior assumption fuzzy memberships fuzzy clustering markov chain monte carlo technique employed estimate parameters proposed classifier sampling perspective rather rivals fuzziness probability b tsk fc collaboratively modeled enhance performance tsk fuzzy classifier terms classification interpretability experimental results synthetic datasets well several real world datasets confirm merits proposed fuzzy classifier â© ieee
10.1007/s12665-017-7087-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036470153&doi=10.1007%2fs12665-017-7087-6&partnerID=40&md5=4de9aa49bb2dabada318320ec4113c7c 0,estimation magnitude designed flood fundamental task crucial determination scale engineering construction development flood disaster risk management projects due high level uncertainty observed data selection frequency distribution model estimation model parameters process designed flood uncertainties consequently bayesian flood frequency analysis method adopted designed flood estimation p iii probability distribution flood frequency model bayesian method adaptive metropolis markov chain monte carlo mcmc sampling algorithm employed estimate posterior distributions parameters upon estimation expectations credible intervals designed floods obtained analyzing drawback likelihood function expressed product probability occurrence sample individual four likelihood functions expressed residuals presented based bayesian mcmc method performance presented likelihood functions compared classical likelihood function taking peak flow uncertainty analysis panjiakou reservoir case study results show expectations flood peak quantiles estimation likelihood functions based residuals observed censored calculated values flood peaks almost obvious differences likelihood function based occurrence probability flood sample based residuals respect expectation quantiles estimation also show expectation credible interval quantiles estimation bayesian mcmc method based whole likelihood function reasonable acquired maximum likelihood function finally relevant flood frequency analyses issues based bayesian mcmc algorithm need studied also presented â© springer verlag gmbh germany
10.1016/j.spa.2017.03.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018780278&doi=10.1016%2fj.spa.2017.03.021&partnerID=40&md5=c775b299bb0d43fa45ed08d91e78619e 0,paper shows theory dirichlet forms used deliver proofs optimal scaling results markov chain monte carlo algorithms specifically metropolisâ€“hastings random walk samplers regularity conditions substantially weaker required original approach based use infinitesimal generators dirichlet form methods added advantage providing explicit construction underlying infinite dimensional context particular enables us directly establish weak convergence relevant infinite dimensional distributions â© author
10.1002/qre.2228 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035101546&doi=10.1002%2fqre.2228&partnerID=40&md5=1aaea8fb4142aa2b2f315d149a31f002 1,assurance test plans chosen manage consumer producer risks develop methods planning bayesian assurance tests degradation data ie basis degradation data collected test decision made whether accept reject product bayesian assurance tests incorporate prior knowledge planning stage use information evaluate posterior consumer producer risks consider prior knowledge takes form related degradation data assurance test plans found meet specified requirements consumer producer risks illustrate planning assurance tests example involving printhead migration data also investigate impact measurement error assurance test plans copyright â© john wiley sons ltd
10.1007/s00477-016-1337-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994085882&doi=10.1007%2fs00477-016-1337-0&partnerID=40&md5=ed49cdc7bc73ae150992682265556b39 0,many studies distribution soil attributes depends spatial location environmental factors prediction process identification performed using existing methods kriging however often restrictive model soil attributes dependent known parametric function environmental factors kriging typically assumes paper investigates semiparametric approach identifying modeling nonlinear relationships spatially dependent soil constituent levels environmental variables obtaining point interval predictions spatial region frequentist bayesian versions proposed method applied measured soil nitrogen levels throughout florida usa compared competing models including frequentist bayesian kriging based array point interval measures sample forecast quality semiparametric models outperformed competing models cases bayesian semiparametric models yielded best predictive results provided empirical coverage probability nearly equal nominal â© springer verlag berlin heidelberg
10.1007/s13226-017-0242-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040092413&doi=10.1007%2fs13226-017-0242-7&partnerID=40&md5=e9094b16d6c6b29482aa9c8c93e1917d 0,sampling intractable probability distribution common important problem scientific computing popular approach solve problem construct markov chain converges desired probability distribution run markov chain obtain approximate sample paper provide two methods improve performance given discrete reversible markov chain methods require knowledge stationary distribution normalizing constant methods produces reversible markov chain stationary distribution original chain dominates original chain ordering introduced peskun illustrate methods two markov chains one connected hidden markov models one connected card shuffling also prove result shows metropolis hastings algorithm preserves peskun ordering markov transition matrices â© indian national science academy
10.1002/qre.2215 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028913717&doi=10.1002%2fqre.2215&partnerID=40&md5=f702fd0f817d60f333190e18ded0035e 0,number effects studied log location scale regression model used analyzing reliability improvement experiment restricted number runs usually small many real examples main effects factor interactions considered work propose using bayesian approach analyze reliability improvement experiments specifying prior effects number effects studied longer restricted number runs aliased effects identified estimated simultaneously analyze real data sets demonstrate proposed approach results show complex interactions present proposed approach provide reliable result copyright â© john wiley sons ltd
10.3837/tiis.2017.12.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041025602&doi=10.3837%2ftiis.2017.12.012&partnerID=40&md5=a77b88fd6217005cdf867d5323ebe7b7 1,sentiments profoundly affect individual behavior well decision making confronted ever increasing amount review information available online desirable provide effective sentiment model detect organize available information improve understanding present information constructive way consumers study developed unified phrase based topic sentiment detection model combined tracking model using incremental hierarchical dirichlet allocation ptsm ihdp model proposed discover evolutionary trend topic based sentiments online reviews ptsm ihdp model firstly assumed review document composed series independent phrases represented topic information sentiment information ptsm ihdp model secondly depended improved time dependency non parametric bayesian model integrating incremental hierarchical dirichlet allocation estimate optimal number topics incrementally building date model evaluate effectiveness model tested model collected dataset compared result predictions traditional models results demonstrate effectiveness advantages model compared several state art methods â© ksii
10.1016/j.matcom.2017.05.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020387450&doi=10.1016%2fj.matcom.2017.05.005&partnerID=40&md5=9daae3b24055b93c226c685a6ef62e7e 0,ebola highly infectious disease generally characterized sporadic outbreaks deterministic ebola model formulated converted itã´ stochastic differential equations adding noise compartment order estimate model parameter values use extended kalman filter technique filtering method sum square errors compute approximation likelihood obtained likelihood function maximum likelihood mcmc methods parameters estimation used parameter estimates provide useful information quantities epidemiological interest two cases analyzed model error covariance set zero bias fully incorporated model comparison two cases carried assess whether bias measure effect parameters states estimation finally investigate whether estimate obtained biased study differs systematically true source population study results indicate increase bias noise states simulation parameters estimation compared deterministic model â© international association mathematics computers simulation imacs
10.1002/etc.3913 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030149697&doi=10.1002%2fetc.3913&partnerID=40&md5=20fc2bdff35add3afa039be8fed5b2db 4,little known effect metal mixtures marine organisms especially exposure environmentally realistic concentrations information however required evaluate need include mixtures future environmental risk assessment procedures assessed effect copper cu â€“nickel ni binary mixtures mytilus edulis larval development using full factorial design included environmentally relevant metal concentrations ratios reproducibility results assessed repeating experiment times observed mixture effects compared effects predicted concentration addition model deviations concentration addition model estimated using markov chain monte carlo algorithm enabled accurate estimation deviations uncertainty results demonstrated reproducibly type interactionâ€”synergism antagonismâ€”mainly depended ni concentration antagonism observed high ni concentrations whereas synergism occurred ni concentrations low î¼g ni l low realistic ni concentration median effective concentration ec ni ni predicted effect concentration pnec european union environmental risk assessment concluded results mixture studies extrapolated concentrations ratios investigated significant mixture interactions occur environmentally realistic concentrations accounted marine environmental risk assessment metals environ toxicol chem â€“ â© setac â© setac
10.1109/TCBB.2017.2779141 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037596238&doi=10.1109%2fTCBB.2017.2779141&partnerID=40&md5=71d07b6d73dfda6a0ecc06eb8be61250 0,drosophila melanogaster important model organism ongoing research neuro behavioral biology especially locomotion analysis become integral part studies thus elaborated automated tracking systems proposed past however approaches share inability precisely segment contours colliding animals leading absence model motion related features collisions translate task tracking resolving colliding animals filtering problem solvable markov chain monte carlo methods elaborate adequate larva model comparing method state art approaches demonstrate algorithm produces significantly better results fraction time facilitates analysis animal behavior interaction detail ieee
10.1785/0120170098 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037365317&doi=10.1785%2f0120170098&partnerID=40&md5=dd526cac75a93a3df0664653917b0214 4,estimate corner frequencies stress drops mw mineral virginia earthquake aftershocks using multiwindow coda spectral ratio method apply bayesian approach using markov chain monte carlo algorithm fit observed spectral ratios selected event pairs brune omega square source spectral model obtain reliable measurements corner frequency well associated uncertainties show use wave coda provides stable source spectral ratios using direct waves select event pairs examining common decay characteristics narrowband coda envelopes determined unusually high stress drop âˆ¼ mpa mainshock assuming simple brune type source model results modeling mainshock spectrum nearest recording station suggest similar values stress drop two main subevents responsible moment release estimated stress drops aftershocks mw range âˆ¼ mpa median value mpa aftershocks mw â‰¥ high stress drops within small range âˆ¼ mpa median value mpa observe apparent decrease stress drop decreasing magnitude mw âˆ¼ rather suggesting possible breakdown self similar source scaling attribute apparent magnitude dependence limited signal noise ratios small shocks limited frequency bandwidth particularly group small magnitude earthquakes occurred loose cluster several kilometers northeast mainshock events unusually low stress drops compared aftershocks main aftershock cluster may possibly indicate triggering seismicity set relatively weak fault joint planes found temporal pattern depth dependence estimated stress drops â© seismological society america rights reserved
10.1002/nav.21778 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043336871&doi=10.1002%2fnav.21778&partnerID=40&md5=acb7f7bb7ca09d7ee3b963a1f6f54e2a 0,propose novel simulation based approach solving two stage stochastic programs recourse endogenous decision dependent uncertainty proposed augmented nested sampling approach recasts stochastic optimization problem simulation problem treating decision variables random optimal decision obtained via mode augmented probability model illustrate methodology newsvendor problem stock dependent uncertain demand single multi item news stand cases provide performance comparisons markov chain monte carlo traditional monte carlo simulation based optimization schemes finally conclude directions future research â© wiley periodicals inc
10.1115/1.4035438 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047053120&doi=10.1115%2f1.4035438&partnerID=40&md5=8548033c8b7d545bcc3af75c98af2170 0,reliable prediction diagnosis abnormal events provide much needed guidance risk management traditional bayesian network traditional bn used dynamically predict diagnose abnormal events however inherent limitation caused discrete categorization random variables degrades assessment reliability paper applied continuous bayesian network cbn based model reduce mentioned limitation compute complex posterior distributions cbn markov chain monte carlo method mcmc used case study conducted demonstrate application cbn based comparative analysis traditional bn cbn presented work highlights use cbn overcome drawbacks traditional bn make dynamic prediction diagnosis analysis reliable copyright â© asme
10.1016/j.ijepes.2017.05.031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021161562&doi=10.1016%2fj.ijepes.2017.05.031&partnerID=40&md5=12126d6f6406bf4fe848bd1daed3163a 1,accurate wind speed simulation essential prerequisite analyze power systems wind power wind speed model considering meteorological conditions seasonal variations proposed paper firstly using path analysis method influence weights meteorological factors calculated secondly meteorological data classified several states using improved fuzzy c means fcm algorithm markov chain used model chronological characteristics meteorological states wind speed proposed model proved accurate capturing characteristics probability distribution auto correlation seasonal variations wind speed compared traditional markov chain monte carlo mcmc autoregressive moving average arma model furthermore proposed model applied adequacy assessment generation systems wind power assessment results modified ieee rts ieee rts demonstrated effectiveness accuracy proposed model â© elsevier ltd
10.1088/1742-6596/936/1/012073 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041235520&doi=10.1088%2f1742-6596%2f936%2f1%2f012073&partnerID=40&md5=d2aa394cdf768bdc1c032c8966353682 0,design oscillator networks generate signal prescribed power spectrum consider networks identical sin wave oscillators kuramoto order parameter output signal system use kullback leibler entropy measure distance power spectrum output signal desired one optimizing connection network markov chain monte carlo method replica exchange found even oscillator network small number elements generate variety time signals output signals include periodic quasi periodic signals prescribed periods aperiodic signals prescribed power spectrums â© published licence iop publishing ltd
10.1016/j.sigpro.2017.05.031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020312846&doi=10.1016%2fj.sigpro.2017.05.031&partnerID=40&md5=6ff865a58f170d67565962e463476634 1,volterra systems significant success modelling nonlinear systems various real world applications however generally assumed nonlinearity degree system known beforehand paper contribute literature volterra system identification vsi numerical bayesian approach identifies model coefficients nonlinearity degree concurrently although numerical bayesian method namely reversible jump markov chain monte carlo rjmcmc algorithm used success various model selection problems use novel context sense memory size nonlinearity degree estimated aforementioned study ensures anomalous approach rjmcmc provides new understanding flexible use enables trans structural transitions different classes models addition transdimensional transitions classically used study performance method synthetically generated data including ofdm communications nonlinear channel â© elsevier b v
10.1016/j.jtcvs.2017.08.034 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029638991&doi=10.1016%2fj.jtcvs.2017.08.034&partnerID=40&md5=68270ad519fa4483967bbbe03f570804 2,objectives create validate prediction model assess outcomes associated norwood operation methods public use dataset multicenter prospective randomized single ventricle reconstruction trial used create novel prediction tool bayesian lasso logistic regression model used variable selection used hierarchical framework representing discrete probability models continuous latent variables depended risk factors particular patient bayesian conditional probit regression markov chain monte carlo simulations used estimate effects predictors means latent variables create score function study outcomes also devised method calculate risk outcomes associated norwood operation actual heart operation study outcomes evaluated hospital mortality composite poor outcome results training dataset used patients generate prediction model model included patient demographics baseline characteristics cardiac diagnosis operation details site volume surgeon experience online calculator tool accessed https soipredictiontool shinyapps io norwoodscoreapp model validation performed observations using internal fold cross validation approach prediction model area curve mortality composite poor outcome validation dataset conclusions new prognostic tool promising first step creating real time risk stratification children undergoing norwood operation tool beneficial purposes benchmarking family counseling research â© american association thoracic surgery
10.1007/s11336-017-9576-7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029144762&doi=10.1007%2fs11336-017-9576-7&partnerID=40&md5=6d9bcdfcc6ee80f40c134fb0d2a9bac2 1,propose nonparametric item response theory model dichotomously scored items bayesian framework model based latent class lc formulation multidimensional dimensions corresponding partition items homogenous groups specified basis inequality constraints among conditional success probabilities given latent class moreover innovative system prior distributions proposed following encompassing approach largest model unconstrained lc model reversible jump type algorithm described sampling joint posterior distribution model parameters encompassing model suitably post processing output make inference number dimensions e number groups items measuring latent trait cluster items according dimensions unidimensionality violated approach illustrated two examples simulated data two applications based educational quality life data â© psychometric society
10.1177/0962280215613378 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038817929&doi=10.1177%2f0962280215613378&partnerID=40&md5=ddd5dd2189761aa29084b73f57583b7b 0,multi type recurrent event data occur frequently longitudinal studies dependent termination may occur terminal time correlated recurrent event times article simultaneously model multi type recurrent events dependent terminal event nonparametric covariate functions modeled b splines develop bayesian multivariate frailty model account correlation among dependent termination various types recurrent events extensive simulation results suggest misspecifying nonparametric covariate functions may introduce bias parameter estimation method development motivated applied lipid lowering trial component antihypertensive lipid lowering treatment prevent heart attack trial â© â© author
10.1007/s11336-017-9554-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013422747&doi=10.1007%2fs11336-017-9554-0&partnerID=40&md5=264f64b5422243116260c3e14e4f6c09 3,samejimaâ€™s graded response model grm gained popularity analyses ordinal response data psychological educational health related assessment obtaining high quality point interval estimates grm parameters attracts great deal attention literature current work derive generalized fiducial inference gfi family multidimensional graded response model implement gibbs sampler perform fiducial estimation compare finite sample performance several commonly used likelihood based bayesian approaches via three simulation studies found proposed method able yield reliable inference even presence small sample size extreme generating parameter values outperforming candidate methods investigation use gfi convenient tool quantify sampling variability various inferential procedures illustrated empirical data analysis using patient reported emotional distress data â© psychometric society
10.1016/j.jappgeo.2017.10.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033596338&doi=10.1016%2fj.jappgeo.2017.10.002&partnerID=40&md5=cbd15b4ca6422646345d2e448e67f02a 5,apply target oriented amplitude versus angle ava inversion estimate petrophysical properties gas saturated reservoir offshore nile delta linear empirical rock physics model derived well log data provides link petrophysical properties porosity shaliness saturation p wave wave velocities density rock physics model properly calibrated investigated reservoir used parameterize exact zoeppritz equations derived equations forward model engine linearized bayesian ava petrophysical inversion data gather inverts ava target reflections estimate petrophysical properties reservoir layer keeping fixed cap rock properties make use iterative gauss newton method solve inversion problem petrophysical property interest discuss benefits introduced wide angle reflections constraining inversion compare posterior probability distributions ppds analytically obtained via local linearization inversion ppds numerically computed markov chain monte carlo mcmc method results porosity best resolved parameter wide angle reflections effectively constrain shaliness estimates guarantee reliable saturation estimates also results local linearization returns accurate ppds good agreement mcmc estimates â© elsevier b v
10.1109/SDF.2017.8126349 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046647111&doi=10.1109%2fSDF.2017.8126349&partnerID=40&md5=19d268e6c5f13ffbe2bccd3818758b53 0,bayesian recursive estimation using large volumes data challenging research topic problem becomes particularly complex high dimensional non linear state spaces markov chain monte carlo mcmc based methods successfully used solve problems main issue employing mcmc evaluation likelihood function every iteration become prohibitively expensive compute alternative methods therefore sought overcome difficulty one method adaptive sequential mcmc asmcmc use confidence sampling proposed method reduce computational cost main idea make use concentration inequalities sub sample measurements likelihood terms evaluated however asmcmc methods require appropriate proposal distributions work propose novel asmcmc framework log homotopy based particle flow filter form adaptive proposal show performance significantly enhanced proposed algorithm still maintaining comparatively low processing overhead â© ieee
10.1016/j.cma.2017.08.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028698824&doi=10.1016%2fj.cma.2017.08.009&partnerID=40&md5=1566fed322b89b7b442fc7e4fbe204a5 2,use mathematical computational models reliable predictions tumor growth decline living organisms one foremost challenges modern predictive science must cope uncertainties observational data model selection model parameters model inadequacy complex physical biological systems paper large classes parametric models tumor growth vascular tissue discussed including models radiation therapy observational data obtained mri murine model glioma observed period three weeks x ray radiation administered days experimental program parametric models tumor proliferation decline presented based balance laws continuum mixture theory particularly mass balance accepted biological hypotheses tumor growth among new model classes include characterizations effects radiation simple models mechanical deformation tumors occam plausibility algorithm opal implemented provide bayesian statistical calibration model classes models well determination plausible models classes relative observational data assess model inadequacy statistical validation processes discussions numerical analysis finite element approximations system stochastic nonlinear partial differential equations characterizing model classes well sampling algorithms monte carlo markov chain monte carlo mcmc methods employed solving forward stochastic problem computing posterior distributions parameters model plausibilities provided results analyses described suggest general framework developed provide useful approach predicting tumor growth effects radiation â©
33.895592689001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040045843&partnerID=40&md5=d5d78e70c62c269e502d791501a12376 3,response surface methodology rsm widely used petroleum industry assistive tool numerical reservoir simulation studies instead generating simulation cases exhaustively solve history matching hm problems proxy models created rsm provide useful benefits terms simplicity computational efficiency however capability proxy models fully capture uncertainty ranges hm results production forecasts might deficient complex problems simplified proxy models deliver partial solutions hence decide whether uncertainty assessment process proxy models complete models deliver many hm solutions required build probability distribution production forecasts therefore developed work flow combine processes integrated proxy based approach searches accepted hm solution probabilistic forecasts evaluated simultaneously addition combined work flow iterative approach gradually modifies proxy models dependent increasing number completed simulation runs continually update original proxy model higher degree polynomial use higher degree polynomial equations appears benefit provide expanded set hm solutions inside uncertain parameter space compared commonly used quadratic form solutions found iterations eventually approximate wider uncertainty ranges probabilistic forecasts consistent direct markov chain monte carlo mcmc method significant reduction simulated cases finally paper applies proxy based approach reservoir simulation model containing horizontal hydraulic fractured well marcellus shale formation proxy based approach helps assess uncertainty reservoir fracture properties unconventional reservoirs also useful evaluating ranges ultimate gas recovery â© society petroleum engineers
10.1051/0004-6361/201731601 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038019657&doi=10.1051%2f0004-6361%2f201731601&partnerID=40&md5=1f67677d6a3f8476098ff1eae097e469 5,context important information evolution jet obtained comparing physical state plasma propagation broad line region jet likely formed intergalactic medium starts decelerate significantly aims compare constraints physical parameters innermost â‰¤ pc outer â‰¥kpc regions c jet means detailed multiwavelength analysis theoretical modeling broadband spectra methods data collected fermi lat ray band swift x ray ultraviolet bands chandra x ray band analyzed together spectral energy distributions modeled using leptonic synchrotron inverse compton model taking account seed photons originating inside outside jet model parameters estimated using markov chain monte carlo method results ray flux inner jet c characterized rapid variation mjd mjd two strong flares observed april within min h flux high â± ã— photon cm â± ã— photon cm respectively â‰¤ ïƒ flares apparent isotropic ray luminosity l ã— erg common radio galaxies broadband emission quiet flaring states described synchrotron self compton emission inverse compton scattering dusty torus photons excluded flaring states x ray emission knots reproduced inverse compton scattering cosmic microwave background photons jet highly relativistic even î” = ue=ub still â‰¤ extreme requirements somewhat softened assuming x rays synchrotron emission second population high energy electrons conclusions found jet power estimated two scales consistent suggesting jet suffer severe dissipation simply becomes radiatively inefficient
10.1037/met0000134 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017382897&doi=10.1037%2fmet0000134&partnerID=40&md5=3cfb62a49725ca395709cbee3eab95c4 2,although immediacy one necessary criteria show strong evidence causal relation single case designs scds inferential statistical tool currently used demonstrate propose bayesian unknown change point model investigate quantify immediacy scd analysis unlike visual analysis considers observations consecutive phases investigate immediacy model considers data points immediacy indicated posterior distribution unknown change point narrow around true value change point model accommodate delayed effects monte carlo simulation phase design shows posterior standard deviations change points decrease increase standardized mean difference phases decrease test length method illustrated real data â© american psychological association
10.1007/s13253-017-0300-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027995281&doi=10.1007%2fs13253-017-0300-y&partnerID=40&md5=40c3acad0a99f650483cb179b5ded1d1 0,abundance estimates animal point count surveys require accurate estimates detection probabilities standard model estimating detection removal sampled point count surveys assumes organisms survey site detected constant rate however assumption often lead biased estimates consider class n mixture models allows detection heterogeneity time flexibly defined time detection distribution ttdd allows fixed random effects abundance detection model thus combination survival time event analysis unknown n unknown p abundance estimation specifically explore two parameter families ttdds e g gamma additionally include mixture component model increased probability detection initial observation period based simulation analyses find modeling ttdd using two parameter family necessary data chance arising distribution nature addition models mixture component outperform non mixture models even truth non mixture finally analyze ovenbird data set chippewa national forest using mixed effect models abundance detection demonstrate effects explanatory variables abundance detection consistent across mixture ttdds flexible ttdds result lower estimated probabilities detection therefore higher estimates abundance supplementary materials accompanying paper appear line â© international biometric society
10.1093/biomet/asx051 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039161035&doi=10.1093%2fbiomet%2fasx051&partnerID=40&md5=1dff8d605fce57c6e83dad9dc7d87e13 1,sampling posterior probability distribution latent states hidden markov model nontrivial even context markov chain monte carlo address andrieu et al proposed way using particle filter construct markov kernel leaves posterior distribution invariant recent theoretical results established uniform ergodicity markov kernel shown mixing rate deteriorate provided number particles grows least linearly number latent states however gives rise cost per application kernel quadratic number latent states prohibitive long observation sequences using blocking strategies devise samplers stable mixing rate cost per iteration linear number latent states easily parallelizable â© biometrika trust
10.1002/sam.11349 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020475269&doi=10.1002%2fsam.11349&partnerID=40&md5=8ef98b2975693a5340a7a7399965ca09 0,paper propose bayesian semiparametric regression model estimate test effect genetic pathway prostate specific antigen psa measurements patients prostate cancer underlying functional relationship genetic pathway psa modeled using reproducing kernel hilbert space rkhs theory rkhs formulation makes model highly flexible capture complex multidimensional relationship genes genetic pathway response moreover higher order nonlinear interactions among genes pathway also automatically modeled kernel based representation illustrate connection semiparametric regression based rkhs linear mixed model choosing special prior distribution model parameters test significance genetic pathway toward phenotypic response like psa propose bayesian hypothesis testing scheme based bayes factor efficient markov chain monte carlo algorithm designed estimate model parameters bayes factors genetic pathway effect simultaneously illustrate effectiveness model five simulation studies one real prostate cancer gene expression data analysis â© wiley periodicals inc
10.1177/0278364917743319 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039870175&doi=10.1177%2f0278364917743319&partnerID=40&md5=20b31e40098f4b584481881c9409bbad 2,demonstration trajectories collected supervisor teleoperation widely used robot learning temporally segmenting trajectories shorter less variable segments improve efficiency reliability learning algorithms trajectory segmentation algorithms sensitive noise spurious motions temporal variation present new unsupervised segmentation algorithm transition state clustering tsc leverages repeated demonstrations task clustering segment endpoints across demonstrations tsc complements motion based segmentation algorithm identifying candidate transitions clustering kinematic similarity correlating kinematic clusters available sensory temporal features tsc uses hierarchical dirichlet process gaussian mixture model avoid selecting number segments priori present simulated results suggest tsc significantly reduces number false positive segments dynamical systems observed noise compared seven probabilistic non probabilistic segmentation algorithms additionally compare algorithms use piecewise linear segment models find tsc recovers segments generated piecewise linear trajectory greater accuracy presence process observation noise maximum noise level tsc recovers ground truth accurately alternatives furthermore tsc runs ã— faster next accurate alternative autoregressive models require expensive markov chain monte carlo mcmc based inference also evaluated tsc recordings surgical needle passing suturing supplemented kinematic recordings manually annotated visual features denote grasp penetration conditions dataset tsc finds needle passing transitions suturing transitions annotated human experts â© â© author
10.1177/1471082X17703855 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033444443&doi=10.1177%2f1471082X17703855&partnerID=40&md5=a97ea7979b67e0d9c439b7f774aa03ff 0,study proposes new model integer valued time seriesâ€”the hysteretic poisson integer valued generalized autoregressive conditionally heteroskedastic ingarch modelâ€”which integrated hysteresis zone switching mechanism conditional expectation modelling framework provides parsimonious representation salient features integer valued time series discreteness dispersion asymmetry structural change adopt bayesian methods markov chain monte carlo sampling scheme estimate model parameters utilize bayesian information criteria model comparison apply proposed model five real time series criminal incidents recorded new south wales police force australia simulation results empirical analysis highlight better performance hysteresis modelling integer valued time series â© â© sage publications
10.1186/s12874-017-0427-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036625039&doi=10.1186%2fs12874-017-0427-0&partnerID=40&md5=662f8b9f88a65d48c0b6f77bb61cc7ef 0,background exploratory preclinical well clinical trials may involve small number patients making difficult calculate analyze pharmacokinetic pk parameters especially pk parameters show high inter individual variability iiv study performance classical first order conditional estimation interaction foce expectation maximization em based markov chain monte carlo bayesian bayes estimation methods compared estimating population parameters distribution data sets low number subjects methods study data sets simulated eight sampling points subject six different levels iiv pk parameter distribution stochastic simulation estimation sse study performed simultaneously simulate data sets estimate parameters using four different methods foce bayes c foce bayes composite method bayes f bayes true initial parameters fixed ï‰ bayes relative root mean squared error rrmse relative estimation error ree used analyze differences true estimated values case study performed clinical data theophylline available nonmem distribution media nonmem software assisted pirana psn xpose used estimate population pk parameters r program used analyze plot results results rrmse ree values parameter fixed effect random effect estimates showed four methods performed equally lower iiv levels foce method performed better em based methods higher iiv levels greater general estimates random effect parameters showed significant bias imprecision irrespective estimation method used level iiv similar performance estimation methods observed theophylline dataset conclusions classical foce method appeared estimate pk parameters reliably bayes method using simple model data containing subjects em based estimation methods considered adapting specific needs modeling project later steps modeling â© author
10.1515/mcma-2017-0119 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037596441&doi=10.1515%2fmcma-2017-0119&partnerID=40&md5=70f4553c105fed5b8727ba3cb571bcab 0,new monte carlo algorithm solving robin boundary value problem described applied calculation electron beam induced current simplified model imaging measurements â© walter de gruyter gmbh berlin boston
10.1214/17-AOAS1075 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042669957&doi=10.1214%2f17-AOAS1075&partnerID=40&md5=ebf766c5938c62af0627249ccb18c643 1,copy number variations cancer cells volatility fluctuations stock prices commonly manifested changepoints occurring positions across related data sequences introduce bayesian modeling framework basic employs changepoint prior capture cooccurrence tendency data type design efficient algorithms sample maximize basic changepoint posterior develop monte carlo expectation maximization procedure select prior hyperparameters empirical bayes fashion use resulting basic framework analyze dna copy number variations nci cancer cell lines identify important events affected price volatility p stocks â© institute mathematical statistics
10.1017/jpr.2017.61 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041309990&doi=10.1017%2fjpr.2017.61&partnerID=40&md5=2dc0ee10017a2b63a89fc77a42771b35 1,paper consider optimal scaling high dimensional random walk metropolis algorithms densities differentiable l p mean may irregular points laplace density example supported interval main result weak convergence markov chain appropriately rescaled time space langevin diffusion process dimension goes log density might nondifferentiable limiting diffusion singular scaling limit established assumptions much weaker one used original derivation roberts et al result important practical implications use random walk metropolis algorithms bayesian frameworks based sparsity inducing priors copyright â© applied probability trust
10.1177/1471082X17699299 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033442361&doi=10.1177%2f1471082X17699299&partnerID=40&md5=15fd25aae3124345d844b73fb4927d18 0,article dirichlet process dp applied cluster subjects longitudinal observations basis clustering ability subjects adapt new circumstances indeed basis clustering depends time changing response variability done providing random change point time variance structure mixed effects models dp assumed prior distribution random change point discrete nature dp utilized cluster subjects according time adaption proposed model useful identify groups subjects distinctive time based progressions declines transition mixed effects models also used account serial correlation among observations time joint modelling approach utilized handle bias created models gibbs sampling technique adopted achieve parameter estimates performance proposed method evaluated via conducting simulation study usefulness proposed model assessed course evaluation dataset â© â© sage publications
10.1111/anzs.12207 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035128247&doi=10.1111%2fanzs.12207&partnerID=40&md5=fc27426761a7ad891537fd17c1f8f6cc 0,present methods fit monotone polynomials bayesian framework including implementations popular readily available modeling languages bugs stan sum squared polynomials parameterisation monotone polynomials previously considered frequentist framework murray mã¼ller turlach considered due superior flexibility compared parameterisations specifics implementation discussed enabling end users adapt work applications testing undertaken real simulated data sets output diagnostics presented demonstrate stan preferable high degree polynomials component wise nature gibbs sampling potentially inappropriate highly connected models code discussed sample scripts show use r freely available https github com hhau bayesianmonpol â© australian statistical publishing association inc published john wiley sons australia pty ltd
10.1049/iet-cvi.2016.0429 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038841166&doi=10.1049%2fiet-cvi.2016.0429&partnerID=40&md5=08b5ba832725fede13cc0eb949fb3940 0,markov random fields mrfs prominent modelling image handle image processing problems however confront bottleneck model selection improving performance difficult decide many objects image automatically motivated bayesian non parametric bn models layered bn mrf proposed proposed model hierarchical lower level random field like model higher level chinese restaurant process crp clustering procedure formulated briefly follows input data first clustered lower level mrf form set components higher level crp used merge components larger clusters furthermore split merge monte carlo markov chain employed quantitative evaluations bsd data set msrc data set show proposed model comparable state art bn models graphical models modelling unsupervised distancedependent problems â© institution engineering technology
10.13224/j.cnki.jasp.2017.12.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043527027&doi=10.13224%2fj.cnki.jasp.2017.12.007&partnerID=40&md5=b8fc8b05a65b49271e783684e976448a 0,according acquisition inspection maintenance information civil aero engine hot section subassembly system typical degradation state judgment experts models sojourn time estimation typical macro degradation state based expert estimation opinion inspection information fusion data set assumptions system state degradation process obeying discrete semi markov chain methods maximum likelihood estimation mcmc monte carlo markov chain applied estimate model parameters sojourn time state transition coefficients macro degradation state based three kinds data meanwhile state transition probability models built certain service cycle optimal inspection maintenance cost optimal inspection intervals three typical macro degradation states e cycles obtained simulation results showed optimal inspection intervals relatively close reality situations civil aviation operation production providing technical supports aspect customer oriented inspection maintenance decision making improving economic benefits civil aviation transport enterprises â© editorial department journal aerospace power right reserved
10.1016/j.beproc.2017.09.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030681541&doi=10.1016%2fj.beproc.2017.09.017&partnerID=40&md5=9939843020739b6bba6e91170e6263ac 1,study aims describe bayesian hierarchical linear model hlm approach longitudinal designs fish experimental aggressive behavior studies alternative classical methods particular discuss advantages bayesian analysis dealing combined variables non statistically significant results required sample size using experiment angelfish pterophyllum scalare species case study groups individuals subjected daily observations recorded min days frequencies attacks displays total attacks attacks + displays record modeled using monte carlo markov chains addition bayesian hlm performed measuring rate increase decrease aggressive behavior time assess probability difference among days results highlighted using combined variable total attacks lead biased conclusions displays attacks showed opposite pattern experiment moreover depending study difference pattern happen clearly subtly subtle changes detected p values implemented contrary bayesian methods provide clear description changes even patterns subtle additionally results showed number replicates invariant study conclusions well using small sample size evident within overlapping days includes social rank stability therefore bayesian analysis seems richer adequate statistical approach fish aggressive behavior longitudinal designs â© elsevier b v
10.1115/1.4036064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047053529&doi=10.1115%2f1.4036064&partnerID=40&md5=b762cee5fea581fc59baebaeb8e3e6b7 0,corrosion degradation common problem boiler tubes power plants resulting unscheduled plant shutdown research degradation corrosion investigated boiler tubes estimating corrosion lifetime special focus made corrosion failures important failure modes mechanisms metallic boiler tubes via failure modes effect analysis fmea method thereby evaluating pitting corrosion common failure mode tubes majority available approaches estimates lifetime pitting corrosion deterministic approaches results valid limited conditions order improve deficiencies available models stochastic method proposed study corrosion life temporal behavior metal degradation analyzed different conditions developed approach proper degradation model selected uncertainty intervals distributions determined model parameters deterministic model converted probabilistic model taking account variability uncertain input parameters model simulated using monte carlo method via simple sampling result life estimation updated bayesian framework using monte carlo markov chain finally element subjected pitting corrosion degradation life distribution obtained modeling results show pitting corrosion stochastic behavior lognormal distribution proper fit pitting corrosion behavior order validate results estimations compared power plant field failure data copyright â© asme
10.3969/j.issn.0372-2112.2017.12.013 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046136774&doi=10.3969%2fj.issn.0372-2112.2017.12.013&partnerID=40&md5=b8f651915bce5ceca165b1f9d86aed28 0,previous approaches integrated circuit parametric yield estimation usually model chip performance pre setting variation basis functions easy result high complexity hand random reduction number basis functions may result accuracy loss order avoid issues sparse estimation approach chip level parametric yield proposed taking power yield instance proposed approach models leakage power stochastically according importance level several key basis functions adaptively selected constribute sparse leakage power model based elastic net finally according bias theory markov chain method power yield estimated efficiently experimental results show proposed approach makes established power model general sparse estimates power yield accurately comparing monte carlo mc simulation relative errors power yield estimation based proposed method less addition approach lead large cost reduction compared mc simulation thus higher efficiency â© chinese institute electronics right reserved
10.1002/jmv.24910 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031127710&doi=10.1002%2fjmv.24910&partnerID=40&md5=4b3ef76f7c0946721d0221827bac06fb 0,zika virus zikv member family flaviviridae zikv emerged brazil causing unprecedented epidemic since virus rapidly spread throughout americas facts highlight need detailed phylogenetic studies understand emergence spread evolution zikv populations reasons bayesian coalescent markov chain monte carlo analysis complete genome sequences zikv strains recently isolated american continent performed results studies revealed increasing diversification zikv strains different genetic lineages co circulation distinct genetic lineages several countries region time recent common ancestor tmrca established around february zikv strains circulating american region mean rate evolution ã— âˆ’ substitutions site year obtained zikv strains included study bayesian skyline plot indicate sharp increase population size february july decline results discussed terms emergence evolution zikv populations american continent â© wiley periodicals inc
10.1534/genetics.117.300403 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037057470&doi=10.1534%2fgenetics.117.300403&partnerID=40&md5=627d7c1de6aac65d4b416bcacc6fc5ab 2,crucial step plant breeding selection combination parents form new crosses genome based prediction guides selection high performing parental lines many crop breeding programs ensures high mean performance progeny warrant maximum selection progress new cross also provide large progeny variance usefulness concept measure gain obtained specific cross accounts variation progeny variance shown genetic gain considerably increased crosses selected based genomic usefulness criterion compared selection based mean genomic estimated breeding values efficient improved method predict genetic variance cross based markov chain monte carlo samples marker effects whole genome regression model suggested simulations representing selection procedures crop breeding programs performance novel approach compared existing methods like selection based mean genomic estimated breeding values optimal haploid values cases higher genetic gain obtained compared previously suggested methods progenies per cross selected genetic gain based estimated usefulness criterion increased genetic standard deviation compared selection based mean genomic estimated breeding values analytical derivations progeny genotypic variance covariance matrix based parental genotypes genetic map information make simulations progeny dispensable allow fast implementation large scale breeding programs â© genetics society america
10.5194/npg-24-701-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036670404&doi=10.5194%2fnpg-24-701-2017&partnerID=40&md5=9396abfde92d901da0bab9e855ffb36c 0,taking model error account data assimilation one needs evaluate prior distribution represented onsager machlup functional numerical experiments study clarifies prior distribution incorporated cost functions discrete time estimation problems consistent previous theoretical studies divergence drift term essential weak constraint var w var necessary markov chain monte carlo euler scheme although former property may cause difficulties implementing w var large systems paper proposes new technique estimating divergence term derivative â© author
10.1002/env.2476 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029395268&doi=10.1002%2fenv.2476&partnerID=40&md5=a07a223886ff5aa9235198dd5fb889c3 1,analyze behavior extreme winds occurring southern california santa ana wind season using latent mixture model mixture representation formulated hierarchical bayesian model fit using markov chain monte carlo two stage model results generalized pareto margins exceedances generates temporal dependence latent markov process construction induces asymptotic independence response allowing dependence extreme subasymptotic levels compare model frequentist analogue inference performed via maximum pairwise likelihood use interval censoring account data quantization estimate extremal index probabilities multiday occurrences extreme santa ana winds range high thresholds copyright â© john wiley sons ltd
10.1111/jcpe.12775 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037151028&doi=10.1111%2fjcpe.12775&partnerID=40&md5=7b56e9851d067801a024ee51599a40a0 2,aim professional oral health care pohc prevents nursing home acquired pneumonia nhap related mortality assessed cost effectiveness pohc versus pohc npohc monetary value eliminating uncertainty future research methods german publicâ€“private payer perspective adopted markov model used following long term care residents admission death cost effectiveness estimated euro disability adjusted life year daly using monte carlo microsimulations value information analyses performed willingness pay threshold daly assumed range â€“ per capita gross domestic product gdp results npohc less costly â‚¬ also less effective dalys pohc â‚¬ dalys presumed payers pohc cost effective cost effectiveness pohc higher smokers underweight pulmonary disease patients eliminating uncertainty nhap costs nhap incidence mortality pohc effectiveness result expected net value â million â‚¬ year even higher values lower gdp thresholds likely decrease time conclusions within chosen setting basis current evidence pohc cost effective given detected uncertainty research seems warranted â© john wiley sons published john wiley sons ltd
10.1007/s10651-017-0391-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034604201&doi=10.1007%2fs10651-017-0391-1&partnerID=40&md5=ca1cf0f990a21f3c986b1ca4a177b01c 0,models multivariate spaceâ€“time geostatistical data received growing interest spatial spatiotemporal epidemiology however specifying models capture associations within among multivariate measurements usually challenge main goal paper introduce review cross covariance functions rich structure computationally feasible integrated nested laplace approximation combined stochastic partial differential equations used inference prediction fast precise alternative computationally intensive markov chain monte carlo methods large set models considered paper models assuming independent shared correlated spatial temporal processes nine possible combinations models independent shared linear models coregionalization spatiotemporal processes different processes applied culicoides data compared bayesian spatial prediction results show central northeastern parts belgium highest prevalence culicoides summer months lowest prevalence winter months â© springer science+business media llc part springer nature
10.1200/JCO.2016.70.4767 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036563163&doi=10.1200%2fJCO.2016.70.4767&partnerID=40&md5=1e374eba2728d573730de8539abf0014 6,purpose estimate prevalence sperm banking among adolescent males newly diagnosed cancer identify factors associated banking outcomes patients methods prospective single group observational study design used test contribution sociodemographic medical psychological health belief communication developmental factors fertility preservation outcomes risk adolescent males n = age years tanner stage parents medical providers eight leading pediatric oncology centers across united states canada completed self report questionnaires within week treatment initiation multivariable logistic regression used calculate odds ratios ors cis specified banking outcomes collection attempt v attempt successful completion banking v banking results among adolescents mean age years standard deviation years made collection attempt successfully banking sperm attempters overall attempt model revealed adolescent consultation fertility specialist ci p = parent recommendation tobank ci p = higher tanner stage ci p = associated anincreased likelihood acollection attempt adolescent history masturbation ci p = banking self efficacy ci p = parent ci p = medical team ci p = recommendation bank associated increased likelihood sperm banking completion conclusion although findings suggest banking underutilized modifiable adolescent parent provider factors associated banking outcomes identified targeted future intervention efforts â© american society clinical oncology
10.1016/j.fertnstert.2017.08.039 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036586747&doi=10.1016%2fj.fertnstert.2017.08.039&partnerID=40&md5=1b8a3aaad12316cdb57c2ca40b76e749 1,objective investigate influence parental sociodemographic communication psychological factors sperm collection attempts among risk adolescent males newly diagnosed cancer design prospective single group observational study design setting pediatric oncology centers patient parents n = newly diagnosed adolescent males increased risk infertility secondary cancer therapy intervention survey based assessment parent factors associated adolescent collection attempts main outcome measure attempt manual collection sperm result parental recommendation bank sperm odds ratio confidence interval ci â€“ perceived self efficacy facilitate banking ci â€“ associated increased likelihood making collection attempt conclusion parental recommendation bank critical influence sperm banking among adolescent males newly diagnosed cancer findings highlight importance effective communication parents patients health care teams discussing preservation options parent perceptions ability facilitate sperm banking time diagnosis also targeted future interventions clinical trial registration number nct â©
10.1177/0962280215602040 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038816278&doi=10.1177%2f0962280215602040&partnerID=40&md5=31c9a87ce1a7857d1f8065312b9b87d8 4,receiver operating characteristic roc curve frequently used measure accuracy continuous markers diagnostic tests area roc curve auc arguably widely used summary index roc curve although small sample size scenario common medical tests comprehensive study small sample size properties various methods construction confidence credible interval ci auc large missing literature paper describe compare non parametric parametric methods construction ci auc number available observations small methods considered include widely adopted also less frequently mentioned knowledge never applied auc context compare different methods carried simulation study data generated binormal models equal unequal variances exponential models various parameters equal unequal small sample sizes found larger true auc value smaller sample size larger discrepancy among results different approaches model correctly specified parametric approaches tend outperform non parametric ones moreover non parametric domain found method based mannâ€“whitney statistic general superior others elucidate potential issues provide possible solutions along general guidance ci construction auc sample size small finally illustrate utility different methods real life examples â© â© author
10.1109/TPAMI.2016.2646685 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038214555&doi=10.1109%2fTPAMI.2016.2646685&partnerID=40&md5=c1b1374a65cf08f4f7120ab581189e43 0,propose novel finite dimensional spaces well behaved rn â†’rn transformations latter obtained fast highly accurate integration continuous piecewise affine velocity fields proposed method simple yet highly expressive effortlessly handles optional constraints e g volume preservation boundary conditions supports convenient modeling choices smoothing priors coarse fine analysis importantly proposed approach partly due rapid likelihood evaluations partly due properties facilitates tractable inference rich transformation spaces including using markov chain monte carlo methods applications include limited monotonic regression generally optimization monotonic functions modeling cumulative distribution functions histograms time warping image warping image registration real time diffeomorphic image editing data augmentation image classifiers gpu based code publicly available â© ieee
10.1111/1475-6773.12786 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033475031&doi=10.1111%2f1475-6773.12786&partnerID=40&md5=4dd2c150f7cd67cf7fc7d18c265e059d 0,objective estimate societal economic health impacts maine school based influenza vaccination siv program h n influenza pandemic data sources primary secondary data covering â€“ â€“ influenza seasons study design estimated weekly monovalent influenza vaccine uptake maine states using difference difference differences analysis assess program impact immunization among six age groups also developed health economic markov microsimulation model conducted monte carlo sensitivity analysis data collection used national survey data estimate impact siv program vaccine coverage used primary data published studies develop microsimulation model principal findings program associated higher immunization among children lower immunization among adults aged â€“ â years older program prevented influenza infections generated â million net economic benefits cost savings lower adult vaccination accounted percent economic gain economic benefits positive percent monte carlo simulations conclusions siv may cost beneficial approach increase immunization pandemics programs designed prevent lower immunization among nontargeted groups â© health research educational trust
10.1287/isre.2017.0724 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038120427&doi=10.1287%2fisre.2017.0724&partnerID=40&md5=436ba988a7a52bd205e4b742f30e684d 1,although keyword auctions often studied context single keyword literature firms generally participate multiple keyword auctions time advertisers purchase variety keywords categorized genericrelevant focal brand competing brand keywords time firms also choose keywords matched search queries exact phrase broad study empirically examines keyword categories match types influence performance advertising campaigns build hierarchical bayesian model address endogeneity problem contained simultaneous equations click rate conversion rate cost per click rank use markov chain monte carlo method identify parameters results suggest important differentiate among various bidding strategies various keyword categories match types also report results related financial performance number sales profit return investment different keywords findings shed light practice sponsored search advertising offering insights manage ad campaigns advertisers bid multiple keywords â© inform
10.1371/journal.pone.0189994 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038838341&doi=10.1371%2fjournal.pone.0189994&partnerID=40&md5=73a4fb1cb05faeb478b7b51e06a98de0 2,malliavin calculus extension classical calculus variations deterministic functions stochastic processes paper aim show practical didactic way calculate malliavin derivative derivative expectation quantity interest model respect underlying stochastic parameters four problems found mechanics non intrusive approach uses malliavin weight sampling mws method conjunction standard monte carlo method models expressed odes pdes discretised using finite difference finite element methods specifically consider stochastic extensions kelvin voigt viscoelastic model discretised finite differences linear elastic bar hyperelastic bar undergoing buckling incompressible navier stokes flow around cylinder discretised finite elements contribution paper extension mws method difficult case non gaussian random variables calculation second order derivatives provide open source code numerical examples paper â© hauseux et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1002/eqe.2922 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021317396&doi=10.1002%2feqe.2922&partnerID=40&md5=5c9a2b393efc0586aa2f7753cb32998f 8,desirable nonlinear dynamic analyses structural fragility assessment performed using unscaled ground motions widespread use simple dynamic analysis procedure known cloud analysis uses unscaled records linear regression impeded alleged inaccuracies paper investigates fragility assessment based cloud analysis adopting performance variable scalar demand capacity ratio equal unity onset limit state shown cloud analysis performed based careful choice records leads reasonable efficient fragility estimates main rules keep mind record selection make sure good portion records leads demand capacity ratio greater unity dispersion records seismic intensity considerable inevitable consequence implementing rules one often needs deal called collapse cases formally consider collapse cases parameter fragility model proposed mixes simple regression logarithmic scale logistic regression joint distribution fragility parameters obtained adopting markov chain monte carlo simulation scheme leading directly fragility confidence intervals resulting fragility curves compare reasonably obtained incremental dynamic analysis multiple stripe analysis variable conditional spectrumâ€“compatible suites records different intensity levels older reinforced concrete frames shear shear flexure flexure dominant behavior copyright â© john wiley sons ltd
10.1016/j.epidem.2017.06.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020911978&doi=10.1016%2fj.epidem.2017.06.002&partnerID=40&md5=aada12a3eeaca4a1f0a6cc9670e65c1c 3,although different structures used modern tuberculosis tb models simulate tb latency remains unclear whether capable reproducing particular activation dynamics empirically observed aimed determine structures replicate dynamics progression accurately reviewed tb modelling articles classified according latency structure employed fitted different models activation dynamics observed infected contacts diagnosed victoria australia amsterdam netherlands obtain parameter estimates six different model structures identified incorporating two latency compartments capable reproducing activation dynamics empirically observed found important differences parameter estimates age also observed marked differences estimates parameter values used many previous models particular two successive latency phases considered first period duration much shorter used previous studies conclusion structures incorporating two latency compartments age stratification employed accurately replicate dynamics tb latency provide catalogue parameter values approach parameter estimation empiric data calibration future tb models â© authors
10.1371/journal.pone.0189234 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039734061&doi=10.1371%2fjournal.pone.0189234&partnerID=40&md5=4110b92f37fe15f24906efd6eeee7bde 2,globalization western honey bee become nearly cosmopolitan species originally restricted old world renowned model biodiversity diverged five evolutionary lineages several geographic â€œsubspecies â€� apis mellifera unicolor indubitably african subspecies endemic madagascar relationship honey bees three archipelagos southwest indian ocean swio hotspot biodiversity misunderstood compared recent mtdna diversity data original characterization nuclear diversity honey bees mascarenes comoros archipelagos using microsatellites also additional mtdna trnaleu cox analysis sampling offers comprehensive dataset swio populations total colonies islands compared samples madagascar africa europe comprehensive mitochondrial screening confirmed honey bees la rã©union mauritius comoros archipelagos mainly african origin colonies coexistence european lineages occurs mascarenes pca bayesian genetic differentiation analysis showed african colonies significantly distinct island diversified among islands archipelagos fst levels progressively decreased significance european african continental populations swio insular continental populations finally among islands archipelago among african populations madagascar shared nuclear background closely related swio island populations except rodrigues mauritius island presented clear cytoplasmic disequilibrium genetic structure characteristic admixed population undergoing hybridization case unicolor ligustica carnica mellifera like individuals finally global genetic clustering analysis helped better depict colonization introduction pattern honey bee populations archipelagos â© techer et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1038/s41598-017-12172-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030322043&doi=10.1038%2fs41598-017-12172-2&partnerID=40&md5=ed4d6c0ad34b1bfeb6986addce458471 2,escherichia coli dna replication yields interlinked chromosomes controlling topological changes associated replication returning newly replicated chromosomes unlinked monomeric state essential cell survival absence topoisomerase topoiv site specific recombination complex xercd dif ftsk remove replication links local reconnection previously showed mathematically unique minimal pathway unlinking replication links reconnection stepwise reducing topological complexity however possibility reconnection preserves increases topological complexity biologically plausible case unlinking pathways probable consider questions analytical numerical study minimal unlinking pathways use markov chain monte carlo algorithm multiple markov chain sampling model local reconnection different substrate topologies knots links distinguish pathways connecting total different topologies conclude minimal pathway unlinking replication links found stringent assumptions probable also present exact results unlinking crossing replication link results point general process topology simplification local reconnection applications going beyond dna â© author
10.1002/2016JE005133 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020619860&doi=10.1002%2f2016JE005133&partnerID=40&md5=21ec32c0a342f4041da9622a4fb1a1ef 13,ascent mount sharp mars science laboratory curiosity rover traversed bagnold dune field model sand modal mineralogy grain size four locations near rover traverse using orbital shortwave infrared single scattering albedo spectra markov chain monte carlo implementation hapke radiative transfer theory fully constrain uncertainties permitted solutions predictions evaluated situ measurements one site curiosity rover show x ray diffraction measured mineralogy basaltic sands within confidence interval model predictions however predictions relatively insensitive grain size nonunique especially modeling composition minerals solid solutions find overall basaltic mineralogy show subtle spatial variations composition around bagnold dunes consistent mafic enrichment sands cumulative aeolian transport distance sorting olivine pyroxene plagioclase grains furthermore large variations fe mg abundances â wt bagnold dunes suggest compositional variability may enhanced local mixing well sorted sand proximal sand sources estimates demonstrate method orbital quantification composition rigorous uncertainty determination provide key constraints interpreting situ measurements compositional variability within martian aeolian sandstones â© authors
10.3892/ol.2017.7158 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032679956&doi=10.3892%2fol.2017.7158&partnerID=40&md5=20375cdd6def8b3e4a130c3ddbd616d7 0,aim present study identify differentially expressed molecular functions demfs breast cancer using gibbs sampling approach molecular functions mfs obtained basis bayesian approach geneset selection package subsequently mfs converted markov chains mcs prior calculating probabilities utilizing mc monte carlo algorithm demfs identified probabilities â‰¥ gene compositions studied finally co expression network constructed via empirical bayes method pathway enrichment analysis genes demfs performed total mfs identified transformed mcs threshold demfs structural molecule activity protein heterodimerization activity obtained demfs comprised genes mapped co expression network genes identified enriched pathways ribosome significant pathway results present study revealed demfs structural molecule activity protein heterodimerization activity may associated pathological molecular mechanisms underlying breast cancer based gibbs sampling â© spandidos publications rights reserved
10.1007/JHEP12(2017)010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037652562&doi=10.1007%2fJHEP12%282017%29010&partnerID=40&md5=fdc8bd3ce03bbde193cadcfd301fa712 2,considered model dark minimal flavour violation dmfv triplet dark matter particles couple right handed type quarks via heavy colour charged scalar mediator studying large spectrum possible constraints assessing entire parameter space using markov chain monte carlo mcmc place strong restrictions allowed parameter space dark matter models type â© author
680.1843092568189 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040354332&partnerID=40&md5=0c2ca75ff9bb34af7e387e821f653411 0,paper aims analyze judicial political attitudes justices turkish constitutional court tcc means item response theory using markov chain monte carlo mcmm algorithms created original database court decisions merit concerning abstract concrete norms reviews dissolution political parties classified categories libertarian statist unclassified votes justices coded one categories result ideal point estimations found neither libertarian statist attitude dominant great majority court justices conclude contrary widely held belief justices tcc adopt strict statist attitude examined period
10.1128/JVI.01372-17 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032823152&doi=10.1128%2fJVI.01372-17&partnerID=40&md5=b2bb5ed8744e4123860bb665678ff670 4,hepatitis c virus hcv transmitted mother child pregnancy childbirth however timing precise biological mechanisms involved process incompletely understood determinants influence transmission particular hcv variants report results longitudinal assessment hcv quasispecies diversity composition cases vertical hcv transmission including women coinfected human immunodeficiency virus type hiv population structure hcv variant spectra based e envelope gene sequences nucleotide positions including hypervariable regions characterized using next generation sequencing median joining network analysis compatible loose transmission bottleneck larger numbers shared hcv variants observed presence maternal coinfection coalescent bayesian markov chain monte carlo simulations revealed median times transmission weeks weeks gestation confidence intervals ranging st trimester considerably earlier previously thought using recombinant autologous hcv pseudoparticles differences uncovered hcv specific antibody responses coinfected mothers mothers infected hcv alone generalized absence neutralization observed finally shifts hcv quasispecies composition seen children around year age compatible disappearance passively transferred maternal immunoglobulins development hcvspecific humoral immunity taken together results provide insights timing dynamics biologic mechanisms involved vertical hcv transmission inform preventative strategies â© american society microbiology
10.4430/bgta0199 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040327267&doi=10.4430%2fbgta0199&partnerID=40&md5=3aabb25f58a31a7d492f1cee55eb838f 4,cast genetic algorithm full waveform inversion ga fwi probabilistic framework multi step procedure allows us estimate posterior probability distribution ppd model space since ga markov chain monte carlo method necessary refine ppd estimated ga ga ppd via resampling model space gibbs sampler gs thus obtaining ga+gs ppds apply procedure two acoustic models inclusion model marmousi model find good agreement derived ppds varying resolution due changes seismic illumination finally randomly extract several models derived ppds start many local full waveform inversions lfwis produce final high resolution models set models used numerically estimate final uncertainty ga+gs+lfwi ppd multimodal wide ppds derived ga optimization become unimodal narrower lfwi well illuminated parts subsurface final ga+gs+lfwi ppds contain true model parameters confirms ability ga optimization finding velocity model suitable input lfwi â© ogs
10.3102/0034654317723009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032927817&doi=10.3102%2f0034654317723009&partnerID=40&md5=e48abe3ba8d3b3e4212965c38b25da0a 1,computer based scaffolding provides temporary support enables students participate become proficient complex skills like problem solving argumentation evaluation meta analyses addressed subject differences cognitive outcomes resulting scaffolding none addressed within subject gains leaves much quantitative scaffolding literature covered existing meta analyses address gap study used bayesian network meta analysis synthesize within subjects preâ€“post differences resulting scaffolding studies generated posterior distribution using markov chain monte carlo samples scaffolding consistently strong effect across student populations stem science technology engineering mathematics disciplines assessment levels strong effect used problem centered instructional models exception inquiry based learning modeling visualization educational levels exception secondary education results also indicate promising areas future scaffolding research including scaffolding among students learning disabilities effect size particularly large á ¡ = â© â© aera
10.1038/s41598-017-09962-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028505039&doi=10.1038%2fs41598-017-09962-z&partnerID=40&md5=e76432f36027f98a5061eb90dc57e562 0,immediate aftermath strong earthquake presence ongoing aftershock sequence scientific advisories terms seismicity forecasts play quite crucial role emergency decision making risk mitigation epidemic type aftershock sequence etas models frequently used forecasting spatio temporal evolution seismicity short term propose robust forecasting seismicity based etas model exploiting link bayesian inference markov chain monte carlo simulation methodology considers uncertainty model parameters conditioned available catalogue events occurred forecasting interval also uncertainty sequence events going happen forecasting interval demonstrate methodology retrospective early forecasting seismicity associated amatrice seismic sequence activities central italy provide robust spatio temporal short term seismicity forecasts various time intervals first days elapsed three main events within sequence predict seismicity within plus minus two standard deviations mean estimate within hours elapsed main event â© author
10.1007/s12561-016-9150-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974823989&doi=10.1007%2fs12561-016-9150-3&partnerID=40&md5=e3a0d137a28626e0a7ef67e8a7cb5479 0,performing studies risks environmental hazards human health requires accurate estimates exposures might experienced populations risk often missing data many epidemiological studies locations times exposure measurements health data match large extent due health exposure data arisen completely different data sources result carefully designed study leading problems â€˜change supportâ€™ â€˜misaligned dataâ€™ cases direct comparison exposure health outcome often possible without underlying model align two spatial temporal domains bayesian approach provides natural framework models however large amounts data arise environmental networks means inference using markov chain monte carlo might computationally feasible setting adapt integrated nested laplace approximation implement spatioâ€“temporal exposure models also propose methods integration large scale exposure models health analyses important model structure allows correct propagation uncertainty predictions exposure model estimates risk associated confidence intervals methods demonstrated using case study levels black smoke uk measured several decades respiratory mortality â© author
10.1111/2041-210X.12826 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026288459&doi=10.1111%2f2041-210X.12826&partnerID=40&md5=cc62c6292ac143888b1796701a8b503d 2,evolutionary integration occurs two phenotypes evolve correlated fashion correlated evolution among traits happen due genetic constraints ontogeny selection important impact trajectory phenotypic evolution phylogenetic trees used study pattern macroevolutionary time scales estimating strength evolutionary covariance among traits time across clades however applications implement models conduct comparative analyses evolutionary integration introduce bayesian markov chain monte carlo approach estimate evolutionary correlation among two traits using evolutionary rate matrix r r covariance matrix represents rates evolution trait structure evolutionary correlation among traits present r package ratematrix resource test hypotheses ofâ evolutionary integration using multivariate data phylogenetic trees ratematrix provides flexible framework allowing number evolutionary rate matrix regimes fitted phylogenetic tree incorporates uncertainty associated parameter estimates ancestral state reconstruction phylogenetic estimation analyses ratematrix package uses novel pruning algorithm significantly improve computational time also provide specific functions facilitate users conduct long mcmc analysis computational resources limited â© authors methods ecology evolution â© british ecological society
10.1007/s40725-017-0069-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043691127&doi=10.1007%2fs40725-017-0069-9&partnerID=40&md5=3cebbf9004a10284630970769090321f 3,purpose review forest models tools analysis prediction productivity services model outputs useful possible errors inputs model structure recognized however errors quantified directly making uncertainty inevitable paper aim clarify terminological confusion around concepts error uncertainty review current methods addressing uncertainty forest modelling recent findings modellers increasingly recognize uncertaintiesâ€”in data model inputs model structureâ€”can represented using probability distributions stimulated use bayesian methods quantifying reducing uncertainty error models forests vegetation achillesâ€™ heel bayesian methods always computational demand solutions found summary conclude future work likely include use bayesian methods use hierarchical modelling replacement model spin bayesian calibration use ensemble modelling bayesian model averaging new ways account model structural error calibration better software bayesian calibration complex models faster markov chain monte carlo algorithms use model emulators novel uncertainty visualization techniques use graphical modelling use risk analysis â© springer international publishing ag
10.1186/s13662-017-1225-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021419419&doi=10.1186%2fs13662-017-1225-z&partnerID=40&md5=d27e3f291e8714756af4ad03d64a427a 1,ebola virus infection severe infectious disease highest case fatality rate become global public health treat makes disease worst specific effective treatment available dynamics much researched understood article new mathematical model incorporating vaccination quarantine study dynamics ebola epidemic developed comprehensively analyzed using fractional derivative sense caputo derivative order î±âˆˆ existence well nonnegativity solution model also verified basic reproduction number calculated besides stability conditions also checked finally simulation done using euler method one top ten influential algorithms known markov chain monte carlo mcmc method different rates vaccination predict effect vaccination infected individual time quarantine discussed results show quarantine vaccination effective ways control ebola epidemic study also seen less possibility individual getting ebola virus second time survived first infection last least real data fitted model showing used predict dynamic ebola epidemic â© author
10.1038/s41598-017-17174-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036594534&doi=10.1038%2fs41598-017-17174-8&partnerID=40&md5=11f6bed699197248115d2ba862a142b2 1,epidemiological parameters livestock diseases often inferred transmission experiments however several limitations inherent design experiments limits precision parameter estimates particular infection times latent periods directly observed infectious periods may also censored present bayesian framework accounting features directly employ markov chain monte carlo techniques provide robust inferences quantify uncertainty estimates describe transmission dynamics using susceptible exposed infectious removed compartmental model gamma distributed transition times fit model published data transmission experiments foot mouth disease virus fmdv african swine fever virus asfv previous analyses data made various assumptions unobserved processes order draw inferences bayesian approach includes unobserved infection times latent periods quantifies along model parameters drawing inferences infection times helps identify infected also provide insights transmission mechanisms furthermore able use models measure difference latent periods inoculated contact challenged animals quantify effect vaccination transmission â© author
10.1111/sjos.12279 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020494587&doi=10.1111%2fsjos.12279&partnerID=40&md5=d1ab75363501b55895bf0062c96addf8 0,estimation time average variance constant tavc asymptotic variance sample mean dependent process fundamental importance various fields statistics frequentists crucial constructing confidence interval mean serving normalizing constant various test statistics forth bayesians widely used evaluating effective sample size conducting convergence diagnosis markov chain monte carlo method paper considering high order corrections asymptotic biases develop new class tavc estimators enjoys optimal l convergence rates different degrees serial dependence stochastic processes high order correction procedure applicable estimation called smoothness parameter essential determining optimal bandwidth comparisons existing tavc estimators comprehensively investigated particular proposed optimal high order corrected estimator best performance terms mean squared error â© board foundation scandinavian journal statistics
10.1371/journal.pone.0189605 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038438515&doi=10.1371%2fjournal.pone.0189605&partnerID=40&md5=e42ef1de5c5575f682c23a834cb1c2f9 1,objective previous â€“ molecular epidemiological study mongolia identified hot spot hiv transmission men sex men msm control infection collaborated ngos promote safer sex hiv testing since mid study carried second molecular epidemiological survey determine status hiv infection mongolia methods study included new cases hiv infection viral rna extracted stocked plasma samples sequenced pol env regions using sanger method near full length sequencing using miseq performed patients suspected infected recombinant hiv phylogenetic analysis performed using neighbor joining method bayesian markov chain monte carlo method results msm main transmission route previous current studies however heterosexual route showed significant increase recent years phylogenetic analysis documented three taxa mongolian b korean b crf b though former two also observed previous study crf b originated singapore malaysia confirmed near full length sequencing although strains mainly detected msm also found increasing numbers heterosexual males females bayesian phylogenetic analysis estimated transmission crf b mongolia around early extended bayesian skyline plot showed rapid increase effective population size mongolian b cluster around crf b cluster around conclusions hiv infection might expand general population mongolia study documented new cluster hiv transmission enhancing understanding epidemiological status hiv mongolia â© jagdagsuren et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.12963/csd.17432 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040349902&doi=10.12963%2fcsd.17432&partnerID=40&md5=3e8d6c0cf4443a1e1f7217be9eed1c92 0,objectives study investigated predictors word reading spelling first grade children dyslexia methods twenty four first graders dyslexia participated study order measure children reading spelling abilities word decoding test word recognition test spelling test conducted early literacy skills including letter knowledge phonological awareness morphological awareness orthographic awareness rapid naming working memory vocabulary measured predictors reading spelling abilities multiple regression markov chain monte carlo mcmc analyses performed explore predictors children word reading spelling abilities results results regression analyses showed children rapid naming score significant predictor decoding skill word recognition letter knowledge significant predictor among early literacy skills letter knowledge also significant predictor spelling ability well letter knowledge found important predictor young dyslexic children reading spelling abilities post hoc analyses performed post hoc analyses revealed letter name knowledge important contributor word recognition skill letter sound knowledge important contributor spelling skill conclusion results study suggest letter knowledge critical element reading spelling development young children dyslexia particular letter names need taught explicitly student experience difficulty reading words letter sounds need taught explicitly students difficulty spelling â© korean academy speech language pathology audiology
10.1016/j.ijpddr.2017.06.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021816687&doi=10.1016%2fj.ijpddr.2017.06.001&partnerID=40&md5=6a98159ae9f4c62217dbe1ef343b783a 11,control human soil transmitted helminths sths relies preventive chemotherapy schoolchildren applying benzimidazoles bz albendazole mebendazole anthelmintic resistance ar common problem nematodes veterinary importance human sths information drug efficacy limited routine monitoring rarely implemented herein efficacy single dose albendazole mg evaluated schools huye district rwanda ascaris predominant sth ascaris eggs detected wet mount microscopy mini flotac method assess cure rate cr faecal egg count reduction fecr blood faecal samples analysed co infections plasmodium sp giardia duodenalis respectively ascaris positive samples collected treatment analysed putatively bz resistance associated î² tubulin gene single nucleotide polymorphisms overall cr mini flotac wet mount microscopy fecr calculated confidence intervals â€“ using sample variance â€“ bootstrapping â€“ applying markov chain monte carlo bayesian approach fecr varied widely individual schools putative bz resistance associated polymorphisms found four ascaris î² tubulin isotype genes examined since fecrs indicate reduced efficacy findings raise suspicion bz resistance absence respective molecular evidence heritable ar local ascaris populations formally proven however since fecrs indicate reduced efficacy bz resistance may suspected alarming calls analyses routine monitoring preventive chemotherapy programs â© authors
10.1214/17-AOAS1077 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042670535&doi=10.1214%2f17-AOAS1077&partnerID=40&md5=ba2b18aa3e01d4d14b3ad0908d5aa724 1,genome wide association studies gwas discovered thousands risk loci heritable disorders far even large meta analyses recovered fraction heritability complex traits recent work utilizing variance components models demonstrated larger fraction heritability complex phenotypes captured additive effects snps evident loci surpassing genome wide significance thresholds typically set bonferroni inspired p â‰¤ ã— âˆ’ procedures control false discovery rate powerful yet still powered detect majority nonnull effects gwas current work proposes novel bayesian semiparametric two group mixture model develops markov chain monte carlo mcmc algorithm covariate modulated local false discovery rate cmfdr probability nonnull depends set covariates via logistic function nonnull distribution approximated linear combination b spline densities weight b spline density depends multinomial function covariates proposed methods motivated work large meta analysis schizophrenia gwas performed psychiatric genetics consortium pgc show new cmfdr model fits pgc schizophrenia gwas test statistics well performing better previously proposed parametric gamma model estimating nonnull density substantially improving power usual fdr using loci declared significant cmfdr â‰¤ perform follow pathway analyses using kyoto encyclopedia genes genomes kegg homo sapiens pathways database demonstrate increased yield cmfdr model results improved ability test pathways associated schizophrenia compared using snps selected according usual fdr â© institute mathematical statistics
10.1007/s10980-017-0575-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030320439&doi=10.1007%2fs10980-017-0575-y&partnerID=40&md5=7657fa7ad9eb34558521c72642feedaf 3,context scientists face several theoretical methodological challenges appropriately describing fundamental wildlife habitat relationships models spatial scales habitat relationships often unknown expected follow multi scale hierarchy typical frequentist information theoretic approaches often suffer collinearity multi scale studies fail converge models complex represent intractable computational burden candidate model sets large objectives objective implement automated bayesian method inference spatial scales habitat variables best predict animal abundance methods introduce bayesian latent indicator scale selection bliss bayesian method select spatial scales predictors using latent scale indicator variables estimated reversible jump markov chain monte carlo sampling bliss suffer collinearity substantially reduces computation time studies present simulation study validate method apply method case study land cover predictors ring necked pheasant phasianus colchicus abundance nebraska usa results method returns accurate descriptions explanatory power multiple spatial scales unbiased precise parameter estimates commonly encountered data limitations including spatial scale autocorrelation effect size sample size bliss outperforms commonly used model selection methods including stepwise aic reduces runtime conclusions given pervasiveness scale dependency ecology implications mismatches scales analyses ecological processes identifying spatial scales species integrating habitat information important step understanding species habitat relationships bliss widely applicable method identifying important spatial scales propagating scale uncertainty testing hypotheses scaling relationships â© springer science+business media b v
10.1111/cob.12213 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049217183&doi=10.1111%2fcob.12213&partnerID=40&md5=5b2418b0cc81e30484e1ec30e3fd96a2 1,addition weight loss randomized controlled trials shown improvement glycaemic control patients taking lorcaserin aim study aim compare adding lorcaserin glucose lowering medications metformin weight glycaemic control systematic review network meta analysis randomized controlled trials conducted included studies published lorcaserin glucose lowering medications type diabetic patients compared placebo different active treatments studies report â‰¥ key outcome change weight hba c hba c hypoglycaemia direct meta analysis performed using dersimonian laird random effects models network meta analysis bayesian markov chain monte carlo random effects models articles screened included lorcaserin reduced weight significantly thiazolidinediones glinides sulphonylureas dipeptidyl peptidase inhibitors may led weight gain significant differences weight change lorcaserin alpha glucoside inhibitors glucagon like peptide agonists sodium glucose cotransporter inhibitors network meta analysis showed lorcaserin non inferior agents hba c reduction achieving hba c risk hypoglycaemia significantly different among studied agents except sulphonylureas associated higher risk hypoglycaemia lorcaserin although additional studies needed analysis suggests population patients body mas index â‰¥ achieve glycaemic control single agent lorcaserin may added alternative add glucose lowering medication â© world obesity federation
10.4067/S0717-65382017000200064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044606475&doi=10.4067%2fS0717-65382017000200064&partnerID=40&md5=c2bf429481e96acc6098f6ede16dc19a 0,phylogenetic study genera south american austral trichopterygini lepidoptera geometridae larentiinae new classification work evaluate taxonomy trichopterygini chile based phylogenetic analysis morphological attributes analysis used tatosoma sauris outgroups two approaches used evaluate phylogenetic relationships parsimony criterion bayesian inference parsimony analysis conducted paup software bayesian analysis markov chain monte carlo using bayesphylogenies software results based phylogenetic hypothesis suggest new taxonomic order trichopterygini andean region southern south america valid genera arrayanaria parra butleriana parra danielaparra kemal kocak fueguina parra hoplosauris butler lagynopteryx berg llampidken parra santos salas pachrophylla blanchard parapachrophylla parra rindgenaria parra tomopteryx philippi triptila warren triptiloides parra santos salas warrenaria parra main changes respect previous taxonomic order genus lagynopteryx berg subordinated trichopterygini toxopaltes warren junior synonym lagynopteryx hoplosauris moesta transferred genus llampidken llampidken valdiviana junior synonym l moesta oparabia arenosa newly combined genus arrayanaria danielaparra viridis junior synonym fragmentata lobophora imbricaria newly combined genus danielaparra triptiloides fasciata junior synonym randallae parapachrophylla michelleae parra n sp described andean region species closely related genus tatosoma new zealand synapomorphies demonstrate swollen metaepimeron hypertrophy second abdominal segment checklist genera species tribe region figures adults genitalia species included â© universidad de concepcion rights reserved
10.1111/2041-210X.12842 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025082396&doi=10.1111%2f2041-210X.12842&partnerID=40&md5=d535f5a9e7e087ae88613972f7326937 2,occupancy models widely used describe distribution rare cryptic speciesâ€”those occur small portion landscape detected reliably single survey however model estimates occupancy ïˆ detection probabilities p often least accurate circumstances available sampling designs occupancy surveys include standard design wherein sites visited k times removal design wherein sites visited k times species interest detected propose new conditional design wherein sites visited one time sites species interest encountered first survey visited additional kâˆ’ times better estimate detection probability used large sample properties maximum likelihood estimators markov chain monte carlo mcmc simulations characterise proposed conditional design compare standard removal designs across wide range true occupancy detection probabilities ïˆ pâ =â increments maximum visits k total sampling effort e number surveys accrued across sites conditional design provided accurate estimates lower standard root mean squared error occupancy standard removal designs calculations simulations species rare ïˆâ â‰¤â well accurate estimates detection probability combinations ïˆ p low occupancy improvements achieved expending greater proportion effort occupied sites improving estimates p thus ïˆ species common ïˆâ â‰¥â removal design generally provided accurate occupancy estimates whereas standard design performed best ïˆ intermediate mcmc simulations p k low recommend conditional design surveys rare species pilot studies multi species surveys include mixtures rare common species hybrid standard conditional design â€“ replicates sites additional replicates sites rare species detected improves occupancy estimates rare species â© authors methods ecology evolution â© british ecological society
10.1007/s10651-017-0387-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032660285&doi=10.1007%2fs10651-017-0387-x&partnerID=40&md5=bc70f5df112376f117a2fafedaaaa3cd 0,propose model consider data dependencies assess spatial temporal variability land use specific floral coverage across landscapes data dependence arising repeated measurements across flowering season taken account using hierarchical archimedean copulas correlation assumed stronger within seasonal periods periods seasonal period bounded probability distribution assigned capture spatial variability floral cover model uses bayesian approach assess land use specific floral covers integrating experts judgments field data model applied assess floral covers four land use types southern sweden seasonal variability captured dividing season two periods according winter oilseed rape flowering floral cover updated using markov chain monte carlo sampling based data landscapes â years repeated measures available two seasonal periods results indicate considering data dependence improved estimation floral cover based data observed season different copula families specifying multivariate probability distributions tested family consistently higher performance four tested land use types uncertainty mode variability floral cover higher data dependence accounted posterior modes floral covers semi natural grassland higher field edges expertâ€™s best guesses higher estimates confirms previous findings expert elicitation processes experts may fail discriminate extreme values bounded range floral cover flower strips estimated smaller higher semi natural grasslands early late season mode floral cover oil seed rape estimated close higher estimates provided expert judgment floral covers different land use classes key parameters quantifying floral resources landscape level whose assessments rely expert judgment field measurements â© author
10.1002/sim.7431 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032985433&doi=10.1002%2fsim.7431&partnerID=40&md5=1d6f65532ec1452440b4d35104008c62 4,synthesize research findings via meta analysis common assume true underlying effect differs across studies total variability consists within study study variances heterogeneity established measures quantify proportion total variation attributed heterogeneity plethora estimation methods available estimating heterogeneity widely used dersimonian laird estimation method challenged knowledge overall performance heterogeneity estimators incomplete identified heterogeneity estimators literature evaluated performance terms mean absolute estimation error coverage probability length confidence interval summary effect via simulation study although previous simulation studies suggested paule mandel estimator compared available estimators dichotomous outcomes estimating heterogeneity markov chain monte carlo good choice informative prior distribution heterogeneity employed eg published cochrane reviews nonparametric bootstrap positive dersimonian laird perform well assessment criteria dichotomous continuous outcomes hartung makambi estimator best choice heterogeneity values close dichotomous outcomes medium heterogeneity values continuous outcomes hence heterogeneity estimators nonparametric bootstrap dersimonian laird positive dersimonian laird perform better suggested paule mandel maximum likelihood provides best performance types outcome absence heterogeneity copyright â© john wiley sons ltd
10.1017/9781316417041 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039944772&doi=10.1017%2f9781316417041&partnerID=40&md5=5a93be232aaddc32d06b772d4a0fa113 10,past several decades computational approaches studying strongly interacting systems become increasingly varied sophisticated book provides comprehensive introduction state art quantum monte carlo techniques relevant applications correlated systems providing clear overview variational wave functions featuring detailed presentation stochastic samplings including markov chains langevin dynamics developed discussion monte carlo methods variational technique described foundations detailed description algorithms topics discussed include optimisation techniques real time dynamics projection methods including green function reptation auxiliary field monte carlo basic definitions advanced algorithms efficient codes book concludes recent developments continuum space quantum monte carlo approaches correlated systems provides extensive reference students researchers working condensed matter theory interested advanced numerical methods electronic simulation â© federico becca sandro sorella rights reserved
10.1088/1361-6579/aa93a1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039065832&doi=10.1088%2f1361-6579%2faa93a1&partnerID=40&md5=f0b6cf699d30cacc6510b6e04d867b6e 2,objective instantaneous phase ip instantaneous frequency electroencephalogram eeg considered notable complements eeg spectrum calculation parameters commonly includes narrow band filtering followed calculation signal analytical form calculation ip highly susceptible filter parameters background noise level especially low analytical signal amplitudes objective study propose robust statistical framework eeg ip estimation analysis approach herein monte carlo estimation scheme proposed robust estimation eeg ip proposed eeg phase related inference reported average confidence intervals obtained repeating ip estimation infinitesimal variations selected expert algorithmic parameters filter bandwidth center frequency background noise level second part paper stochastic model consisting superposition narrow band foreground background eeg used derive analytically probability density functions instantaneous envelope ie ip eeg signals justify proposed monte carlo scheme main results instantaneous analytical envelope eeg empirically used previous studies shown fundamental impact accuracy eeg phase contents rigorously shown ip estimation quality highly depends ie phase frequency interpretations low ie statistically unreliable require hypothesis test significance impact proposed method previous studies including time domain phase synchrony phase resetting phase locking value phase amplitude coupling studied examples findings research set forth new standards eeg phase frequency estimation analysis techniques â© institute physics engineering medicine
10.1080/03610918.2016.1255972 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019122982&doi=10.1080%2f03610918.2016.1255972&partnerID=40&md5=cabc8e6dbc8047e5747368f1d2d083b6 0,article perform bayesian estimation stochastic volatility models heavy tail distributions using metropolis adjusted langevin mala riemman manifold langevin mmala methods provide analytical expressions application methods assess performance methodologies simulated data illustrate use two financial time series datasets â© taylor francis group llc
10.1016/j.ecolmodel.2017.09.008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029694021&doi=10.1016%2fj.ecolmodel.2017.09.008&partnerID=40&md5=e060e81a99a91d90dc33d0ad104c790c 2,forests important component global carbon c cycle capture retain large amounts c annually depending stand characteristics climate disturbance regimes climate disturbance regimes shifting important able accurately represent corresponding changes forest c dynamics well calibrated models carbon budget model canadian forest sector cbm cfs widely used model simulating c dynamics managed forests stand regional national levels use bayesian markov chain monte carlo mcmc technique calibrate parameters cbm cfs assimilating c stocks six deadwood soil pools estimated data collected plots within canadian national forest inventory calibration led improvement simulation c stocks small fine woody debris reducing rmse followed snag stems rmse reduced coarse woody debris calibrated parameters resulted increased rates c cycling fine coarse woody debris soil organic layer distinct c dynamics hardwood softwood dominated stands increased temperature sensitivity c contained mineral soil parameter calibration considerably improved simulation small fine woody debris snags stem pools model representation branch snag coarse woody debris soil organic layer mineral soil pools substantially improved lack substantial improvements calibrated model performance indicated need including additional processes c dynamics simulation change modelling paradigm illustrate potential need include lignin effect deadwood decay suggest exploration effects tree species soil types mosses performance cbm cfs â©
10.3390/su9112138 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035012219&doi=10.3390%2fsu9112138&partnerID=40&md5=7d7da81b33e94c3a0780933d36b2bb88 10,paper experiments artificial neural networks model bayesian approach small real estate sample output distribution calculated operating numerical integration weights space markov chain hybrid monte carlo method mchmcm real estate sample mchmcm compared neural networks model nns traditional multiple regression analysis mra penalized spline semiparametric method pssm four methods developed testing forecasting capacity reliability mchmcm real estate field markov chain hybrid monte carlo method proved best model absolute average percentage error â© authors
10.1109/ASE.2017.8115657 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041448047&doi=10.1109%2fASE.2017.8115657&partnerID=40&md5=ffce6f560dcb5a7beb8f15424c192bb7 0,online offline commerce customer services may need composed online offline services composition challenging requires effective selection appropriate services turn support optimal combination online offline services paper address challenge proposing approach service composition combines offline route planning social collaboration optimize service selection frame general service composition problems using timed automata propose optimization procedure incorporates markov chain monte carlo mcmc algorithm stochastically select concrete composite service model checking approach searching optimal collaboration plan lowest cost given certain time constraint procedure evaluated using simulation rich scenario effectiveness scalability â© ieee
10.1109/PIERS-FALL.2017.8293580 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045335827&doi=10.1109%2fPIERS-FALL.2017.8293580&partnerID=40&md5=fd8a5b9099f0ebc945c6da399c9e077a 0,soil moisture remote sensing products ground verification soil moisture situ sampling heterogeneous consistent remote sensing pixel scale important extensive sampling soil moisture surface heterogeneous effective upscaling multi point situ soil moisture remote sensing pixel scale however difficult collect extensively soil moisture signal complicated dynamically changing considering sparsity soil moisture effects observation noise paper models linear programming problem soil moisture remote sensing pixel situ sampling data using hierarchical non parametric bayesian linear regression model assume specific distribution regression parameters learned adaptively nonparametric bayesian method addition implement dirichlet process exploit spatial similarity situ sampling data soil moisture thus improve spatial upscaling accuracy due dirichlet process without explicit mathematical expression model posteriori probability distribution hard deal end gibbs sampling scheme based mcmc markov chain monte carlo adopted infer optimal regression weighting coefficient spatial scale soil moisture situ sampling effectively upscaled experimental results show spatial upscaling method nonparametric bayesian linear regression closer observed remote sensing pixel scale better state art bayesian method kriging method â© electromagnetics academy rights reserved
10.3847/1538-4357/aa9658 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038024641&doi=10.3847%2f1538-4357%2faa9658&partnerID=40&md5=d38d131a0353a7eec12c54b178c4dee0 0,erratum provide corrected sets r difference ratio values associated uncertainties overestimated original paper noted roxburgh due missing trimming post processing markov chain monte carlo mcmc chains values typical reduction ratio uncertainties performing trimming factor see figure parameters optimized peak bagging instance individual mode frequencies unaffected trimming performed original work lund et al also provide updated values î” î½ values l = modes note values presented presented original work obtained single peakbagging procedure see lund et al details yet verified independent analyses using input power spectra examples updated tables original paper given tables v note tables individual mode parameters table added completeness parameters tables unchanged compared original paper addition corrected values mentioned provide covariance matrices mode frequencies frequency difference ratios r second differences î” î½ legacy sample lund et al published original work values provided erratum available online version paper figure presented table presented â© american astronomical society rights reserved
10.3847/2041-8213/aa9704 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035344907&doi=10.3847%2f2041-8213%2faa9704&partnerID=40&md5=e3fef48fd891c1962d72536962fb352b 2,hezaveh et al showed deep learning used model parameter estimation trained convolutional neural networks determine parameters strong gravitational lensing systems demonstrate method obtaining uncertainties parameters review framework variational inference obtain approximate posteriors bayesian neural networks apply network trained estimate parameters singular isothermal ellipsoid plus external shear total flux magnification show method capture uncertainties due different levels noise input data well training architecture related errors made network evaluate accuracy resulting uncertainties calculate coverage probabilities marginalized distributions lensing parameter tuning single variational parameter dropout rate obtain coverage probabilities approximately equal confidence levels calculated resulting accurate precise uncertainty estimates results suggest application approximate bayesian neural networks astrophysical modeling problems fast alternative monte carlo markov chains allowing orders magnitude improvement speed â© american astronomical society rights reserved
10.1088/1742-6596/921/1/012017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036463889&doi=10.1088%2f1742-6596%2f921%2f1%2f012017&partnerID=40&md5=696e503ffc08c546d94025f2284ae3b2 0,canonical technique monte carlo simulations statistical physics importance sampling via suitably constructed markov chain approaches quite successful particularly well suited parallelization chain dynamics sequential replicated chains used increase statistics relaxes equilibrium intrinsic time constant reduced parallel work population annealing sequential monte carlo method simulates ensemble system replica cooling protocol population element makes naturally well suited massively parallel simulations bias systematically reduced increasing population size present implementation population annealing graphics processing units discuss behavior different systems undergoing continuous first order phase transitions â© published licence iop publishing ltd
10.1080/02664763.2016.1266309 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006109972&doi=10.1080%2f02664763.2016.1266309&partnerID=40&md5=a085f4d63af4217328b803098d5f82be 1,typical joint modeling longitudinal measurements time event data assumes two models share common set random effects normal distribution assumption sometimes underlying population sample extracted heterogeneous population detecting homogeneous subsamples important scientific question paper finite mixture normal distributions shared random effects proposed considering heterogeneity population detecting whether unobserved heterogeneity exits use simple graphical exploratory diagnostic tool proposed verbeke molenberghs assess whether traditional normality assumption random effects mixed model adequate joint modeling setting case evidence normality homogeneity finite mixture normals used shared random effects distribution bayesian mcmc procedure developed parameter estimation inference methodology illustrated using simulation studies also proposed approach used analyzing real hiv data set using heterogeneous joint model data set individuals classified two groups group high risk group moderate risk â© informa uk limited trading taylor francis group
10.1080/02664763.2016.1259401 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997050393&doi=10.1080%2f02664763.2016.1259401&partnerID=40&md5=24f4178595b62f4a99c7bc2e258f56f1 0,foxhound training enclosures facilities wild trapped foxes placed large fenced areas dog training purposes although purpose facilities train dogs without harming foxes dog related mortality reported issue enclosures using data fox enclosure virginia investigate factors influence fox survival dog training facilities propose set policies improve fox survival particular bayesian hierarchical model formulated compute fox survival probabilities based fox time enclosure number dogs allowed enclosure one time calculations complicated missing information number dogs enclosure many days study elicit expert knowledge prior number dogs account uncertainty missing data reversible jump markov chain monte carlo used model selection presence missing covariates use model examine possible changes foxhound training enclosure policy effect changes may fox survival â© informa uk limited trading taylor francis group
10.1080/03610926.2016.1260740 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026898790&doi=10.1080%2f03610926.2016.1260740&partnerID=40&md5=7825a86afd15d8818cdddf89d93ddb27 1,frailty models used survival analysis account unobserved heterogeneity individual risks disease death analyze bivariate data related survival times e g matched pairs experiments twin family data shared frailty models suggested models based assumption frailty acts multiplicatively hazard rate article assume frailty acts additively hazard rate introduce shared inverse gaussian frailty models three different baseline distributions namely generalized log logistic generalized weibull exponential power distribution introduce bayesian estimation procedure using markov chain monte carlo technique estimate parameters involved models apply models real life bivariate survival dataset mcgilchrist aisbett related kidney infection data better model suggested data â© taylor francis group llc
10.1142/S1793524518500018 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034599362&doi=10.1142%2fS1793524518500018&partnerID=40&md5=f2060c03db060ab89de643dea55b4a84 0,paper formulate analyze mathematical model investigate transmission dynamics tomato bacterial wilt disease tbwd mukono district uganda derive basic reproduction number formula presented prove existence disease free equilibrium point globally stable formula presented endemic equilibrium exists formula presented model parameters estimated using markov chain monte carlo mcmc methods robustness tested model parameters observed identifiable numerical simulations show soil solarization sensitization farmers help eliminate disease uganda modified tomato bacterial wilt model control terms formulated â© world scientific publishing company
10.1109/UPEC.2016.8114092 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047745614&doi=10.1109%2fUPEC.2016.8114092&partnerID=40&md5=a8c4220f44392f66c5c5b0dba8032a94 2,present energy distribution companies seek improve service implement alternatives determine capability distribution system devices allow cover electric demand paper proposes stochastic analysis manage demand response energy depending voltage curve profiles established historical measurements proposal based stochastic prediction energetic demand using monte carlo algorithms markov chains mcmc analysis voltage profile deterministic variable analysis associated prediction maximum power required satisfy peak demand period distribution systems predominance residential load also seeking planning networks increase efficiency quality reliability power supply peak hours order reduce contingencies operation distribution networks periods peak demand especially systems residential load predominant taking considerable growth due insertion electric cookers â© ieee
10.1016/j.icarus.2017.06.028 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027223055&doi=10.1016%2fj.icarus.2017.06.028&partnerID=40&md5=bf128af2693513d623ebf565b654a8bc 0,estimates asteroid masses based gravitational perturbations orbits objects mars spacecraft asteroids satellites case asteroid asteroid perturbations leads inverse problem least dimensions aim derive mass perturbing asteroid six orbital elements perturbing asteroid test asteroid based astrometric observations developed implemented three different mass estimation algorithms utilizing asteroid asteroid perturbations rough â€˜marchingâ€™ approximation asteroidsâ€™ orbital elements fitted thereby reducing problem one dimensional estimation mass implementation nelderâ€“mead simplex method significantly markov chain monte carlo mcmc approach describe algorithms particular focus mcmc algorithm present example results using synthetic real data results agree published mass estimates suggest published uncertainties may misleading consequence using linearized mass estimation methods finally discuss remaining challenges algorithms well future plans â© elsevier inc
10.1016/j.jcp.2017.08.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027524963&doi=10.1016%2fj.jcp.2017.08.005&partnerID=40&md5=c93325b8a674fda0b6f1abe9a6a7c019 2,paper concerned characterization propagation errors associated data limitations polynomial chaos based stochastic methods uncertainty quantification issue arise uncertainty quantification limited amount data available available information suffice accurately determine probability distributions must assigned uncertain variables bayesian method assigning probability distributions becomes attractive allows stochastic model account explicitly insufficiency available information previous work applications bayesian method already implemented using metropolisâ€“hastings gibbs markov chain monte carlo mcmc methods paper present alternative implementation uses alternative mcmc method built around itã´ stochastic differential equation sde ergodic bayesian posterior draw together mathematics literature number formal properties itã´ sde lend support use implementation bayesian method describe discretization including choice free parameters using implicit euler method demonstrate proposed methodology problem uncertainty quantification complex nonlinear engineering application relevant metal forming â© elsevier inc
10.1109/ISWCS.2017.8108153 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041440460&doi=10.1109%2fISWCS.2017.8108153&partnerID=40&md5=25092513cf851174667ace03503a2ff7 0,g communication bring surge traffic cellular network traffic cellular network strong variability time also strong spatio temporal correlation brings large difficulty predict order make reasonable use communication network resources important describe predict spatio temporal information traffic cellular network paper propose traffic prediction algorithm based bayesian spatio temporal model predict spatial distribution traffic cellular network different moments via realistic traffic data base stations bss firstly select gaussian predictive process gpp basic model bayesian spatio temporal model set proper prior distribution parameters secondly train basic model gibbs sampling realistic traffic data obtain posterior distribution parameters predict spatio temporal information traffic cellular network markov chain monte carlo mcmc computational techniques finally make theoretical analysis prediction accuracy prediction results index agreement ia prediction results three different areas reach indicate good prediction performance traffic prediction algorithm used predict spatio temporal information traffic cellular network different areas â© ieee
10.5194/amt-10-4341-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034060852&doi=10.5194%2famt-10-4341-2017&partnerID=40&md5=18b21bb9b5426891dd432319853fdb32 1,optical particle counters opcs common tools situ measurement aerosol particle number size distributions actual quantity measured opcs intensity light scattered individual particles necessary translate distribution detected scattering signals desired information e distribution particle sizes crucial part challenge modeling opc response calibration instrument words establishing relation instrument specific particle scattering cross section measured signal amplitude date existing methods lack comprehensive parametrization opc response particularly regarding instrument induced broadening signal amplitude distributions deficiency lead significant size distribution biases introduce advanced opc response model including simple parametrization broadening effect self consistent way evaluate calibration measurements using markov chain monte carlo mcmc method outline consistently derive particle number size distributions realistic uncertainty estimates within new framework based measurements particle standards two opcs grimm model skyopc dmt passive cavity aerosol spectrometer probe pcasp demonstrate residuals measured modeled response substantially reduced using new approach instead existing methods importantly investigated set measurements new approach yields results conform true size distributions within range model uncertainty presented innovations help improving accuracy opc derived size distributions assessment precision â© author
10.1109/NAPS.2017.8107304 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040580101&doi=10.1109%2fNAPS.2017.8107304&partnerID=40&md5=c4c9ff41a1fd98d045a106179a14d16f 0,following piece work dedicated solving unit commitment optimal scheduling problem high levels wind power penetration presence pumped hydro storage facility task divided two parts baseline scheduling b reserve scheduling baseline scheduling meets day ahead forecast load wind energy reserve scheduling meets variation load wind energy baseline schedule markov chain transition matrix used quantify upward downward reserves paper reveals results considering different aspects fuel cost reliability emissions reservoir volume objective function also monte carlo analysis results performed understand probabilistic nature problem using frequency distribution load wind data different cases analyzed conclude probabilistic fuzzy schedule answers question status also imply time windows maintenance scheduling turn activities â© ieee
10.16285/j.rsm.2017.11.035 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039073948&doi=10.16285%2fj.rsm.2017.11.035&partnerID=40&md5=caaf53aa5ba5368a8f1290c46ac4f353 1,geotechnical engineering reliability analysis design difficult accurately select random field parameters correlation function accurately describe spatial variability soil parameters based bayesian theory paper presents method quantify spatial variability effective internal friction angle sand proper correlation function using prior knowledge cone penetration test cpt data used determine random field parameters correlation function effective internal friction angle sand method method takes reasonable account uncertainty empirical regression equation effective internal friction angle cone resistance markov chain monte carlo simulation mcmcs method applied paper generate random samples following posterior distribution mcmcs samples used calculate posterior distribution gaussian copula based method plausibility candidate correlation function obtained probable correlation function selected finally proposed approaches illustrated validated using real life cpt data obtained nges texas university shown proposed approaches correctly reasonably determine random field parameters correlation function sand effective friction angle using indirect cpt data possible accurately describe spatial variability sand effective friction angle correlation function effective friction angle sand site nges texas university second order markov correlation function â© science press right reserved
10.1002/sim.7407 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030318228&doi=10.1002%2fsim.7407&partnerID=40&md5=8d26af6bc78c8ecda72115f390a41125 0,growth models used describing dynamics body weight height generally consider trait independently proposed modeling height weight trajectories jointly nonlinear heteroscedastic mixed model based jenss bayley growth function correlated individual random effects using bayesian inference techniques simulations showed model provides good estimates growth parameters illustrated used assess associations maternal smoking pregnancy early life factor potentially involved prenatal programming obesity children growth birth â years age used real data eden study large french mother child cohort study high number height weight measurements total approximately â measurements traits across children results supported existence relationship maternal smoking pregnancy growth birth â years age children mothers smoked throughout pregnancy shown display higher body mass index first months life onwards compared children nonsmokers â years age mean body mass index â kg higher unexposed children mainly explained fact children tended smaller birth rapidly exceeded weight children nonsmokers postnatally copyright â© john wiley sons ltd
10.1002/nme.5530 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017395475&doi=10.1002%2fnme.5530&partnerID=40&md5=ae731d7bd8a1e2a404f9b5a036ea6e78 0,advances nondestructive material characterization providing wealth information exploited gain insight general aspects material performance particular discover relationships microstructure thermo mechanical properties polycrystalline complex composite materials order facilitate integration measurements existing models well inform new physics based predictions developed c++ mpi computational framework sensitivity analysis parameter estimation framework utilizes micro mechanical modeling based fast fourier transforms direct adjoint formulations markov chain monte carlo sampling techniques illustrate characteristics framework demonstrate utility computing residual stresses arising thermal expansion elastic composite using data simulated experiments show availability nondestructive measurements crucial reduce uncertainty predictions emphasizing importance integrated experimental modeling data analysis approach improved material characterization design copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1088/1361-6420/aa9417 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038362414&doi=10.1088%2f1361-6420%2faa9417&partnerID=40&md5=59d4b053a222c652109298b7c7b659d1 0,major challenges bayesian inverse problems arise need repeated evaluations forward model required markov chain monte carlo mcmc methods posterior sampling many attempts accelerating bayesian inference relied surrogates forward model typically constructed repeated forward simulations performed offline phase although approaches quite effective reducing computation cost little analysis approximation posterior inference work prove error bounds kullback leibler kl distance true posterior distribution approximation based surrogate models rigorous error analysis show forward model approximation converges certain rate prior weighted l norm posterior distribution generated approximation converges true posterior least two times faster kl sense error bound hellinger distance also provided provide concrete examples focusing use surrogate model based methods present efficient technique constructing stochastic surrogate models accelerate bayesian inference approach christoffel least squares algorithms based generalized polynomial chaos used construct polynomial approximation forward solution support prior distribution numerical strategy predicted convergence rates demonstrated nonlinear inverse problems involving inference parameters appearing partial differential equations â© iop publishing ltd
10.1016/j.tcs.2016.11.017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015672779&doi=10.1016%2fj.tcs.2016.11.017&partnerID=40&md5=94d21d6f713e09d0fa2a1c28a5345f97 1,motivated derandomization markov chain monte carlo mcmc paper investigates deterministic random walk deterministic process analogous random walk recent progress analysis vertex wise discrepancy e lâˆž discrepancy little known total variation discrepancy e l discrepancy plays important role analysis fpras based mcmc paper investigates l discrepancy expected number tokens markov chain number tokens corresponding deterministic random walk first give simple nontrivial upper bound mtâ�ž l discrepancy ergodic markov chains number edges transition diagram tâ�ž mixing time markov chain give better upper bound mtâ�ž non oblivious deterministic random walks corresponding markov chain ergodic lazy also present lower bounds â© elsevier b v
10.1016/j.tcs.2017.02.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014102905&doi=10.1016%2fj.tcs.2017.02.006&partnerID=40&md5=3422d0e056a4d7d82a8632133312755b 0,statistical phylogenetic inference methods use tree rearrangement operations subtreeâ€“pruneâ€“regraft spr perform markov chain monte carlo mcmc across tree topologies structure graph induced tree rearrangement operations important determinant mixing properties mcmc motivating study underlying spr graph greater detail paper investigate spr graph rooted trees rspr graph new way calculating ricciâ€“ollivier curvature respect uniform metropolisâ€“hastings random walks value quantifies degree pair random walkers specified points move towards negative curvature means move away one another average positive curvature means move towards order calculate curvature develop fast new algorithms rspr graph computation develop formulas characterizing number rspr neighbors tree changes rspr operation applied tree give bounds curvature well flatness limit theorem indicating paths small topology changes easy traverse however find large topology changes e moving large subtree give pairs trees negative curvature show using simulation mean access time distributions depend distance degree curvature demonstrating relevance results stochastic tree search â© authors
10.1145/3132847.3132928 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037327776&doi=10.1145%2f3132847.3132928&partnerID=40&md5=5edc79f7b5e9f22b12166e2f321b6e82 0,survival analysis regression models used understand effects explanatory variables e g age sex weight etc survival probability however sensitive survival data medical data serious concerns privacy individuals data set medical data used fit regression models closest work addressing privacy concerns work cox regression linearly projects original data lower dimensional space however weakness approach formal privacy guarantee projection work aim propose solutions regression problem survival analysis protection differential privacy golden standard privacy protection data privacy research end extend output perturbation objective perturbation approaches originally proposed protect differential privacy empirical risk minimization erm problems addition also propose novel sampling approach based markov chain monte carlo mcmc method practically guarantee differential privacy better accuracy show proposed approaches achieve good accuracy compared non private results guaranteeing differential privacy individuals private data set â© association computing machinery
10.23919/EPE17ECCEEurope.2017.8099246 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042014959&doi=10.23919%2fEPE17ECCEEurope.2017.8099246&partnerID=40&md5=84def790616cb87eeeb8146555cb3b9f 0,constant random wear failures sub modules sm within modular multi level converter mmc examined constant random failures calculated using binomial distribution formula using constant failure rate wear failures calculated using discrete markov chain modelling monte carlo estimation failure rate sm increasing time results compared various maintenance intervals different levels availability show trends characteristics shown large gains availability relatively small increases number redundant sms required additionally number redundant sms required support longer maintenance intervals increase less linear rate making increasing maintenance intervals applications offshore converter stations attractive â© assigned jointly european power electronics drives association institute electrical electronics engineers ieee
10.1109/ICDSP.2017.8096043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040317812&doi=10.1109%2fICDSP.2017.8096043&partnerID=40&md5=5ff1748ab96ef1ce75c3e8f389d7d764 0,monte carlo mc methods widely used bayesian inference signal processing machine learning statistics work introduce adaptive importance sampler mixes together benefits importance sampling markov chain monte carlo mcmc approaches different parallel mcmc chains provide location parameters proposal probability density functions pdfs used method mcmc algorithms consider tempered version posterior distribution invariant density also provide exhaustive theoretical support explaining presented technique even anti tempering strategy reducing scaling posterior beneficial numerical results confirm advantages proposed scheme â© ieee
10.1109/ICDSP.2017.8096055 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040315383&doi=10.1109%2fICDSP.2017.8096055&partnerID=40&md5=bfb4b7bd76ce92a74f0967ef8bd0444b 2,present probabilistic framework determining initial settings kernel adaptive filters kafs ii constructing fully adaptive kafs whereby addition weights dictionaries kernel parameters learnt sequentially achieved formulating estimator probabilistic model defining dedicated prior distributions kernel parameters weights dictionary enforcing desired properties sparsity model trained using subset data initialise standard kafs updated sequentially time new observation becomes available due nonlinear non gaussian properties model learning inference achieved using gradient based maximum aposteriori optimisation markov chain monte carlo methods confidently used compute predictions proposed framework validated nonlinear time series synthetic real world nature outperformed standard kafs terms mean square error sparsity learnt dictionaries â© ieee
10.1080/10543406.2017.1293081 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015699143&doi=10.1080%2f10543406.2017.1293081&partnerID=40&md5=305a03bdd5e163af9b8a3227d94f8adb 1,literature unified approaches test proof concept estimate target dose including multiple comparison procedure using modeling approach permutation approach proposed klingenberg discuss compare operating characteristics unified approaches develop alternative approach bayesian framework based posterior distribution penalized log likelihood ratio test statistic bayesian approach much flexible handle linear nonlinear doseâ€“response relationships efficient permutation approach operating characteristics bayesian approach comparable sometimes better approaches wide range doseâ€“response relationships yields credible intervals well predictive distribution response rate specific dose level target dose estimation bayesian approach easily extended continuous categorical time event responses illustrate performance proposed method extensive simulations phase ii clinical trial data examples â© taylor francis group llc
10.3847/1538-3881/aa8d6f https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034439575&doi=10.3847%2f1538-3881%2faa8d6f&partnerID=40&md5=3bdc5d7d8ee2fee6bdab1a2554415fe5 1,present orbital elements mass sums visual binary stars spectral types b k five arenew orbits periods ranging yr two double line spectroscopic binaries noprevious orbits individual component masses using combined astrometric radial velocity data aformal uncertainty âˆ¼ mo adopting published photometry trigonometric parallaxes plus ownmeasurements place objects h r diagram discuss evolutionary status objects arepart survey characterize binary population stars southern hemisphere using soar mtelescope+hrcam ctio orbital elements computed using newly developed markov chain monte carlo mcmc algorithm delivers maximum likelihood estimates parameters well posterior probabilitydensity functions allow us evaluate uncertainty derived parameters robust way forspectroscopic binaries using approach possible derive self consistent parallax system thecombined astrometric radial velocity data orbital parallax compares well trigonometricparallaxes also present mathematical formalism allows dimensionality reduction feature spacefrom seven three search parameters seven dimensions including parallax case ofspectroscopic binaries astrometric data makes possible explore smaller number parameters ineach case improving computational efficiency mcmc code â© american astronomical society rights reserved
10.1002/qre.2113 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028643001&doi=10.1002%2fqre.2113&partnerID=40&md5=4d2ee96952f6fc22dfd26c55ed817d1e 2,paper cox proportional hazard model error effect applied study accelerated life test investigated statistical inference bayesian methods using markov chain monte carlo techniques performed order estimate parameters involved model predict reliability accelerated life testing proposed model applied analysis knock sensor failure time data observations data censored failure times constant stress level assumed weibull distribution analysis failure time data accelerated life test used posterior estimation parameters prediction reliability function well comparisons classical results maximum likelihood estimation copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1016/j.autcon.2017.07.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028540345&doi=10.1016%2fj.autcon.2017.07.003&partnerID=40&md5=e43130c94d17f90ead9a77f8d159caa5 4,paper proposes bayesian statistics based analytical solution markov chain monte carlo mcmc method based numerical solution estimate credible interval fraction nonconforming solutions provide accurate reliable interpretable estimation sampling uncertainty used improve functionality automated nonconforming quality management systems reveal inherent mathematical mechanism functions analytical solution step step proof calculation example provided numerical solution specialized metropolis hastings algorithm illustrative simulation example provided elaborate stochastic processes method industrial case study pipe fabrication company alberta canada presented demonstrate feasibility applicability proposed credible interval estimation methods results case study indicate solutions accurately reliably serve nonconforming quality inference purpose research implemented decision making tool credible interval estimation provide valuable support understanding improving quality performance automated nonconforming quality control processes â© elsevier b v
10.1002/esp.4189 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032702419&doi=10.1002%2fesp.4189&partnerID=40&md5=94d16ac2c54bd82ad183cfea6d6468ab 1,identifying sand provenance depositional aeolian environments e g dunefields elucidate sediment pathways fluxes inform potential land management strategies windblown sand dust hazard health infrastructure however complexity pathways typically makes challenging proposition uncertainties composition mixed source sediments often reported study demonstrates quantitative fingerprinting method within bayesian markov chain monte carlo mcmc framework offers great potential exploring provenance uncertainties associated aeolian sands eight samples taken dunes small km ashkzar erg central iran three distinct potential sediment sources surrounding area analyzed tracers including geochemical elements trace major rare earth elements ree eight ree ratios kruskalâ€“wallis h tests stepwise discriminant function analysis dfa allowed identification optimum composite fingerprint based six tracers rb sr sr la yb n ga î´ce bayesian mixing model applied derive source apportionment estimates within uncertainty framework substantial variation uncertainties fingerprinting results samples yielding clear discrimination components less clear fingerprints quaternary terraces fans contribute largest component dunes also extensive surrounding unit clay flats marls however contribute proportion small outcrop extent successful application methods aeolian sediment deposits demonstrates potential providing quantitative estimates aeolian sediment provenances mixed source arid settings may prove especially beneficial sediment derived multiple sources methods provenance e g detrital zircon uâ€“pb dating possible due mineralogical constraints copyright â© john wiley amp sons ltd copyright â© john wiley sons ltd
10.1007/s00477-016-1344-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994297177&doi=10.1007%2fs00477-016-1344-1&partnerID=40&md5=214ee140397f72c993afe8cc72f486a6 2,focus bayesian estimation strongly heterogeneous transmissivity fields conditional data sampled set locations aquifer log transmissivity modeled stochastic gaussian process parameterized truncated karhunenâ€“loã¨ve kl expansion consider fields characterized short correlation scale compared size observed domain systems associated kl decomposition still requires high number parameters thus hampering efficiency bayesian estimation underlying stochastic field distinctive aim work present efficient approach stochastic inverse modeling fully saturated groundwater flow types strongly heterogeneous domains methodology grounded construction optimal sparse kl decomposition achieved retaining limited set modes expansion mode selection driven model selection criteria conditional available data hydraulic heads optionally bayesian inversion optimal sparse kle inferred using markov chain monte carlo mcmc samplers test bed illustrate approach way suite computational examples noisy head values sampled given randomly generated system findings suggest proposed methodology yields globally satisfactory inversion stochastic head fields comparison reference values corresponding mcmc predictive distributions suggests observed values well reproduced probabilistic sense cases reference values unsampled locations typically far measurements captured posterior probability distributions cases quality estimation improved e g increasing number measurements threshold selection kl modes â© springer verlag berlin heidelberg
10.1287/mnsc.2016.2529 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032570233&doi=10.1287%2fmnsc.2016.2529&partnerID=40&md5=054ee39fea96ccae8290e09d165d28ef 2,paper develops estimates structural model two sided markets durable platform intermediaries affiliated products models buyers purchase decisions platforms affiliated products sellers decisions price setting entry accounting dynamic interaction two distinct groups platform participants estimate proposed model paper develops bayesian markov chain monte carlo estimation approach incorporates nonparametric approximation interpolation methods proposed model estimation method applied bit generation u video game industry results counterfactual experiments show dynamic behavior platform participants significant impacts platformadoption affiliated product market failed platform survived priced two sides properly dynamic two sided market environment â© informs
10.1016/j.csda.2017.05.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020300016&doi=10.1016%2fj.csda.2017.05.005&partnerID=40&md5=bfae58cf2d7c9e9c11adb7b316c878f3 1,although markov chain monte carlo mcmc popular parameter inference alleviation burden calculation crucial due limit processors memory disk bottleneck especially true terms handling big data recent years researchers developed parallel mcmc algorithm full data partitioned subdatasets samples drawn subdatasets independently different machines without communication extant literature machines deemed identical however due heterogeneity data put different machines random nature mcmc assumption â€œidentical machinesâ€� questionable propose powered embarrassing parallel mcmc pepmcmc algorithm full data posterior density product sub posterior densities posterior densities different subdatasets raised constraint powers proven equivalent weighted averaging procedure work powers determined based maximum likelihood criterion leads finding maximum likelihood point within convex hull estimates different machines prove asymptotic exactness apply several cases verify strength comparison unparallel unpowered parallel algorithms furthermore connection normal kernel density parametric density estimations certain conditions investigated â© elsevier b v
10.3150/16-BEJ810 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019100236&doi=10.3150%2f16-BEJ810&partnerID=40&md5=5c983d401727dc860a7d782993af8b53 2,although hamiltonian monte carlo proven empirical success lack rigorous theoretical understanding algorithm many ways impeded principled developments method use algorithm practice paper develop formal foundations algorithm construction measures smooth manifolds demonstrate theory naturally identifies efficient implementations motivates promising generalizations â© isi bs
10.1007/s11222-016-9699-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987660795&doi=10.1007%2fs11222-016-9699-1&partnerID=40&md5=1449cd79c574d7ff978357d7ea4a321b 0,big data analysis high computational cost bayesian methods often limits applications practice recent years many attempts improve computational efficiency bayesian inference propose efficient scalable computational technique state art markov chain monte carlo methods namely hamiltonian monte carlo key idea explore exploit structure regularity parameter space underlying probabilistic model construct effective approximation geometric properties end build surrogate function approximate target distribution using properly chosen random bases efficient optimization process resulting method provides flexible scalable efficient sampling algorithm converges correct target distribution show choosing basis functions optimization process differently method related approaches construction surrogate functions generalized additive models gaussian process models experiments based simulated real data show approach leads substantially efficient sampling algorithms compared existing state art methods â© springer science+business media new york
10.1016/j.ejor.2017.04.019 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018970493&doi=10.1016%2fj.ejor.2017.04.019&partnerID=40&md5=3e6697884dbed0f187284ea7c162492a 3,new results derived optimal preventive maintenance schedule single item finite horizon based bayesian models failure rate function two types failure rate functionsâ€”increasing bathtub shapesâ€”are considered cases optimality conditions efficient algorithms find optimal maintenance schedule given bayesian parametric model bathtub shaped failure rate functions used class increasing failure rate functions tackled extended gamma process illustrate approaches using real failure time data south texas project nuclear operating company bay city texas â© elsevier b v
10.1016/j.enbuild.2017.08.069 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028925119&doi=10.1016%2fj.enbuild.2017.08.069&partnerID=40&md5=366bd453c54e919c881c5e7e8f6ed535 9,bayesian calibration proposed kennedy hagan increasingly applied building energy models due ability account discrepancy observed values model predictions however application limited calibration using monthly aggregated data computationally inefficient dataset large study focuses improvements current implementation bayesian calibration building energy simulation achieved using information theory select representative subset entire dataset calibration using effective markov chain monte carlo mcmc algorithm u turn sampler nuts extension hamiltonian monte carlo hmc explore posterior distribution calibrated model assessed evaluating accuracy convergence application proposed method demonstrated using two cases studies trnsys model water cooled chiller mixed use building singapore energyplus model cooling system office building pennsylvania u case studies convergence achieved parameters posterior distribution gelmanâ€“rubin statistics rë† within â± coefficient variation root mean squared error cvrmse normalized mean biased error nmbe also within thresholds set ashrae guideline â© elsevier b v
10.1002/qre.2114 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008498483&doi=10.1002%2fqre.2114&partnerID=40&md5=e36cea72f7f3236a26356d67b7d5ce67 2,degradation modeling might alternative conventional life test reliability assessment high quality products paper develops bayesian approach step stress accelerated degradation test reliability inference population made based posterior distribution underlying parameters aid markov chain monte carlo method sequential reliability inference individual product normal condition also proposed simulation study illustrative example presented show appropriateness proposed method copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1016/j.automatica.2017.07.053 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027880897&doi=10.1016%2fj.automatica.2017.07.053&partnerID=40&md5=524aa1f0eee3cb5af9e5885da11384ea 4,paper introduce novel method linear system identification quantized output data model impulse response zero mean gaussian process whose covariance kernel given recently proposed stable spline kernel encodes information regularity exponential stability serves starting point cast system identification problem bayesian framework employ markov chain monte carlo methods provide estimate system particular design two methods based called gibbs sampler allow also estimate kernel hyperparameters marginal likelihood maximization via expectationâ€“maximization method numerical simulations show effectiveness proposed scheme compared state art kernel based methods employed system identification quantized data â© elsevier ltd
10.1016/j.dss.2017.08.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029561760&doi=10.1016%2fj.dss.2017.08.005&partnerID=40&md5=e5443bc316f142f66331af2dd22dfa88 0,dealing mailing decisions direct marketing company focus assessing three alternative approaches model unobserved heterogeneity based finite mixtures continuous mixtures mixture dirichlet processes mdp respectively models estimated markov chain monte carlo mcmc simulation based pseudo bayes factors psbf find finite mixture model turns superior models based either mdp continuous mixture whereas mdp finds similar estimates compared finite mixture approach estimates continuous mixture differ variables according finite mixture type mailing effect purchase behavior addition customers show supersaturation effects mailings due different coefficient estimates managerial implications differ depending model relate particular continuous mixture model recommend mailings finite mixture approach â© elsevier b v
10.1016/j.jhydrol.2017.09.035 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029937114&doi=10.1016%2fj.jhydrol.2017.09.035&partnerID=40&md5=a4a29b80714f68c32e1f2fd313833ac9 0,hydrologic frequency analysis commonly used engineers hydrologists provide basic information planning design management hydraulic water resources systems assumption stationarity however increasing evidence climate change possible assumption stationarity prerequisite traditional frequency analysis hence results conventional analysis become questionable study consider framework frequency analysis extremes based b spline quantile regression allows model data presence non stationarity dependence covariates linear non linear dependence markov chain monte carlo mcmc algorithm used estimate quantiles posterior distributions coefficient determination bayesian information criterion bic quantile regression used order select best model e quantile choose degree number knots adequate b spline quantile regression model method applied annual maximum minimum streamflow records ontario canada climate indices considered describe non stationarity variable interest estimate quantiles case results show large differences non stationary quantiles stationary equivalents annual maximum minimum discharge high annual non exceedance probabilities â© elsevier b v
10.1007/s10518-017-0169-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020747816&doi=10.1007%2fs10518-017-0169-8&partnerID=40&md5=7578f062e10a172d6fb7757912326fae 4,viscous dampers dissipation devices widely employed seismic structural control date performance systems equipped viscous dampers extensively analysed employing deterministic approaches however approaches neglect response dispersion due uncertainties input well variability system properties recent works highlighted important role seismic input uncertainties seismic performance linear nonlinear viscous dampers study analyses effect variability damper properties probabilistic system response risk particular paper aims evaluating impact tolerance allowed devicesâ€™ quality control production tests terms variation exceedance probabilities engineering demand parameters edps relevant seismic performance preliminary study carried relate variability constitutive damper characteristics tolerance limit allowed tests evaluate consequences deviceâ€™s dissipation properties subsequent part study sensitivity dynamic response analysed harmonic analysis finally seismic response sensitivity studied evaluating influence allowed variability constitutive damper characteristics response hazard curves providing exceedance probability per year edps set linear elastic systems different dynamic properties equipped linear nonlinear dampers considered analyses subset simulation employed together markov chain monte carlo method achieve confident estimate small exceedance probabilities â© springer science+business media b v
10.3390/s17112491 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032725427&doi=10.3390%2fs17112491&partnerID=40&md5=a95fe590309b70cb048759328edad14e 1,line scanning cameras capture single line pixels increasingly used ground based mobile robotic platforms applications advantageous directly georeference camera data world coordinates accurate estimate cameraâ€™s pose required paper focuses common case mobile platform equipped rigidly mounted line scanning camera whose pose unknown navigation system providing vehicle body pose estimates propose novel method estimates cameraâ€™s pose relative navigation system approach involves imaging manually labelling calibration pattern distinctly identifiable points triangulating points camera navigation system data reprojecting order compute likelihood maximised estimate camera pose additionally markov chain monte carlo mcmc algorithm used estimate uncertainty offset tested two different platforms method able estimate pose within â° â° also propose several approaches displaying interpreting results human readable way â© authors licensee mdpi basel switzerland
10.1080/03772063.2017.1379889 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041345421&doi=10.1080%2f03772063.2017.1379889&partnerID=40&md5=d9602808fa52847096cf9a56d689de9e 0,order analyze non stationary signals like electroencephalogram eeg sometimes easier segment signals pseudo stationary segments paper cascade linear predictive coding lpc non linear volterra filter employed modeling noise eeg signal methodology applied procedure change point detection estimating number change points exact location powerful way detect change points precisely possible earlier results completed constructing algorithms use cascade lpc non linear volterra filter modeling relation noisy signal noise practical situations bayesian configuration posterior distribution change point sequence constructed markov chain monte carlo procedure used sampling posterior distribution simulation results segmentation synthetic real eeg data show applying newly proposed methodology specificity sensitivity segmentation highly improved case synthetic data change points estimated completely precise correct times estimated least accuracy times â© iete
10.1007/s11222-016-9703-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988345859&doi=10.1007%2fs11222-016-9703-9&partnerID=40&md5=39958acabad14ae00525a570dd248a46 0,regression modelling beyond mean response found lot attention last years expectile regression special computationally convenient case type models expectiles offer quantile like characterisation complete distribution include mean special case frequentist framework expectile regression combined covariate effects quite different forms particular nonlinear spatial effects propose bayesian expectile regression based asymmetric normal distribution auxiliary likelihood allow additional inclusion bayesian regularisation priors covariates linear effects proposal densities based iteratively weighted least squares updates resulting markov chain monte carlo simulation algorithm developed evaluated simulations application special focus simulations lies evaluation coverage properties bayesian credible bands quantification detrimental effect arising misspecification auxiliary likelihood â© springer science+business media new york
10.1177/1094342016649420 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035017087&doi=10.1177%2f1094342016649420&partnerID=40&md5=827d696d6bea02bb15d0435907e84ada 2,novel perturbative monte carlo mixed quantum mechanics qm molecular mechanics mm approach recently developed simulate molecular systems complex environments however required accuracy efficiently simulate complex molecular systems usually granted cost long executing times alleviate problem new parallelization strategy multi level monte carlo molecular simulations herein proposed heterogeneous systems simultaneously exploits fine grained data level coarse grained markov chain level task grained pure qm pure mm qm mm procedures parallelism ensure efficient execution heterogeneous systems composed central processing units multiple possibly different graphical processing units achieved making use opencl library together appropriate dynamic load balancing schemes conducted evaluation real benchmarking data speed x computational bottleneck part observed results global speed x whole simulation reducing time typical simulation hours hours â© â© author
10.1007/s11222-016-9702-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990913361&doi=10.1007%2fs11222-016-9702-x&partnerID=40&md5=35a085ee560d90d6a6229be671c1c971 1,stationary time series models built parametric distributions general limited scope due assumptions imposed residual distribution autoregression relationship present modeling approach univariate time series data makes assumptions stationarity accommodate complex dynamics capture non standard distributions model transition density arises conditional distribution implied bayesian nonparametric mixture bivariate normals results flexible autoregressive form conditional transition density defining time homogeneous non stationary markovian model real valued data indexed discrete time obtain computationally tractable algorithm posterior inference utilize square root free cholesky decomposition mixture kernel covariance matrix results simulated data suggest model able recover challenging transition densities non linear dynamic relationships also illustrate model time intervals eruptions old faithful geyser extensions accommodate higher order structure develop state space model also discussed â© springer science+business media new york
10.13196/j.cims.2017.11.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040539794&doi=10.13196%2fj.cims.2017.11.001&partnerID=40&md5=f502fe4c32239fc5027566b9b73afc90 0,choose multiple dynamic quality control charts sensitive control performance performance analysis model multiple dynamic control charts established corresponding selection strategy proposed matlab environment markov chain method monte carlo simulation method used solve model computational efficiency precision two methods compared analyzed process control control solve problem many conversions optimal selection strategy variable sampling inlerval vsi variable sampling size interval vssi multiple quality control charts given priority practical selection size target small vsi multi variate cumulative sum control chart mcusum control chart optimal practice lt î´ lt vssi hotelling control chart selected î´ gt kind multivariate adaptive control chart suitable â© editorial department cims right reserved
10.1016/j.cpc.2017.06.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028032759&doi=10.1016%2fj.cpc.2017.06.020&partnerID=40&md5=8e4cf9b4fb25a56ec68d8333fd813f44 3,population annealing promising recent approach monte carlo simulations statistical physics particular simulation systems complex free energy landscapes hybrid method combining importance sampling markov chains elements sequential monte carlo form population control appears provide algorithmic capabilities simulation systems roughly comparable established approaches parallel tempering intrinsically much suitable massively parallel computing tap structural advantage present highly optimized implementation population annealing algorithm gpus promises speed ups several orders magnitude compared serial implementation cpus sample code simulations ferromagnetic ising model easily adapted simulations spin models including disordered systems code includes implementations advanced algorithmic features recently suggested namely automatic adaptation temperature steps multi histogram analysis data different temperatures program summary program title paising program files doi http dx doi org sgzt b b licensing provisions creative commons attribution license cc programming language c cuda external routines libraries nvidia cuda toolkit newer nature problem program calculates internal energy specific heat several magnetization moments entropy free energy ising model square lattices edge length l periodic boundary conditions function inverse temperature î² solution method code uses population annealing hybrid method combining markov chain updates population control code implemented nvidia gpus using cuda language employs advanced techniques multi spin coding adaptive temperature steps multi histogram reweighting additional comments code repository https github com levbarash paising system size size population replicas limited depending memory gpu device used default parameter values used sample programs l= î = î² = î²f= î”î²= r= typical run time nvidia tesla k gpu seconds single spin coded ssc seconds multi spin coded msc program see section description parameters â© elsevier b v
10.1002/stc.2004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013298141&doi=10.1002%2fstc.2004&partnerID=40&md5=524ed1878a416bd33e522815e18b9675 4,model updating based vibration response measurements technique reducing inherent modeling errors finite element fe models arise simplifications idealized connections uncertainties regard material properties updated fe models relatively fewer discrepancies real structural counterparts provide depth predictions dynamic behaviors structures future analysis study develop full scale fe model major long span bridge update model improve agreement identified modal properties real measured data fe model using bayesian model updating scheme sensitivity based cluster analysis performed determine robust efficient updating parameters include physical parameters similar effects targeted natural frequencies hybrid monte carlo method one markov chain monte carlo sampling methods used obtain posterior probability distributions updating parameters finally uncertainties updated parameters variability fe model modal properties evaluated copyright â© john wiley sons ltd
10.5144/0256-4947.2017.433 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042180444&doi=10.5144%2f0256-4947.2017.433&partnerID=40&md5=c57ea2b667018be34d5ffb0724fa9b6e 2,background promising clinical humanistic outcomes associated use new oral agents treatment relapsing remitting multiple sclerosis rrms first cost effectiveness study comparing medications saudi arabia objectives aimed compare cost effectiveness fingolimod teriflunomide dimethyl fumarate interferon ifn b products avonex rebif first line therapies treatment patients rrms saudi payer perspective design cohort simulation model markov model setting tertiary care hospital methods hypothetical cohort rrms saudi patients assumed enter markov model model time horizon years annual cycle length model developed based expanded disability status scale edss evaluate cost effectiveness five disease modifying drugs dmds healthcare system perspective data edss progression relapse rates obtained literature cost data obtained king faisal specialist hospital research centre riyadh saudi arabia results expressed incremental cost effectiveness ratios icers net monetary benefits nmb saudi riyals converted equivalent us base case willingness pay wtp threshold assumed sar one way sensitivity analysis probabilistic sensitivity analysis conducted test robustness model main outcome measures icers nmb results base case analysis results showed rebif optimal therapy wtp threshold avonex lowest icer value qaly compared rebif one way sensitivity analysis demonstrated results sensitive utility weights health state three four cost rebif conclusion none dmds found cost effective treatment rrms wtp threshold analysis dmds cost effective wtp limitations current analysis reflect saudi population preference valuation health states consider societal perspective terms cost
10.1097/MD.0000000000008632 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037690111&doi=10.1097%2fMD.0000000000008632&partnerID=40&md5=e5c293d9ea67a183cc6a668dae704af4 6,background bariatric surgery proved effective strategy treating obesity however randomized controlled trials rcts common bariatric surgery procedures roux en gastric bypass rygb sleeve gastrectomy sg laparoscopic adjustable gastric band lagb reported inconsistent results performed systematic review network meta analysis synthesize evidence effectiveness common bariatric procedures relevant rcts methods present study systematic review network meta analysis rcts rcts must meet following criteria included analysis patients body mass index bmi â‰¥ kg reported least outcome interest compared least bariatric procedures follow ups least year primary outcome weight loss expressed differences mean bmi reduction percentage excess weight loss ewl following year surgery network meta analysis based bayesian framework markov chain monte carlo simulation approach results eleven rcts met criteria included review trials n = differences mean bmi reduction ci rygb versus sg ci rygb versus lagb ci sg versus lagb eight rcts n = reported percentage excess weight loss ewl mean differences rygb sg rygb lagb sg lagb ci ci ci respectively meta analysis indicated low heterogeneity studies node splitting analysis showed studies consistent direct indirect comparisons p gt conclusion rygb sg yielded similar weight loss effect superior lagb factors complications patient preference considered surgical consultations copyright â© author
10.1371/journal.pone.0188660 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035755085&doi=10.1371%2fjournal.pone.0188660&partnerID=40&md5=482d3cce198e7a777983e9f90cdac9bd 0,horizontal behavior highly migratory marine species difficult decipher animals wide ranging spend minimal time ocean surface utilize remote habitats satellite telemetry enables researchers track individual movements population level inferences rare due data limitations result difficulty capture sporadic tag reporting introduce bayesian modeling framework address population level questions satellite telemetry data data sparse also outline approach identifying informative variables use within model tested modeling approach using large telemetry dataset shortfin makos isurus oxyrinchus allowed us assess effects various degrees data paucity first permuted random forest analysis implemented determine variables informative next generalized additive mixed model used help define relationship remaining variable response variable using jags rjags analysis bayesian hierarchical models using markov chain monte carlo simulation developed movement model generate parameter estimates variables interest randomly reducing tagging dataset percent recalculating parameter estimates demonstrate proposed bayesian approach applied data limited situations also demonstrate two commonly used linear mixed models maximum likelihood estimation mle similarly applied additionally simulate data known parameter values test modelâ€™s ability recapture values despite performing similarly advocate using bayesian mle approach due ability later studies easily utilize results past study inform working models ability use prior knowledge via informed priors systems information available â© public library science rights reserved open access article free copyright may freelyreproduced distributed transmitted modified built upon otherwise used anyone lawful purpose work made available creative commons cc public domain dedication
10.1287/moor.2016.0834 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032943613&doi=10.1287%2fmoor.2016.0834&partnerID=40&md5=cb9482abb0bd3e839854e107ee32afbe 0,often applications rare events estimation optimal control required one calculates principal eigen function eigenvalue nonnegative integral kernel except finite dimensional case usually neither principal eigenfunction eigenvalue computed exactly paper develop numerical approximations quantities show generic interacting particle algorithm used deliver numerical approximations eigenquantities associated called twisted markov kernel well approximations relevant aforementioned applications addition study collection random integral operators underlying algorithm address mean pathwise properties obtain error estimates finally numerical examples provided context importance sampling computing tail probabilities markov chains computing value functions class stochastic optimal control problems copyright â© informs
10.1016/j.cageo.2017.04.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017370156&doi=10.1016%2fj.cageo.2017.04.001&partnerID=40&md5=153833798a36de04fbf404af8905c5ca 3,bayesian inverse modeling techniques computationally expensive many forward simulations needed sampling posterior distribution parameters paper combine implicit sampling method generalized polynomial chaos expansion gpce significantly reduce computational cost performing bayesian inverse modeling three steps approach find maximizer likelihood function using deterministic approaches construct gpce based surrogate model using results limited number forward simulations efficiently sample posterior distribution parameters using implicit sampling method cost constructing gpce based surrogate model decreased using sparse bayesian learning reduce number gpce coefficients determined demonstrate approach synthetic ponded infiltration experiment simulated tough surrogate model highly accurate mean relative error predicting saturation predicting likelihood function posterior distribution parameters obtained using proposed technique nearly indistinguishable results obtained either implicit sampling method markov chain monte carlo method utilizing full model â© elsevier ltd
10.1016/j.ress.2017.07.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026443552&doi=10.1016%2fj.ress.2017.07.007&partnerID=40&md5=92f80727c3d759342c43e85766247195 2,paper presents efficient method reliability based design optimization rbdo robust complex systems involving computationally expensive numerical models large number random variables novel method belongs type decoupling approaches failure probability function fpf approximated partitioned design space setting augmented reliability formulation specific design configuration failure probability system proportional probability density value design variables conditioned failure event thus transforming fpf approximation problem density estimation paper partition design space several subspaces estimate density failure samples subspace binning constructing regression functions sufficient failure samples efficiently generated subspace using markov chain monte carlo method guarantees accuracy fpf approximation ultimately entire design space three illustrative examples involving structural systems subjected static dynamic loadings discussed demonstrate efficiency accuracy proposed method â© elsevier ltd
10.1177/1060028017722007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405541&doi=10.1177%2f1060028017722007&partnerID=40&md5=735cd4fe2ab6c4c463862ccefd85a5ac 0,background numerous economic models published evaluating treatment chronic hepatitis c virus hcv infection none provide comprehensive comparison among new antiviral agents objective evaluate cost effectiveness recommended therapies treatment genotypes chronic hcv methods using data clinical trials observational analyses drug pricing databases markov decision models developed hcv genotypes compare recommended drugs perspective third party payer year time horizon probabilistic sensitivity analysis psa conducted assigning distributions clinical cure age entering model costs health state quality adjusted life years qalys health state monte carlo simulation repetitions model results lifetime model genotype effects ranged qalys total costs ranged lifetime model genotype treatments range effects qalys total costs ranging grazoprevir elbasvir optimal strategy followed velpatasvir sofosbuvir second best strategy simulations genotypes drug costs efficacy grazoprevir elbasvir primary model drivers conclusions grazoprevir elbasvir cost effective compared strategies genotypes effects strategies similar cost drug initial year driving results â© â© author
10.1016/j.mri.2017.06.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021101214&doi=10.1016%2fj.mri.2017.06.011&partnerID=40&md5=33d1f6192a7e57492c84803183b1c01d 2,purpose applied recently introduced bayesian analytic method achieve clinically feasible vivo mapping proteoglycan water fraction pgwf human knee cartilage improved spatial resolution stability compared existing methods materials methods multicomponent driven equilibrium single pulse observation mcdespot datasets acquired knees two healthy young subjects one older subject previous knee injury dataset processed using bayesian monte carlo bmc analysis incorporating two component tissue model assessed performance reproducibility bmc conventional analysis stochastic region contraction src estimation pgwf stability bmc analysis pgwf tested comparing independent high resolution hr datasets two young subjects results unlike src bmc derived maps two hr datasets essentially identical furthermore src maps showed substantial random variation estimated pgwf mean values differed obtained using bmc addition pgwf maps derived conventional low resolution lr datasets exhibited partial volume magnetic susceptibility effects artifacts absent hr pgwf images finally analysis showed regional variation pgwf estimates substantially higher values younger subjects compared older subject conclusions bmc mcdespot permits hr vivo mapping pgwf human knee cartilage clinically feasible acquisition time hr mapping reduces impact partial volume magnetic susceptibility artifacts compared lr mapping finally bmc mcdespot demonstrated excellent reproducibility determination pgwf â©
10.1002/pst.1822 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028305033&doi=10.1002%2fpst.1822&partnerID=40&md5=00ed1a48f3049c432be81da83c3fe196 0,many new anticancer agents combined existing drugs combining number drugs may expected better therapeutic effect monotherapy owing synergistic effects furthermore drive drug development reduce associated cost growing tendency combine phase ii trials respect phase ii oncology trials assessment dose combinations existing methodologies efficacy based tumor response safety based toxicity modeled binary outcomes possible enroll treat next cohort patients unless best overall response determined current cohort thus trial duration might potentially extended unacceptable degree study proposed method randomizes next cohort patients phase ii part dose combination based estimated response rate using available observed data upon determination overall response current cohort compared proposed method existing method using simulation studies demonstrated percentage optimal dose combinations selected proposed method less existing method trial duration proposed method shortened compared existing method proposed method meets ethical financial requirements believe potential contribute expedite drug development copyright â© john wiley sons ltd
10.1002/pst.1818 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022347587&doi=10.1002%2fpst.1818&partnerID=40&md5=d3dff189b27b61e23998ef0425c110ca 0,main purpose dose escalation trials identify dose safe efficacious investigations later studies paper introduce dose escalation designs incorporate dose limiting events dose limiting toxicities dlts indicative responses efficacy procedure flexible nonparametric model used modelling continuous efficacy responses logistic model used binary dlts escalation decisions based combination probabilities dlts expected efficacy gain function basis setup introduce types bayesian adaptive dose escalation strategies first type procedures called â€œsingle objective â€� aims identify recommend single dose either maximum tolerated dose highest dose considered safe optimal dose safe dose gives optimum benefit risk second type called â€œdual objective â€� aims jointly estimate maximum tolerated dose optimal dose accurately recommended doses obtained dose escalation procedures provide information safety efficacy profile novel drug facilitate later studies evaluate different strategies via simulations based example constructed real trial patients type diabetes use stopping rules assessed find nonparametric model estimates efficacy responses well different underlying true shapes dual objective designs give better results terms identifying real target doses compared single objective designs copyright â© john wiley sons ltd
10.1016/j.neuroimage.2017.08.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027868620&doi=10.1016%2fj.neuroimage.2017.08.009&partnerID=40&md5=34c94764051098231caabedc67c626c8 1,dominant approach neuroimaging data analysis employs voxel unit computation convenient voxels lack biological meaning size arbitrarily determined resolution image propose multivariate spatial model neuroimaging data characterised linearly weighted combination multiscale basis functions map onto underlying brain nuclei networks nuclei model elementary building blocks derived reflect functional anatomy brain resting state model estimated using bayesian framework accurately quantifies uncertainty automatically finds accurate parsimonious combination basis functions describing data demonstrate utility framework predicting quantitative spect images striatal dopamine function compare variety basis sets including generic isotropic functions anatomical representations striatum derived structural mri two different soft functional parcellations striatum derived resting state fmri rfmri found combination âˆ¼ multiscale functional basis functions accurately represented striatal dopamine activity functional basis functions derived advanced parcellation technique known instantaneous connectivity parcellation icp provided parsimonious models dopamine function importantly functional basis functions derived resting fmri accurate structural generic basis sets representing dopamine function striatum fixed model order demonstrate translational validity framework constructing classification models discriminating parkinsonian disorders subtypes show icp approach basis set performs well across comparisons performs better overall classical voxel based approach spatial model constitutes elegant alternative voxel based approaches neuroimaging studies atoms biologically informed also adaptive high resolutions represent high dimensions efficiently capture long range spatial dependencies important challenging objectives neuroimaging data â© authors
10.1016/j.ijnonlinmec.2017.08.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028728449&doi=10.1016%2fj.ijnonlinmec.2017.08.003&partnerID=40&md5=9e2521cd86e4fa95c00110dc4340b616 2,smooth discontinuous oscillator fractional derivative damping combined harmonic random excitations investigated paper short memory principle introduced evolution process oscillator fractional derivative damping described markov chain stochastic generalized cell mapping method used obtain steady state probability density functions response stochastic response bifurcation oscillator fractional derivative damping discussed detail found smoothness parameter noise intensity amplitude frequency harmonic force induce occurrence stochastic p bifurcation system monte carlo simulation verifies effectiveness method adopt paper â© elsevier ltd
10.1093/bioinformatics/btx407 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050446142&doi=10.1093%2fbioinformatics%2fbtx407&partnerID=40&md5=36f330bc4119e3a3cf91cd4b0f0a9fdf 0,results propose novel method inferring transcriptional regulation using simple yet biologically interpretable model find logic set candidate genes associated transcription factors tfs regulate transcriptional process gene interest dynamic model links mrna transcription rate target gene activation states tfs assuming interactions consistent across multiple experiments time trans dimensional markov chain monte carlo mcmc algorithm used efficiently sample regulatory logic different combinations parents rank estimated models posterior probabilities demonstrate compare methodology methods using simulation examples apply study transcriptional regulation selected target genes arabidopsis thaliana microarray time series data obtained multiple biotic stresses show method able detect complex regulatory interactions consistent multiple experimental conditions availability implementation programs written matlab statistics toolbox release b mathworks inc natick massachusetts united states available github https github com giorgosminas trs http www warwick ac uk fac sci systemsbiology research software contact giorgos minas warwick ac uk b f finkenstadt warwick ac uk supplementary information supplementary data available bioinformatics online motivation availability data dynamic gene expression multiple experimental conditions provides new information makes key goal identifying transcriptional regulators gene also underlying logical structure attainable â© author published oxford university press
10.1016/j.jclinepi.2017.07.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029498552&doi=10.1016%2fj.jclinepi.2017.07.006&partnerID=40&md5=83720b358066bcf95d4fe5ef2c1f7753 3,objectives aim study identify validity effect estimates serious rare adverse events clinical study reports antidepressants trials across different meta analysis methods study design setting four serious rare adverse events cause mortality suicidality aggressive behavior akathisia meta analyzed using different methods yusuf peto odds ratio ignores studies events compared alternative approaches generalized linear mixed models glmms conditional logistic regression bayesian approach using markov chain monte carlo mcmc beta binomial regression model results estimates four outcomes change substantially across different methods yusuf peto method underestimated treatment harm overestimated precision especially estimated odds ratio deviated greatly example odds ratio suicidality children adolescents confidence interval = â€“ using yusuf peto method increased â€“ using conditional logistic regression â€“ using beta binomial â€“ using glmm finally â€“ using mcmc approach conclusion method used meta analysis rare events data influences estimates obtained exclusion double zero event studies give misleading results ensure reduction bias erroneous inferences sensitivity analyses performed using different methods instead yusuf peto approach particular beta binomial method shown superior simulation study â© elsevier inc
10.1002/bit.26379 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028574980&doi=10.1002%2fbit.26379&partnerID=40&md5=6eb446f643a417a3e53275c9d7702774 2,c metabolic fluxes analysis c mfa remains powerful approach determine intracellular metabolic reaction rates decisions strain engineering experimentation heavily rely upon certainty fluxes estimated uncertainty quantification vast majority c mfa studies relies confidence intervals paradigm frequentist statistics however well known confidence intervals given experimental outcome uniquely defined result confidence intervals produced different methods different nevertheless equally valid high relevance c mfa since practitioners regularly use three different approximate approaches calculating confidence intervals means computational study realistic model central carbon metabolism e coli provide strong evidence confidence intervals used field depend strongly technique calculated thus use leads misinterpretation flux uncertainty order provide better alternative confidence intervals c mfa demonstrate credible intervals paradigm bayesian statistics give reliable flux uncertainty quantifications readily computed high accuracy using markov chain monte carlo addition widely applied chi square test means testing whether model reproduces data examined closer â© wiley periodicals inc
10.3150/16-BEJ814 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019069896&doi=10.3150%2f16-BEJ814&partnerID=40&md5=63a998dbecc45ff312987e5ca4001321 1,paper proposes new exact simulation method simulates realisation proposal density uses exact simulation langevin diffusion check whether proposal accepted rejected comparing existing coupling past method new method require constructing fast coalescence markov chains comparing existing rejection sampling method new method require proposal density function bound target density function new method much efficient existing methods certain problems application exact simulation posterior finite mixture models presented â© isi bs
10.3150/16-BEJ827 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019141501&doi=10.3150%2f16-BEJ827&partnerID=40&md5=b94bdd6009123a1182cfcfc4b7686a85 0,strassen classical martingale coupling theorem states two random vectors ordered convex resp increasing convex stochastic order admit martingale resp submartingale coupling analysing topological properties spaces probability measures equipped wasserstein metric applying measurable selection theorem prove conditional version result random vectors conditioned random element taking values general measurable space provide analogue conditional martingale coupling theorem language probability kernels discuss applied analysis pseudo marginal markov chain monte carlo algorithms also illustrate results imply existence measurable minimiser context martingale optimal transport â© isi bs
10.1140/epjc/s10052-017-5274-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034632989&doi=10.1140%2fepjc%2fs10052-017-5274-y&partnerID=40&md5=943ddd5f29e59f1ec33f63097f029393 3,introduce scannerbit statistics sampling module public open source global fitting framework gambit scannerbit provides standardised interface different sampling algorithms enabling use comparison multiple computational methods inferring profile likelihoods bayesian posteriors statistical quantities current version offers random grid raster nested sampling differential evolution markov chain monte carlo mcmc ensemble monte carlo samplers also announce release new standalone differential evolution sampler diver describe design usage interface scannerbit subject diver three samplers nested sampler multinest mcmc great native scannerbit implementation ensemble monte carlo algorithm walk battery statistical tests use realistic physical likelihood function based scalar singlet model dark matter examine performance sampler function adjustable settings dimensionality sampling problem evaluate performance four metrics optimality best fit found completeness exploring best fit region number likelihood evaluations total runtime bayesian posterior estimation high resolution walk provides accurate timely mapping full parameter space profile likelihood analysis less ten dimensions find diver multinest score similarly terms best fit speed outperforming great walk ten dimensions diver substantially outperforms three samplers metrics â© author
10.1007/s11222-016-9700-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987625575&doi=10.1007%2fs11222-016-9700-z&partnerID=40&md5=bb970f328a46a0a5501cb4123a51e882 1,markov chain monte carlo mcmc algorithms bayesian computation gaussian process based models default parameterisations slow converge due presence spatial induced dependence structures main focus paper study effect assumed spatial correlation structure convergence properties gibbs sampler default non centred parameterisation rival centred parameterisation cp mean structure general multi process gaussian spatial model investigation finds answers many pertinent yet unanswered questions choice two assuming covariance parameters known compare exact rates convergence two varying strength spatial correlation level covariance tapering scale spatially varying covariates number data points number structure block updating spatial effects amount smoothness assumed matã©rn covariance function also study effects introducing differing levels geometric anisotropy spatial model case unknown variance parameters investigated using well known mcmc convergence diagnostics simulation study real data example modelling air pollution levels london used illustrations generic pattern emerges cp preferable presence spatial correlation information obtained example additional data points increased covariate variability â© author
10.29220/CSAM.2017.24.6.605 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044087590&doi=10.29220%2fCSAM.2017.24.6.605&partnerID=40&md5=8f625e6d35ea5b5f2d5b5ad9e5b1fcc7 0,paper presents proportional odds cure models allow spatial correlations including spatial frailty interval censored data setting parametric cure rate models independent dependent spatial frailties proposed compared approach enables different underlying activation mechanisms lead event interest addition number competing causes may responsible occurrence event interest follows geometric distribution markov chain monte carlo method used bayesian framework inferential purposes model comparison bayesian criteria used influence diagnostic analysis conducted detect possible influential extreme observations may cause distortions results analysis finally proposed models applied analysis real data set smoking cessation results application show parametric cure model frailties first activation scheme better findings â© korean statistical society korean international statistical society
10.1016/j.hrtlng.2017.09.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029815526&doi=10.1016%2fj.hrtlng.2017.09.001&partnerID=40&md5=93b13e85fca99cfa7842ac863367fa9d 4,recent evidence challenges superiority amiodarone compared anti arrhythmic medications agent choice pulseless ventricular tachycardia vt ventricular fibrillation vf conducted bayesian network traditional meta analyses investigate relative efficacies amiodarone lidocaine magnesium mgso placebo treatments pulseless vt vf eleven studies patients randomized trials patients non randomized studies patients included meta analysis search conducted february using medline embase cochrane library estimates reported odds ratio credible interval cri markov chain monte carlo mcmc modeling used estimate relative ranking probability treatment group based surface cumulative ranking curve sucra bayesian analysis demonstrated lidocaine superior effects survival hospital discharge compared amiodarone cr â€“ mgso cr â€“ placebo cr â€“ statistical differences among treatment groups regarding survival hospital admission h hrs return spontaneous circulation rosc probability analysis revealed lidocaine effective therapy survival hospital discharge sucra conclude lidocaine may effective anti arrhythmic agent survival hospital discharge patients pulseless vt vf â© elsevier inc
10.1007/s10260-017-0379-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016223080&doi=10.1007%2fs10260-017-0379-x&partnerID=40&md5=3505cc7a6e04affd624aea298e8f78c4 0,sample surveys often insufficient sample size obtain reliable direct estimates parameters interest certain domains precision increased introducing small area models â€˜borrow strengthâ€™ connecting different areas use explicit linking models area specific random effects auxiliary covariate information one consequence use small area models small area estimates lower example county geographic level typically aggregate estimate corresponding higher example state geographic level benchmarking statistical procedure reconciling differences paper provides new perspectives benchmarking problem especially complex bayesian small area models require markov chain monte carlo estimation two new approaches bayesian benchmarking introduced one procedure based minimum discrimination information another procedure fully bayesian self consistent conditional benchmarking notably proposed procedures construct adjusted posterior distributions whose first higher order moments consistent benchmarking constraints shown certain existing benchmarked estimators special cases proposed methodology normality giving distributional justification use benchmarked estimates additionally â€˜flexibleâ€™ benchmarking constraint introduced higher geographic level estimate considered fixed simultaneously adjusted along lower level estimates â© springer verlag berlin heidelberg
10.29220/CSAM.2017.24.6.561 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044029535&doi=10.29220%2fCSAM.2017.24.6.561&partnerID=40&md5=6686eafab30d87fa35a5281e353a97d2 0,bayesian statistics play key role design analysis clinical trials demonstrated medical device trials bayesian statistics well developed revolution computing powers markov chain monte carlo development made calculation posterior distributions within computational reach food drug administration fda initiative bayesian statistics medical device clinical trials began almost years ago reviewed detail along key decisions made along way bayesian hierarchical modeling using data previous studies bayesian adaptive designs usually non informative prior discussed leveraging prior study data accomplished bayesian hierarchical modeling enormous advantage bayesian adaptive designs achieved accompanied modeling primary endpoint produce predictive posterior distribution simulations crucial providing operating characteristics bayesian design especially complex adaptive design fda bayesian guidance medical device trials addressed approaches well exchangeability type error sample size treatment response adaptive randomization using famous extracorporeal membrane oxygenation example discussed interesting real example bayesian analysis using failed trial interesting subgroup prior information presented implications likelihood principle considered recent exciting area using bayesian hierarchical modeling pediatric extrapolation using adult data clinical trials historical control information previous trials underused area lends easily bayesian methods future including recent trends decision theoretic trials bayesian benefit risk virtual patients appalling lack penetration bayesian clinical trials medical literature discussed â© korean statistical society korean international statistical society
10.1097/MD.0000000000008679 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036524934&doi=10.1097%2fMD.0000000000008679&partnerID=40&md5=3fbbfd8518deeedd14759ab2e89c9090 0,objective network meta analysis aims compare efficacy safety nonoperative regimens placebo pregabalin gm ganglioside venlafaxine extended release venlafaxine xr fampridine conventional ground training ot body weight supported treadmill training bwstt robotic assisted gait training ragt +ot body weight supported ground training bwsot treating spinal cord injury sci methods clinical controlled trials nonoperative regimens sci retrieved electronic database traditional pairwise bayesian network meta analyses performed compare efficacy safety nonoperative regimens treatment sci weighted mean difference wmd odds ratios surface cumulative ranking curve sucra calculated using markov chain monte carlo engine open bugs v r v package gemtc v results total clinical controlled trials meeting inclusion criteria selected meta analysis aspect efficacy results pairwise meta analysis indicated ragt+ot bwsot might best efficacy sci patients terms lower extremity motor score lems compared conventional ot efficacy ragt+ot sci patients relatively better conventional ot terms walking index spinal cord injury wisci aspect safety constipation rate placebo sci patients relatively higher venlafaxine xr however respect headache urinary tract infection significant difference safety placebo pregabalin gm ganglioside venlafaxine xr fampridine sci patients results sucra values suggested bwsot highest sucra value lems ragt+ot highest sucra value wisci venlafaxine xr highest sucra value constipation venlafaxine xr highest sucra value headache gm ganglioside highest sucra value urinary tract infection conclusion results provide evidence ragt+ot bwsot might best efficacy treatment sci venlafaxine xr gm ganglioside showed adequate safety sci â© copyright author published wolters kluwer health inc
10.1016/j.dam.2017.06.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026230759&doi=10.1016%2fj.dam.2017.06.003&partnerID=40&md5=9a8fdd9952b33108091ae6713d3ad932 0,consider bipartite version color degree matrix problem bipartite graph g u v e half regular vertices u degree give necessary sufficient conditions bipartite degree matrix also known demand matrix color degree matrix edge disjoint union half regular graphs also give necessary sufficient perturbations transform realizations half regular degree matrix based perturbations markov chain monte carlo method designed inverse acceptance ratios polynomial bounded realizations half regular degree matrix generalizations latin squares also appear applied neuroscience â©
10.1109/HPEC.2017.8091050 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041234620&doi=10.1109%2fHPEC.2017.8091050&partnerID=40&md5=0a05da6cfe522b0c23e7f1afa44af203 1,processing graph data large scale though important useful real world applications continues challenging particularly problems graph partitioning optimal graph partitioning np hard several methods provide approximate solutions reasonable time yet scaling approximate algorithms also challenging paper describe efforts towards improving scalability one technique stochastic block partition baseline algorithm ieee hpec graph challenge key contributions improvements parallelization baseline bottom algorithm especially markov chain monte carlo mcmc nodal updates bayesian inference new top divide conquer algorithm capable reducing algorithmic complexity static partitioning also suitable streaming partitioning parallel single node multi cpu implementation parallel multi node mpi implementation although focus algorithmic scalability python implementation obtains speedup ã— fastest baseline parallel c++ run graph size k vertices divided subgraphs multi cpu single node machine achieves speedup ã— cluster machines cpus k node graph divided subgraphs ã— speedup k node graph divided subgraphs multi cpu single node machine â© ieee
10.1103/PhysRevX.7.041025 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034428242&doi=10.1103%2fPhysRevX.7.041025&partnerID=40&md5=b716095b820661fa00aaa9c1fca37e59 6,pulsar timing laser interferometer gravitational wave gw detectors superb laboratories study gravity theories strong field regime combine tools test mono scalartensor theory damour esposito farã¨se def predicts nonperturbative scalarization phenomena neutron stars nss first applying markov chain monte carlo techniques use absence dipolar radiation pulsar timing observations five binary systems composed ns white dwarf eleven equations state eoss nss derive stringent constraints two free parameters def scalar tensor theory since binary pulsar bounds depend ns mass eos find current pulsar timing observations leave scalarization windows e regions parameter space scalarization still prominent investigate scalarization windows closed pulsar timing constraints improved laserinterferometer gw detectors spontaneous dynamical scalarization sets early late stages binary ns bns evolution early inspiral bns carrying constant scalar charge employ fisher matrix analysis show advanced ligo improve pulsar timing constraints eoss next generation detectors cosmic explorer einstein telescope able improve bounds eleven eoss using late inspiral bns estimate eoss consideration onset dynamical scalarization happen early enough improve constraints def parameters obtained combining five binary pulsars thus near future complementarity pulsar timing direct observations gws ground extremely valuable probing gravity theories strong field regime
10.1109/TCST.2017.2762288 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032742883&doi=10.1109%2fTCST.2017.2762288&partnerID=40&md5=80015703068665b0cd25551ea420bd5b 0,human driven autonomously driven cars today act often reactively decisions cars follow lead uncomfortable inefficient sometimes unsafe situations stop go traffic paper proposes methods probabilistic anticipation motion preceding vehicle control motion ego vehicle construct markov chain predictor based observed behavior preceding vehicle maximum likelihood motion predictor based historical traffic speed different locations times heuristics proposed combining two predictions determine probability distribution position preceding vehicle future planning horizon chance constrained model predictive control framework employed optimize motion ego vehicle given probabilistic prediction motion preceding vehicle effectiveness proposed approach evaluated multiple simulation scenarios ieee
10.1007/s10729-017-9420-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032505849&doi=10.1007%2fs10729-017-9420-8&partnerID=40&md5=de82bb61c82d4cbe35ab67057b64bfbf 0,markov models commonly used decision making studies many application domains however widely adopted methods performing sensitivity analysis models uncertain transition probability matrices tpms article describes two simulation based approaches conducting probabilistic sensitivity analysis given discrete time finite horizon finite state markov model using tpms sampled specified uncertainty set according relevant probability distribution first approach assumes prior knowledge probability distribution row tpm independently sampled uniform distribution rowâ€™s uncertainty set second approach involves random sampling truncated multivariate normal distribution tpmâ€™s maximum likelihood estimators rows subject condition row nonnegative elements sums one two sampling methods easily implemented reasonable computation times case study illustrates application methods medical decision making problem involving evaluation treatment guidelines glycemic control patients type diabetes natural variation patientâ€™s glycated hemoglobin hba c modeled markov chain associated tpms subject uncertainty â© springer science+business media llc
10.5194/hess-21-5375-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032494407&doi=10.5194%2fhess-21-5375-2017&partnerID=40&md5=71feb3c3cc178ee052088d277dbf690f 0,substantial interpretation electromagnetic induction emi measurements requires quantifying optimal model parameters uncertainty nonlinear inverse problem purpose adaptive bayesian markov chain monte carlo mcmc algorithm used assess multi orientation multi offset emi measurements agriculture field non saline saline soil mcmc posterior distribution computed using bayes rule electromagnetic forward model based full solution maxwell equations used simulate apparent electrical conductivity measured configurations emi instrument cmd mini explorer uncertainty parameters three layered earth model investigated using synthetic data results show scenario non saline soil parameters layer thickness compared layers electrical conductivity informative therefore difficult resolve application proposed mcmc based inversion field measurements drip irrigation system demonstrates parameters model well estimated saline soil compared non saline soil provides useful insight parameter uncertainty assessment model outputs â© author
10.1080/02664763.2016.1258549 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996490528&doi=10.1080%2f02664763.2016.1258549&partnerID=40&md5=d5d6f69bfa2f2a213493e5a5d2fb8ea2 2,paper statistical inference unknown parameters burr type iii biii distribution based unified hybrid censored sample studied maximum likelihood estimators unknown parameters obtained using expectationâ€“maximization algorithm observed bayes estimators obtained explicit forms hence lindley approximation markov chain monte carlo mcmc technique used compute bayes estimators highest posterior density credible intervals unknown parameters based mcmc samples provided new model selection test developed discriminating two competing models unified hybrid censoring scheme finally potentiality biii distribution analyze real data illustrated using fracture toughness data three different materials namely silicon nitride si n zirconium dioxide zro sialon si âˆ’ xalxoxn âˆ’ x observed present data sets biii distribution better fit weibull distribution frequently used fracture toughness data analysis â© informa uk limited trading taylor francis group
10.1080/02664763.2016.1259400 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997605077&doi=10.1080%2f02664763.2016.1259400&partnerID=40&md5=d4b1ecfc996a18d1aff9ec2b1f73e63d 0,study concerned extension mallowsâ€“bradleyâ€“terry ranking model one block comparison consisting items interest situations allow expression preference consider modification mallowsâ€“bradleyâ€“terry ranking model introducing additional parameter called index discrimination model permits ties model maximum likelihood estimates parameters found using maximizationâ€“minimization algorithm evaluation mathematical expectations involved log likelihood equation obtained generating samples monte carlo markov chain stationary distribution addition simulation study asymptotic properties assessment made proposed method applied analyze data election â© informa uk limited trading taylor francis group
10.1016/j.ecolmodel.2017.08.016 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028721202&doi=10.1016%2fj.ecolmodel.2017.08.016&partnerID=40&md5=7510745d051fcb27f1da689a060dceb9 0,ammonia oxidizing bacteria archaea aoa aob perform rate limiting step nitrification biogeochemical process controls availability inorganic nitrogen terrestrial aquatic ecosystems sought investigate field values aoa aob ammonia uptake kinetics along domain level contributions ammonia oxidation temperate forest soils accomplish goal constructed ecosystem model simulates ammonia oxidation temperate forest soils based inorganic nitrogen pools aoa aob population dynamics observed situ incubations model used bayesian markov chain monte carlo procedure choose likely combination situ ammonia uptake parameters aoa aob including km aoa km aob vmax aoa vmax aob domain level contributions ammonia oxidation extracted best fit solution model selected values indicate aob responsible simulated ammonia oxidation across sites aoa responsible remaining believe approach demonstrate applied microbially mediated biogeochemical fluxes elemental cycles well â© elsevier b v
10.23919/EUSIPCO.2017.8081197 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041423929&doi=10.23919%2fEUSIPCO.2017.8081197&partnerID=40&md5=f7d8a695fae72dee3b0c5e3b1deac948 2,monte carlo mc methods widely used bayesian inference optimization statistics signal processing machine learning two well known class mc methods importance sampling techniques markov chain monte carlo mcmc algorithms work introduce group importance sampling gis framework different sets weighted samples properly summarized one summary particle one summary weight gis facilitates design novel efficient mc techniques instance present group metropolis sampling gms algorithm produces markov chain sets weighted samples gms general outperforms multiple try schemes shown means numerical simulations â© eurasip
10.23919/EUSIPCO.2017.8081191 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040461650&doi=10.23919%2fEUSIPCO.2017.8081191&partnerID=40&md5=138bed2f674ed0bc9b011bd630771a14 1,gibbs sampling well known markov chain monte carlo mcmc algorithm extensively used signal processing machine learning statistics key point successful application gibbs sampler ability draw samples full conditional probability density functions efficiently general case possible order speed convergence chain required generate auxiliary samples however intermediate information finally disregarded work show auxiliary samples recycled within gibbs estimators improving efficiency extra cost theoretical exhaustive numerical comparisons show validity approach â© eurasip
10.1109/ICRAECT.2017.31 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040006730&doi=10.1109%2fICRAECT.2017.31&partnerID=40&md5=332bf2a2e506c588b4ccc58819743fe5 0,compilation high quality traffic data one basic concerns real time traffic video surveillance since video surveillance figurative applications security traffic monitoring law enforcement detecting recognizing vehicle objects video imperative part video surveillance systems going guide tracking detected objects gathering decisive information vehicular detection classification decisive guide traffic control gathering traffic info used intelligent transportation systems vehicular classification poses thought provoking problem vehicles high intra class variation comparatively low inter class variation time consuming varying performance different weather conditions etc hence demand employing innovative efficient data collection technique give advantageous continuous data collection acceptable level accuracy paper surveys prominent published literature last years evaluate summarize work done far field motivation paper provide review current methods employed traffic data collection intelligent transport system available literature estimate best one accomplish parameter conditions â© ieee
10.23919/EUSIPCO.2017.8081571 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041475372&doi=10.23919%2fEUSIPCO.2017.8081571&partnerID=40&md5=5d13b16acd17590714e3b26bcff27c45 1,many prediction studies using real life measure ments wind speed power electricity load rain fall utilize linear autoregressive moving average arma based models due simplicity general character however real life applications exhibit nonlinear character modelling linear time series may become problematic among nonlinear arma models polynomial arma parma models belong class linear parameters paper propose reversible jump markov chain monte carlo rjmcmc based complete model estimation method estimates parma models parameters including nonlinearity degree proposed method unique manner estimating nonlinearity degree model orders model coefficients time moreover paper rjmcmc examined anomalous way performing transitions linear nonlinear model spaces â© eurasip
10.23919/EUSIPCO.2017.8081205 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041530553&doi=10.23919%2fEUSIPCO.2017.8081205&partnerID=40&md5=8451cfd500cd005acabc00a50c2f66f9 0,paper studies new bayesian algorithm joint reconstruction classification reflectance confocal microscopy rcm images application identification human skin lentigo proposed bayesian approach takes advantage distribution multiplicative speckle noise affecting true reflectivity images appropriate priors unknown model parameters markov chain monte carlo mcmc algorithm proposed jointly estimate model parameters image true reflectivity classifying images according distribution reflectivity precisely metropolis within gibbs sampler investigated sample posterior distribution bayesian model associated rcm images build estimators parameters including labels indicating class rcm image resulting algorithm applied synthetic data real images clinical study containing healthy lentigo patients â© eurasip
10.23919/EUSIPCO.2017.8081561 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041461269&doi=10.23919%2fEUSIPCO.2017.8081561&partnerID=40&md5=f593c37196068bd995810f60719756f7 0,paper considers analysis communication protocols wireless networks implementing cooperation hybrid automatic repeat request harq type decoder type ii decoder chase combining using example three node network show communication protocol modeled using finite state markov chains model efficiently predicts performance system however complexity depends number states increases fast protocol gets sophisticated derive simplified model using state aggregation obtain compact description used predict performance reduced complexity moreover show simplified model describes probabilistic communication protocol network monte carlo simulations show theoretical predictions match simulated performance â© eurasip
10.1063/1.4995425 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026860225&doi=10.1063%2f1.4995425&partnerID=40&md5=bbe945ca056d8114611e90f7e99e306e 1,use first principles density functional theory characterize binding sites diffusion mechanisms ga adatom gaas î² ã— surface diffusion system complex process involving eleven unique binding sites sixteen different hops neighboring binding sites among binding sites identify four different superbasins motion binding sites within superbasin much faster hops exiting superbasin describe diffusion use recently developed local superbasin kinetic monte carlo lskmc method accelerates conventional kinetic monte carlo kmc simulation describing superbasins absorbing markov chains find lskmc times faster kmc conditions probed study characterize distribution exit times superbasins find sometimes always exponential characterize conditions superbasin exit time distribution exponential demonstrate lskmc simulations assuming exponential superbasin exit time distribution yield diffusion coefficients conventional kmc â© author
10.1063/1.4984932 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020382450&doi=10.1063%2f1.4984932&partnerID=40&md5=8f2cf12c0ef3003c9be42559db02dffb 3,markov state models msms related kinetic network models frequently used study long timescale dynamical behavior biomolecular materials systems msms often constructed bottom using brute force molecular dynamics md simulations model contains large number states kinetic pathways known priori however resulting network generally encompasses parts configurational space regardless additional md performed several states pathways still remain missing implies duration msm faithfully capture true dynamics term validity time msm always finite unfortunately much shorter md time invested construct model general framework relates kinetic uncertainty model validity time missing states pathways network topology statistical sampling presented performing additional calculations frequently sampled states pathways may alter msm validity time new class enhanced kinetic sampling techniques introduced aims targeting rare states pathways contribute uncertainty validity time boosted effective manner examples including straightforward energy landscapes lattice models biomolecular systems provided illustrate application method developments presented interest kinetic monte carlo community well â© author
10.1080/07474938.2017.1307548 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019740331&doi=10.1080%2f07474938.2017.1307548&partnerID=40&md5=4b8a716261003e887bf7d305f5df7ccc 0,paper develops tests null hypothesis linearity context autoregressive models markov switching means variances tests robust identification failures plague conventional likelihood based inference methods approach exploits moments normal mixtures implied regime switching process uses monte carlo test techniques deal presence autoregressive component model specification proposed tests respectable power comparison optimal tests markov switching parameters carrasco et al â also quite attractive owing computational simplicity new tests illustrated empirical application autoregressive model usa output growth â© taylor francis group llc
10.1109/PHM.2017.8079119 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039955320&doi=10.1109%2fPHM.2017.8079119&partnerID=40&md5=14efeba54c5fbc1b3bd2c58852e8027e 0,remaining useful life rul prediction one critical procedures prognostics health management phm existing literature rul prediction methods assumption maintenance activity whole life time degrading system however practical systems experience various kinds maintenance activities operation article presents approach predict rul class nonlinear degrading systems stochastic maintenance predict rul systems stochastic maintenance wiener process based degradation model proposed switches states normal operation maintenance described continuous time markov chain ctmc addition maximum likelihood estimation mle adopted estimate unknown parameters degradation model transition probability normal operation maintenance analytical form first hitting time fht degradation process difficult derive presence maintenance activities avoid complicated mathematical derivation stochastic differential monte carlo method used obtain numerical result rul distribution numerical study presented illustrate validate proposed method â© ieee
10.3389/fnins.2017.00586 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032028819&doi=10.3389%2ffnins.2017.00586&partnerID=40&md5=7dd98483e1a41f72422a5e07423c275a 1,well known data diffusion weighted imaging dwi follow rician distribution rician distribution also relevant functional magnetic resonance imaging fmri data obtained high temporal spatial resolution propose general regression model non central ï‡ nc ï‡ distributed data heteroscedastic rician regression model prominent special case model allows parameters rician distribution linked explanatory variables relevant variables chosen bayesian variable selection highly efficient markov chain monte carlo mcmc algorithm proposed capture full model uncertainty simulating joint posterior distribution model parameters binary variable selection indicators simulated regression data used demonstrate rician model able detect signal much accurately traditionally used gaussian model low signal noise ratios using diffusion dataset human connectome project also shown commonly used approximate gaussian noise model underestimates mean diffusivity md fractional anisotropy fa single diffusion tensor model compared rician model â© wegmann eklund villani
10.1109/WHISPERS.2015.8075438 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039167056&doi=10.1109%2fWHISPERS.2015.8075438&partnerID=40&md5=f881e077eda7ce2eb59f0ba363442c7f 0,paper presents new bayesian collaborative sparse regression method linear unmixing hyperspectral images contribution twofold first propose new bayesian model structured sparse regression supports sparse abundance vectors priori spatially correlated across pixels secondly propose advanced markov chain monte carlo algorithm estimate posterior probabilities materials present absent pixel conditionally maximum marginal posteriori configuration support compute mmse estimates abundance vectors remarkable property algorithm self adjusts values parameters markov random field thus relieving practitioners setting regularisation parameters namely cross validation proposed methodology illustrated real hyperspectral data â© ieee
10.1109/WHISPERS.2014.8077636 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038574984&doi=10.1109%2fWHISPERS.2014.8077636&partnerID=40&md5=0d3215a768f0bd3b3b0d2a57e2b08223 0,reduce huge consumption processing hyperspectral images hsi novel bayesian unmixing compressive sensing framework proposed compress reconstruct hsi effectively called structured sparse bayesian umixing compressive sensing ssbucs ssbucs unites compressive sensing hyperspectral linear mixed model bayesian framework hsi decomposed linear combination endmembers abundance matrix abundance matrix transformed structured sparse signal wavelet domain compressive sensing employed sparse signal produce compact result recover hsi markov chain monte carlo mcmc method based gibbs sampling proposed imposing structured sparse prior abundance matrix experimental results verify superiority proposed method several state art methods â© ieee
10.1109/WHISPERS.2015.8075442 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039151806&doi=10.1109%2fWHISPERS.2015.8075442&partnerID=40&md5=790646ce8fdec8c022db8d97e12588f5 0,paper presents unsupervised bayesian algorithm hyper spectral image unmixing accounting endmember variability variability obtained assuming pixel linear combination random endmembers weighted corresponding abundances additive noise also considered proposed model generalizing normal compositional model proposed model unsupervised since estimates abundances mean covariance matrix endmember classification map indicating class pixel also obtained based estimated abundances simulations conducted real dataset show potential proposed model terms unmixing performance analysis hyperspectral images â© ieee
10.1109/ICIEAM.2017.8076474 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039945044&doi=10.1109%2fICIEAM.2017.8076474&partnerID=40&md5=bb6ab38837b898b799cc4458aec0ba32 0,paper dwells design diagnostic system expert assessment significance threats security industrial networks proposed system based new cyber attacks classification presupposes existence two structural blocks industrial network virtual model based scan selected nodal points generator cyber attacks sets diagnostic expert assessment quality improved use markov chains monte carlo numerical method numerical algorithm generating cyber attacks sets based lpï„ sequence â© ieee
10.1109/WHISPERS.2016.8071782 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037529472&doi=10.1109%2fWHISPERS.2016.8071782&partnerID=40&md5=c5b22478f9bf21e090aa3da146bb6984 0,paper presents new bayesian spectral unmixing algorithm analyse remote scenes sensed via multispectral lidar measurements first approximation lidar waveform consists temporal signature observed target depends wavelength laser source considered corrupted poisson noise number spectral bands large enough becomes possible identify quantify main materials scene top estimation classical lidar based range profiles thanks anomaly detection capability proposed hierarchical bayesian model coupled efficient markov chain monte carlo algorithm allows robust estimation depth images together abundance outlier maps associated observed scene proposed methodology illustrated via experiments conducted real multispectral lidar data â© ieee
10.1080/03610926.2016.1235193 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024394960&doi=10.1080%2f03610926.2016.1235193&partnerID=40&md5=bbb0f33147db62f3f851bc7cd5f76455 0,stationary bilinear sb model used describe processes time varying degree persistence depends past shocks study develops methods bayesian inference model comparison forecasting sb model using monthly u k inflation data find sb model outperforms random walk first order autoregressive ar autoregressive moving average arma models terms root mean squared forecast errors addition sb model superior three models terms predictive likelihood majority forecast observations â© taylor francis group llc
10.1080/03610926.2016.1228961 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021820604&doi=10.1080%2f03610926.2016.1228961&partnerID=40&md5=a5822876372a108c94e6905e908bb2bb 0,commonly asserted gibbs sampler special case metropolisâ€“hastings mh algorithm statement true certain gibbs samplers true general version taught used often namely deterministic scan gibbs sampler note prove exist deterministic scan gibbs samplers exhibit detailed balance hence considered mh samplers nuances various gibbs sampling schemes discussed â© taylor francis group llc
10.1002/2017GL075043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031326195&doi=10.1002%2f2017GL075043&partnerID=40&md5=47277884a8835ff40b24007c1f2865e0 1,yield strength oceanic lithosphere determines mode mantle convection terrestrial planet low temperature plasticity olivine aggregates generally believed govern plastic rheology stiffest part lithosphere far proposed flow laws mechanism exhibit nontrivial discrepancies revisit recent high pressure deformation data mei et al comprehensive inversion approach based markov chain monte carlo sampling inversion results indicate uncertainty relevant flow law parameters considerably greater previously thought depending choice flow law parameters strength oceanic lithosphere vary substantially carrying different implications origin plate tectonics earth reduce flow law ambiguity suggest important establish theoretical basis estimating macroscopic stress high pressure experiments also better utilize marine geophysical observations â© american geophysical union rights reserved
10.1002/sim.7385 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024919729&doi=10.1002%2fsim.7385&partnerID=40&md5=3ce95da4ecdba6194f15310c91f62749 1,motivated study measuring diabetes related risk factors complications postulate extension standard formulation joint models longitudinal survival outcomes wherein longitudinal outcome cumulative effect hazard event weighted recency focus relationship biomarker hba c development sight threatening retinopathy since impact hba c marker risk sight threatening retinopathy expected cumulative evolution hba c marker time contributing progressively greater damage vascular structure retina opting parametric approach propose use normal skewed normal probability density functions weight functions estimating relevant parameters directly data use recency weighted cumulative effect specification allows us incorporate differences development longitudinal profile time calculation hazard ratios subjects proposed functions provide us parameters clinically relevant interpretations retaining degree flexibility addition also allow answering important clinical questions regarding relative importance various segments biomarkers history estimation risk event copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1109/INAES.2017.8068537 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037155708&doi=10.1109%2fINAES.2017.8068537&partnerID=40&md5=322934369d145996ffaa365c99759031 0,hepatitis one major health problems progress chronic hepatitis cancer currently computer based diagnosis commonly use among medical examination diagnosis examined using disease dataset reference make decisions however dataset incomplete contained many instances containing missing values situation lead results analysis biased one method handling missing values multiple imputation hepatitis dataset arbitrary pattern missing values pattern handled using markov chain monte carlo mcmc fully conditional specification fcs multiple imputation algorithms research conducted experiment compare combinations multiple imputations algorithm principal component analysis pca instance selection instance selection applied reduce data selecting variables contribute greatly dataset goal improve accuracy analysis data missing values arbitrary pattern results showed fcs pca best performance higher accuracy lowest error rate â© ieee
10.1080/00949655.2017.1349131 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022050587&doi=10.1080%2f00949655.2017.1349131&partnerID=40&md5=cb784667c661a13ea0a09c31d5611320 0,introduce multivariate heteroscedastic measurement error model replications scale mixtures normal distribution model provide robust analysis viewed generalization multiple linear regression model structure distribution assumption efficient method based markov chain monte carlo developed parameter estimation deviance information criterion conditional predictive ordinates used model selection criteria simulation studies show robust inference behaviours model misspecification distributions outliers work illustrative example real data set measurements plant root decomposition â© informa uk limited trading taylor francis group
10.1080/00949655.2017.1342824 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021411981&doi=10.1080%2f00949655.2017.1342824&partnerID=40&md5=e56521325855d9e655b28eebbdd1e932 0,max stable process natural approach modelling extrenal dependence spatial data however estimation difficult due intractability full likelihoods one approach used estimate posterior distribution parameters max stable process employ composite likelihoods markov chain monte carlo mcmc samplers possibly adjustment credible intervals paper investigate performance composite likelihood based mcmc samplers various settings gaussian extreme value process brownâ€“resnick process based findings suggestions made facilitate application estimator real data â© informa uk limited trading taylor francis group
10.1080/00949655.2017.1349769 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022100759&doi=10.1080%2f00949655.2017.1349769&partnerID=40&md5=4f0a8773b4b5462e4ac95922bc7e8524 1,uniform shrinkage prior usp distribution unknown variance component random effects model known produce good frequency properties usp parameter determines shape density function neglected whether usp maintain good frequency properties regardless choice shape parameter investigate choice shape parameter usp produces bayesian interval estimates random effects meet nominal confidence levels better several existent choices literature using univariate multivariate gaussian hierarchical models show usp achieve best frequency properties shape parameter makes usp behave similarly improper flat prior distribution unknown variance component â© informa uk limited trading taylor francis group
10.1016/j.vaccine.2017.09.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029580752&doi=10.1016%2fj.vaccine.2017.09.020&partnerID=40&md5=5bc627288e1c7addcad6576e59693d56 0,recently developed vaccines provide new way controlling rotavirus sub saharan africa models transmission dynamics rotavirus critical estimating current burden imperfect surveillance assessing potential effects vaccine intervention strategies examine rotavirus infection maradi area southern niger using hospital surveillance data provided epicentre collected two years additionally cluster survey households region allows us estimate proportion children diarrhea consulted health structure model fit future projections necessarily particular given model thus competing models underlying epidemiology ensemble approach account uncertainty compare results across several variants susceptible infectious recovered sir compartmental models quantify impact modeling assumptions estimates model specific parameters estimated bayesian inference using markov chain monte carlo use bayesian model averaging generate ensemble estimates current dynamics including estimates r burden infection region well impact vaccination short term dynamics long term reduction rotavirus incidence varying levels coverage ensemble models predicts current burden severe rotavirus disease â€“ population year dose vaccine schedule achieving coverage reduce burden â€“ â©
10.1186/s12872-017-0692-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031021427&doi=10.1186%2fs12872-017-0692-1&partnerID=40&md5=cb46f799b1cab3d10d43807270f21dba 2,background novel anticoagulations noacs increasingly prescribed prevention stroke premenopausal women atrial fibrillation small studies suggest noacs associated higher risk abnormal uterine bleeds vitamin k antagonists vkas direct empirical evidence benefit risk profile rivaroxaban compared vkas subgroup synthesize available indirect evidence estimate decision uncertainty treatments assess whether research premenopausal women warranted methods markov model annual cycles lifetime horizon developed comparing rivaroxaban frequently prescribed noac population vkas clinical event rates associated quality adjusted life years health care costs obtained different sources adjusted gender age history stroke monte carlo simulation iterations performed hypothetical cohort premenopausal women estimated reflective population premenopausal women af netherlands results simulation rivaroxaban better treatment option prevention ischemic strokes premenopausal women iterations similarly intracranial hemorrhages major abnormal uterine bleeds minor abnormal uterine bleeds major extracranial hemorrhages minor extracranial hemorrhages chance rivaroxaban offers quality adjusted life years expected value perfect information netherlands equals quality adjusted life years million euros conclusions risk rivaroxaban offers worse rather better benefit risk profile vitamin k antagonists premenopausal women although rivaroxaban preferred vkas population research warranted preferably take shape internationally coordinated registry study including noacs â© author
10.1145/3157737.3157750 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041106359&doi=10.1145%2f3157737.3157750&partnerID=40&md5=2bfe91e6432826a4c8b696c06e8744fd 0,one challenging parts traffic modeling model traffic behavior traffic incidents one possible approaches problem use historical data identify typical incidents use knowledge classify future time series classification utilized example prediction traffic incident duration procedure requires solutions several problems first problem historical time series traffic incidents clustered clusters parametrized second problem time series new ongoing incidents classified existing clusters classification utilized prediction length main aim article propose solution problems methods utilized addressing problems called markov chains dynamic time warping bayesian classification monte carlo simulation â© association computing machinery
10.1021/acs.jpcb.7b08199 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031328582&doi=10.1021%2facs.jpcb.7b08199&partnerID=40&md5=de4b02eb6f4b0cc4f26c3ca633c3e032 1,wide range cellular processes initiates upon recognizing binding proteins specific dna sites typically recognition process incredibly fast owing complex mechanism combines different modes translocation protein studies performed selected dna topologies suggested dna topology might alter balance two modes therefore target search kinetics detailed role target search mechanism remains unclear present discrete state stochastic approach allows us incorporate topological information dna molecule explicitly predict role process proteins search specific binding sites dna applying theory closed loop different supercoiled dna topologies find target search efficiency protein strongly influenced dna topology furthermore topology promotes juxtaposition distant dna sites number position relative distances juxtaposition sites play crucial role facilitating search process providing additional routes approach target site predictions validated extensive monte carlo simulations â© american chemical society
10.3847/1538-4357/aa8bb4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031930707&doi=10.3847%2f1538-4357%2faa8bb4&partnerID=40&md5=32fe81cae606b44dde01f44092114fa6 9,current upcoming radio interferometric experiments aiming make statistical characterization high redshift cm fluctuation signal spanning hydrogen reionization x ray heating epochs universe however connecting cm statistics underlying physical parameters complicated theoretical challenge modeling relevant physics computational speeds quick enough enable exploration high dimensional weakly constrained parameter space work use machine learning algorithms build fast emulator accurately mimic expensive simulation cm signal across wide parameter space embed emulator within markov chain monte carlo framework order perform bayesian parameter constraints large number model parameters including govern epoch reionization epoch x ray heating cosmology worked example use emulator present updated parameter constraint forecast hydrogen epoch reionization array experiment showing characterization fiducial cm power spectrum considerably narrow allowed parameter space reionization heating parameters help strengthen planck constraints ïƒg provide generalized emulator code implementation specifically cm parameter constraints publicly available software â© american astronomical society rights reserved
10.1109/RADAR.2016.8059259 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034662060&doi=10.1109%2fRADAR.2016.8059259&partnerID=40&md5=1aeaaebd2be55c9ebe3766a3525fb0c8 0,group tracking based markov chain monte carlo particle filter mcmc pf algorithm high accuracy individual target tracking group tracking main problem mcmc pf algorithm calculation burden considers kinds hypotheses state vector measurement vector observation model therefore paper originally use results data association prior hypotheses management reduce variety feasible hypotheses also raise new method target state proposal based group information kalman framework end simulation results demonstrate new algorithms track individual target infer correct group structure less time consumption previous work â© ieee
10.1103/PhysRevB.96.161102 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037677955&doi=10.1103%2fPhysRevB.96.161102&partnerID=40&md5=f5d693804c1aea1ec5e32faa9ed752f0 13,recently introduced self learning monte carlo method general purpose numerical method speeds monte carlo simulations training effective model propose uncorrelated configurations markov chain implement method framework continuous time monte carlo method auxiliary field quantum impurity models introduce train diagram generating function dgf model probability distribution auxiliary field configurations continuous imaginary time orders diagrammatic expansion using dgf propose global moves configuration space show self learning continuous time monte carlo method significantly reduce computational complexity simulation â© american physical society
10.1016/j.bpj.2017.08.015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030656687&doi=10.1016%2fj.bpj.2017.08.015&partnerID=40&md5=e256cb764b1ab6f80c7bc1b412513267 0,rotary sequential hydrolysis metabolic machine f atpase prominent manifestation high coordination among multiple chemical sites ring shaped molecular machines also functionally essential f tightly couple chemical reactions central î³ shaft rotation high speed afm experiments identified sequential hydrolysis maintained f stator ring even absence î³ rotor explore origins intrinsic sequential performance computationally investigated essential inter subunit couplings hexameric ring mitochondrial bacterial f first reproduced stochastic monte carlo simulations experimentally determined sequential hydrolysis schemes kinetically imposing inter subunit couplings following subsequent tri site atp hydrolysis cycles f ring found key couplings support sequential hydrolysis accelerate neighbor site adp pi release upon certain atp binding hydrolysis reaction kinetically identified couplings examined atomistic molecular dynamics simulations coarse grained level reveal underlying structural mechanisms enforced targeted conformational changes atp binding hydrolysis one chemical site f ring monitored ensuing conformational responses neighboring sites using structure based simulations notably found asymmetrical neighbor site opening facilitates adp release upon enforced atp binding also captured complete charge hopping process pi release subsequent enforced atp hydrolysis neighbor site confirming recent single molecule analyses regard role atp hydrolysis f studies therefore elucidate coordinated chemical kinetics structural dynamics mechanisms underpinning sequential operation f ring â© biophysical society
10.1080/00401706.2017.1317290 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026548170&doi=10.1080%2f00401706.2017.1317290&partnerID=40&md5=6198aaff48dd816f9a33e8227546ae81 0,spatially varying coefficient process model nonstationary approach explaining spatial heterogen eity allowing coefficients vary across space article develop methodology generalizing model accommodate geographically hierarchical data article considers two level hierarchical structures allow coefficients low level high level units vary space assume spatially varying low level coefficients follow multivariate gaussian process spatially varying high level coefficients follow multivariate simultaneous autoregressive model develop extending standard simultaneous autoregressive model incorporate multivariate data apply proposed model transaction data houses sold part city los angeles results show proposed model predicts housing prices fits data effectively â© american statistical association american society quality
10.1109/INFOCOM.2017.8057071 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034040095&doi=10.1109%2fINFOCOM.2017.8057071&partnerID=40&md5=acce1e721273fd209f47bcd12ba492f5 1,study called rao blackwellization variance reduction technique via conditioning monte carlo methods judiciously applied graph sampling neighborhood exploration despite popularity monte carlo methods little known markov chain monte carlo methods never discussed random walk based graph sampling first propose two forms rao blackwellization used swap replacement virtually reversible random walk graph sampling methods prove rao blackwellized estimators reduce asymptotic variances original estimators yet maintain inherent unbiasedness variance reduction translate lowering number samples required achieve desired sampling accuracy however sampling cost neighborhood exploration required may outweigh improvement even leading higher total amortized cost considering provide generalization rao blackwellization allows one choose suitable extent obtaining rao blackwellized samples order achieve right balance sampling cost accuracy finally provide simulation results via real world datasets confirm theoretical findings â© ieee
10.1080/01621459.2016.1222291 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024502621&doi=10.1080%2f01621459.2016.1222291&partnerID=40&md5=1dd9e913b60c0c30c01f57fe135a628c 1,present offline iterated particle filter facilitate statistical inference general state space hidden markov models given model sequence observations associated marginal likelihood l central likelihood based inference unknown statistical parameters define class â€œtwistedâ€� models member specified sequence positive functions ïˆ associated ïˆ auxiliary particle filter provides unbiased estimates l identify sequence ïˆ optimal sense ïˆ auxiliary particle filterâ€™s estimate l zero variance practical applications ïˆ unknown ïˆ auxiliary particle filter straightforwardly implemented use iterative scheme approximate ïˆ demonstrate empirically resulting iterated auxiliary particle filter significantly outperforms bootstrap particle filter challenging settings applications include parameter estimation using particle markov chain monte carlo algorithm â© author published license taylor francis â© â© pieralberto guarniero adam johansen anthony lee
10.1080/10618600.2017.1336444 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411823&doi=10.1080%2f10618600.2017.1336444&partnerID=40&md5=ada6859caebd43168a73730075f59fe2 0,present bayesian framework registration real valued functional data core approach series transformations data functional parameters developed differential geometric framework aim avoid discretization functional objects long possible thus minimizing potential pitfalls associated high dimensional bayesian inference approximate draws posterior distribution obtained using novel markov chain monte carlo mcmc algorithm well suited estimation functions illustrate approach via pairwise multiple functional data registration using simulated real datasets supplementary material article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/01621459.2016.1222288 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024504456&doi=10.1080%2f01621459.2016.1222288&partnerID=40&md5=9846f4e978700b939e9208a0488eeee5 0,introduce hamming ball sampler novel markov chain monte carlo algorithm efficient inference statistical models involving high dimensional discrete state spaces sampling scheme uses auxiliary variable construction adaptively truncates model space allowing iterative exploration full model space approach generalizes conventional gibbs sampling schemes discrete spaces provides intuitive means user controlled balance statistical efficiency computational tractability illustrate generic utility sampling algorithm application range statistical models supplementary materials article available online â© author published license taylor francis â© â© michalis k titsias christopher yau
10.1080/15598608.2017.1305922 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018505121&doi=10.1080%2f15598608.2017.1305922&partnerID=40&md5=46e453252e8914bab5e3d5c4f52d5a4c 0,circular time series received relatively little attention statistics modeling complex circular time series using state space approach nonexistent literature article introduce flexible bayesian nonparametric approach state space modeling observed circular time series even latent states circular random variables crucially assume forms observational evolutionary functions circular nature unknown time varying model unknown circular functions appropriate wrapped gaussian processes desirable properties develop effective markov chain monte carlo strategy implementing bayesian model judiciously combining gibbs sampling metropolisâ€“hastings methods validation ideas simulation study two real bivariate circular time series data sets assume one variables unobserved revealed encouraging performance model methods finally analyze data set consisting directions whale migration considering unobserved ocean current direction latent circular process interest results obtain encouraging posterior predictive distribution observed process correctly predicts observed whale movement â© grace scientific publishing llc
10.1080/10618600.2017.1322091 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031090051&doi=10.1080%2f10618600.2017.1322091&partnerID=40&md5=ad1c6c7db93da9e651916005f15bf4c5 0,discuss efficient bayesian estimation dynamic covariance matrices multivariate time series factor stochastic volatility model particular propose two interweaving strategies substantially accelerate convergence mixing standard mcmc approaches similar marginal data augmentation techniques proposed acceleration procedures exploit nonidentifiability issues frequently arise factor models new interweaving strategies easy implement come almost extra computational cost nevertheless boost estimation efficiency several orders magnitude shown extensive simulation studies conclude application algorithm dimensional exchange rate dataset illustrates superior performance new approach real world data supplementary materials article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/16843703.2017.1304041 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016126453&doi=10.1080%2f16843703.2017.1304041&partnerID=40&md5=b9b3b8355a32cc430e6989ffe9a89638 2,conventionally standard control chart implements fixed sample size process monitoring study propose optimal statistical design variable sample size vss multivariate exponentially weighted moving average mewma chart based median run length mrl proposal based fact percentiles run length distribution especially mrl reflective reliable performance evaluation respect skewed run length distribution mrl vss mewma chart computed using markov chain approach verified monte carlo simulation benchmarking purposes performance vss mewma chart compared standard mewma chart synthetic chart terms mrl numerical results show vss mewma chart performs better standard mewma chart synthetic chart detecting shifts process mean vector finally application provided illustration implementation vss mewma chart based mrl â© international chinese association quantitative management
10.1109/INFOCOM.2017.8057077 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025166811&doi=10.1109%2fINFOCOM.2017.8057077&partnerID=40&md5=33d905c76528c20c06708feef9cada67 1,device device communications long term evolution lte networks relies discovery process enable user equipment ue determine applications services supported neighboring ues especially important groups ues operate outside coverage area base station amount time required discovery information reach every ue group depends number ues group dimensions discovery resource pool associated physical sidelink discovery channel psdch additional factor half duplex property current ues paper use markov chain characterize performance mode direct discovery resulting analytical model gives distribution time ue discover ues group validate model using monte carlo network simulations â© ieee
10.1080/10618600.2017.1328365 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860564&doi=10.1080%2f10618600.2017.1328365&partnerID=40&md5=672bd4a7f9cf61f1607071dafb093f8a 0,stochastic epidemic models describe dynamics epidemic disease spreads population typically fraction cases observed set discrete times absence complete information time evolution epidemic gives rise complicated latent variable problem state space size epidemic grows large population size increases makes analytically integrating missing data infeasible populations even moderate size present data augmentation markov chain monte carlo mcmc framework bayesian estimation stochastic epidemic model parameters measurements augmented subject level disease histories mcmc algorithm propose new subject level path conditional data using time inhomogenous continuous time markov process rates determined infection histories individuals method general may applied broad class epidemic models minimal modifications model dynamics emission distribution present algorithm context multiple stochastic epidemic models data binomially sampled prevalence counts apply method data outbreak influenza british boarding school supplementary material article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/01621459.2017.1281811 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041103280&doi=10.1080%2f01621459.2017.1281811&partnerID=40&md5=0bd878ef21c1942c18ec550f98d45632 0,article considers problem analyzing associations power spectra multiple time series cross sectional outcomes data observed multiple subjects motivating application comes sleep medicine researchers able noninvasively record physiological time series signals sleep frequency patterns signals quantified power spectrum contain interpretable information biological processes important problem sleep research drawing connections power spectra time series signals clinical characteristics connections key understanding biological pathways sleep affects treated improve health analyses challenging must overcome complicated structure power spectrum multiple time series complex positive definite matrix valued function article proposes new approach analyses based tensor product spline model cholesky components outcome dependent power spectra approach flexibly models power spectra nonparametric functions frequency outcome preserving geometric constraints formulated fully bayesian framework whittle likelihood based markov chain monte carlo mcmc algorithm developed automated model fitting conducting inference associations outcomes spectral measures method used analyze data study sleep older adults uncovers new insights stress arousal connected amount time one spends bed supplementary materials article available online â© american statistical association
10.1080/15598608.2017.1281180 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012882020&doi=10.1080%2f15598608.2017.1281180&partnerID=40&md5=5a06052261a24f8acad2535bd24c3787 0,nonparametric regression important tool exploring unknown relationship response variable set explanatory variables also known regressors article introduces associated discrete kernel multivariate nonparametric count regression estimation propose bayesian approach based upon likelihood cross validation monte carlo markov chain mcmc method deriving global optimal bandwidths simulation real count data point performance binomial triangular discrete kernels comparative study bayesian approach cross validation technique also presented â© grace scientific publishing llc
10.1002/mp.12508 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029544689&doi=10.1002%2fmp.12508&partnerID=40&md5=048fbc2186b0cb40c31cedc69d26c3db 1,purpose high dose rate irradiation mv linac x rays wide spread means treat cancer tissue radiotherapy treatment planning relies mathematical description surviving fraction sf linear quadratic model lqm formula however even case high dose rate treatment repair kinetics dna damage dose delivery time plays function predicting dose sf relation may call sf model selection question considering dose delivery time dose rate effects dres radiotherapy vitro cell experiments study demonstrate importance dose delivery time high dose rate irradiations used radiotherapy means bayesian estimation methods evaluate model selection sf three types models lqm two microdosimetric kinetic models without dres mkmdr mkm applied describe vitrosf data work references parameters model evaluated markov chain monte carlo mcmc simulation results mcmc analysis shows cell survival curve mkmdr fits experimental data best terms deviance information criterion dic fractionated regimen fractions total dose gy final cell survival estimated mkmdr higher lqm suggests additional fractions required attaining total dose equivalent yield effect conventional regimen using lqm fractionated radiotherapy conclusions damage repair dose delivery time plays key role precisely estimating cell survival even high dose rate radiotherapy consequently suggested cell killing model without repair factor short dose delivery time may overestimate actual cell killing fractionated radiotherapy â© american association physicists medicine
10.1016/j.cpc.2017.05.027 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021283147&doi=10.1016%2fj.cpc.2017.05.027&partnerID=40&md5=93be0cb991a148b392ac67139aee2ed3 4,analysis tool software package fast nps used analyse smfret data obtain quantitative structural information macromolecules natural environment algorithm bayesian model gives rise multivariate probability distribution describing uncertainty structure determination since fast nps aims easy use general purpose analysis tool large variety smfret networks established mcmc based sampling engine approximates target distribution requires parameter specification user efficient local exploration automatically adapt multivariate proposal kernel according shape target distribution order handle multimodality sampler equipped parallel tempering scheme fully adaptive respect temperature spacing number chains since molecular surrounding dye molecule affects spatial mobility thus smfret efficiency introduce dye models selected every dye molecule individually models allow user represent smfret network great detail leading increased localisation precision finally tool validate chosen model combination provided programme summary programme title fast nps programme files doi http dx doi org ztzj r licencing provisions apache programming language gui matlab mathworks core sampling engine c++ nature problem sampling highly diverse multivariate probability distributions order solve macromolecular structures smfret data solution method mcmc algorithm fully adaptive proposal kernel parallel tempering scheme â© elsevier b v
10.1371/journal.pone.0186391 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031756592&doi=10.1371%2fjournal.pone.0186391&partnerID=40&md5=95e2de423b715030477ae322501028d9 2,progressive character tooth formation records aspects mammalian life history diet seasonal behavior climate tooth mineralization occurs two stages secretion maturation overlap degree despite decades study spatial temporal pattern elemental incorporation enamel mineralization remains poorly characterized use synchrotron x ray microtomography markov chain monte carlo sampling estimate mineralization patterns ontogenetic series sheep molars n = adopt bayesian approach posits general pattern maturation estimated individual population level mineral density variation time approach converts static images mineral density dynamic model mineralization demonstrates enamel secretion maturation waves advance nonlinear rates distinct geometries enamel secretion ordered maturation geometry varies within population appears driven diffusive processes model yields concrete expectations integration physiological environmental signals particular significance paleoseasonality research study also provides avenue characterizing mineralization patterns taxa synchrotron imaging data model available application multiple disciplines including health material science paleontological research â© green et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.16383/j.aas.2017.c160200 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035008344&doi=10.16383%2fj.aas.2017.c160200&partnerID=40&md5=0bebfb41c1964f61ee9529a04d0f9442 0,learning imbalanced datasets traditional fuzzy systems low rate identification minority class firstly antecedent parameter learning stage new clustering method called bayesian fuzzy clustering based competitive learning bfccl proposed partition input space antecedents rules bfccl considers repulsed force clustering prototypes different classes uses alternating iterative strategy obtain optimal model parameters markov chain monte carlo method secondly consequent parameter learning stage based maximum separation strategy keeping distance minority class classification hyperplane larger distance majority class hyperplane method effectively correct skewness classification hyperplane based ideas zero order takagi sugeno kang fuzzy system imbalanced data classification tsk idc proposed experimental results artificial real world medicine datasets illustrate effectiveness tsk idc minority majority classes imbalanced data classification well good robustness interpretability copyright â© acta automatica sinica rights reserved
10.1107/S1600576717012742 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030572405&doi=10.1107%2fS1600576717012742&partnerID=40&md5=120a98509a37977f644a5dc4782e23d6 2,laterally periodic nanostructures investigated grazing incidence small angle x ray scattering gisaxs using diffraction patterns reconstruct surface shape model visible light scattering rigorous calculations near far field numerical solution maxwell equations finite element method well established application technique x rays still challenging owing discrepancy incident wavelength finite element size drawback vanishes gisaxs small angles incidence conical scattering geometry periodicity surface structures allows rigorous computation diffraction efficiencies sufficient numerical precision develop metrology tools based gisaxs lamellar gratings line widths anm produced state art electron beam lithography etched silicon high surface sensitivity gisaxs conjunction maxwell solver allows detailed reconstruction grating line shape thick non homogeneous substrates well reconstructed geometric line shape models statistically validated applying markov chain monte carlo sampling technique reveals gisaxs able reconstruct critical parameters like widths lines sub nanometre uncertainty shallow incidence angles grazing incidence small angle x ray scattering gisaxs allow use rigorous maxwell solver combination finite element method reconstruction nanometre sized periodic surface structures â© international union crystallography
10.1007/s00170-017-0567-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019726364&doi=10.1007%2fs00170-017-0567-8&partnerID=40&md5=9d2af8826731e7b5a6c88ac47ac143ce 1,predicting process forces micromilling difficult due complex interaction cutting edge work material size effect process dynamics study describes application bayesian inference identify force coefficients micromilling process metropolis hastings mh algorithm markov chain monte carlo mcmc approach used identify probability distributions cutting edge ploughing force coefficients based experimental measurements mechanistic model micromilling bayesian inference scheme allows predicting upper lower limits micromilling forces providing useful information stability boundary calculations robust process optimization first part paper micromilling experiments performed investigate influence micromilling process parameters machining forces tool edge condition surface texture experimental conditions used study built edge formation observed significant influence process outputs micromilling titanium alloy ti al v second part bayesian inference explained detail applied model micromilling force prediction force predictions validated experimental measurements paper concludes discussion effectiveness employing bayesian inference micromilling force modeling considering special machining cases â© springer verlag london
10.1016/j.jmarsys.2017.05.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019351720&doi=10.1016%2fj.jmarsys.2017.05.004&partnerID=40&md5=8e4668c0f39f4c0df235a3d62206b4df 0,methods extracting empirically theoretically sound parameter values urgently needed aquatic ecosystem modelling describe key flows variation system compare three bayesian formulations mechanistic model parameterization differ assumptions variation parameter values various datasets global analysis variation separate analysis independent variation hierarchical analysis variation arising shared distribution defined hyperparameters tested methods using computer generated empirical data coupled simplified reasonably realistic plankton food web models respectively methods adequate simulated example demonstrated well designed hierarchical analysis result accurate precise parameter estimates predictions due ability combine information across datasets however results also highlighted sensitivity hyperparameter prior distributions important caveat hierarchical analysis complex empirical example hierarchical analysis able combine precise identification parameter values reasonably good predictive performance although ranking methods less straightforward conclude hierarchical bayesian analysis promising tool identifying key ecosystem functioning parameters variation empirical datasets â© elsevier b v
22.21977854116963 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032947988&partnerID=40&md5=9a3535d9a75d8a04f890d44b2a3a4d8f 2,paper makes two contributions bayesian machine learning algorithms firstly propose stochastic natural gradient expectation propagation snep novel alternative expectation propagation ep popular variational inference algorithm snep black box variational algorithm require simplifying assumptions distribution interest beyond existence monte carlo sampler estimating moments ep tilted distributions opposed ep guarantee convergence snep shown convergent even using monte carlo moment estimates secondly propose novel architecture distributed bayesian learning call posterior server posterior server allows scalable robust bayesian learning cases data set stored distributed manner across cluster compute node containing disjoint subset data independent monte carlo sampler run compute node direct access local data subset targets approximation global posterior distribution given data across whole cluster achieved using distributed asynchronous implementation snep pass messages across cluster demonstrate snep posterior server distributed bayesian learning logistic regression neural networks â© leonard hasenclever stefan webb thibaut lienart sebastian vollmer balaji lakshminarayanan charles blundell yee whye teh
10.3390/e19100561 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031898257&doi=10.3390%2fe19100561&partnerID=40&md5=d68ad7f914e4ea33dafa6ae1490e9e8d 0,markov chain monte carlo sampling propagators including numerical integrators stochastic dynamics central calculation thermodynamic quantities determination structure molecular systems efficiency paramount great extent determined integrated autocorrelation time iact quantity varies depending observable estimated suggested maximum iact observables relevant metric reviewed method estimating quantity reversible propagators satisfy detailed balance maximum iact determined spectral gap forward transfer operator irreversible propagators maximum iact far less greater might inferred spectral gap consistent recent theoretical results mention past practical experience suggesting irreversible propagators generally perform better much better reversible ones typical irreversible propagators parameter controlling mix ballistic diffusive movement gain insight effect damping parameter langevin dynamics optimal value obtained multidimensional quadratic potential energy function â© authors
10.1016/j.csda.2017.04.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019005042&doi=10.1016%2fj.csda.2017.04.005&partnerID=40&md5=26f3664eb3d3db8faa088b6c063ea986 1,application bayesian methods often requires metropolisâ€“hastings related algorithms sample intractable posterior distribution especially challenging cases strongly correlated parameters multimodal posteriors exotic forms metropolisâ€“hastings preferred generating samples within reasonable time algorithms require nontrivial often prohibitive tuning little performance guarantees light difficulty new parallelizable algorithm called weighted particle tempering introduced weighted particle tempering easily tuned suitable broad range applications algorithm works running multiple random walk metropolis chains directed tempered version target distribution weighting iterates resampling algorithm performance monotonically improves underlying chains feature simplifies tuning use simulation studies weighted particle tempering shown outperform two similar methods parallel tempering parallel hierarchical sampling addition two case studies explored breast cancer classification graphical models financial data â© elsevier b v
10.1109/TIFS.2017.2705629 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021666887&doi=10.1109%2fTIFS.2017.2705629&partnerID=40&md5=a04fa3d123c66d3c0ec5c393636a9006 2,analyze sets intrusion detection records observed networks several large nonresidential organizations protected form intrusion detection prevention service analyses reveal process intrusion detection networks exhibits significant degree burstiness well strong memory burstiness memory properties comparable natural processes driven threshold effects different bursty human activities explore time series models observable network security incidents based partially observed data using hidden markov model restricted hidden states fit using markov chain monte carlo techniques examine output fitted model respect statistical properties demonstrate model adequately accounts intrinsic bursting within observed network incidents result alternation two stochastic processes analysis lead directly new detection capabilities practical implications gaining better understanding observed burstiness significant include opportunities quantifying network risks defensive efforts â© ieee
10.1145/3132704 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031324940&doi=10.1145%2f3132704&partnerID=40&md5=906f59676758f9db027ae32b6d8737af 2,study markov chain monte carlo mcmc methods operating primary sample space interactions multiple sampling techniques observe incorporating sampling technique state markov chain done multiplexed metropolis light transport impedes ability chain properly explore path space transitions sampling techniques lead disruptive alterations path samples address issue reformulate multiplexed mlt reversible jump mcmc framework rjmcmc introduce inverse sampling techniques turn light paths random numbers produce allows us formulate novel perturbation locally transition sampling techniques without changing geometry path derive correct acceptance probability using rjmcmc investigate generalize concept noninvertible sampling techniques commonly found practice introduce probabilistic inverses extend perturbation cover sampling methods found light transport simulations theory reconciles inverses rjmcmc yielding unbiased algorithm call reversible jump mlt verify correctness implementation canonical practical scenarios demonstrate improved temporal coherence decrease structured artifacts faster convergence wide variety scenes â© acm
10.1177/0962280215596186 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031687121&doi=10.1177%2f0962280215596186&partnerID=40&md5=5d813932d4ff5ac6c4cbff8b6281e329 5,paper extend spatially explicit survival model small area cancer data allowing dependency space time using accelerated failure time models spatial dependency modeled directly definition survival density hazard functions models developed context county level aggregated data two cases considered first assumes spatial temporal distributions independent second allows dependency spatial temporal components apply models prostate cancer data louisiana seer cancer registry â© author
10.1162/NECO_a_01000 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029290123&doi=10.1162%2fNECO_a_01000&partnerID=40&md5=5c1bc66bb377465f72a88c0f911d8912 2,cluster analysis functional magnetic resonance imaging fmri data often performed using gaussian mixture models time series standardized data reside hypersphere modeling assumption questionable consequences ignoring underlying sphericalmanifold rarely analyzed part due computational challenges imposed directional statistics letter discuss bayesian von mises fisher vmf mixture model data unit hypersphere present efficient inference procedure based collapsed markov chain monte carlo sampling comparing vmf gaussian mixture models synthetic data demonstrate vmf model slight advantage inferring true underlying clustering compared gaussian based models data generated mixture vmfs mixture gaussians subsequently normalized thus performing model selection two models agreement analyzing multisubjectwhole brain resting state fmri data healthy adult subjects find vmf mixture model considerably reliable gaussian mixture model comparing solutions across models trained different groups subjects find two models disagree optimal number components analysis indicates fmri data support thousand clusters confirm result overfitting demonstrating better prediction data held subjects results highlight utility using directional statistics model standardized fmri data demonstrate whole brain segmentation fmri data requires large number functional units order adequately account discernible statistical patterns data â© massachusetts institute technology
10.1016/j.ress.2016.11.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009210567&doi=10.1016%2fj.ress.2016.11.020&partnerID=40&md5=ceebbf7b38feed209615a6b6696ee7da 6,consider three state continuous time semi markov process weibull distributed transition times model degradation mechanism industrial equipment build model original combination techniques proposed building semi markov degradation model based expert knowledge field data within bayesian statistical framework issues addressed prior elicitation model parameters values experts avoiding possible information commitment ii development markov chain monte carlo algorithm sampling posterior distribution iii posterior inference model parameters values basis estimation time dependent state probabilities prediction equipment remaining useful life developed bayesian model offers possibility updating system reliability estimation every time new evidence gathered application modeling framework illustrated way real industrial case study concerning degradation diaphragms installed production line biopharmaceutical industry â© elsevier ltd
10.1111/rssa.12321 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032957010&doi=10.1111%2frssa.12321&partnerID=40&md5=7eaa81a14655956539da344dd881eaf1 0,area level models fayâ€“herriot model aim improve direct survey estimates small areas borrowing strength related covariates direct estimates across areas multivariate form related population characteristics jointly modelled area level models allow inference functions two characteristics may exploit dependence response variables improve small area predictions model covariates observed random error drawn another survey important account error modelling present bayesian analysis multivariate fayâ€“herriot model functional measurement error allowing joint modelling related characteristics accounting random observation error covariates apply modelling poverty rates school aged children us counties predicting poverty rates â€“ changes application measurement error model results great improvements prediction compared direct estimates ignoring measurement error results uncertainty estimates misleading propose computational approach implementing model via independence chain markov chain monte carlo algorithm prove propriety posterior distribution class non informative priors â© authors royal statistical society article contributed us government employees work public domain usa
10.3390/e19100524 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031914866&doi=10.3390%2fe19100524&partnerID=40&md5=855814e7ef1cba94726e593f739a1e5a 0,information geometry extended exponential families received much recent attention variety important applications notably categorical data analysis graphical modelling specifically log linear modelling essential geometry comes closure exponential family high dimensional simplex parallel great deal interest purely fisher riemannian structure extended exponential families especially markov chain monte carlo literature parallel developments raise challenges addressed variety levels theoretical practical relatedly conceptual methodological centrally endeavour paper makes explicit underlying geometry two areas via analysis limiting behaviour fundamental geodesics information geometry amari + geodesics respectively overall substantially complete account information geometry extended exponential families provided hitherto case illustrate importance benefits novel formulation applications â© authors
10.1111/rssa.12301 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021354639&doi=10.1111%2frssa.12301&partnerID=40&md5=054cf41089d5f69fcd78ad2c4288d370 0,brazilian institute geography statistics performs annual service survey focuses segments tertiary sector sample estimates economic activities north north east midwest regions brazil low precision due sample design furthermore one main variables interest considerably skewed potential outliers overcome problem skew normal skew models proposed produce model based estimates small domain estimation models relate operating revenue variables potential auxiliary variables number employed people wages obtained business register models proposed compared usual fayâ€“herriot model assumptions known unknown sampling variances transformed log version assumption known variances evaluation studies real business survey data show models proposed seem efficient small area predictions skewed data customarily employed fayâ€“herriot model well log normal version â© royal statistical society
10.1016/j.jbankfin.2017.06.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025829564&doi=10.1016%2fj.jbankfin.2017.06.010&partnerID=40&md5=a68c6049145b8b7a09189a8a7c0dc02e 1,paper analyzes wide range flexible drift diffusion specifications stochastic volatility jumpâ€“diffusion models daily p index returns find model performance driven almost exclusively specification diffusion component whereas drift specifications second order importance variance dynamics non affine models resemble popular non parametric high frequency estimates variance outperformance mainly accumulated turbulent market regimes finally show jump diffusion models yield reliable estimates expected return variance swap contracts â© elsevier b v
10.1007/s11004-017-9693-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021879749&doi=10.1007%2fs11004-017-9693-y&partnerID=40&md5=00b8e42729ac2e7fdb7ae3851caebc31 1,seismic inverse modeling transforms appropriately processed geophysical data physical properties earth essential process reservoir characterization paper proposes work flow based markov chain monte carlo method consistent geology well logs seismic data rock physics information uses direct sampling multiple point geostatistical method generating realizations prior distribution metropolis sampling adaptive spatial resampling perform approximate sampling posterior distribution conditioned geophysical data assess important uncertainties sampling general approach finding likely model however since rejection sampling requires large number evaluations generating posterior distribution inefficient suitable reservoir modeling metropolis sampling able perform equivalent sampling forming markov chain iterative spatial resampling algorithm perturbs realizations spatially dependent variable preserving spatial structure conditioning subset points however practical applications subset conditioning points selected random get stuck long time non optimal local minimum paper demonstrated adaptive subset sampling improves efficiency iterative spatial resampling depending acceptance rejection criteria possible obtain chain geostatistical realizations aimed characterizing posterior distribution metropolis sampling validity applicability proposed method illustrated results seismic lithofacies inversion stanford vi synthetic test sets â© international association mathematical geosciences
10.1016/j.autcon.2017.06.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024876897&doi=10.1016%2fj.autcon.2017.06.010&partnerID=40&md5=2236ebd1111046d5487e129360df8e0d 1,importance constructability often understated design phase construction project issues regarding constructability often receive sufficient attention late design changes paper proposes quantitative measure truss structural system design used index constructability aspect standardization repetition elements early design stages construction regarded co operative undertaking among architects specify form building builders implement construction tasks designed form alone provide enough information specify feasible processes actual building sufficient fabrication information needed fabricators completely certain concerning actually build form goal study establish model estimating amount information needed construction based shannon information theory amount information based uncertainty concerning assembly construction topological graph designed form knowledge base shared designer builder design build communication model paper entropy uncertainty shown quantified index constructability assessment attributes standardization repetition markov chain monte carlo method symmetry group theories also used model analyze different levels assembly scope research currently focused analyzing constructability truss structure systems assessment constructability demonstrated six different types truss structural systems five alternative designs assessed schoolhouse project cambodia requiring easy construction identified theoretical model results show methodology help architects design easily constructed truss structural systems explore important design principles improving constructability limitations future works discussed final two sections â© elsevier b v
10.1016/j.compbiolchem.2017.07.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024896892&doi=10.1016%2fj.compbiolchem.2017.07.002&partnerID=40&md5=dabeff4be3b74f4aab01e0f3641199af 0,objective explore disturbed molecular functions pathways clear cell renal cell carcinoma ccrcc using gibbs sampling methods gene expression data ccrcc samples adjacent non tumor renal tissues recruited public available database molecular functions expression changed genes ccrcc classed gene ontology go project molecular functions converted markov chains markov chain monte carlo mcmc algorithm implemented perform posterior inference identify probability distributions molecular functions gibbs sampling differentially expressed molecular functions selected posterior value genes appeared times differentially expressed molecular functions â‰¥ defined pivotal genes functional analysis employed explore pathways pivotal genes strongly co regulated genes results work obtained molecular functions differentially expressed oxidoreductase activity showed highest posterior value gene composition analysis identified pivotal genes survival analysis indicated pivotal genes used strong independent predictor poor prognosis patients ccrcc pathway analysis identified one pivotal pathway âˆ’ oxidative phosphorylation conclusions identified differentially expressed molecular functions pivotal pathway ccrcc using gibbs sampling results considered potential signatures early detection therapy ccrcc â© elsevier ltd
10.1061/(ASCE)HE.1943-5584.0001571 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025120060&doi=10.1061%2f%28ASCE%29HE.1943-5584.0001571&partnerID=40&md5=9a462d8485c71919f956e39cb0cb2a13 2,present study analyzes various uncertainties nonstationarity streamflow projections wainganga river basin india representative concentration pathways rcps using layer variable infiltration capacity vic l model uncertainties associated multiple climate models parameters return levels modeled using reliability ensemble averaging rea bayesian analysis delta method respectively recent development extreme value theory evt theannual maximum flows past future modeled nonstationary assumption validated using akaike information criterion aic value likelihood ratio test results obtained study indicate stationary assumption good fit observed stabilized radioactive forcing scenarios rcp whereas highest greenhouse gas emission scenarios rcp nonstationary modeling suitable obtained future flood quantiles rcp likely critical coming century stationary nonstationary assumptions however nonstationary estimate return levels lower return periods useful design low capacity hydraulic structures analysis nonstationary return levels revealed change detection return levels lower return period much earlier higher return period uncertainty analysis return levels showed larger uncertainty bound case rcp rather rcp furthermore quantification uncertainty stationary nonstationary assumptions using bayesian analysis markov chain monte carlo mcmc simulation provided high uncertainty range case nonstationary assumption compared stationary assumption â© american society civil engineers
10.1038/s41559-017-0280-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031925206&doi=10.1038%2fs41559-017-0280-x&partnerID=40&md5=b88137c61d3c08036305913f2ed026e6 5,bayesian methods become popular molecular phylogenetics due availability user friendly software running sophisticated models evolution however bayesian phylogenetic models complex analyses often carried using default settings may appropriate summarize major features bayesian phylogenetic inference discuss bayesian computation using markov chain monte carlo mcmc sampling diagnosis mcmc run ways summarizing mcmc sample discuss specification prior choice substitution model partitioning data finally provide list common bayesian phylogenetic software packages recommend appropriate applications â© author
10.1371/journal.pone.0185910 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031768433&doi=10.1371%2fjournal.pone.0185910&partnerID=40&md5=5afd4ba10beaba3d2d4d646ab5d37861 1,consider continuous time markov chain model sir disease dynamics two levels mixing called stochastic households model provide two methods inferring model parametersâ€”governing within household transmission recovery household transmissionâ€”from data day upon individual became infectious household infection occurred might available first hundred studies method form bayesian markov chain monte carlo allows us calculate joint posterior distribution parameters hence household reproduction number early growth rate epidemic first method performs exact bayesian inference using standard data augmentation approach second performs approximate bayesian inference based likelihood approximation derived branching processes methods compared computational efficiency posteriors compared branching process shown good approximation remains computationally efficient amount data increased â© walker et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1093/biostatistics/kxx007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032448364&doi=10.1093%2fbiostatistics%2fkxx007&partnerID=40&md5=79408acbc1e0deaf2c761f40b8e18edb 2,combined inference heterogeneous high dimensional data critical modern biology clinical various kinds molecular data may available single study classical genetic association studies regress single clinical outcome many genetic variants one one increasing demand joint analysis many molecular outcomes genetic variants order unravel functional interactions unfortunately existing approaches joint modeling either simplistic powerful impracticable computational reasons inspired richardson others bayesian statistics consider sparse multivariate regression model allows simultaneous selection predictors associated responses markov chain monte carlo mcmc inference models prohibitively slow number genetic variants exceeds thousand propose variational inference approach produces posterior information close mcmc inference much reduced computational cost extensive numerical experiments show approach outperforms popular variable selection methods tailored bayesian procedures dealing within hours problems involving hundreds thousands genetic variants tens hundreds clinical molecular outcomes â© author published oxford university press rights reserved
10.1002/cncr.30863 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021424388&doi=10.1002%2fcncr.30863&partnerID=40&md5=571f17287f72eb07e2fbb9a860bc4949 5,background regorafenib multikinase inhibitor demonstrated prolonged survival months second line agent patients hepatocellular carcinoma hcc progress sorafenib therapy objective current study examine cost effectiveness regorafenib treatment hcc methods authors constructed markov simulation model patients unresectable hcc child pugh cirrhosis received treatment regorafenib versus best supportive care model inputs regorafenib effectiveness rates adverse events patients hcc based published clinical trial data literature review quality adjusted life years qalys calculated along incremental cost effectiveness ratio icer regorafenib therapy one way sensitivity analyses also conducted simultaneously model parameters various monte carlo simulation parameters regorafenib cost threshold cost effectiveness achieved determined results regorafenib provided increase qalys cost icer regorafenib compared best supportive care way sensitivity analyses scenarios regorafenib cost effective cost threshold analysis regorafenib priced per pill cost effective icer conclusions regorafenib cost effective second line agent treatment hcc marginal increase qalys high cost lowering cost regorafenib improving selection patients achieve maximal survival benefit improve value second line treatment option patients hcc cancer â€“ â© american cancer society â© american cancer society
10.1177/0272989X17696996 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028646517&doi=10.1177%2f0272989X17696996&partnerID=40&md5=4997a7e6caf91af9f60da670771c689e 1,background new cancer biomarkers discovered rapid pace however tests vary predictive performance characteristics unclear best use methods investigated stage biomarker based screening strategies context prostate cancer using partially observable markov model simulate patients progression prostate cancer states mortality prostate cancer causes patients screened every years ages patient serum prostate specific antigen psa specified threshold first stage second stage biomarker test administered evaluated design characteristics stage strategies using newly discovered biomarkers examples monte carlo simulation used estimate number screening biopsies prostate cancer deaths quality adjusted life years qalys per men results cancer biomarkers significantly underperformed high grade cancer biomarkers terms qalys screening strategy used psa threshold ng ml second biomarker test high grade sensitivity specificity respectively maximized qalys strategy resulted prostate cancer death rate within using psa alone threshold ng ml reducing number biopsies sensitivity analysis suggests results robust respect variation model parameters conclusions two stage biomarker screening strategies using new biomarkers risk thresholds optimized high grade cancer detection may increase quality adjusted survival reduce unnecessary biopsies â© author
10.1134/S1995423917040024 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042731035&doi=10.1134%2fS1995423917040024&partnerID=40&md5=12c7ede8cf2a58f59b33194897512af5 0,part paper consider web page ranking problem also known problem finding pagerank vector google problem discuss link problem ergodic theorem describe different numerical methods solve problem together theoretical background asmarkov chain monte carlo equilibrium macrosystem â© pleiades publishing ltd
10.1177/0962280217708671 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031675034&doi=10.1177%2f0962280217708671&partnerID=40&md5=ebeb79dde157f5637fbfab62b41cf90d 0,frailty models provide convenient way modeling unobserved dependence heterogeneity survival data accounted duly result incorrect inference gamma frailty models commonly used purpose alternative continuous distributions possible well however cure rate present survival data continuous distributions may appropriate since individuals long term survival times encompass zero frailty propose flexible probability distribution induced discrete frailty present special discrete probability distributions specifically focus special hyper poisson distribution develop corresponding bayesian simulation influence diagnostics application real dataset means intensive markov chain monte carlo algorithm illustrate usefulness proposed model well inferential results developed â© author
10.1002/bjs.10582 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023625408&doi=10.1002%2fbjs.10582&partnerID=40&md5=3152ed8d932998e2cc5434714490bb87 7,background intraoperative nerve monitoring ionm provides dynamic neural information recommended high risk thyroid surgery analysis cost effectiveness ionm preventing bilateral recurrent laryngeal nerve rln injury investigated methods markov chain model constructed based ionm use base case patient defined year old woman presenting â· cm left sided papillary thyroid cancer developed rln injury loss monitoring signal planned bilateral thyroidectomy hypothesized surgeon used ionm rln injury detected operation concluded thyroid lobectomy avoid risk contralateral rln injury cost us dollars converted euros probabilities utility scores identified literature government resources length follow set years willingness pay wtp â‚¬ us per quality adjusted life year qaly results end year using ionm strategy accrued â‚¬ â· us â· effectiveness â· qalys whereas use ionm strategy accrued â‚¬ â· us â· effectiveness â· qalys incremental costâ€“effectiveness ratio comparing use versus use ionm â‚¬ â· us â· per qaly proposed wtp indicating ionm preferred cost effective management plan monte carlo simulation test considered variability main study factors hypothetical sample patients showed ionm preferred strategy â· per cent population conclusion use ionm cost effective patients undergoing bilateral thyroid surgery â© bjs society ltd published john wiley sons ltd
10.7589/2016-09-220 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031049194&doi=10.7589%2f2016-09-220&partnerID=40&md5=49857247f71328cb623426e206d39db8 0,infection brucella spp long known cause abortion infertility reproductive loss domestic livestock increasingly documented marine mammals past two decades report molecular evidence brucella infection asian sea otters enhydra lutris lutris brucella dna detected rectal swab samples collected bering island russia animals previously documented brucella seroprevalence markedly higher prevalence documented sea otters enhydra lutris north america dna sequences amplified identical one previously isolated brucella spp including strains terrestrial marine hosts phylogenetic analysis sequence suggested one animal shedding brucella spp dna sequence matching brucella abortus strain whereas two animals yielded sequence matching group strains including isolates classified brucella pinnipedialis brucella melitensis results highlight diversity brucella spp within single sea otter population â© wildlife disease association
10.1007/s11999-017-5437-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021914885&doi=10.1007%2fs11999-017-5437-z&partnerID=40&md5=b1fa1370c5ffb1abf42cefd730ef6081 4,background failure hip preservation alleviate symptoms potentially subjects patient reoperation conversion surgery tha adding recovery time risk cost risk calculator using algorithm predict likelihood patient undergoes arthroscopic hip surgery undergo tha within â years helpful knowledge tool exists questions preoperative intraoperative variables time hip arthroscopy associated subsequent conversion tha variables used develop predictive tool conversion tha materials methods patients undergoing arthroscopy january december registered longitudinal database inclusion criteria study group patients undergoing hip arthroscopy labral tear eventually conversion surgery tha patients compared control group patients underwent hip arthroscopy labral tear undergo conversion surgery tha study period underwent surgery time available followup minimum â years mean â â±â â years considered analysis multivariate regression analyses preoperative intraoperative variables performed using results multivariate regression developed simplified calculator may helpful counseling patient regarding risk conversion tha hip arthroscopy results variables simultaneously associated conversion tha model older age rate ratio ci â€“ pâ â lower preoperative modified harris hip score rate ratio rr ci â€“ pâ =â decreased femoral anteversion rr ci â€“ pâ =â revision surgery rr ci â€“ pâ =â femoral outerbridge grades ii iv grade ii rr ci â€“ pâ =â grade iii rr ci â€“ pâ =â grade iv rr ci â€“ pâ =â performance acetabuloplasty rr ci â€“ pâ =â lack performance femoral osteoplasty rr ci â€“ pâ =â using results multivariate regression developed simplified calculator may helpful counseling patient regarding risk conversion surgery tha hip arthroscopy conclusion multiple risk factors identified possible risk factors conversion tha hip arthroscopy weighted calculator based data presented may useful predicting failure hip arthroscopy labral treatment determining best candidates hip preservation remains challenging careful attention long term followup identifying characteristics associated successful outcomes focus study level evidence level iii therapeutic study â© association bone joint surgeonsâ®
10.1037/xlm0000404 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017399357&doi=10.1037%2fxlm0000404&partnerID=40&md5=b7a118155163fe2be9c2dbc695ac3b50 0,researchers often sought understand learning curve terms multiple component processes studies measured mathematically modeled processes complex task particular remains need reconcile abrupt changes strategy use co occur gradual changes task completion time thus current study aimed assess degree strategy change abrupt gradual whether strategy aggregation partially explain gradual performance change also aimed show bayesian methods used model effect practice strategy use achieve aims participants completed blocks practice complex computer based task wynton anglim booking wab task task allowed multiple component strategies e memory retrieval information reduction insight also aggregated global measure strategy use bayesian hierarchical models used compare abrupt gradual functions component aggregate strategy use task completion time well modeled power function global strategy use explained substantial variance performance change component strategy use tended abrupt whereas change global strategy use gradual well modeled power function thus differential timing component strategy shifts leads gradual changes overall strategy efficiency provides one reason smooth learning curves co occur abrupt changes strategy use â© american psychological association
10.1111/ecog.02194 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010450404&doi=10.1111%2fecog.02194&partnerID=40&md5=fb21e0c028accdfce2a91e9dff20f2ef 3,documentation biological invasions often incomplete records lagging behind speciesâ€™ actual spread spatio temporally heterogeneous extent imperfect observation bears risk underestimating already realised distribution invading species misguiding management efforts misjudging potential future impacts paper develop hierarchical modelling framework disentangles determinants invasion observation processes models spatio temporal heterogeneity detection patterns infers actual yet partly undocumented distribution species particular time illustrate model case study application invasion common ragweed ambrosia artemisiifolia austria invasion part model reconstructs historical spread species across grid âˆ¼ ã— km cells driven spatio temporal variation physical site conditions propagule production dispersal â€˜backgroundâ€™ introductions unknown sources observation part models detection speciesâ€™ occurrences based heterogeneous sampling efforts human population density estimated local invasion level fitted hierarchical model using bayesian inference approach parameters estimated markov chain monte carlo mcmc actual spread artemisiifolia concentrated climatically well suited lowlands mainly driven spatio temporal propagule pressure source cells long distance dispersal occurring rather frequently annual detection probabilities estimated vary depending mainly sampling intensity model suggested half actual distribution species yet documented hierarchical model offers flexible means account imperfect observation spatio temporal variability detection efficiency inferences used disentangle aspects invasion dynamics patterns data collection develop improved future surveying schemes design efficient invasion management strategies â© authors
10.3310/hta21580 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033402252&doi=10.3310%2fhta21580&partnerID=40&md5=22e282c2fa5f7a1a965a77ad9cbbe717 0,background real time modelling essential component public health response outbreak pandemic influenza uk model epidemic reconstruction based realistic epidemic surveillance data developed model needs enhancing provide spatially disaggregated epidemic estimates ensuring real time implementation feasible objectives advance state art real time pandemic modelling developing existing epidemic model capture spatial variation transmission devising efficient computational algorithms provision timely statistical analysis incorporating freely available software methods markov chain monte carlo mcmc sampling used derive bayesian statistical inference using pandemic data two candidate modelling approaches parallel region pr approach splitting pandemic non interacting epidemics occurring spatially disjoint regions meta region mr approach treating country single meta population long range contact rates informed census data commuting model discrimination performed posterior mean deviance statistics alongside practical considerations real time context use sequential monte carlo smc algorithms carry real time analyses investigated alternative mcmc using simulated data designed sternly test algorithms smc derived analyses compared â€˜gold standardâ€™ mcmc derived inferences terms estimation quality computational burden results pr approach provides better timely fit epidemic data estimates pandemic quantities interest consistent across approaches pr approach across regions e g r consistently estimated dropping summer school holiday smc approach developed required tailoring tackle sudden â€˜shockâ€™ data resulting pandemic intervention semi automated smc algorithm outperforms mcmc terms precision estimates timely provision software implementing findings developed installed within public health england phe key staff trained use limitations pr model lacks predictive power forecast spread infection early stages pandemic whereas mr model may limited dependence commuting data describe transmission routes demand resources increases severe pandemic data general practices hospitalisations may become unreliable biased smc algorithm developed semi automated therefore statistical literacy required achieve optimal performance conclusions following objectives study found timely spatially disaggregate real time pandemic inference feasible system assumes data per pandemic preparedness plans developed rapid implementation future work recommendations modelling studies investigating impact pandemic interventions e g vaccination school closure utility alternative data sources e g internet searches augment traditional surveillance correct handling test sensitivity specificity serological data propagating uncertainty real time modelling â© netscc
10.1016/j.ijforecast.2017.06.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026913671&doi=10.1016%2fj.ijforecast.2017.06.006&partnerID=40&md5=b09085c1fc3972dc4abf2941e9dd9521 1,paper develops vector autoregressive models infinite hidden markov structures motivated recent empirical success hierarchical dirichlet process mixture models financial macroeconomic applications begin developing new markov chain monte carlo mcmc method built upon precision based algorithms order improve computational efficiency investigate forecast performances infinite hidden markov switching models forecasting results suggest models separate infinite hidden markov processes var coefficients volatilities generally forecast better specifications infinite hidden markov switching models using single infinite hidden markov process govern model parameters tends result poor forecasts gains obtained forecasting inflation rate gdp growth seem come allowing time variation volatilities rather conditional mean coefficients contrast forecasting short term interest rate important allow time variation model parameters â© international institute forecasters
10.1016/j.engstruct.2017.06.071 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030479775&doi=10.1016%2fj.engstruct.2017.06.071&partnerID=40&md5=e5cd30d52653fdfbc4382d0bd182cd8c 0,paper bayesian approach developed conduct uncertainty quantification single breathing crack beam structure using nonlinear forced responses proposed methodology determines breathing crack characteristics also quantifies associated uncertainties inferred values information important fatigue crack monitoring remaining life prediction cracked beam structures first single degree freedom model developed characterize nonlinear behavior cracked beam modified homotopy perturbation method mhpm applied determine analytical approximate solutions bayesian inference approach proposed applying markov chain monte carlo mcmc technique random walk metropolis algorithm employed objective estimate crack size location nonlinear vibration responses noise added represent actual measurement data finally proposed probabilistic damage detection approach successfully demonstrated breathing crack status quantified associated uncertainties leads new way detecting single breathing crack beam structures â© elsevier ltd
10.1002/qj.3138 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031114463&doi=10.1002%2fqj.3138&partnerID=40&md5=12ba21467ae926a0d3501ca64a51dd3e 8,inverse modelling emissions atmospheric species pollutants significantly progressed past years however spite seemingly reliable estimates retrievals rarely accompanied objective estimate uncertainty except gaussian statistics assumed errors often unrealistic assumption assess rigorous techniques meant compute uncertainty context inverse modelling time emission rates â€“ called source term â€“ point wise atmospheric tracer log normal statistics used positive source term prior possibly observation errors precludes simple gaussian statistics based solutions firstly called empirical bayesian approach parameters error statistics â€“ hyperparameters â€“ first estimated maximizing likelihood via expectationâ€“maximization algorithm enables robust estimation source term uncertainties attached retrieved source rates total emission estimated using four monte carlo techniques importance sampling based laplace proposal ii naive randomize optimize rto sampling approach iii unbiased rto sampling approach iv basic markov chain monte carlo mcmc simulation secondly methods compared thorough hierarchical bayesian approach using mcmc based transdimensional representation source term reduce computational cost methods improvements thereof applied estimation atmospheric caesium source terms chernobyl nuclear power plant accident april may fukushima daiichi nuclear power plant accident march study provides first consistent rigorous quantification uncertainty best estimates â© royal meteorological society
10.1371/journal.pcbi.1005836 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032731576&doi=10.1371%2fjournal.pcbi.1005836&partnerID=40&md5=9943256b5dbb910eaa0e642313da80b2 2,new architectures multilayer artificial neural networks new methods training rapidly revolutionizing application machine learning diverse fields including business social science physical sciences biology interpreting deep neural networks however currently remains elusive critical challenge lies understanding meaningful features network actually learning present general method interpreting deep neural networks extracting network learned features input data describe algorithm context biological sequence analysis approach based ideas statistical physics samples maximum entropy distribution possible sequences anchored input sequence subject constraints implied empirical function learned network using framework demonstrate local transcription factor binding motifs identified network trained chip seq data nucleosome positioning signals indeed learned network trained chemical cleavage nucleosome maps imposing constraint maximum entropy distribution also allows us probe whether network learning global sequence features high gc content nucleosome rich regions work thus provides valuable mathematical tools interpreting extracting learned features feed forward neural networks â© finnegan song
10.1534/genetics.117.300151 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030666936&doi=10.1534%2fgenetics.117.300151&partnerID=40&md5=9e5368fcfa5b9957373cc54a050d9ffe 7,evolutionary transitions male female heterogamety common vertebrates invertebrates theoretical studies transitions found genotypes equally fit continuous paths intermediate equilibria link two sex chromosome systems observation led belief neutral evolution along paths drive transitions arbitrarily small fitness differences among sex chromosome genotypes determine system evolution leads study stochastic evolutionary dynamics along equilibrium paths find non neutrality transitions retaining ancestral pair sex chromosomes creating new pair fact substitution rates biased favor dominant sex determining chromosomes fix higher probabilities mutations effect using diffusion approximations show non neutrality result â€œdrift induced selectionâ€� operating every point along equilibrium paths stochastic jumps paths return average directional bias favor dominant segregating sex chromosome results offer novel explanation observed preponderance dominant sex determining genes hint drift induced selection may common force standard population genetic systems â© genetics society america
10.1007/s11424-017-6010-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018370077&doi=10.1007%2fs11424-017-6010-2&partnerID=40&md5=66645dc91c4937f887bec2786f19c5d0 0,paper proposes bayesian semiparametric accelerated failure time model doubly censored data errors covariates authors model distributions unobserved covariates regression errors via dirichlet processes moreover authors extend bayesian lasso approach semiparametric model variable selection authors develop markov chain monte carlo strategies posterior calculation simulation studies conducted show performance proposed method authors also demonstrate implementation method using analysis pbc data actg data â© institute systems science academy mathematics systems science cas springer verlag berlin heidelberg
10.1016/j.advwatres.2016.10.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006056338&doi=10.1016%2fj.advwatres.2016.10.004&partnerID=40&md5=99267a7112d02ae159fd60526e5081c9 4,although treatment cholera well known cheap outbreaks epidemic regions still exact high death tolls mostly due unpreparedness health care infrastructures face unforeseen emergencies context mathematical models prediction evolution ongoing outbreak paramount importance test real time forecasting framework readily integrates new information soon available periodically issues updated forecast spread cholera modeled spatially explicit scheme accounts dynamics susceptible infected recovered individuals hosted different local communities connected hydrologic human mobility networks framework presents two major innovations cholera modeling use data assimilation technique specifically ensemble kalman filter update state variables parameters based observations use rainfall forecasts force model exercise simulating state system predictive capabilities novel tools set initial phase haitian cholera outbreak using information available time serves benchmark results suggest assimilation procedure sequential update parameters outperforms calibration schemes based markov chain monte carlo moreover forecasting mode model usefully predicts spatial incidence cholera least one month ahead performance decreases longer time horizons yet allowing sufficient time plan deployment medical supplies staff evaluate alternative strategies emergency management â© authors
10.1016/j.spl.2017.05.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020426936&doi=10.1016%2fj.spl.2017.05.011&partnerID=40&md5=60dfe6002b4bdee06f2565c1c2639f60 1,markov chain monte carlo mcmc algorithms ubiquitous probability theory general machine learning particular markov chain devised stationary distribution probability distribution interest one samples given distribution running markov chain â€œlong timeâ€� appears stationary collects sample however chains often complex theoretical guarantees stationarity actually reached paper study gibbs sampler posterior distribution simple case latent dirichlet allocation attractive bayesian unsupervised learning model text generation text classification turns situations mixing time gibbs sampler exponential length documents practically impossible properly sample posterior documents sufficiently long â©
10.1016/j.irfa.2017.08.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029424910&doi=10.1016%2fj.irfa.2017.08.004&partnerID=40&md5=f879f6bd654079b1f1d64f840d89d08b 1,parameter estimation risk non trivial asset pricing risk management adopt bayesian estimation paradigm supported markov chain monte carlo inferential techniques incorporate parameter estimation risk financial modelling option pricing activities find merton jump diffusion mjd model outperforms black scholes bs model sample sample addition construction bayesian posterior option price distributions two well known models offers robust view influence parameter estimation risk option prices well quantities interest finance probabilities default derive var type parameter estimation risk measure option pricing show parameter estimation risk bring significant impact greeks hedging activities regarding computation default probabilities find impact parameter estimation risk increases gearing level alter important risk management decisions â© elsevier inc
10.22034/APJCP.2017.18.10.2709 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031934745&doi=10.22034%2fAPJCP.2017.18.10.2709&partnerID=40&md5=ab296ad2b7a2aedbdc10b82d070716c7 0,background previous study classify malignant breast tumor details based markov chain monte carlo mcmc convergence western nigeria study therefore aims profile patients living benign malignant breast tumor two different hospitals among women western nigeria focus prognostic factors mcmc convergence materials methods hospital based record used identify prognostic factors malignant breast cancer among women western nigeria paper describes bayesian inference demonstrates usage estimation parameters logistic regression via markov chain monte carlo mcmc algorithm result bayesian approach compared classical statistics results mean age respondents â± years women aged years results techniques suggest age women least high school education significantly higher risk diagnosed malignant breast tumors benign breast tumors results also indicate reduction standard errors associated coefficients obtained bayesian approach addition simulation result reveal women least high school times risk malignant breast lesion western nigeria compared benign breast lesion conclusion concluded efforts required towards creating awareness advocacy campaigns prevalence malignant breast lesions reduced especially among women application bayesian produces precise estimates modeling malignant breast cancer
10.3847/1538-4357/aa88bf https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031094155&doi=10.3847%2f1538-4357%2faa88bf&partnerID=40&md5=2eb75d3d978b04ff6a912545387825ab 0,cosmological origin carbon fourth abundant element universe well known matter heavy debate investigate behavior c h order constrain production mechanism carbon measured emission line intensities spectral range space telescope imaging spectrograph stis long slit spectra starburst galaxies local universe determined chemical abundances traditional nebular analysis used markov chain monte carlo method determine carbon oxygen abundances lie parameter space conclude c abundance measurements sensible analyzed behavior sample c versus h diagram respect objects dlas neutral ism measurements disk halo stars finding type object seems located specific region diagram sample shows steeper c versus h slope respect samples suggesting massive stars contribute production c n higher metallicities objects massive stars numerous otherwise intermediate mass stars dominate c n production â© american astronomical society rights reserved
10.1093/mnras/stx1531 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041370662&doi=10.1093%2fmnras%2fstx1531&partnerID=40&md5=a6f1aea3ee258799a21ea8f6d83bdfc2 7,subset short gamma ray bursts sgrbs exhibit rebrightening highenergy light curves known extended emission bursts potential discern various models proposed describe sgrbs model needs account extended emission paper combine fallback accretion magnetar propeller model investigate morphological changes fallback accretion model light curves fit afterglows sgrbs exhibiting extended emission swift archive parametrized fallback terms existing parameters within propeller model solved disc mass angular frequency magnetar time apply markov chain monte carlo routine produce fits data present fits extended emission sgrb sample morphologically energetically consistent data provided swift burst alert telescope x ray telescope parameters derived fits consistent predictions formagnetar properties fallback accretionmodels fallback accretion provides noticeable improvement fits light curves sgrbs extended emission compared previous work play important role explaining features variability flares long dipole plateaux â© authors
10.1089/aid.2017.0091 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031115661&doi=10.1089%2faid.2017.0091&partnerID=40&md5=eb70e4a53c10ee1fc471f044045277cc 1,crf bc originally formed yunnan province china spread quickly injecting drug users idus recent years introduced men sex men msm become dominant strain china study performed comprehensively phylodynamic analysis crf bc sequences china crf bc sequences identified china retrieved database sequences obtained laboratory added make dataset representative maximum likelihood ml tree constructed phyml maximum clade credibility mcc tree effective population size predicted using markov chains monte carlo sampling method beast software total crf bc sequences coving bp gag gene according hxb calculator included dataset three epidemic clusters identified two clusters comprised sequences idus one cluster mainly contained sequences msms time recent common ancestor clusters composed sequences msms estimated two rapid spreading waves effective population size crf bc infections identified skyline plot second wave coincided expanding msm cluster results indicated control crf bc infections msms help decrease epidemic china â© copyright mary ann liebert inc
10.1007/s11295-017-1177-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027588966&doi=10.1007%2fs11295-017-1177-1&partnerID=40&md5=72408c71e5ce58a1a49f5b13ac60ebc5 1,despite interest foresters inter specific hybrid trees still little known quantitative genetics especially true hybrid hl larix decidua el l kaempferi jl long term well designed multi site experiments necessary estimate parameters required hl breeding programs paper presents results diallel mating trial nine el nine jl set three contrasted sites growth traits height circumference quality traits wood density stem form heartwood proportion bud flush measured plantation â years plantation wood density heartwood proportion assessed using increment cores spatial analysis take account environmental heterogeneity tree level fitted multi trait bayesian mcmc markov chain monte carlo genetic model study confirmed situations hl expressed heterosis best parent growth traits taking advantage early faster growth loss wood density however growth traits showed low levels heritability hand bud flush stem flexuosity high heritabilities wood density clearly jl control site dependent heritabilities expressed el additive genetic correlations presented traits high heritabilities showed high correlation performances pure species hybridization well high across site correlations discussion focused interest genetic parameters hybrid larch breeding programs â© springer verlag gmbh germany
10.7511/jslx201705003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040171435&doi=10.7511%2fjslx201705003&partnerID=40&md5=3ac8379125caea9b1b4735b140ca2b1f 0,traditional models critical diagonal crack angle shear critical reinforced concrete rc column generally deterministic exhibit low accuracy large scatter due fact consider uncertainties various influential factors material parameters geometric dimension boundary constraints order overcome limitations probabilistic model critical diagonal crack angle shear critical rc column established study deterministic model critical diagonal crack angle shear critical rc column proposed based variable angle truss model first probabilistic model critical diagonal crack angle shear critical rc column takes account influence epistemic aleatory uncertainties developed combining bayesian theory markov chain monte carlo mcmc method moreover analytical expressions mean variance probabilistic critical diagonal crack angle also derived accuracy efficiency proposed probabilistic model validated comparing experimental data existing deterministic models indicates proposed probabilistic model describe probabilistic characteristic critical diagonal crack angle shear critical rc column reasonably importantly proposed probabilistic model provides benchmark calibrate confidence level traditional deterministic models also efficient way determine characteristic values critical diagonal crack angles shear critical rc column different confidence levels â© editorial office chinese journal computational mechanics right reserved
10.1016/j.rse.2017.08.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026904414&doi=10.1016%2fj.rse.2017.08.012&partnerID=40&md5=522dd723cb291f5a717a2959d165088b 1,thorough understanding full waveform fw lidar data processing associated uncertainty critical vegetation applications retrieving forest structure variables estimating forest biomass paper applies bayesian non linear modeling concept process small footprint fw lidar data bayesian decomposition collected study site national ecological observatory network neon investigate potential waveform decomposition uncertainty estimation specifically several possible models suitable fitting waveforms assessed within bayesian framework gaussian model selected perform bayesian decomposition subsequently conducted performance evaluation uncertainty analysis parameter derived point cloud surface model levels results model reasonableness show gaussian model superior alternative models respect uncertainty physical meaning processing efficiency converting waveforms discrete points model comparisons demonstrate bayesian decomposition utilized fw lidar data processing results comparable direct decomposition dd gold rl richardsonâ€“lucy approaches terms root mean squared error rmse point distances waveform based point cloud reference point cloud additionally points extracted fw lidar data methods discrete return lidar data especially mid story vegetation based results height bins percentile heights canopy lidar density individual tree level moreover uncertainty estimates bayesian method enhance credibility decomposition results probabilistic sense capture true error estimates trace uncertainty propagation along processing steps example results surface model yield larger rmse values vs wider credible interval quantile point clouds compact distribution contrast commonly used deterministic approaches bayesian decomposition method produce ensemble reasonable parameter estimates probability markov chain monte carlo mcmc sampling posterior distribution model parameters parameter estimates corresponding derived products queried provide meaningful interpretation results associated uncertainty flat priors empirical priors achieve good performance decomposition empirical priors tend significantly speed model convergence bayesian approach also renders important insight uncertainty model performance evaluation using field data generating reasonable prediction intervals reduce inherent errors field measurements â©
10.1002/sim.7384 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021697702&doi=10.1002%2fsim.7384&partnerID=40&md5=f9f3fde854ced1c9d2f5bfcfcd275310 0,systems biology great interest identify new genes previously reported associated biological pathways related various functions diseases identification new pathway modulating genes promote understanding pathway regulation mechanisms also allow identification novel targets therapeutics recently biomedical literature considered valuable resource investigate pathway modulating genes majority currently available approaches based co occurrence genes within abstract reported approaches show sub optimal performances abstracts contain information single gene overcome limitation propose novel statistical framework based concept ontology fingerprint uses gene ontology extract information large biomedical literature data proposed framework simultaneously identifies pathway modulating genes facilitates interpreting functions new genes also propose computationally efficient posterior inference procedure based metropolisâ€“hastings within gibbs sampler parameter updates poor man reversible jump markov chain monte carlo approach model selection evaluate proposed statistical framework simulation studies experimental validation application studies pathway modulating genes yeast r implementation proposed model currently available https dongjunchung github io bayesgo copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1002/sim.7374 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021305386&doi=10.1002%2fsim.7374&partnerID=40&md5=36a81bd8385c0c7ef50f3b8825394fa9 1,subgroup identification clustering important problem biomedical research gene expression profiles commonly utilized define subgroups longitudinal gene expression profiles might provide additional information disease progression captured baseline profiles alone therefore subgroup identification accurate effective aid longitudinal gene expression data however existing statistical methods unable fully utilize data patient clustering article introduce novel clustering method bayesian setting based longitudinal gene expression profiles method called bclustlong adopts linear mixed effects framework model trajectory genes time clustering jointly conducted based regression coefficients obtained genes order account correlations among genes alleviate high dimensionality challenges adopt factor analysis model regression coefficients dirichlet process prior distribution utilized means regression coefficients induce clustering extensive simulation studies show bclustlong improved performance clustering methods applied dataset severely injured burn trauma patients model able identify interesting subgroups copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.5194/bg-14-4295-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030465062&doi=10.5194%2fbg-14-4295-2017&partnerID=40&md5=913daced06ed31e7e3675c6162de0802 4,calibration terrestrial ecosystem models important challenging bayesian inference implemented markov chain monte carlo mcmc sampling provides comprehensive framework estimate model parameters associated uncertainties using posterior distributions effectiveness efficiency method strongly depend mcmc algorithm used work differential evolution adaptive metropolis dream algorithm used estimate posterior distributions parameters data assimilation linked ecosystem carbon dalec model using years daily net ecosystem exchange data collected harvard forest environmental measurement site eddy flux tower calibration dream results better model fit predictive performance compared popular adaptive metropolis scheme moreover dream indicates two parameters controlling autumn phenology multiple modes posterior distributions identifies one mode application suggests dream suitable calibrate complex terrestrial ecosystem models uncertain parameter size usually large existence local optima always concern addition effort justifies assumptions error model used bayesian calibration according residual analysis result indicates heteroscedastic correlated gaussian error model appropriate problem consequent constructed likelihood function alleviate underestimation parameter uncertainty usually caused using uncorrelated error models â© author
10.1016/B978-0-12-813968-4.00008-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048016788&doi=10.1016%2fB978-0-12-813968-4.00008-0&partnerID=40&md5=7982b28bbd666bc54c476582b196e778 1,paper motivated imaging genetics studies goal perform feature selection among multivariate phenotypes ultrahigh dimensional genotypes specifically propose novel multilevel sequential selection procedure bayesian multivariate response regression model select informative features among multivariate responses ultrahigh dimensional predictors treat identification nonzero elements sparse coefficient matrix hierarchical feature selection problem first selecting potential nonzero rows among matrix genotype selection localizing nonzero elements within marked rows phenotype selection genotypewise selection accomplished constructing multilevel auxiliary selection models different scales actual scale auxiliary model treated another level ultimate phenotypewise selection apply method alzheimer disease neuroimaging initiative biologically meaningful results obtained â© elsevier inc rights reserved
10.11990/jheu.201605025 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035147825&doi=10.11990%2fjheu.201605025&partnerID=40&md5=b183919c62976e67ed9243e9fda3187a 0,dynamic system simulation effective ship embarking disembarking harbors necessary quantitatively analyze identify risk evolution ship pilotage specific waters safety control study working process pilotage operation ship port waters analyzed risk degrees different ship pilotage operation tasks determined calculation result shows transfer pilotage state complies markov steady state characteristics remains stable tide type fluctuations addition transferring variable remarkably affects whole ship flow harbor dynamic system simulation model markov chain monte carlo algorithm suitable risk analysis maritime traffic risk provide basic law evolution risk safety management marine traffic â© editorial department journal heu right reserved
10.7527/S1000-6893.2017.220832 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037540479&doi=10.7527%2fS1000-6893.2017.220832&partnerID=40&md5=9631180125f74bc65eae413286bd8472 1,quantify uncertainties model low cycle fatigue life prediction classic model calibration method applied using bayesian theory error term verified normality test posterior distribution model parameter samples obtained markov chain monte carlo mcmc simulation application presented interval fatigue life prediction well describes dispersity real tests small data samples correlation analysis samples parameters conducted establish heteroscedastic regression model comparison two models shows heteroscedastic regression model questionable uncertainty quantification performance morris global sensitivity analysis method applied quantify sensitivity parameters manson coffin model indicating non informative prior reasonable posterior distribution sensitive prior â© press chinese journal aeronautics right reserved
10.1016/j.ecolmodel.2017.07.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026211612&doi=10.1016%2fj.ecolmodel.2017.07.011&partnerID=40&md5=be7b383646d864c2fdf96058e64afccd 2,bayesian method involving markov chain monte carlo mcmc technique implemented pesticide fate transport model estimate best input parameter ranges considering uncertainties included observed pesticide concentrations model methodology used integrating mcmc technique pollutant fate transport models detailed uncertainties encompassed dissolution rate adsorption coefficient herbicide mefenacet greatly reduced mcmc simulations addition optimal set input parameters extracted mcmc simulations accurately reproduced mefenacet concentrations paddy water paddy soil compared original published dataset consequently simultaneously optimizing multiple parameters environmental models conducting uncertainty analysis mcmc technique exhibits powerful capability improving reliability accuracy computer models main strengths mcmc methodology consideration uncertainties input parameters observations prior distributions input parameters reformulate additional knowledge available â© elsevier b v
10.1109/CLUSTER.2017.68 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032646282&doi=10.1109%2fCLUSTER.2017.68&partnerID=40&md5=1cd17d14999add8d1c21f5ccc1d97f84 0,markov chain monte carlo methods provide tool tackling high dimensional problems many core systems readily available today surprise leveraging parallelism samplers subject recent research focus solutions shared memory architectures however perform poorly distributed memory environment paper introduces fully decentralized version affine invariant sampler observing pseudorandom number generator makes stochastic algorithms deterministic communication minimized hidden computation two cases opposite ends communication computation ratio spectrum used evaluation currently available master slave solution tenfold reduction execution time measured â© ieee
10.1103/PhysRevE.96.032312 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029828746&doi=10.1103%2fPhysRevE.96.032312&partnerID=40&md5=df56d5d7b12e56b1ea95cadb062babb7 3,simplicial complexes popular alternative networks comes describing structure complex systems primarily encode multinode interactions explicitly new description comes need principled null models allow easy comparison empirical data propose natural candidate simplicial configuration model core contribution efficient uniform markov chain monte carlo sampler model demonstrate usefulness short case study investigating topology three real systems randomized counterparts using betti numbers two three systems model allows us reject hypothesis organization beyond local scale â© american physical society
10.1080/00949655.2017.1341887 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021297390&doi=10.1080%2f00949655.2017.1341887&partnerID=40&md5=60f65c02b3d500d6028c8f65579e363e 0,screening procedures play important role data analysis especially high throughput biological studies datasets consist covariates independent subjects article bayesian screening procedure introduced binary response models logit probit links contrast many screening rules based marginal information involving one covariates proposed bayesian procedure simultaneously models covariates uses closed form screening statistics specifically use posterior means regression coefficients screening statistics imposing generalized g prior regression coefficients derive analytical form posterior means compute screening statistics without markov chain monte carlo implementation evaluate utility proposed bayesian screening method using simulations real data analysis sample size small simulation results suggest improved performance comparable computational cost â© informa uk limited trading taylor francis group
10.1088/1742-6596/890/1/012146 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030709760&doi=10.1088%2f1742-6596%2f890%2f1%2f012146&partnerID=40&md5=53ed0226cebf029098055d0da235ca61 0,analysis flood trends vital since flooding threatens human living terms financial environment security data annual maximum river flows sabah fitted generalized extreme value gev distribution maximum likelihood estimator mle raised naturally working gev distribution however previous researches showed mle provide unstable results especially small sample size study used different bayesian markov chain monte carlo mcmc based metropolis hastings algorithm estimate gev parameters bayesian mcmc method statistical inference studies parameter estimation using posterior distribution based bayes theorem metropolis hastings algorithm used overcome high dimensional state space faced monte carlo method approach also considers uncertainty parameter estimation presents better prediction maximum river flow sabah â© published licence iop publishing ltd
10.1109/ECOC.2017.8346217 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046950338&doi=10.1109%2fECOC.2017.8346217&partnerID=40&md5=3de64b5d686d5ecf601b1ecb4a3fcd5e 6,model experimentally demonstrate self learning abstraction process based statistical assessment real time monitoring data amplifier non linear noise parameters periodically updated enables accurate qot estimator â© ieee
10.1186/s12918-017-0453-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029765475&doi=10.1186%2fs12918-017-0453-x&partnerID=40&md5=551ad59866992c800252f98b4342e489 0,background phylogenetic analysis key way understand current research biological processes detect theory evolution natural selection evolutionary relationship species generally reflected form phylogenetic trees many methods constructing phylogenetic trees based optimization criteria extract biological data via modeling features compare characteristics study biological evolution species results use maximum likelihood bayesian inference method establish phylogenetic trees multi chain markov chain monte carlo sampling method used select optimal phylogenetic tree resolving local optimum problem correlation model phylogenetic analysis assumes phylogenetic trees built homogeneous data however exists large deviation presence heterogeneous data use conscious detection solve compositional heterogeneity method evaluated two sets experimental data group bacterial ribosomal rna gene data group genetic data five homologous species conclusions method obtain accurate phylogenetic trees homologous data also detect compositional heterogeneity experimental data provide efficient method enhance accuracy generated phylogenetic tree â© author
10.1093/mnras/stx1402 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023772587&doi=10.1093%2fmnras%2fstx1402&partnerID=40&md5=36f12fd9ed801678bccb2b5bec7b86c1 3,present î³ ray observations flat spectrum radio quasar pks + z= using fermi large area telescope data accumulated january december î³ ray flare observed january flux increased â± ã— photon cm flux doubling time scale short spectral analysis shows april april mev gev photon index hardened changes range î“ = time hardest photon index î“ = â± observed mjd common flat spectrum radio quasars period î³ ray spectrum shows possible deviation simple power law shape indicating spectral cutoff ecut = â± gev spectral energy distributions quiescent flaring states modelled using one zone leptonic models include synchrotron synchrotron self compton external inverse compton processes model parameters estimated using markov chain monte carlo method emission flaring states modelled assuming either bulk lorentz factor magnetic field increased modelling shows hint hardening low energy index underlying non thermal distribution electrons responsible emission april hardening agrees î³ ray data pointed significant î³ ray photon index hardening april â© authors published oxford university press
10.1109/ICTIS.2017.8047838 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032824341&doi=10.1109%2fICTIS.2017.8047838&partnerID=40&md5=fdcbf70bd6c2f89d24a04f14b81e56c0 0,order control reduce risk water transportation necessary study evolution trend marine traffic risk new risk simulation model based markov chain monte carlo algorithm mcmc proposed marine traffic risk analysis near land first spatial state transfer model ship traffic risk waters adjacent land established second spatial transfer hypothesis matrix conducted ships operating offshore coastal port waters third risk value traffic waters stochastic process obtained using mcmc method carry random sampling finally combined typical coastal marine traffic data risk occurrence law changing trend analyzed different traffic waters simulation empirical data shows ship traffic risks respectively offshore coastal port waters risk high unstable restricted waters mcmc simulation method applied study characteristics traffic risk waters adjacent land provides theoretical reference improving safety accident prevention certain marine traffic waters â© ieee
10.1109/ICTIS.2017.8047839 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032806648&doi=10.1109%2fICTIS.2017.8047839&partnerID=40&md5=3848165370acb1df7f19bf929422aedc 0,order quantitatively analyze identify risk evolution ship pilotage specific waters necessary simulation dynamic system effectively carry ship harbor purpose safety control firstly degree risk different pilotage tasks established ship transition equation fairway berth vicinity anchorage roadsteads proposed harbor pilotage workflow analysis secondly markov chain transition matrix risk simulation model pilotage dynamic system constructed state stochastic transition trends dynamic risk different pilotage tasks analyzed thirdly help data binding scenarios harbor pilotage status risk simulation harbor pilotage dynamic systems built furthermore examples verification carried harbor pilotage samples eastern china illustrative example shows transition pilotage state steady state markov characteristics keeps stable fluctuations non symmetric flow ship harbor causes pilotage risk fluctuation time change overall situation risk ship pilotage remains steady value individual risk ship pilotage remains steady value dynamic system simulation model using markov chain monte carlo algorithm suitable maritime traffic risk analysis turns basic characteristic evolution risk marine traffic safety control â© ieee
10.1088/1742-6596/888/1/012216 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032442360&doi=10.1088%2f1742-6596%2f888%2f1%2f012216&partnerID=40&md5=9a33a8533f11cd44d31e8b6b39cb525c 0,present details first k neutrino antineutrino oscillation results data collected using muon neutrino enhanced neutrino beam muon antineutrino enhanced neutrino beam analysed equating ã— protons target pot ã— pot respectively disappearance appearance data analysed using bayesian markov chain monte carlo method providing first ever sensitivity cp violating phase î´cp k data alone k data favour near maximal mixing sin î consistent previous k measurements value sin î consistent measurements reactor experiments î´cp close ï€ fitting k data alone credible interval î´cp disfavours values around ï€ î´cp âˆ‰ rad using prior sin î reactor measurements credible interval contains î´cp âˆ‰ rad disfavouring cp conserving values â±ï€ effect result î´cp prior also investigated presented â© published licence iop publishing ltd
10.1080/03610926.2016.1205619 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020725414&doi=10.1080%2f03610926.2016.1205619&partnerID=40&md5=1eb2c300a4b07e462d1ca0e5b85a34b6 0,three linear prediction methods single missing value stationary first order multiplicative spatial autoregressive model proposed based quarter observations observations first neighborhood observations nearest neighborhood three different types innovations including gaussian symmetric thin tailed exponential skew right asymmetric laplace skew heavy tailed considered case proposed predictors compared based two well known criteria mean square prediction pitman measure closeness parameter estimation performed maximum likelihood least square errors markov chain monte carlo mcmc â© taylor francis group llc
10.1016/j.ymssp.2017.02.042 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016606537&doi=10.1016%2fj.ymssp.2017.02.042&partnerID=40&md5=a34688901eba5c4ae0a4fb8edf8455a0 5,imprecise probability based methods developed study parameter estimation finite element model updating concrete structures measurements imprecisely defined bayesian analysis using metropolis hastings algorithm parameter estimation generalized incorporate imprecision present prior distribution likelihood function measured responses three different cases considered imprecision present prior distribution measurements ii imprecision present parameters finite element model measurement iii imprecision present prior distribution parameters finite element model measurements procedures also developed integrating imprecision parameters finite element model finite element software abaqus proposed methods verified reinforced concrete beams prestressed concrete beams tested laboratory part study â© elsevier ltd
10.1016/j.engstruct.2017.05.063 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033376517&doi=10.1016%2fj.engstruct.2017.05.063&partnerID=40&md5=67bb6e2cc0bfdda77ee65bfc47e4d252 1,study investigates failure probability steel frame structures terrorist attack vehicle borne improvised explosive device vbied two step approach used evaluate collapse potential structures blast loads first step damage degree responses structural members blast loads determined based equivalent singleâ€“degree freedom system second step post blast collapse behavior steel frame structures investigated using nonlinear macro based numerical model improve computational efficiency failure probability calculated using subset simulation method cooperated advanced delayed rejection adaptive markov chain monte carlo simulation algorithm variability blast load vertical gravity load structural material properties considered computational framework applied prototype story steel frame study failure risk vbied results show reliability assessment framework used study provides accurate efficient prediction failure risk structures blast loads compared direct monte carlo simulation method framework also presents approach determination effective measures protecting structures blast loads â© elsevier ltd
10.1088/1741-4326/aa8387 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034456169&doi=10.1088%2f1741-4326%2faa8387&partnerID=40&md5=4e9450c6e931e6d26d7f15aa0354e413 1,remains open question explain dramatic change intrinsic rotation induced slight changes electron density white et al phys plasmas one proposed explanation momentum transport sensitive second derivatives temperature density profiles lee et al plasma phys control fusion widely considered impossible measure higher derivatives paper show possible estimate second derivatives electron density temperature using nonparametric regression technique known gaussian process regression technique avoids constraining fit assuming explicit functional form fitted curve uncertainties obtained rigorously using markov chain monte carlo sampling small enough reasonable explore hypotheses depend second derivatives found differences second derivatives peaked hollow rotation cases rather small suggesting changes second derivatives likely explain experimental results â© iaea vienna
10.1016/j.prevetmed.2017.07.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024843002&doi=10.1016%2fj.prevetmed.2017.07.005&partnerID=40&md5=73ceed1c06c314889095e3aabab52257 1,accurate information geographic distribution domestic animal populations helps biosecurity authorities efficiently prepare rapidly eradicate exotic diseases foot mouth disease fmd developing maintaining sufficiently high quality data resources expensive time consuming statistical modelling population density distribution begun applied farm animal populations although commonly used wildlife ecology developed zero inflated poisson regression models bayesian framework using environmental socioeconomic variables predict counts livestock units lsus cattle spatially referenced farm polygons commercially available new zealand farm database agribase farm level counts cattle lsus varied considerably region heterogeneous farming landscape new zealand amount high quality pasture per farm significantly associated presence cattle lsus internal model validation predictive performance showed models able predict count animal population groups farms located randomly selected â km zones high level accuracy predicting cattle lsu counts individual farms less accurate predicted counts statistically significantly variable farms contract grazing dry stock replacement dairy heifers dairy cattle currently producing milk compared farm types analysis presents way predict numbers lsus cattle farms using environmental socio economic data technique potential extrapolated predicting pastoral based livestock species â© elsevier b v
10.1016/j.ymssp.2017.02.023 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016649492&doi=10.1016%2fj.ymssp.2017.02.023&partnerID=40&md5=e813c995f39df89af5e06326df3283e0 6,paper introduces bayesian regularization applied force analysis technique fat method identifying vibration sources displacement measurements fat based equation motion structure instead transfer matrix case inverse problems particularity allows estimation vibration sources without need boundary conditions nevertheless method highly sensitive noise perturbations needs careful regularization two bayesian approaches thus presented firstly empirical bayesian regularization shows better robustness l curve gcv regularizations keeping low numerical cost secondly fully bayesian procedure using markov chain monte carlo mcmc algorithm provides credible intervals variables interest besides automatically regularized vibration source field particular measurement quality evaluated noise variance estimation uncertainties source level quantified wide frequency range unique measurement scan â© elsevier ltd
10.1016/j.virusres.2017.03.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017410681&doi=10.1016%2fj.virusres.2017.03.020&partnerID=40&md5=1451b729bd8d5b34623c12bae11b9ab5 4,grapevine red blotch associated virus grbav causative agent red blotch disease member genus grablovirus family geminiviridae first known geminivirus vitis spp limited information available epidemiology red blotch disease hectare vitis vinifera cv â€˜cabernet francâ€™ vineyard napa county california usa selected monitoring grbav spread three year period â€“ based initially low disease incidence aggregation symptomatic vines edge vineyard proximal wooded riparian area incidence diseased plants increased â€“ annually spatial analysis diseased plants year using ordinary runs analysis within rows spatial analysis distance indices sadie demonstrated aggregation spatiotemporal analysis consecutive years within association function sadie revealed strong overall association among three years x = â€“ analysis epidemic spread fitting stochastic spatiotemporal model using monte carlo markov chain method identified strong evidence localized within vineyard spread spatial pattern consisting combination strongly aggregated randomly isolated symptomatic vines within years post planting suggested unique epidemic attributes compared grapevine viruses vectored mealybugs soft scales dagger nematodes typical within row spread small scale autocorrelation well documented findings consistent existence new type vector grapevine virus â© elsevier b v
10.1080/15325008.2017.1404660 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041107739&doi=10.1080%2f15325008.2017.1404660&partnerID=40&md5=0cf42e5c3fbf483cc9f4e10d4a774dfa 1,probabilistic adequacy evaluation allocated spinning reserve beneficial economically regulating foremost auxiliary service counterbalance unforeseen generation demand mismatches time horizon probabilistic spinning reserve adequacy investigation task may vary several dozens minutes adaptive importance sampling methods classical cross entropy method variants appealing instead classical non sequential monte carlo estimate desired reliability indices due rareness demand supplied contingencies article new adaptive cross entropy method proposed particularly nesting specially optimized partially collapsed gibbs sampler help avoidance locally trapped markov chain samples may encountered traditional cross entropy methods rts utilized illustrating superiority proposed method termed e micem parent method e markov chain monte carlo integrated cross entropy method two traditional indices including loss load probability expected demand supplied comparatively evaluated simulation results suggest e micem superior efficiency estimating two indices advices also given build parameter regulation e micem applicable systems different dimensions â© copyright â© taylor francis group llc
10.1109/EMBC.2017.8037422 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032222132&doi=10.1109%2fEMBC.2017.8037422&partnerID=40&md5=84fdeed99c6205fdaf0ef25a93b0096d 1,paraquat n n dimethyl bipyridium dichloride potent widely used herbicide agricultural countries including thailand presence chemical body lead toxic effects liver kidney lung pulmonary toxicity identified main cause acute toxicity animals humans chronic exposure paraquat associated parkinson disease humans paraquat transported lungs neutral amino acid transporter therefore physiologically based pharmacokinetic pbpk model paraquat developed description protein transporter mechanism develop pbpk model paraquat pharmacokinetic study paraquat rats selected thailis pubmed database selected study contained tissue specific concentration time course information paraquat concentration levels liver kidney lung physiologic parameters acquired literature determined using markov chain monte carlo mcmc technique developed pbpk model consisted organ compartments e kidney liver slowly perfused organs richly perfuse organs lung featuring incorporation neutral amino acid transporter lung model simulations explain data literature adequately describe pharmacokinetics paraquat rats developed pbpk model may able help understanding paraquat induced parkinson disease well risk assessment paraquat â© ieee
10.1051/epjconf/201714602007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030471352&doi=10.1051%2fepjconf%2f201714602007&partnerID=40&md5=3f79b5d8fdb008afb5fe9cefdfd1eda0 1,model parameters necessary ingredients theoretical models always predicted theory formal mathematical framework associated evaluation work needed obtain best set parameters resonance parameters optical models fission barrier average width multigroup cross sections bayesian statistical inference comparing theory experiment formal rule related methodology estimate posterior density probability function set parameters solving equation following type pdf posterior âˆ¼ pdf prior ã— likelihood function fitting procedure seen estimation posterior density probability set parameters referred xâ†’ knowing prior information parameters likelihood gives probability density function observing data set knowing xâ†’ solve problem two major paths taken add approximations hypothesis obtain equation solved numerically minimum cost function generalized least square method referred gls use monte carlo sampling prior distributions estimate final posterior distribution monte carlo methods natural solution bayesian inference problems avoid approximations existing traditional adjustment procedure based chi square minimization propose alternative choice probability density distribution priors likelihoods paper propose use calling bayesian monte carlo referred bmc rest manuscript whole energy range thermal resonance continuum range nuclear reaction models energies algorithms presented based monte carlo sampling markov chain objectives bmc propose reference calculation validating gls calculations approximations test probability density distributions effects provide framework finding global minimum several local minimums exist application resolved resonance unresolved resonance continuum evaluation well multigroup cross section data assimilation presented â© authors published edp sciences
10.5194/isprs-archives-XLII-2-W7-647-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031029033&doi=10.5194%2fisprs-archives-XLII-2-W7-647-2017&partnerID=40&md5=3ebd5264e25063ca6b164790a42d9690 0,image segmentation method based gaussian mixture model gmm problems number component usually fixed number e fixed class gmm sensitive image noise paper proposed rs image segmentation method combining gmm reversible jump markov chain monte carlo rjmcmc proposed algorithm gmm designed model distribution pixel intensity rs image assume number component random variable respectively build prior distribution parameter order improve noise resistance used gibbs function model prior distribution gmm weight coefficient according bayes theorem build posterior distribution rjmcmc used simulate posterior distribution estimate parameters finally optimal segmentation obtained rs image experimental results show proposed algorithm converge optimal number class get ideal segmentation results
10.1093/mnras/stx1219 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023757611&doi=10.1093%2fmnras%2fstx1219&partnerID=40&md5=6661028197a719820be1bef6e855380f 4,dwarf galaxies among dark matter dominated structures universe excellent test beds dark matter theories unfortunately mass modelling systems suffers well documented mass velocity anisotropy degeneracy case spherically symmetric systems describe method non parametric modelling radial tangential velocity moments method numerical velocity anisotropy inversion parametric mass models radial velocity dispersion profile ïƒ ï€ modelled b spline optimization three step process consists evolutionary modelling determine mass model form best b spline basis represent ïƒ ï€ ii optimization smoothing parameters iii markov chain monte carlo analysis determine physical parameters mass anisotropy degeneracy reduced mass model inference irrespective kinematics test method using synthetic data algorithm constructs best kinematic profile discriminates competing dark matter models apply method fornax dwarf spheroidal galaxy using king brightness profile testing various dark matter mass models model inference favours simple mass follows light system find anisotropy profile fornax tangential î² r lt estimate total mass mtot = + ã— mâš™ mass light ratio ï…v = + mâš™ lâš™ algorithm present robust computationally inexpensive method non parametric modelling spherical clusters independent mass anisotropy degeneracy â© authors published oxford university press behalf royal astronomical society
10.1016/j.ecolmodel.2017.05.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021203611&doi=10.1016%2fj.ecolmodel.2017.05.009&partnerID=40&md5=3ea839f210be052500c439ce86b31381 0,black leaf streak disease blsd caused fungal pathogen mycosphaerella fijiensis considered destructive foliar disease banana advance knowledge dynamics disease plant scale well components varietal resistance designed calibrated evaluated mechanistic model simulate disease banana plant model runs discrete time plant scale describes plant growth pathogen dynamics optimal epidemiological conditions model divided two modules deterministic plant sub model simulates simplified architecture growth banana pathogen sub model simulates detailed life cycle pathogen including infection lesion growth asexual sexual sporulation dispersal spores plant three influential epidemiological parameters identified sensitivity analysis model lesion growth rate infection efficiency incubation period estimated bayesian framework using markov chain monte carlo methods acquired data dynamics leaf lesions natural conditions posterior densities provided precise knowledge pathogen life history traits evaluation model using independent data set confirmed good quality predictions simulations allowed us evaluate impact host resistance components auto infection plant scale leaf emergence rate linked cropping practices severity blsd foliar disease simulation model help design new methods controlling blsd â© elsevier b v
10.1002/sim.7347 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020121164&doi=10.1002%2fsim.7347&partnerID=40&md5=47836f62fa3f4dc52f8d1363903cc0e1 1,multilevel item response theory mlirt models widely used analyze multivariate longitudinal data mixed types e g categorical continuous clinical studies mlirt models often unidimensional assumption multiple outcomes clinical manifestations univariate latent variable however unidimensional assumption may unrealistic diseases may heterogeneous characterized multiple impaired domains variable clinical symptoms disease progressions relax assumption propose multidimensional latent trait linear mixed model mltlmm allow multiple latent variables within item multidimensionality one outcome manifestation one latent variable conduct extensive simulation studies assess unidimensional mlirt model proposed mltlmm model simulation studies suggest mltlmm model outperforms unidimensional model multivariate longitudinal outcomes manifested multiple latent variables proposed model applied two motivating studies amyotrophic lateral sclerosis clinical trial ceftriaxone pooled resource open access als clinical trials database copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.3847/1538-4357/aa844f https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029516709&doi=10.3847%2f1538-4357%2faa844f&partnerID=40&md5=52942e751c0c1a096a7436649fd10fc8 0,distance âˆ¼ pc nearest brown dwarf neighbor luhman ab extensively studied since discovery years ago yet fundamental parameter masses individual dwarfs constrained precision work present full astrometric orbit barycentric motion luhman ab first precision measurements individual component masses draw upon archival observations spanning years european southern observatory eso schmidt telescope deep near infrared survey southern sky denis public fors data large telescope vlt new astrometry gemini south multiconjugate adaptive optics system gems finally include three radial velocity measurements two components vlt crires spanning one year new data sampling full period orbit use markov chain monte carlo algorithm fit parameter model incorporating mutual orbit barycentric motion parameters constrain individual masses dwarf l dwarf measurements luhman ab mass ratio barycentric motion parameters consistent previous estimates literature utilizing recent astrometry gems derived measurements luhman ab separation agree closely hubble space telescope hst measurements made epoch derived mutual orbit agrees measurements within hst uncertainties mas â© american astronomical society rights reserved
10.1016/j.ajhg.2017.08.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028057012&doi=10.1016%2fj.ajhg.2017.08.002&partnerID=40&md5=f2ad37ff5c0f2ea8585038b1a58323b2 6,genome wide association studies gwass identified many complex loci however loci reside noncoding regions unknown biological functions integrative analysis incorporates known functional information gwass help elucidate underlying biological mechanisms prioritize important functional variants hence develop flexible bayesian variable selection model efficient computational techniques integrative analysis different previous approaches method models effect size distribution probability causality variants different annotations jointly models genome wide variants account linkage disequilibrium ld thus prioritizing associations based quantification annotations allowing multiple associated variants per locus method dramatically improves computational speed posterior sampling convergence taking advantage block wise ld structures human genomes simulations method accurately quantifies functional enrichment performs powerfully prioritizing true associations alternative methods power gain especially apparent multiple associated variants ld reside locus applied method depth gwas age related macular degeneration individuals variants find strongest enrichment causality among non synonymous variants ã— likely causal ã— larger effect sizes variants transcription repressed polycomb enhancer regions well identify five additional candidate loci beyond known amd risk loci conclusion method shown efficiently integrate functional information gwass helping identify functional associated variants underlying biology â©
10.1103/PhysRevLett.119.101301 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029695760&doi=10.1103%2fPhysRevLett.119.101301&partnerID=40&md5=1ff5a6529969c19eb307f8f907b89d51 20,compute bayesian evidence models considered main analysis planck cosmic microwave background data utilizing carefully defined nearest neighbor distances parameter space reuse monte carlo markov chains already produced parameter inference compute bayes factors b many different model data set combinations standard parameter flat cold dark matter model cosmological constant î›cdm favored models considered curvature mildly favored cosmic microwave background lensing included many alternative models strongly disfavored data including primordial correlated isocurvature models lnb= nonzero scalar tensor ratio lnb= running spectral index lnb= curvature lnb= nonstandard numbers neutrinos lnb= nonstandard neutrino masses lnb= nonstandard lensing potential lnb= evolving dark energy lnb= sterile neutrinos lnb= extra sterile neutrinos nonzero scalar tensor ratio lnb= models less strongly disfavored respect flat î›cdm analyses based bayesian evidence final numbers depend widths parameter priors adopt priors used planck analysis performing prior sensitivity analysis quantitative conclusion extensions beyond standard cosmological model disfavored planck data newer hubble constant measurements included î›cdm become disfavored mildly compared dynamical dark energy model lnbâˆ¼+ â© american physical society
10.5194/tc-11-2089-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028864578&doi=10.5194%2ftc-11-2089-2017&partnerID=40&md5=d8e3bce00c6bcbe1f92ba70f8c313960 2,quantitative characterization soil organic carbon oc content essential due significant impacts surface subsurface hydrological thermal processes microbial decomposition oc turn important predicting carbon climate feedbacks quantification particularly important vulnerable organic rich arctic region challenging achieve due general limitations conventional core sampling analysis methods extremely dynamic nature hydrological thermal processes associated annual freeze thaw events study develop test inversion scheme flexibly use single multiple datasets including soil liquid water content temperature electrical resistivity tomography ert data estimate vertical distribution oc content approach relies fact oc content strongly influences soil hydrological thermal parameters therefore indirectly controls spatiotemporal dynamics soil liquid water content temperature correlated electrical resistivity employ community land model simulate nonisothermal surface subsurface hydrological dynamics bedrock top canopy consideration land surface processes e g solar radiation balance evapotranspiration snow accumulation melting ice liquid water phase transitions inversion combine deterministic adaptive markov chain monte carlo mcmc optimization algorithm estimate posteriori distributions desired model parameters hydrological thermal geophysical variable transformation simulated subsurface temperature liquid water content ice content explicitly linked soil electrical resistivity via petrophysical geophysical models validate developed scheme using different numerical experiments evaluate influence measurement errors benefit joint inversion estimation oc parameters also quantify propagation uncertainty estimated parameters prediction hydrological thermal responses find compared inversion single dataset temperature liquid water content apparent resistivity joint inversion datasets significantly reduces parameter uncertainty find joint inversion approach able estimate oc sand content within shallow active layer top ä�â‚¬m soil high reliability due small variations temperature moisture within shallow permafrost ä�â‚¬m depth approach unable estimate oc confidence however soil porosity functionally related oc mineral content often observed organic rich arctic soil uncertainty oc estimate depth remarkably decreases study documents value new surface subsurface deterministic stochastic inversion approach well benefit including multiple types data estimate oc associated hydrological thermal dynamics â© author
10.1103/PhysRevE.96.033301 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029889631&doi=10.1103%2fPhysRevE.96.033301&partnerID=40&md5=85ed4769d68445b14a1457ba17d5252d 1,herdeiro doyon phys rev e physreve introduced numerical recipe dubbed uv sampler offering precise estimations conformal field theory cft data planar two dimensional critical ising model made use scale invariance emerging critical point order sample finite sublattice marginals infinite plane gibbs measure model producing holographic boundary distributions main ingredient markov chain monte carlo sampler invariance dilation paper presents generalization higher dimensions critical ising model leads numerical estimations subset cft data scaling weights structure constants fitting measured correlation functions results shown agree recent precise estimations numerical bootstrap methods kos poland simmons duffin vichi j high energy phys jhep â© american physical society
10.1186/s13059-017-1297-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028857221&doi=10.1186%2fs13059-017-1297-9&partnerID=40&md5=f40051e29f13ca35b43aa1d4e3e85ea3 1,single molecule rna fluorescence situ hybridization smfish provides unparalleled resolution measurement abundance localization nascent mature rna transcripts fixed single cells developed computational pipeline bayfish infer kinetic parameters gene expression smfish data multiple time points gene induction given underlying model gene expression bayfish uses monte carlo method estimate bayesian posterior probability model parameters quantify parameter uncertainty given observed smfish data tested bayfish synthetic data smfish measurements neuronal activity inducible gene npas primary neurons â© author
10.1080/10543406.2016.1226323 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989942901&doi=10.1080%2f10543406.2016.1226323&partnerID=40&md5=bebf9df5be0b5b683595224a1b3f4139 0,agreement different measurement methods important issue several disciplines like example medicine metrology engineering article agreement measures common literature analyzed bayesian point view posterior inferences agreement measures obtained based well known bayesian inference procedures bivariate normal distribution consequence general simple effective method presented require markov chain monte carlo methods applied considering great variety prior distributions illustratively method exemplified using five objective priors bivariate normal distribution tool assessing adequacy model discussed results simulation study application real dataset also reported â© â© taylor francis
10.1061/(ASCE)EM.1943-7889.0001316 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021692750&doi=10.1061%2f%28ASCE%29EM.1943-7889.0001316&partnerID=40&md5=e509eaa3e3643313e542a5c96329db66 0,uncertain changes spatial distribution structural parameters caused deterioration damage may weaken structure result unexpected losses properties casualties recent decades identify spatial distribution parameters various system identification si methods developed based optimization algorithms employing various regularization techniques however optimization based si methods may suffer ill posedness optimization problem uncertain measurement noises moreover depending boundary traction conditions accuracy robustness si methods may differ paper overcome technical challenges identification spatial distribution new si method developed modifying transitional markov chain monte carlo tmcmc addition modifications introduced sampling algorithm proposed method enhances robustness si results exploiting results maximum likelihood estimation finite element updating identify general shapes spatial distribution reasonable number parameters spatial deterioration model proposed based modes obtained based random field model called karhunen loeve expansion proposed si method tested demonstrated numerical examples steel plate b pillar structure effects random measurement errors also considered numerical examples demonstrate accuracy robustness proposed method â© american society civil engineers
10.1080/03772063.2017.1369909 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029904715&doi=10.1080%2f03772063.2017.1369909&partnerID=40&md5=f4f229d94865d26b68ada34e74b5f14b 0,paper target tracking algorithm based improved unscented particle filter markov chain monte carlo mcmc proposed proposed method improved unscented kalman filter ukf used generate proposal distribution particle swarm optimization pso integrates ukf proposal moreover sample impoverishment created resampling step restrained mcmc move step resampling experiments presented evaluate performance proposed algorithm results show proposed algorithm significant advantages tracking accuracy classical algorithms â© iete
978.2410911886537 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030651197&partnerID=40&md5=ad0902ed623575f9403089129351565e 0,develop new bayesian markov chain monte carlo algorithm euler discretized feller square root stochastic volatility models demonstrate performance algorithm simulations empirical analyses specifically algorithm use laplace approximation posterior density conditional variance probability kernel generalized inverse gaussian distribution derived joint density return conditional variance easily applied extended stochastic volatility models fat tailed distributions lã©vy jump processes addition conduct simulation experiment investigating comparing size power parametric specification tests checking certain finite dimensional moment conditions without correction parameter estimation uncertainty nonparametric hong li â€™s omnibus test affected parameter estimation uncertainty parametric nonparametric tests based probability integral transform prediction densities returns obtained using auxiliary particle filter algorithms experiment result shows classical parametric specification test may worse size distortion better power hong li â€™s test â© korean econometric society rights reserved
10.1061/(ASCE)EM.1943-7889.0001066 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020649483&doi=10.1061%2f%28ASCE%29EM.1943-7889.0001066&partnerID=40&md5=7c7ac29d093f78b117df0e9d56f99785 0,abstract available
10.1061/(ASCE)EM.1943-7889.0001066 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020660282&doi=10.1061%2f%28ASCE%29EM.1943-7889.0001066&partnerID=40&md5=47cafc79887c647a43e5f3d989961fa3 0,abstract available
10.1061/(ASCE)EM.1943-7889.0001325 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021860481&doi=10.1061%2f%28ASCE%29EM.1943-7889.0001325&partnerID=40&md5=4246792c84a1fe08ee67f4b42770926c 0,typesetting process expressions prior belief prior distribution prior pdf transformed previous belief previous distribution previous pdf misnomers expressions previous expect two occurrences replaced prior asce regrets error â© asce
10.1016/j.ymssp.2016.12.023 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015268280&doi=10.1016%2fj.ymssp.2016.12.023&partnerID=40&md5=08e65fc1b47c6e2e878f668e254a2bdf 5,paper authors present method facilitates computationally efficient parameter estimation dynamical systems continuously growing set measurement data shown proposed method utilises sequential monte carlo samplers guaranteed fully parallelisable contrast markov chain monte carlo methods applied wide variety scenarios within structural dynamics ability allow convergence one parameter estimates data analysed sets apart sequential methods particle filter â© elsevier ltd
10.1016/j.anucene.2017.04.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018723689&doi=10.1016%2fj.anucene.2017.04.020&partnerID=40&md5=628c11e9fe02ddf4ff93aaefc1e6b4c9 2,quantifying uncertainty contributors best estimate thermal hydraulic th codes getting attention safety analysis nuclear industry recent decades yet evaluation intrinsic physical models may readily measured quantification process usually subjective inaccurate paper investigates statistical methodology order get probability density function pdf model parameters objectively based observed experimental responses simplification mathematical model described parameter estimation solution using markov chain monte carlo mcmc algorithm demonstrated direct evaluations computationally intensive surrogate models using radial basis function rbf constructed substitute complex forward calculations efficiently improve accuracy surrogate model adaptive approach based cross entropy minimization densify training samples space posterior pdf applied application uncertainties model parameters related reflood phenomena implemented relap code quantified indicated developed method independent codes feasible efficient apply check uncertainty propagation proves uncertainty bands envelope experiment measurements advantage accuracy model calibration posterior mean value also presents good improvement calculations â© elsevier ltd
10.1109/DT.2017.8024325 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030110812&doi=10.1109%2fDT.2017.8024325&partnerID=40&md5=ec17f2ad87b7ddbd7d6b4370f6b77029 0,paper parameters reliability characteristics mixture failure time distribution estimated based complete sample using markov chain monte carlo mcmc method maximum likelihood estimation via cross entropy ce algorithm maximum likelihood estimation frequently used method parameter estimation mcmc recently emerged good alternative popular mcmc method called metropolis hastings algorithm used provide complete analysis concerned posterior distribution simulation study provided compare mcmc ce differences estimates obtained two approaches evaluated â© ieee
10.1016/j.ress.2017.04.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018561948&doi=10.1016%2fj.ress.2017.04.004&partnerID=40&md5=e81f765c3ade927d14f7b41864e76baf 4,mathematical numerical models increasingly employed simulate system behavior identify sequences events configurations system design operational parameters lead system extreme conditions critical region cr however numerical model computationally expensive ii high dimensional iii complex tasks become challenging paper propose adaptive framework efficiently tackling problem dimensionality reduction technique employed identifying factors variables affect system behavior ii meta model sequentially trained replace computationally expensive model computationally cheap one iii adaptive exploration algorithm based markov chain monte carlo introduced exploring system state space using meta model iv clustering techniques visualization high dimensional data e g parallel coordinates plot employed summarize retrieved information method employed explore power network model involving inputs crs properly identified limited computational cost compared another exploration technique literature e latin hypercube sampling â© elsevier ltd
10.1016/j.ijnonlinmec.2017.03.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016710749&doi=10.1016%2fj.ijnonlinmec.2017.03.012&partnerID=40&md5=c80872c1f3094a32cf74c51eeea76741 2,bayesian approaches statistical inference system identification became practical development effective sampling methods like markov chain monte carlo mcmc however size complexity inference problems dramatically increased improved mcmc methods required dynamical systems based samplers effective extension traditional mcmc methods samplers treat posterior probability distribution potential energy function dynamical system enabling better exploit structure inference problem present algorithm second order langevin mcmc sol mc stochastic dynamical system based mcmc algorithm uses damped second order langevin stochastic differential equation sde sample posterior distribution design sde desired posterior probability distribution stationary distribution since method based upon underlying dynamical system utilize existing work develop implement optimize sampler performance choose parameters speed convergence stationary distribution reduce temporal state energy correlations samples apply sampler system identification problem non linear hysteretic structure model investigate method globally identifiable unidentifiable conditions â© elsevier ltd
10.1016/j.eneco.2017.08.029 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031743138&doi=10.1016%2fj.eneco.2017.08.029&partnerID=40&md5=3116d709417c32dc84ff536e98cda148 0,partial linear models provide intuitively appealing way examine gasoline demand one examine response price varies according price level people income however despite intuitive appeal partial linear models tended produce implausible erratic price effects blundell et al propose solution problem involves using slutsky shape restrictions improve precision nonparametric estimate demand function propose estimating constrained partially linear model three steps weights optimized minimizing objective function slutsky constraint bandwidths selected least squares cross validation linear coefficients estimated using profile least squares limitation three step estimation method bandwidths selected based pre estimated parameters improve blundell et al solution derive posterior develop posterior simulation algorithm simultaneously estimate linear coefficients bandwidths kernel estimator weights imposed slutsky condition proposed sampling algorithm estimate constrained partially linear model household gasoline demand employing household survey data united states canada â€“ find plausible price effects â© elsevier b v
10.1109/TR.2017.2713760 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023596317&doi=10.1109%2fTR.2017.2713760&partnerID=40&md5=417fad98cbdf7561b7dc47e175a5be87 0,damage diagnosis prognosis play important role ensuring safety mechanical aerospace civil structures existing structural damage estimation methods limited providing estimate damage magnitude current time instance revealing evolving path structural damage highly desirable practice prognosis remaining useful life prediction paper propose dynamic data driven hierarchical bayesian degradation model takes advantage physical finite element model data driven bayesian framework tackle structural damage growth prediction damage growth trend efficiently accurately estimated gibbs sampling systematic case analyses performed validate demonstrate effectiveness proposed method â© ieee
10.1016/j.jsr.2017.06.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022100358&doi=10.1016%2fj.jsr.2017.06.005&partnerID=40&md5=2b478f7f5e6b9a02f5d7e9bd5b25387d 2,introduction safety performance functions spfs essential tools highway agencies predict crashes identify hotspots assess safety countermeasures highway safety manual hsm variety spfs provided different types roadway facilities crash types severity levels agencies lacking necessary resources develop localized spfs may opt apply hsm spfs jurisdictions yet municipalities want develop maintain regional spfs might encounter issue small sample bias bayesian inference conducted address issue combining current data prior information achieve reliable results follows essence bayesian statistics application informative priors obtained spfs expertsâ€™ experiences method study investigate applicability informative priors bayesian negative binomial spfs rural divided multilane highway segments florida california spf non informative priors developed state parametersâ€™ distributions assigned state spf informative priors performances spfs evaluated applying state spfs state analysis conducted total kabco severe kab crashes results conclusions practical applications per results applying one state spf informative priors state spf independent variable estimates latter state conditions yields better goodness fit gof values applying former state spf non informative priors conditions latter state total severe crash spfs hence localities preferred develop localized spfs adopt spfs elsewhere cut resources application informative priors shown facilitate process â© national safety council elsevier ltd
10.1016/j.dss.2017.06.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021049186&doi=10.1016%2fj.dss.2017.06.001&partnerID=40&md5=702d5c5cd3aae4d0cebcb3839022ebe1 3,broad aim paper answer following query relationship social media sentiments stock returns time varying provide satisfactory response novel methodologyâ€”a symbiosis bayesian dynamic linear models seemingly unrelated regressions â€”is introduced two sets dow jones industrial average stock data corresponding social media data yahoo finance stock message boards used comprehensive empirical study key findings affirmative response question b models social media sentiments market returns perform least well models include fama french momentum factors c significant correlations stocks ranging âˆ’ data sets â© elsevier b v
10.1007/s00477-016-1260-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966716017&doi=10.1007%2fs00477-016-1260-4&partnerID=40&md5=1739aa6c99b3b3ba8aa1dccd1b9b142b 2,seismic intensity measured mercalliâ€“cancaniâ€“sieberg mcs scale provides assessment ground shaking level deduced building damages natural environment changes observed effects feelings generally moving away earthquake epicentre effects lower intensities may vary space areas amplify reduce shaking depending earthquake source geometry geological features local factors currently istituto nazionale di geofisica e vulcanologia analyzes seismic event intensity data collected online macroseismic questionnaire available web page www haisentitoilterremoto questionnaire responses aggregated municipality level analyzed obtain intensity defined ordinal categorical scale main aim work model macroseismic attenuation obtain intensity prediction equation describes decay macroseismic intensity function magnitude distance hypocentre employ ordered probit model assuming intensity response variable related link probit function predictors differently commonly done macroseismic literature approach takes properly account qualitative ordinal nature macroseismic intensity defined mcs scale using markov chain monte carlo methods estimate posterior probability intensity site moreover comparing observed estimated intensities able detect anomalous areas terms residuals kind information useful better assessment seismic risk promoting effective policies reduce major damages â© springer verlag berlin heidelberg
10.1515/sagmb-2016-0014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028889632&doi=10.1515%2fsagmb-2016-0014&partnerID=40&md5=d8bdeb4ee091f975bd56e68a6135c2c2 0,important topic bioinformatics protein structure alignment statistical methods proposed problem align two protein structures based global geometric information without considering effect neighbourhood structures paper provide bayesian model align protein structures considering effect local global geometric information protein structures local geometric information incorporated model partial procrustes distance small substructures substructures composed î² carbon atoms side chains parameters estimated using markov chain monte carlo mcmc approach evaluate performance model simulation studies furthermore apply model real dataset assess accuracy convergence rate results show model much efficient previous approaches â© walter de gruyter gmbh berlin boston
10.1016/j.nimb.2017.04.060 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018770654&doi=10.1016%2fj.nimb.2017.04.060&partnerID=40&md5=46d5a10fef0d6c682825342c41a74b98 2,use classical monte carlo transport model electrons moving near surface inside solids reproduce measured reflection electron energy loss spectroscopy reels spectra combination classical transport model markov chain monte carlo mcmc sampling oscillator parameters called reverse monte carlo rmc method developed used obtain optical constants ni work systematic study electronic optical properties ni performed energy loss range â€“ â ev measured reels spectra primary energies â ev â ev â ev reliability method tested comparing results previous data moreover accuracy optical data confirmed applying oscillator strength sum rule perfect screening sum rule â© elsevier b v
10.1002/asmb.2210 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996508252&doi=10.1002%2fasmb.2210&partnerID=40&md5=d6c514880bb04327c51cfb2ce8ad3f86 1,present bayesian decision theoretic approach developing replacement strategies consider semiparametric model describe failure characteristics systems specifying nonparametric form cumulative intensity function taking account effect covariates parametric form use gamma process prior cumulative intensity function complicates bayesian analysis updating based failure count data develop bayesian analysis model using markov chain monte carlo methods determine replacement strategies adoption markov chain monte carlo methods involves data augmentation algorithm show implementation approach using actual data railroad tracks copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1016/j.jhydrol.2017.05.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021663319&doi=10.1016%2fj.jhydrol.2017.05.002&partnerID=40&md5=d124a099bd0dc0ed4a7258829f936c64 1,diversity vegetation semi arid ephemeral wetlands determined niche availability species competition influenced changes water availability salinity hypothesise ignoring physiological differences competition species managing wetland hydrologic regimes lead decrease vegetation diversity even overall wetland carrying capacity improved using ecohydrological model capable resolving water vegetation salt feedbacks investigate water surface groundwater management interventions combat vegetation decline beneficial casuarina obesa melaleuca strobophylla co dominant tree species lake toolibin salt affected wetland western australia simulations reveal trying reduce negative effect salinity management interventions created environment favouring c obesa intensifying climate induced trend wetland experiencing lower water availability higher root zone salinity testing alternative scenarios show interventions improve strobophylla biomass possible promoting hydrologic conditions less specific niche requirements c obesa modelling uncertainties explored via markov chain monte carlo mcmc algorithm overall study demonstrates importance including species differentiation competition ecohydrological models form basis wetland management â© elsevier b v
10.1002/etep.2366 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018436954&doi=10.1002%2fetep.2366&partnerID=40&md5=c04567d202d3217b3c1cdf127cad1f25 0,prevalence renewable energy source power system necessary appraise voltage stability integration system probabilistic methods traditional markov chain monte carlo mcmc simulation show great calculation precision probabilistic assessment always involved complicated sampling iterations gibbs sampling method currently used mcmc simulation instead gibbs sampling method paper presents application slice sampling mcmc simulation voltage stability probabilistic assessment power system renewable source firstly probabilistic models renewable source generation constructed sample space renewable source outputs obtained slice sampling samples sample space calculated power flow finally voltage stability margin obtained result power flow calculation probabilistic assessment voltage stability implemented furthermore mcmc simulations using gibbs sampling slice sampling compared gelman rubin diagnostic kullback leibler divergence tests ieee bus system ieee bus system respectively results show slice sampling method simpler efficient gibbs sampling method voltage stability probabilistic assessment copyright â© john wiley sons ltd
10.1007/s13253-017-0286-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021114864&doi=10.1007%2fs13253-017-0286-5&partnerID=40&md5=a0c2afd41ae493127ae6e6888b7db978 3,mechanistic modelling animal movement often formulated discrete time despite problems scale invariance handling irregularly timed observations natural solution formulate continuous time yet uptake slow lack implementation often excused difficulty interpretation aim bolster usage developing continuous time model interpretable parameters similar popular discrete time models use turning angles step lengths movement defined joint bearing speed process parameters dependent continuous time behavioural switching process creating flexible class movement models methodology presented markov chain monte carlo inference given irregular observations involving augmenting observed locations reconstruction underlying movement process applied well known gps data elk cervus elaphus previously modelled discrete time demonstrate interpretable nature continuous time model finding clear differences behaviour time insights short term behaviour obtained discrete time â© author
10.12693/APhysPolA.132.1112 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033394863&doi=10.12693%2fAPhysPolA.132.1112&partnerID=40&md5=10d754a80dad5a3c817d8d9aa0c4c6ac 0,markov chain monte carlo methods mcmc iterative algorithms used many bayesian simulation studies inference easily obtained directly defined model reversible jump mcmc methods belong special type mcmc methods dimension parameters change iteration study suggest gibbs sampling place rjmcmc decrease computational demand calculation high dimensional systems evaluate performance suggested algorithm three real benchmark datasets comparing accuracy computational demand strong alternatives namely birth death mcmc rjmcmc quic algorithms comparative analyses detect gibbs sampling improves computational cost rjmcmc without losing accuracy
10.1142/S0578563417500140 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031289391&doi=10.1142%2fS0578563417500140&partnerID=40&md5=2c06a89558153db42620a1db44d8ff2d 0,study proposes safety evaluation process prevention structure tsunamis updated guideline e fema p used deterministic analysis probabilistic approach adopted consider uncertainties involved overcome incomplete data tsunamis markov chain monte carlo mcmc simulation developed increase quantity historical data taiwan followed use least squares support vector machine ls svm estimate probability density function pdf random variables based fragility analyses superstructure substructure entire system wall thickness wall thickness likely governing factor compared pile diameter conversely pile diameter likely dominating factor pile size decreases cm cm threshold value shift addition wall thickness height greater greater likelihood failure probability governed substructure based historical records probability failure seawall extremely low nevertheless results shown line engineering judgement computation procedure established present study used reference performing safety analysis tsunami structures insufficient data â© world scientific publishing company
10.1016/j.jhydrol.2017.07.021 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026254077&doi=10.1016%2fj.jhydrol.2017.07.021&partnerID=40&md5=e0e485caae2b44329c382852218b73d3 2,common practice infrequent e g monthly stream water quality sampling state environment monitoring may combined high resolution stream flow data provide sufficient information accurately characterise dominant nutrient transfer pathways predict annual catchment yields proposed approach use spatially lumped catchment model streamgem predict daily stream flow nitrate concentration mg lâˆ’ n four contrasting mesoscale headwater catchments based four years daily rainfall potential evapotranspiration stream flow measurements monthly daily nitrate concentrations posterior model parameter distributions estimated using markov chain monte carlo sampling code dreamzs log likelihood function assuming heteroscedastic distributed residuals despite high uncertainty model parameters flow nitrate calibration data well reproduced across catchments nash sutcliffe efficiency log transformed data nsl range â€“ daily flow â€“ nitrate concentration slight increase size residuals separate validation period considered acceptable nsl range â€“ daily flow â€“ nitrate concentration excluding one data set limited validation data proportions flow nitrate discharge attributed near surface fast seasonal groundwater slow deeper groundwater consistent expectations based catchment geology results weida stream thuringia germany using monthly opposed daily nitrate data intents purposes identical suggesting four years monthly nitrate sampling provides sufficient information calibration streamgem model prediction catchment dynamics study highlights remarkable effectiveness process based spatially lumped modelling commonly available monthly stream sample data elucidate high resolution catchment function appropriate calibration methods used correctly handle inherent uncertainties â© elsevier b v
10.1111/biom.12644 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009787615&doi=10.1111%2fbiom.12644&partnerID=40&md5=cf23ef3cc16468aa6184d6870901a766 2,assess compliance air quality regulations environmental protection agency epa must know site exceeds pre specified level case ozone level compliance fixed parts per billion high extreme locations present new space time model threshold exceedances based skew process method incorporates random partition permit long distance asymptotic independence allowing sites near one another asymptotically dependent incorporate thresholding allow tails data speak also introduce transformed ar time series allow temporal dependence finally model allows high dimensional bayesian inference comparable computation time traditional geostatistical methods large data sets apply method ozone analysis july find model improves gaussian max stable methods terms predicting exceedances high level â© international biometric society
10.1093/biomet/asx033 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037128794&doi=10.1093%2fbiomet%2fasx033&partnerID=40&md5=b1e099107704822a6409cee5fd92c121 3,standard posterior sampling algorithms markov chain monte carlo procedures face major challenges scaling massive datasets propose simple general posterior interval estimation algorithm rapidly accurately estimate quantiles posterior distributions one dimensional functionals algorithm runs markov chain monte carlo parallel subsets data averages quantiles estimated subset provide strong theoretical guarantees show credible intervals algorithm asymptotically approximate full posterior leading parametric order algorithm better balance accuracy efficiency competitors across variety simulations real data example â© biometrika trust
10.5351/CSAM.2017.24.5.507 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044066457&doi=10.5351%2fCSAM.2017.24.5.507&partnerID=40&md5=45424b13ad4c7e5311fa75a93025bd8d 1,volatility plays crucial role theory applications asset pricing optimal portfolio allocation risk management paper proposes combined model autoregressive moving average arfima generalized autoregressive conditional heteroscedasticity grach skewed error distribution accommodate important features volatility data long memory heteroscedasticity asymmetric error distribution fully bayesian approach proposed estimate parameters model simultaneously yields parameter estimates satisfying necessary constraints model approach easily implemented using free user friendly software jags generate markov chain monte carlo samples joint posterior distribution parameters method illustrated using daily volatility index chicago board options exchange cboe jags codes model specification provided appendix â© korean statistical society korean international statistical society
10.1214/17-AOAS1046 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031498677&doi=10.1214%2f17-AOAS1046&partnerID=40&md5=4a059382364e5a05f4257d81ad2bd5cb 5,bayesian methods large scale multiple regression provide attractive approaches analysis genome wide association studies gwas example estimate heritability complex traits allowing polygenic sparse models incorporating external genomic data priors increase power yield new biological insights however methods require access individual genotypes phenotypes often easily available provide framework performing analyses without individual level data specifically introduce â€œregression summary statisticsâ€� rss likelihood relates multiple regression coefficients univariate regression results often easily available rss likelihood requires estimates correlations among covariates snps also obtained public databases perform bayesian multiple regression analysis combining rss likelihood previously proposed prior distributions sampling posteriors markov chain monte carlo wide range simulations rss performs similarly analyses using individual data estimating heritability detecting associations apply rss gwas human height contains individuals typed million snps analyses individual level data practically impossible estimates heritability consistent precise previous results using subsets data also identify many previously unreported loci show evidence association height analyses software available https github com stephenslab rss â© institute mathematical statistics
10.1007/s00180-017-0730-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020751350&doi=10.1007%2fs00180-017-0730-6&partnerID=40&md5=22f56a556a6d13f4102794428809225a 0,understanding viruses offer protection closely related emerging strains vital creating effective vaccines many viruses multiple serotypes often co circulate testing large numbers vaccines infeasible therefore development silico predictor cross protection strains important help optimise vaccine choice present sparse hierarchical bayesian model detecting relevant antigenic sites virus evolution sabre account experimental variability data predict antigenic variability method uses spike slab priors identify sites viral protein important neutralisation virus using sabre method able identify number key antigenic sites within several viruses well providing estimates significant changes evolutionary history serotypes show method outperforms alternative established methods standard mixed effects models mixed effects lasso mixed effects elastic nets also propose novel proposal mechanisms markov chain monte carlo simulations improve mixing convergence established component wise gibbs sampler â© author
10.1214/17-AOAS1054 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031490784&doi=10.1214%2f17-AOAS1054&partnerID=40&md5=7041ed978352c676b280d86070ff7a85 0,fã¶rster resonance energy transfer fret quantum physical phenomenon energy may transferred one molecule neighbor molecule molecules close enough using fluorophore molecule marking proteins cell possible measure microscopic images extent fret takes place fluorophores provides indirect information spatial distribution proteins questions particular interest whether extent proteins possibly different types interact whether appear independently paper propose new likelihood based approach statistical inference fret microscopic data likelihood function obtained detailed modeling fret data generating mechanism conditional protein configuration next follow bayesian approach introduce spatial point process prior model protein configurations depending hyperparameters quantifying intensity point process posterior distributions evaluated using markov chain monte carlo propose infer microscope related parameters initial step reference data without interaction proteins new methodology applied simulated real datasets â© institute mathematical statistics
10.21314/JCF.2017.329 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030092584&doi=10.21314%2fJCF.2017.329&partnerID=40&md5=f528fe0ef43e03acbc12a34295bf79db 1,risk based asset allocation models received considerable attention recent years increased popularity due part difficulty estimating expected returns well financial crisis helped reinforce key role risk asset allocation propose generalized risk budgeting grb approach portfolio construction grb portfolio assets grouped possibly overlapping subsets subset allocated prespecified risk budget minimum variance risk parity risk budgeting portfolios special instances grb portfolio grb portfolio optimization problem find grb portfolio optimal riskâ€“return profile risk measured using positively homogeneous risk measure subsets form partition assets expected return restrict long portfolios grb problem fact solved convex optimization problem general however grb problem constrained nonconvex problem propose two solution approaches first approach uses semidefinite programming relaxation obtain upper bound optimal objective function value second approach develop numerical algorithm integrates augmented lagrangian markov chain monte carlo methods order find point vicinity good local optimum point supplied standard nonlinear optimization routine goal finding local optimum merit second approach generic nature particular provides strategy choosing starting point nonlinear optimization algorithm â© infopro digital risk ip limited
10.1093/biomet/asx031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037129236&doi=10.1093%2fbiomet%2fasx031&partnerID=40&md5=80890f5775994f646d15a4a0cdcee639 2,consider pseudo marginal metropolis hastings kernel pm constructed using average exchangeable random variables analogous kernel ps averages lt random variables using embedding technique facilitate comparisons provide lower bound asymptotic variance ergodic average associated pm terms asymptotic variance corresponding ergodic average associated ps showthat bound tight disprove conjecture random variables averaged independent asymptotic variance pm never less times variance ps conjecture however hold continuous time markov chains results imply computational cost algorithm proportional often better set = provide intuition findings differ markedly recent results pseudo marginal kernels employing particle filter approximations results exemplified two simulation studies first computational cost effectively proportional second considerable start cost iteration â© biometrika trust
10.1088/1674-4527/17/9/94 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030848262&doi=10.1088%2f1674-4527%2f17%2f9%2f94&partnerID=40&md5=435c443260e75da4187aefc771e28c3c 0,carried new photometric observations asteroid dione three apparitions understand basic physical properties based new brightness model new photometric observational data published data dione analyzed characterize morphology dione photometric phase curve brightness model cellinoid ellipsoid shape three parameter h g g magnitude phase function system involved model solve phase function system parameters dione considering asymmetric shape asteroid also applied asteroids especially without enough photometric data solve convex shape using amarkov chainmonte carlo mcmc method dione absolutemagnitude h = + mag phase function parameters g = + g = + obtained simultaneously dione simplistic shape orientation pole rotation period also determined preliminarily â© national astronomical observatories cas iop publishing ltd
10.2166/washdev.2017.118 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029917831&doi=10.2166%2fwashdev.2017.118&partnerID=40&md5=a5b57c34dbb9657b935ef24e1499423f 0,mortality rates diseases affected water quality research examines roles two factors related water quality namely quality drinking water termed â€˜waterâ€™ quality sanitation termed â€˜sanitationâ€™ two age related diseases cardiovascular disease diabetes cdd chronic respiratory conditions crc considered adjusting personal health issues environmental geographical factors dataset consists worldwide mortality rates adults mentioned diseases countries countries clustered within continents geographically literature shows importance considering geographical effect continent furthermore two diseases highly related accordingly multivariate multilevel model fitted dataset results indicated usage improved drinking water sources sanitation facilities decreases chance mortality two diseases increases furthermore difference risk diseases statistically significant continents showed north america europe lower risk cdd crc compared asia oceania therefore results revealed factors â€˜waterâ€™ â€˜sanitationâ€™ play important roles macro geographical variation cdd crc â© iwa publishing
10.1109/TSIPN.2017.2731160 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049506334&doi=10.1109%2fTSIPN.2017.2731160&partnerID=40&md5=0235fd2ce71281ddb680a4d1408fbee2 1,understanding process contagion disseminates throughout network great importance many real world applications required sophistication inference approach depends type information want extract well number observations available us analyze scenarios underlying network structure parental relationships link strengths needs detected also infection times must estimated assume observation diffusion process set time series one node network exhibit changepoints infection occurs formulating model describe contagion selecting appropriate prior distributions seek find set model parameters best explains observations modeling problem bayesian framework exploit monte carlo markov chain sequential monte carlo time series analysis techniques develop batch online inference algorithms evaluate performance proposed algorithms via numerical simulations synthetic network contagions analysis real world datasets â© ieee
10.1017/apr.2017.22 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029620205&doi=10.1017%2fapr.2017.22&partnerID=40&md5=7cfd4f9f0d1b8cea1a67115e6f613a45 3,markov chain monte carlo mcmc methods provide essential tool statistics sampling complex probability distributions standard approach mcmc involves constructing discrete time reversible markov chains whose transition kernel obtained via metropolis hastings algorithm recent interest alternative schemes based piecewise deterministic markov processes pdmps one approach based zig zag process introduced bierkens roberts proved provide highly scalable sampling scheme sampling big data regime see bierkens et al paper study performance zig zag sampler focusing one dimensional case particular identify conditions central limit theorem holds characterise asymptotic variance moreover study influence switching rate diffusivity zig zag process identifying diffusion limit switching rate tends based results compare performance zig zag sampler existing monte carlo methods analytically simulations â© copyright applied probability trust
10.1134/S2070048217050088 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029755683&doi=10.1134%2fS2070048217050088&partnerID=40&md5=58318e79efe6c66857d17f5ad7686154 0,simplest stochastic lattice model excitable medium considered lattice cell one three states excited refractory quiescent transitions different cell states occur prescribed probabilities model designed studying transfer excitation cardiac muscle nerve fiber cellular subcellular levels also modeling spreading epidemics elementary events lattice simulated kinetic monte carlo method consists constructing markov chain lattice states corresponding solution master equation effective algorithm implementing kinetic monte carlo simulations suggested number arithmetic operations time step proposed algorithm practically independent lattice size enables making calculations two three dimensional lattices large size cells shown model reproduces basic spatiotemporal structures solitary traveling pulses pulse trains concentric spiral waves spiral turbulence characteristic excitable medium basic properties traveling pulses spiral waves considered stochastic lattice model studied compared known properties deterministic equations reaction diffusion type usually employed modeling excitable media â© pleiades publishing ltd
10.1016/j.radonc.2017.08.015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028645982&doi=10.1016%2fj.radonc.2017.08.015&partnerID=40&md5=61a7f2d47bc9de353d8bb5ddcd636995 0,propose bayesian hierarchical model applicable calibration linear quadratic model radiation doseâ€“response experimental data used model calibration taken clonogenic survival assay conducted human breast cancer cells mda mb across range radiation doses â€“ gy employing markov chain monte carlo methods calibrated proposed bayesian hierarchical model computed posterior distributions model parameters survival fraction doseâ€“response probability densities key contributions include proposal model incorporates multiple sources inter intra experiment variability commonly neglected standard frequentist approach subsequent application vitro experimental data â© elsevier b v
10.1007/s40328-016-0183-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027515916&doi=10.1007%2fs40328-016-0183-3&partnerID=40&md5=3e0b37913877e6d916cf924a7ed6348d 2,present satellite sar persistent scatterer interferometry already estimate surface changes near â mm theoretical precision limit however ascending descending acquisitions available sar services provide three dimensional changes routinely though slow deformation processes basically three dimensional paper geometric features ascending descending sar data possible fusion geodetic data summarised geometric equations introduced necessary derive two characteristic changes observation plain defined ascending descending unit vectors pointing sar satellite positions unambiguously derivable characteristic changes transformed vertical east changes may biased possible north displacement geometric features symmetric asymmetric acquisitions also investigated monte carlo simulation used investigate precision two estimated components experienced precisions sensitive one degree standard deviations positional angles gaussâ€“markov model least square adjustment method used derive statistical properties reasonable data fusion contribute applications although complementary satellites already proposed literature provide precise autonomous solutions practise gnss levelling data used direct data fusion whereas even errorless levelled high changes contribute proper estimation northern components gnss derived changes best candidates interpolated measured directly moreover two techniques properly compensate weaknesses interferometric sar techniques sensitive enough north changes contribute precision height estimation weakest components gnss technique statement valid standard deviations combined data comparable test computations geometric parameters available sentinel images used cover area szã©chenyi istvã¡n geophysical observatory experimental integrated geodetic benchmark located combining ascending descending backscatterers possibility gnss gravimetric traditional geodetic measurements well â© akadã©miai kiadã³
10.1007/s11277-017-4241-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018295822&doi=10.1007%2fs11277-017-4241-0&partnerID=40&md5=06ccb648a3d545fa42697be96105da87 1,time slotted channel hopping tsch mechanism created ieee e amendment meet need industrial wireless sensor networks combines time slotted access channel hopping deterministic behavior mechanism offers two types links dedicated links shared links order reduce probability repeated collisions shared links mechanism implemented retransmission backoff algorithm named tsch collision avoidance tsch ca article develop two dimensional markov chain model ieee e tsch ca mechanism take account deterministic behavior mechanism order evaluate performances estimate stationary distribution chain derive theoretical expressions collision probability data packet loss rate reliability energy consumption throughput delay jitter analyze impact number devices sharing link fixed network size different traffic conditions finally accuracy theoretical analysis validated monte carlo simulation shown performances ieee e tsch parameters strongly related number devices sharing link â© springer science+business media new york
10.5061/dryad.r6j80 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039042971&doi=10.5061%2fdryad.r6j80&partnerID=40&md5=bc4876ca7015280708d0206f8304caf9 4,individuals population vary growth due hidden observed factors age genetics environment disease carryover effects past environments size affects fitness growth trajectories scale affect population dynamics however difficult estimate growth data fromwild populations missing observations observation error previous work shown linear mixed models lmms underestimate hidden individual heterogeneity repeatedmeasures missing demonstrate flexible robust way model growth trajectories show state space models ssms fit using r package growmod far less biased lmms fit simulated data sets missing repeated measures observation error method much faster markov chain monte carlo methods allowing models tested shorter time scenarios simulated ssms gave estimates little bias repeated measuresweremissing use thismethod quantify growth soay sheep using data froma long termmark recapture study demonstrate growth decreased age population density weather conditions individuals reproductive method improves ability quantify growth varies among individuals response attributes environments experience particular relevance wild populations â© university chicago
10.1109/ISCC.2017.8024556 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030535955&doi=10.1109%2fISCC.2017.8024556&partnerID=40&md5=0a30b4b1a77905bb861287f1a811d330 0,paper revisit problem deriving expected number transmissions multicasting random linear coded rlc packets single hop wireless channels show deriving closed form expression instance problem previous analytical formulation accurately model true expected number transmissions especially smaller finite field size understanding similar wireless multi hop network problem deriving exact closed form expression expected number transmissions single hop rlc wireless network complex open problem unknown whether scalable closed form expression problem exists propose computationally efficient monte carlo method derive good approximation expected number transmissions â© ieee
10.1002/jrsm.1236 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018588715&doi=10.1002%2fjrsm.1236&partnerID=40&md5=0a424ccc212934ecde3fbe34b6bf3647 4,meta analysis necessitate combination parallel cross trial designs differences trial designs potential biases notably associated crossover trials one often combines trials designs decreases power meta analysis combine results clinical trials parallel cross designs extend method proposed accompanying study account random effects propose hierarchical mixed model allowing combination types trial designs accounting additional covariates random effects introduced account heterogeneity trial treatment effect interactions introduce multilevel model bayesian hierarchical model combined trial design meta analysis analysis models restricted iterative generalised least square monte carlo markov chain presented methods compared combined design meta analysis model salt reduction models respective advantages perspective meta analysis discussed however access trial data particular sequence period data cross trials remains major limitation meta analytic combination trial designs copyright â© john wiley sons ltd
10.1166/jmihi.2017.2137 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027327113&doi=10.1166%2fjmihi.2017.2137&partnerID=40&md5=7c1dd7114ce559e288711eef16581f70 0,according medical image characteristics fmcmc algorithm fuzzy entropy measurement markov chain monte carlo based medical image segmentation algorithm proposed based stochastic markov chain model combining fuzzy entropy measurement address challenges taking complexity uncertainty medical images fuzzy entropy edge measurement curves designed via fuzzy entropy describe features medical image firstly secondly random sequence closed curves generated markov chains shifting probability following monte carlo method utilized simulate accelerate convergence designed image segmentation model lastly ideal boundary curve adopted closed region edge maximal edge probability value experiment results demonstrate validity presented algorithm moreover also indicates segmentation algorithm higher ability anti noise achieve accurate medical image segmentation quickly exactly â© copyright american scientific publishers rights reserved
10.1007/s12094-017-1647-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016104499&doi=10.1007%2fs12094-017-1647-9&partnerID=40&md5=d25a7843db641122efbac45a73af9a3a 3,purpose second line chemotherapy shown benefit patients advanced gastric cancer agc extending overall survival os progression free survival pfs study aimed assess efficacy cost effectiveness second line treatment elderly patients agc methods medical records follow information elderly patients â‰¥ â years agc received second line chemotherapy collected markov model comprising three health states pfs progressive disease death developed simulate process agc cost calculated perspective chinese society sensitivity analyses applied explore impact essential variables results forty three elderly patients agc receiving second line chemotherapy included study median os â months confidence interval ci â€“ pfs â months ci â€“ treatment related death occurred frequently drug related grade aes diarrhea leukopenia nausea incremental cost effective ratio qaly second line chemotherapy versus bsc threshold ã— per capita gdp china conclusion second line chemotherapy optimal strategy elderly agc patients china efficacy cost effectiveness perspective â© federaciã³n de sociedades espaã±olas de oncologã­a feseo
10.3390/nu9090983 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029168230&doi=10.3390%2fnu9090983&partnerID=40&md5=9e463d08c3ba49f7633fb0748181fb7c 8,interventions targeting portion size energy density food beverage products identified promising approach obesity prevention study modelled potential cost effectiveness package size cap single serve sugar sweetened beverages ssbs ml package size cap product reformulation reduce energy content packaged ssbs energy reduction cost effectiveness intervention modelled australia population using multi state life table markov model lifetime time horizon long term health outcomes modelled calculated changes body mass index impact health adjusted life years halys intervention costs estimated limited societal perspective cost health outcomes discounted total intervention costs estimated aud aud million interventions resulted reduced mean body weight package size cap kg energy reduction kg halys gained package size cap energy reduction cost offsets estimated aud million package size cap aud billion energy reduction cost effectiveness analyses showed interventions â€œdominantâ€� likely result long term cost savings health benefits package size cap kj reduction ssbs likely offer excellent â€œvalue moneyâ€� obesity prevention measures australia â© authors
10.1007/s13253-017-0285-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020114691&doi=10.1007%2fs13253-017-0285-6&partnerID=40&md5=acdd6c5d3dd9d1a42222afff6cab8e59 4,data streams observed without error regular time intervals discrete time hidden markov models hmms become immensely popular analysis animal location auxiliary biotelemetry data however measurement error temporally irregular data often pervasive telemetry studies particularly marine systems relatively small amounts missing data missing completely random typically problematic hmms temporal irregularity result observations aligning regular time steps required hmms fitting hmms explicitly account uncertainty attributable location measurement error temporally irregular observations forms missing data typically requires computationally demanding techniques markov chain monte carlo mcmc using simulation real world bearded seal erignathus barbatus example investigate practical alternative incorporating measurement error temporally irregular observations hmms based multiple imputation position process drawn single state continuous time movement model two stage approach relatively simple performed existing software using efficient maximum likelihood methods completely parallelizable generally found approach perform well across broad range simulated measurement error irregular sampling rates latent states locations reliably recovered nearly simulated scenarios however high measurement error coupled low sampling rates often induced bias estimated probability distributions data streams derived imputed position process estimated effects spatial covariates state transition probabilities results two stage analysis bearded seal data similar computationally intensive single stage mcmc analysis two stage analysis required much less computation time custom model fitting algorithms thus found two stage multiple imputation approach promising terms ease implementation computation time performance code implementing approach using r package â€œmomentuhmmâ€� provided supplementary materials accompanying paper appear online â© author
10.1007/s11356-017-9720-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023769939&doi=10.1007%2fs11356-017-9720-z&partnerID=40&md5=209abe02abd9dff5b8e1addb222ec1c1 1,objective paper provide efficient framework effluent trading river systems proposed framework consists two pessimistic optimistic decision making models increase executability river water quality trading programs models used purpose stochastic fallback bargaining sfb reach agreement among wastewater dischargers stochastic multi criteria decision making smcdm determine optimal treatment strategy monte carlo simulation method used incorporate uncertainty analysis uncertainty arises stochastic nature errors calculation wastewater treatment costs results river water quality simulation model used inputs models proposed models used case study zarjoub river northern iran determine best solution pollution load allocation best treatment alternatives selected model imported initial pollution discharge permits optimization model developed trading pollution discharge permits among pollutant sources results show sfb based water pollution trading approach reduces costs us providing relative consensus among pollutant sources meanwhile smcdm based water pollution trading approach reduces costs us less acceptable pollutant sources therefore appears giving due attention stability words acceptability pollution trading programs pollutant sources essential element success â© springer verlag gmbh germany
10.1051/0004-6361/201730587 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028765998&doi=10.1051%2f0004-6361%2f201730587&partnerID=40&md5=6867e5d7b82ac5440caa30e426ad0556 3,context current constraints models galaxy evolution rely morphometric catalogs extracted multi band photometric surveys however catalogs altered selection effects difficult model correlate non trivial ways lead contradictory predictions taken account carefully aims address issue developed new approach combining parametric bayesian indirect likelihood pbil techniques empirical modeling realistic image simulations reproduce large fraction selection effects allows us perform direct comparison observed simulated images infer robust constraints model parameters methods use semi empirical forward model generate distribution mock galaxies set physical parameters galaxies passed image simulator reproducing instrumental characteristics survey extracted way observed data discrepancy simulated observed data quantified minimized custom sampling process based adaptive markov chain monte carlo methods results using synthetic data matching properties canada france hawaii telescope legacy survey deep field demonstrate robustness internal consistency approach inferring parameters governing size luminosity functions evolutions different realistic populations galaxies also compare results approach obtained classical spectral energy distribution fitting photometric redshift approach conclusions pipeline infers efficiently luminosity size distribution evolution parameters limited number observables three photometric bands compared sed fitting based set observables method yields results accurate free systematic biases â© eso
10.1161/CIRCULATIONAHA.117.027067 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023759129&doi=10.1161%2fCIRCULATIONAHA.117.027067&partnerID=40&md5=a006af85ba0936287a9f97cc40d6aad2 7,background statins effective primary prevention atherosclerotic cardiovascular disease american college cardiology american heart association acc aha guideline expands recommended statin use cost effectiveness compared guidelines methods used cardiovascular disease policy model estimate cost effectiveness acc aha guideline relative current use adult treatment panel iii guidelines universal statin use men years age women years age year horizon sensitivity analyses varied costs risks benefits main outcomes incremental cost effectiveness ratios numbers needed treat years per quality adjusted life year gained results approach produces substantial benefits net cost savings relative status quo full adherence adult treatment panel iii guideline result million statin users status quo number needed treat years per quality adjusted life year gained acc aha guideline potentially result million statin users adult treatment panel iii guideline marginal number needed treat years per quality adjusted life year gained moderate intensity statin use men years age women years age result million statin users acc aha guideline marginal number needed treat years per quality adjusted life year gained cases benefits greater men women results vary moderately different risk thresholds instituting statins statin toxicity estimates depend greatly disutility caused daily medication use pill burden conclusions population level acc aha guideline expanded statin use primary prevention projected treat people save lives cost less compared adult treatment panel iii men women whether individuals benefit long term statin use primary prevention depends disutility associated pill burden degree cardiovascular risk â© american heart association inc
10.1097/EDE.0000000000000680 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028830774&doi=10.1097%2fEDE.0000000000000680&partnerID=40&md5=9476c0dbf3987eb0065ceaa01bace7fe 1,abstract available
10.1097/EDE.0000000000000679 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028866964&doi=10.1097%2fEDE.0000000000000679&partnerID=40&md5=5c739cfd2fb0cf67403c70f8f374a6eb 0,abstract available
10.1007/s10198-016-0851-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001055589&doi=10.1007%2fs10198-016-0851-9&partnerID=40&md5=839c4b986bddbb0e39272be5baf144fa 1,background policymakers need know cost effectiveness interventions prevent type diabetes objective study estimate cost effectiveness prevention initiative targeting weight reduction increased physical activity healthier diet persons pre diabetic states comparing hypothetical intervention versus intervention swedish setting methods markov model used study cost effectiveness prevention program based lifestyle change versus control group prevention applied analyses done deterministically probabilistically based monte carlo simulation six different scenarios defined sex age groups â years cost quality adjusted life year qaly differences intervention intervention incremental cost effectiveness ratios icers estimated visualized cost effectiveness planes ce planes cost effectiveness acceptability curves cea curves results icers cost effective ranged â â‚¬ qaly gained women â years â â‚¬ qaly gained men â years cea curves showed probability intervention cost effective threshold value â â‚¬ per qaly gained high scenarios ranging discussion conclusion prevention delay onset feasible cost effective small investment healthy lifestyle change physical activity diet together weight loss likely cost effective â© author
10.1007/s00180-017-0710-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010973222&doi=10.1007%2fs00180-017-0710-x&partnerID=40&md5=b5f765f1844ed6c8982700163b5861bb 0,frequentist standard errors measure uncertainty estimator basis statistical inferences frequestist standard errors also derived bayes estimators however except special cases computation standard error bayesian estimators requires bootstrapping combination markov chain monte carlo highly time consuming discuss alternative approach computing frequentist standard errors bayesian estimators including importance sampling several numerical examples show approach much computationally efficient standard bootstrap â© springer verlag berlin heidelberg
10.4103/jrms.JRMS_926_16 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035083631&doi=10.4103%2fjrms.JRMS_926_16&partnerID=40&md5=c6ea82589be869fb679584050e606a29 0,background study aimed determine comprehensive maternal characteristics associated birth weight using bayesian modeling materials methods total participants included prospective study nutritional status supplement consumption pregnancy demographic socioeconomic characteristics anthropometric measures physical activity pregnancy outcomes considered effective variables birth weight bayesian approach complex statistical models using markov chain monte carlo approach used modeling data considering real distribution response variable results strong positive correlation infant birth weight maternal intake vitamin c folic acid vitamin b vitamin selenium calcium iron phosphorus potassium magnesium micronutrients fiber protein macronutrients based high posterior density regions parameters bayesian model none maternal characteristics statistical association birth weight conclusion higher maternal macro micro nutrient intake pregnancy associated lower risk delivering low birth weight infants findings support recommendations expand intake nutrients pregnancy high level â© journal research medical sciences
10.5351/CSAM.2017.24.5.457 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044064924&doi=10.5351%2fCSAM.2017.24.5.457&partnerID=40&md5=d812694681f0195ca8c7385420b7c476 0,develop random partition procedure based dirichlet process prior laplace distribution gibbs sampling laplace mixture linear mixed regressions dirichlet process implemented random partition model number clusters unknown approach provides simultaneous partitioning parameter estimation computation classification probabilities unlike counterparts full gibbssampling algorithm developed efficient markov chain monte carlo posterior computation proposed method illustrated simulated data one real data energy efficiency tsanas xifara energy buildings â© korean statistical society korean international statistical society
10.1007/s11222-016-9681-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978877426&doi=10.1007%2fs11222-016-9681-y&partnerID=40&md5=77c230c65f9dfca4bb75e0293383aa15 2,latent feature models powerful tool modeling data globally shared features nonparametric distributions exchangeable sets features indian buffet process offer modeling flexibility letting number latent features unbounded however current models impose implicit distributions number latent features per data point implicit distributions may match knowledge data work demonstrate restricted indian buffet process circumvents restriction allowing arbitrary distributions number features observation discuss several alternative constructions model apply insights develop markov chain monte carlo variational methods simulation posterior inference â© springer science+business media new york
10.1002/cjs.11318 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018613525&doi=10.1002%2fcjs.11318&partnerID=40&md5=2ec5696a8f0ff2d4e93166cb4f65fc9a 0,work proposes bayesian approach analysis semiparametric density ratio model model useful integration data multiple sources proposed bayesian analysis uses non parametric likelihood transformed gaussian prior â€œnon parametric partâ€� model former choice guarantees validity bayesian analysis contrast semiparametric bayesian analyses rely empirical likelihoods whereas latter choice allows representation expected smoothness property describe markov chain monte carlo algorithm fit model found empirically display good convergence behaviour model illustrated analysis motor vibration data obtained three different locations motor canadian journal statistics â€“ â© statistical society canada â© statistical society canada
10.1142/S2010132517500213 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023205841&doi=10.1142%2fS2010132517500213&partnerID=40&md5=4dc8d33b3da850373cb798dea64102ec 1,number occupants space significantly affect ventilation control using neural network bayesian markov chain monte carlo mcmc methods study estimates number occupants based co concentration room abilities methods recognize input parameter characteristics compared certain circumstances parameters optimized improve estimation accuracy neural network trains input dataset co concentrations ventilation rates occupancy patterns tapped delay lines meanwhile bayesian mcmc calculates given co data mathematical model based statistical approach present space model single office room co concentration determined several simulation schemes experiments estimation accuracy neural network depends complexity input parameters e co concentration ventilation rate whereas bayesian mcmc influenced uncertainty co concentration methods produce acceptable estimates certain treatments â© world scientific publishing company
601.6816205642543 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030033071&partnerID=40&md5=1a78d6931253767836f7e1e874e83402 0,statistical modeling analysis social networks evolved important area research related complex relationships among social entities paper new monitoring method based exponential random graph model ergm presented control charts used detect control states networks markov chain monte carlo mcmc algorithm used parameter estimation purposes monitoring statistics based generalized likelihood ratio test glrt applied detect departures anomalies networks case study social network used depict properties benefits proposed methodology results show glr chart better performance average run length arl compared cusum chart detecting large shifts cusum chart better detecting small shifts
10.4169/college.math.j.48.4.265 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033473938&doi=10.4169%2fcollege.math.j.48.4.265&partnerID=40&md5=27a7c79f13e764f8bd4a9a97554a9a7b 0,learning probability hard frustrating many students however learning probability examples board games make task interesting fun present sequence increasingly difficult probability problems derived popular board game carcassonne question appropriate either college classroom undergraduate research topics including basic counting problems expected value bayesâ€™s theorem markov chains monte carlo simulation problems solutions questions left open reader explore â© mathematical association america
10.1002/rra.3162 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019868728&doi=10.1002%2frra.3162&partnerID=40&md5=fa643fe1b8df0fcfe3a34f28052a4a73 1,warm cool ambient temperatures winter generate plasticity within year timing oviposition breeding phenology shifts use reaction norm many riverine ectotherms within year timing oviposition hynobius kimurae caudata hynobiidae predicted constant different water temperatures mountain stream clarify difference experimentally controlling water temperatures fall spring thus changing durations aquatic hibernation dates oviposition determined whether oviposition advanced water temperatures increase earlier usual delayed water temperatures increase later usual oviposition delayed usual earlier exposure high water temperatures spring earlier usual exposing higher water temperatures hibernation days submergence oviposition responsive cumulative daily water temperatures submergence oviposition within population rate increase days submergence oviposition different populations constant within population even minimal water temperatures varied year running program markov chain monte carlo generalized linear mixed model bayesian computation interpret confounding effects neither different treatments different years statistically affected days submergence oviposition results suggest biological clock exits days submergence oviposition h kimurae allow survival situations either warmer cooler environments copyright â© john wiley sons ltd
10.3847/1538-4357/aa845e https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029066981&doi=10.3847%2f1538-4357%2faa845e&partnerID=40&md5=8aeab2056ceb9ca47c8d54fc94fbd029 4,dwarf galaxies known remarkably low star formation efficiency due strong feedback adopting dwarf galaxies milky way mw laboratory explore flexible semi analytic galaxy formation model understand feedback processes shape satellite galaxies mw using markov chain monte carlo exhaustively search large parameter space model rigorously show general wisdom strong outflows primary feedback mechanism simultaneously explain stellar mass function mass metallicity relation mw satellites extended model assumes fraction baryons prevented collapsing low mass halos first place accurately constrained simultaneously reproduce observations inference suggests two different physical mechanisms needed explain two different data sets particular moderate outflows weak halo mass dependence needed explain mass metallicity relation prevention baryons falling shallow gravitational potentials low mass halos e g pre heating needed explain low stellar mass fraction given subhalo mass â© american astronomical society rights reserved
10.1111/ppa.12666 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772438&doi=10.1111%2fppa.12666&partnerID=40&md5=2098cb4679ac93219e5514e118c8dd0c 2,phytophthora sojae destructive soilborne pathogen causing seedling damping root rot soybean glycine max goal study determine genetic structure p â sojae populations fujian china nine microsatellite markers used investigate genetic variation p â sojae populations sampled fujian province northeastern china jilin heilongjiang provinces overall low genetic diversity hardyâ€“weinberg disequilibrium formula presented index index association significantly different zero detected populations results consistent self fertilization clonal modes reproduction pathogen however using bayesian markov chain monte carlo approach principal component analysis neighbour joining nj algorithm fujian p â sojae populations clustered three distinct groups one included isolates northeast populations significant estimates pairwise fixation indices fst detected populations especially different clusters hypothesized cropping system used limited dispersal ability human mediated gene flow may account observed genetic structure p â sojae populations fujian china addition high virulence frequency pathogen different cultivars carrying known major r genes resistance rapid increase virulence frequency indicated major r genes used manage seedling damping root rot diseases soybean glycine max â© british society plant pathology
10.1051/0004-6361/201527852e https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029756704&doi=10.1051%2f0004-6361%2f201527852e&partnerID=40&md5=4a2a8348bf02757f17f6a6d88e3638c0 0,ghelfi et al performed global analysis top atmosphere data recent pamela bess ams data obtain h interstellar fluxes uncertainties simple parametric formula provided fluxes shown fig interest wide range astrophysics problems however parametric form eq contains error coeficients c c table incorrect new eq table replace eq table ghelfi et al formula presented formula presented discussed ghelfi et al first five columns table coeficients median credible intervals markov chain monte carlo mcmc analysis without voyager data considered high estimate h fluxes valid mev n last column provides best fit including voyager data assumed insterstellar considered low estimate h fluxes table presented â© eso
10.1016/j.dark.2017.07.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027236190&doi=10.1016%2fj.dark.2017.07.003&partnerID=40&md5=999bd8dbba9c41a7127df3be7cacc62d 3,extend alternative phenomenological approach inflation means equation state sound speed functions number e folds four phenomenological parameters approach captures number possible inflationary models including non canonical kinetic terms scale dependent non gaussianities perform markov chain monte carlo analyses using latest cosmological publicly available measurements include cosmic microwave background cmb data planck satellite within parameterization discard scale invariance significance ïƒ running spectral index constrained î±s=âˆ’ âˆ’ + ã— âˆ’ cl errors limit tensor scalar ratio r lt cl cmb data alone find significant evidence alternative parameterization present cosmological observations maximum amplitude equilateral non gaussianity obtain fnl equil lt much smaller current planck mission errors strengthening case future high redshift sky surveys reach required accuracy equilateral non gaussianities â© elsevier b v
10.1214/17-AOAS1027 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031498647&doi=10.1214%2f17-AOAS1027&partnerID=40&md5=75622bbc8fd91e301ca57d5d5fc03b04 4,gravitational field galaxy act lens deflect light emitted distant object quasar strong gravitational lensing causes multiple images quasar appear sky since light gravitationally lensed image traverses different path length quasar earth fluctuations source brightness observed several images different times time delay fluctuations used constrain cosmological parameters inferred time series brightness data light curves image estimate time delay construct model based state space representation irregularly observed time series generated latent continuous time ornsteinâ€“uhlenbeck process account microlensing additional source independent long term extrinsic variability via polynomial regression bayesian strategy adopts metropolisâ€“hastings within gibbs sampler improve sampler using ancillarity sufficiency interweaving strategy adaptive markov chain monte carlo introduce profile likelihood time delay approximation marginal posterior distribution bayesian profile likelihood approaches complement producing almost identical results bayesian method principled profile likelihood simpler implement demonstrate estimation strategy using simulated data doubly quadruply lensed quasars observed data quasars q + j + â© institute mathematical statistics
10.1093/sysbio/syw119 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019776034&doi=10.1093%2fsysbio%2fsyw119&partnerID=40&md5=034ae7b8afcf75b179a15a06ed1c8598 13,develop bayesian method inferring species phylogeny multispecies coalescent msc model improve mixing properties markov chain monte carlo mcmc algorithm traverses space species trees implement two efficient mcmc proposals first based subtree pruning regrafting spr algorithm second based node slider algorithm like nearest neighbor interchange nni algorithm implemented previously new algorithms propose changes species tree simultaneously altering gene trees multiple genetic loci automatically avoid conflicts newly proposed species tree method integrates gene trees naturally taking account uncertainty gene tree topology branch lengths given sequence data simulation study performed examine statistical properties new method method found show excellent statistical performance inferring correct species tree near certainty loci included dataset prior species trees impact particularly small numbers loci analyzed several previously published datasets real simulated rattlesnakes philippine shrews comparison alternative methods results suggest bayesian coalescent based method statistically efficient heuristic methods based summary statistics implementation computationally efficient alternative full likelihood methods themsc parameter estimates rattlesnake data suggest drastically different evolutionary dynamics nuclear mitochondrial loci even though support largely consistent species trees discuss different challenges facing marginal likelihood calculation transmodel mcmc alternative strategies estimating posterior probabilities species trees â© author
10.1371/journal.pcbi.1005697 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030468714&doi=10.1371%2fjournal.pcbi.1005697&partnerID=40&md5=65ea16fcbc9935a25a7dec6b33744f25 7,heterogeneities contact networks major effect determining whether pathogen become epidemic persist endemic levels epidemic models determine interventions successfully prevent outbreak need account social structure mixing patterns contact patterns vary across age locations e g home work school including predictors transmission dynamic models pathogens spread socially improve modelsâ€™ realism data population based contact diaries eight european countries polymod study projected countries using bayesian hierarchical model estimated proclivity age location specific contact patterns countries using markov chain monte carlo simulation household level data demographic health surveys nine lower income countries socio demographic factors several line databases countries used quantify similarity countries estimate contact patterns home work school locations countries contact data available accounting demographic structure household structure known variety metrics including workforce participation school enrolment contacts highly assortative age across countries considered pronounced regional differences age specific contacts home noticeable inter generational contacts asian countries settings moreover variations contact patterns location work place contacts least assortative variations led differences effect social distancing measures age structured epidemic model contacts important role transmission dynamic models use contact rates characterize spread contact transmissible diseases study provides estimates mixing patterns societies contact data polymod yet available â© prem et al
10.1016/j.fishres.2017.04.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018352174&doi=10.1016%2fj.fishres.2017.04.004&partnerID=40&md5=486d42fe89ffc84ff59f0740d0c2746a 1,age growth estimates based growth band counts sectioned vertebrae produced longnose skate raja rhina big skate beringraja binoculata formerly raja binoculata populations gulf alaska british columbia california previous growth studies involving estimates different laboratories usa alaska fisheries science center afsc pacific shark research center psrc moss landing marine laboratories canada fisheries oceans canada dfo produced dissimilar results either species highlighting need development consistent age determination protocol importantly age validation study archived large specimens longnose skate big skate collected monterey bay ca minimum preliminary age estimates vertebral growth band counts old enough suggest radiocarbon c signals bomb testing conducted late used establish dates growth band formation end micro milled skate vertebral thin sections measured î” c using mass spectrometry estimated year growth band formation based estimated age growth band counts using unstained stained preparation methods non linear random effects modeling implemented markov chain monte carlo mcmc simulation used compare skate î” c data set marine teleost otolith reference chronology california current system results showed î” c measurements big skate non informative none archived samples old enough comparison reference curve hence validation age estimation approach possible however longnose skate î” c data informative fit pulse function models compare results reference chronology modeling results indicated longnose skate age estimates based unstained vertebral thin sections less biased overestimated smaller degree estimates based stained vertebral thin sections degree bias depended agency ageing criteria least biased age estimates produced age readers afsc afsc age estimates probability age estimates longnose skate withinâ + âˆ’ years expected age based radiocarbon assays able validate age estimation methodology longnose skate establish criteria growth band counts useful generate region specific accurate growth life history parameters required reliable stock assessment approaches â© elsevier b v
10.1007/s10958-017-3498-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026833638&doi=10.1007%2fs10958-017-3498-x&partnerID=40&md5=096e1dd15a02c7511cfe27665625e72c 0,consider system two independent alternating renewal processes states initial shift one process relative one integral equation respect expectation time first time processes state derived derive equation use method called minimal chains overlapping intervals chain generates breaking semi markov process intervals composing interval solution integral equation obtained case lengths intervals exponential distributions lengths intervals arbitrary distributions general distributions intervals monte carlo method applied processes simulated numerically computer histogram estimates expectation function demonstrated bibliography titles â© springer science+business media llc
10.1016/j.enggeo.2017.06.014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021456942&doi=10.1016%2fj.enggeo.2017.06.014&partnerID=40&md5=c0e36b5f71d41cfc9293841d05a16de5 4,one essential tasks excavation tunnels tbm reliable estimation performance needed planning cost control decision making feasibility tunneling project current study aims predicting rate penetration rop tbm basis rock mass parameters including uniaxial compressive strength ucs intact rock brittleness bi angle plane weakness tbm driven direction î± distance planes weakness dpw end datasets queens water tunnel project new york city compiled used establish models bayesian inference approach implemented identify appropriate models estimating rop among eight candidate models proposed selected tbm empirical models fitted field data unknown parameters models considered random variables winbugs software uses bayesian analysis complex statistical models markov chain monte carlo mcmc techniques employed compute posterior predictive distributions mean values model parameters obtained via mcmc simulations considered model prediction performance evaluation meanwhile deviance information criterion dic used main prediction accuracy indicator therefore rank models taking account fit complexity overall results indicate proposed rop model possesses satisfactory predictive performance â© elsevier b v
10.1109/SNPD.2017.8022746 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030845149&doi=10.1109%2fSNPD.2017.8022746&partnerID=40&md5=e01a1e86249a4c2c4d1abea1f166bc02 0,latent dirichlet allocation lda based topic inference data classification method used efficiently extremely large data sets however processing time large due serial computational behavior markov chain monte carlo method used topic inference propose pipelined hardware architecture memory allocation scheme accelerate lda using parallel processing proposed architecture implemented reconfigurable hardware called fpga field programmable gate array using opencl design environment according experimental results achieved maximum speed times maintaining quality compared conventional cpu based implementation â© ieee
10.11743/ogg20170419 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029852717&doi=10.11743%2fogg20170419&partnerID=40&md5=b0e6c645d5e01f62dbc582aace67f921 0,carbonate karst reservoirs lower middle ordovician tahe oilfield feature large burial depth irregular distribution complex reservoir types strong heterogeneity thus reservoir type identification always challenging oil gas exploration development area paper documented new impedance inversion method e waveform indication based inversion based bayesian discriminant theory markov chain monte carlo sampling algorithm method based reservoir type identification seismic reflection characteristics petrophysical analyses used optimize sample wells observing seismic waveform similarities establish initial impedance model referring sampling spacing curve characteristics relationship proposed distribution prior information firstly established achieve efficient sampling priori solution space metropolis hastings sampling algorithm used sample posterior probability distribution obtain maximum posterior probability solution application method identifying types ordovician karst reservoirs tahe oilfield shows significant improvement inversion accuracy better utilization horizontal variation seismic waveforms reveal effectively types spatial lateral distribution reservoirs provides fine characterization reservoirs â© editorial office oil gas geology right reserved
10.1109/ACCESS.2017.2746141 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028697217&doi=10.1109%2fACCESS.2017.2746141&partnerID=40&md5=2e1cb392925e5a2a0a68623b22f77f5b 3,paper propose novel probabilistic localization approach relies metropolis hastings mh algorithm based bayesian approach visible light communication vlc systems due usage mh algorithm markov chain monte carlo methods positioning capability proposed approach becomes robust varying channel propagation conditions measurement uncertainties validity proposed approach demonstrated numerical analyses based simulations indoor environments comparative manner least square ls differential ls algorithms based localization solutions circumventing shortcomings ls based approaches addressing short range challenge vlc based positioning system efficient hybrid localization framework also developed multi tier heterogeneous networks hetnets jointly considering vlc radio frequency networks methodology mainly considers independent positioning solution branches estimate target location utilizing mh based bayesian approach based simulation results proposed framework multi tier hetnets provides robust performance overall show new vlc localization scheme performance short range enhanced hetnets effectiveness localization long range improved â© ieee
10.1186/s12711-017-0339-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028339369&doi=10.1186%2fs12711-017-0339-9&partnerID=40&md5=1ef81b83b23a78e34af35b009dc4d56d 0,background rapid adoption genomic selection due two key factors availability high throughput dense genotyping statistical methods estimate predict breeding values development methods still ongoing far consensus best approach currently linear non linear methods genomic prediction gp treated distinct approaches aim study evaluate implementation iterative method called gbc incorporates aspects linear genomic best linear unbiased prediction g blup non linear bayes c methods gp iterative nature gbc makes less computationally demanding similar non markov chain monte carlo mcmc approaches however bayesian method gbc differs mcmc non mcmc based methods combining aspects g blup bayes c methods gp relative performance compared g blup bayes c methods used imputed k single nucleotide polymorphism snp dataset based illumina bovine k beadchip included snps records daughter yield deviations somatic cell count fat yield milk yield protein yield used response variables results gbc frequently marginally superior g blup bayes c terms prediction accuracy significantly better g blup fat yield average across four traits gbc yielded increase prediction accuracy g blup bayes c respectively computationally gbc much faster bayes c similar g blup conclusions results show incorporating aspects g blup bayes c single model improve accuracy gp commonly used method g blup generally gbc statistically perform better g blup bayes c probably due close relationships reference validation individuals nevertheless flexible tool sense simultaneously incorporates aspects linear non linear models gp thereby exploiting family relationships also accounting linkage disequilibrium snps genes large effects application gbc gp merits exploration â© author
10.1103/PhysRevE.96.022413 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028653166&doi=10.1103%2fPhysRevE.96.022413&partnerID=40&md5=5b851eaec798c7ecd547869871a4acc3 0,rapid experimental advances enable simultaneous electrophysiological recording neural activity single cell resolution across large regions nervous system models neural network activity necessarily increase size complexity thus increasing computational cost simulating challenge analyzing present method approximate activity firing statistics general firing rate network model wilson cowan type subject noisy correlated background inputs method requires solving system transcendental equations fast compared monte carlo simulations coupled stochastic differential equations implement method several examples coupled neural networks show results quantitatively accurate even moderate coupling strengths appreciable amount heterogeneity many parameters work useful investigating various neural attributes qualitatively affect spiking statistics coupled neural networks â© american physical society
10.7554/eLife.25062 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029232429&doi=10.7554%2feLife.25062&partnerID=40&md5=d445c7ea41522d09cf49d1f1a8deac76 2,background exercise induced cognitive improvements traditionally observed following aerobic exercise interventions sustained sessions moderate intensity tested effect week high intensity training hit regimen measures cognitive control working memory multicenter randomized allocation placebocontrolled trial methods children aged years randomly assigned hit active control group matched enjoyment motivation primary analysis compared improvements six cognitive tasks representing two cognitive constructs n = secondary outcomes included genetic data physiological measurements results week hit regimen resulted improvements measures cognitive control bfm = g = working memory bfm = g = moderated bdnf genotype met carriers showing larger gains post exercise val homozygotes conclusion study suggests promising alternative enhance cognition via short potent exercise regimens clinical trial registration protocol university auckland â© moreau et al
10.1016/j.tecto.2017.04.027 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019374596&doi=10.1016%2fj.tecto.2017.04.027&partnerID=40&md5=fd143279f470f264c055155154e31c24 3,faults one building blocks subsurface modeling studies incomplete observations subsurface fault networks lead uncertainty pertaining location geometry existence faults practice gaps incomplete fault network observations filled based tectonic knowledge interpreter intuition pertaining fault relationships modeling fault network uncertainty realistic models represent tectonic knowledge still challenge although methods address specific sources fault network uncertainty complexities fault modeling exists unifying framework still lacking paper propose rigorous approach quantify fault network uncertainty fault pattern intensity information expressed means marked point process marked strauss point process fault network information constrained fault surface observations complete partial within bayesian framework structural prior model defined quantitatively express fault patterns geometries relationships within bayesian framework structural relationships faults particular fault abutting relations represented level set based approach markov chain monte carlo sampler used sample posterior fault network realizations reflect tectonic knowledge honor fault observations apply methodology field study nankai trough kumano basin target uncertainty quantification deep site attenuated seismic data partially visible faults many faults missing survey interpretation structural prior model built shallow analog sites believed undergone similar tectonics compared site study fault network uncertainty field quantified fault network realizations conditioned structural rules tectonic information partially observed fault surfaces show proposed methodology generates realistic fault network models conditioned data conceptual model underlying tectonics â© elsevier b v
10.1103/PhysRevE.96.022410 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028713802&doi=10.1103%2fPhysRevE.96.022410&partnerID=40&md5=bd3974e4b8c948b31e189fe31e616419 0,mechanosensitive channels ion channels act cells safety valves opening osmotic pressure becomes high making cells avoid damage releasing ions found cellular membrane large number organisms interact means deformations induce membrane show collective dynamics arising interchannel interactions lead first second order phase transitions fraction open channels equilibrium relating formation channel clusters show results considerable delay response cells osmotic shocks extreme cell cell stochastic variations response times despite large numbers channels present cell discuss results relevant e coli â© american physical society
10.3847/1538-4357/aa81ca https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028760046&doi=10.3847%2f1538-4357%2faa81ca&partnerID=40&md5=075e9ebf8dec38d358688cba6aa26912 1,present first kinematic study extraplanar diffuse ionized gas edig nearby face disk galaxy using optical emission line spectroscopy robert stobie spectrograph southern african large telescope use markov chain monte carlo method decompose n ii hî± ii emission lines h ii region diffuse ionized gas emission extraplanar diffuse gas distinguished emission line ratios n ii î» hî± rotational velocity lag respect disk km projection interesting implications isotropy velocity dispersion diffuse gas km factor higher milky way nearby edge disk galaxies turbulent pressure gradient sufficient support edig layer dynamical equilibrium electron scale height kpc however dynamical equilibrium model must finely tuned reproduce rotational velocity lag evidence local bulk flows near star forming regions disk suggesting dynamical state gas may intermediate dynamical equilibrium galactic fountain flow one first efforts study edig kinematics face galaxy study demonstrates feasibility characterizing radial distribution bulk velocities vertical velocity dispersions low inclination systems â© american astronomical society rights reserved
10.1146/annurev-astro-082214-122339 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027980732&doi=10.1146%2fannurev-astro-082214-122339&partnerID=40&md5=ad94b5c83c4b8efda559938de48d68bf 13,markov chain monte carlo based bayesian data analysis become method choice analyzing interpreting data almost disciplines science astronomy past decade also seen steady increase number papers employ monte carlo based bayesian analysis new efficient monte carlo based methods continuously developed explored review first explain basics bayesian theory discuss set data analysis problems within framework next provide overview various monte carlo based methods performing bayesian data analysis finally discuss advanced ideas enable us tackle complex problems thus hold great promise future also distribute downloadable computer software https github comsanjibsbmcmc python implements algorithms examples discussed â© copyright annual reviews rights reserved
10.1016/j.jsv.2017.05.005 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019689912&doi=10.1016%2fj.jsv.2017.05.005&partnerID=40&md5=2027e16af0a990b88c1fc9dfcc9d7f02 0,dynamic properties viscoelastic materials show highly frequency temperature dependency numerical methods structural systems containing type material require accurate mathematical models describe dynamical behaviour material behaviour modelled using constitutive equation based fractional derivative operators considering temperature dependence material thermorheologically simple postulate quest information constitutive model parameters phrased statistical inverse problem bayesian framework markov chain monte carlo mcmc method used explore posterior density model parameters using measured data dynamic tests different temperatures agreement measured data predictive capabilities sixteen models quantitatively assessed using two validation metrics based validation metrics analysis possible conclude range temperature calibration data set key point implementation frequency temperature superposition principle ftsp verified defining scenarios assessing agreement model predictions set available experimental data results quite compelling due fact proposed approach easy handed furthermore approach applied generic constitutive model using ftsp â© elsevier ltd
10.1080/02664763.2016.1238058 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990172626&doi=10.1080%2f02664763.2016.1238058&partnerID=40&md5=017dd3b257a23cf2000bc4decbc2ca27 0,sinh normal independent distributions class symmetric heavy tailed distributions include sinh normal distribution special case used extensively birnbaumâ€“saunders regression models explore use markov chain monte carlo methods develop bayesian analysis nonlinear regression models sinh normal independent distributions assumed random errors term provides robust alternative sinh normal nonlinear regression model bayesian mechanisms parameter estimation residual analysis influence diagnostics developed extend results farias lemonte bayesian inference birnbaum saunders nonlinear regression model stat methods appl pp used sinh normal independent distributions known scale parameter special cases based sinh student sinh st sinh slash sinh sl sinh contaminated normal sinh cn distributions discussed detail two real datasets finally analyzed illustrate developed procedures â© informa uk limited trading taylor francis group
10.1080/08120099.2017.1362663 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028531341&doi=10.1080%2f08120099.2017.1362663&partnerID=40&md5=87a715416e3f4fb45cb867ceea8ef2f0 0,borehole temperature data potential record historical variations ground air surface temperature yet reliable purpose drilled boreholes available explore impacts particularly southern hemisphere deep tynong borehole approximately â km ese melbourne australia drilled specifically determine conductive heat flow provides unique dataset evaluating ground surface temperature history southeastern australia steady state conductive heat flow â± mw mâˆ’ determined deeper borehole sections measured temperature profiles clearly demonstrating progressive divergence observed temperature profile equilibrium model upper âˆ¼ â hole applied bayesian method employing reverse jump markov chain monte carlo search algorithm explore origins variation results indicate â°c increase ground surface temperature since least â years relatively stable ground surface temperature inversion results consistent trend surface air temperature recorded southeast victoria historical meteorological data since inferred increase ground surface temperature evident prior likely cumulative effect land clearing rise surface air temperature â© geological society australia
10.1080/00036846.2016.1270414 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011562602&doi=10.1080%2f00036846.2016.1270414&partnerID=40&md5=7a52f7553e0aba92a6045c5a72d432bd 0,empirical studies attempted clarify mechanism illegal dumping examining degree per bag pricing plays role however previous research behaviour avoiding paying charge waste collection tended neglect called â€˜immoral disposal â€™ less risky illegal dumping legal penalty study define immoral disposal dumping waste manner immoral illegal detect existence immoral disposal apply spatial econometric approach namely extended panel spatial durbin model identify actual spillover effect garbage pricing neighbouring municipalities immoral disposal total waste major finding study immoral disposal exists unit based pricing two tiered pricing fixed pricing â© informa uk limited trading taylor francis group
10.1002/sim.7301 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018797427&doi=10.1002%2fsim.7301&partnerID=40&md5=248fe6f1ca28febc20dc75a785faa1f6 1,using original data collected referral relations hospitals serving large regional community show recently derived bayesian exponential random graph models may adopted illuminate core empirical issues research relational coordination among healthcare organisations show rigorous bayesian computation approach supports fully probabilistic analytical framework alleviates well known problems estimation model parameters exponential random graph models also show main structural features interhospital patient referral networks prior studies described reproduced accuracy specifying system local dependencies produce â€“ time induced â€“ decentralised collaborative arrangements hospitals copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1186/s12864-017-4030-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027507554&doi=10.1186%2fs12864-017-4030-x&partnerID=40&md5=0c52f031dd688fb56791f5ed4cd5a3bf 1,background using whole genome sequence data might improve genomic prediction accuracy compared high density snp arrays lead identification casual mutations affecting complex traits traits accurate genomic predictions achieved non linear bayesian methods however number variants size reference population increase computational time required implement bayesian methods typically monte carlo markov chain sampling becomes unfeasibly long results applied new method hyb br hybrid bayesr implements mixture model normal distributions hybridizes expectation maximization em algorithm followed markov chain monte carlo mcmc sampling genomic prediction large dairy cattle population imputed whole genome sequence data imputed whole genome sequence data included variant genotypes holstein jersey bulls cows traits included fat yield milk volume protein kg fat protein milk well fertility heat tolerance hyb br achieved genomic prediction accuracies high full mcmc implementation bayesr predicting validation set holstein jersey bulls multi breed prediction validation set australian red bulls across breed prediction hyb br ten fold reduction compute time compared mcmc implementation bayesr hours versus hours also demonstrate many cases hyb br identified sequence variants high posterior probability affecting milk production fertility traits similar identified bayesr heat tolerance hyb br bayesr found variants close promising candidate genes associated trait detected previous studies conclusions results demonstrate hyb br feasible method simultaneous genomic prediction qtl mapping whole genome sequence large reference populations â© author
10.1186/s12942-017-0104-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027460122&doi=10.1186%2fs12942-017-0104-x&partnerID=40&md5=b107acb46bcbc2c01d4d3ee3bd94df75 5,background dengue high incidence arboviral disease tropical countries around world colombia endemic country due favourable environmental conditions vector survival spread dengue surveillance colombia based passive notification cases supporting monitoring prediction risk factor identification intervention measures even though surveillance network works adequately disease mapping techniques currently developed employed many health problems widely applied select colombian city bucaramanga apply bayesian areal disease mapping models testing challenges difficulties approach methods estimated relative risk dengue disease census section geographical unit composed approximately city blocks period january december included covariates normalized difference vegetation index ndvi land surface temperature lst obtained satellite images fitted bayesian areal models complete period annual aggregation time scales fixed space varying coefficients covariates using markov chain monte carlo simulations addition used cohen kappa agreement measures compare risk year year every year complete period aggregation results found ndvi providing information lst estimating relative risk dengue although effects small ndvi directly associated high relative risk dengue risk maps dengue produced estimates obtained modeling process year year risk agreement census section sligth fair conclusion study provides example implementation relative risk estimation using bayesian models disease mapping small spatial scale covariates relate satellite data dengue disease using areal data approach commonly found literature main difficulty study find quality data generating expected values input models remark importance creating population registry small spatial scale relevant risk estimation dengue also important surveillance notifiable diseases â© author
10.1063/1.4998163 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027284466&doi=10.1063%2f1.4998163&partnerID=40&md5=122a6f9ddd87262196e574ace52a89d3 2,time frequency dependence electric field induced phase transition batio bizn ti studied using situ x ray diffraction kinetics field induced phase transition cubic tetragonal phases described using modified kolmogorov avrami ishibashi kai equation unlike previous works assumptions e g unimodal gaussian distribution transition rates needed present work utilized bayesian inference markov chain monte carlo algorithm obtain distribution transition rates empirically without priori assumption distribution results show transition rate coefficient increases frequency applied field increases mean value exponent n modified kai equation close implying field induced phase transition site saturated growth induced phase occurred primarily surface â© author
10.1145/3097983.3098100 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029038319&doi=10.1145%2f3097983.3098100&partnerID=40&md5=9869f2357fed15ffc58afe42a7da1b22 2,diabetes serious disease affecting large number people although cure diabetes managed especially advances sensor technology lots data may lead improvement diabetes management properly mined however usually exists noise errors observed behavioral data poses challenges extracting meaningful knowledge overcome challenge learn latent state represents patient condition states inferred behavioral data unknown priori paper propose novel framework capture trajectory latent states patients behavioral data exploiting demographic differences similarities patients conduct hypothesis test illustrate importance demographic data diabetes management validate behavioral feature follows exponential gaussian distribution integrating aspects use demographic feature restricted hidden markov model dfrhmm estimate trajectory latent states integrating demographic behavioral data dfrhmm latent state mainly determined previous state demographic features nonlinear way markov chain monte carlo techniques used model parameter estimation experiments synthetic real datasets show dfrhmm effective diabetes management â© acm
10.1080/00949655.2017.1332196 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019674624&doi=10.1080%2f00949655.2017.1332196&partnerID=40&md5=4fc0ddd90ac2d9228d25a8f6ff5165fe 0,practice survival data often collected geographical regions shared spatial frailty models used model spatial variation survival times often implemented using bayesian markov chain monte carlo method however method comes price slow mixing rates heavy computational cost may render impractical data intensive application alternatively frailty model assuming independent identically distributed iid random effect easily efficiently implemented therefore used simulations assess bias efficiency loss estimated parameters residual spatial correlation present using iid random effect simulations indicate shared frailty model iid random effect estimate regression coefficients reasonably well even residual spatial correlation present percentage censoring high number clusters cluster size low therefore primary goal assess covariate effects one may choose frailty model iid random effect whereas goal predict hazard additional care needs given due efficiency loss parameter baseline hazard â© informa uk limited trading taylor francis group
10.1142/S0217751X17501330 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027167560&doi=10.1142%2fS0217751X17501330&partnerID=40&md5=5b685f152498e75d7c2395024cda9842 0,motivated physics strings branes develop class markov chain monte carlo mcmc algorithms involving extended objects starting collection parallel metropolis hastings mh samplers place auxiliary grid couple together via nearest neighbor interactions leads class suburban samplers e spread metropolis coupling samplers way modifies mixing rate speed convergence markov chain many cases allow sampler easily overcome free energy barriers target distribution test general theoretical considerations performing several numerical experiments suburban samplers fluctuating grid topology performance strongly correlated average number neighbors increasing average number neighbors zero initially leads increase performance though critical connectivity effective dimension deff âˆ¼ groupthink takes performance sampler declines â© world scientific publishing company
10.1080/03610918.2016.1152365 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014568342&doi=10.1080%2f03610918.2016.1152365&partnerID=40&md5=97e1db80acbd226f0d8543df224de0dc 1,article propose evaluate compare markov chain monte carlo mcmc methods estimate parameters generalized extreme value model employed bayesian approach using traditional metropolis hastings methods hamiltonian monte carlo hmc riemann manifold hmc rmhmc methods obtain approximations posterior marginal distributions interest applications real datasets simulation studies provide evidence extra analytical work involved hamiltonian monte carlo algorithms compensated efficient exploration parameter space â© taylor francis group llc
10.1088/1361-6382/aa8124 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028338627&doi=10.1088%2f1361-6382%2faa8124&partnerID=40&md5=53292c763d521fc5b56e5c9131ed2985 0,design direct test local position invariance lpi post newtonian gravity using timing observation triple pulsar psr j + test takes advantage large gravitational acceleration exerted outer white dwarf inner neutron star white dwarf binary using machineprecision three body simulations dedicated markov chain monte carlo mcmc techniques various sampling strategies noise realizations estimate whitehead parameter already limited î¾ â‰² cl published timing data spanning january may constraint still orders magnitude looser best limit yet able independently falsify whitehead gravity theory î¾ = addition new test immune extra assumptions involves full dynamics three body system strongly self gravitating neutron star â© iop publishing ltd
10.1186/s12913-017-2502-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026912219&doi=10.1186%2fs12913-017-2502-y&partnerID=40&md5=fc8552013cb5a5b81fb18648f91c778e 1,background uk national health service provides stop smoking services pregnant women sssp lack evidence concerning best organised study investigates influences services effectiveness also propensity engage pregnant smokers support stopping smoking methods survey data collected sssp augmented data hospital episode statistics uk national census reach propensity engage smokers support defined percentage pregnant smokers setting quit date sssp support effectiveness percentage women set quit date also reported abstinence four weeks later bivariate e two outcome variable response markov chain monte carlo model used identify service level factors associated reach effectiveness sssp results beta coefficients represent percentage change reach effectiveness covariate providing majority one one contacts clinic rather home increased reach î² ci effectiveness î² ci reach sssp also increased population served deprived î² increase reach one unit increase imd score ci lower proportion people dependent children î² ci lower proportion people managerial professional occupations î² ci effectiveness sssp decreased areas greater percentage people years educational qualifications î² ci conclusions engage pregnant smokers encourage quit may efficient sssp support focussed around clinics rather women homes reach sssp inversely associated disadvantage efforts made contact women less likely achieve abstinence short longer term â© author
10.1145/3077136.3080766 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029392129&doi=10.1145%2f3077136.3080766&partnerID=40&md5=cdae50635c63235009edbc88f85aad56 2,using classical statistical significance tests researchers discuss pd+jh probability observing data hand something extreme assumption hypothesis h true e p value usually want phjd probability hypothesis true given data use bayesian statistics state art markov chain monte carlo mcmc methods obtaining posterior distributions longer problem instead classical p values confidence intervals offen misinterpreted respectively probability hypothesis correct probability true parameter value drops within interval easily obtain phjd credible intervals represent exactly moreover bayesian tests easily handle virtually hypothesis equality means obtain expected posteriori eap value statistic interested provide simple tools encourage ir community take paired unpaired bayesian tests comparing two systems using variety trec ntcir data compare phjd p values credible intervals con dence intervals bayesian eap effect sizes classical ones results show p values confidence intervals respectively regarded approximations really want namely phjd credible intervals b sample effect sizes classical significance tests di er considerably bayesian eap effect sizes suggests former poor estimates population effect sizes paired unpaired tests propose ir community report eap credible interval probability hypothesis true raw di erence means also effect size terms glass î´ â© copyright held owner author
10.1109/QRS-C.2017.35 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034441650&doi=10.1109%2fQRS-C.2017.35&partnerID=40&md5=ae737835efd5a1438af4884dbd1a0fda 0,residual life time estimation significant complex systems paper method proposed estimate residual life products satellite platform fusing real time updating failure lifetime degradation data linear wiener process adopted model degradation data drift diffusion parameters assumed random variables besides lifetime data described inverse gauss distribution maximum likelihood function lifetime degradation data integrated considering continually collected data satellite platform practical approach combined bayesian idea proposed update probability density function residual life time due complexity model monte carlo markov chain mcmc applied estimate parameters finally example infrared sensitive single machine provided illustrate effectiveness validity proposed method â© ieee
10.1063/1.4995920 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028319587&doi=10.1063%2f1.4995920&partnerID=40&md5=783ca27fedc3667451bcbca1220b0c5b 0,hierarchical bayesian modeling large point referenced spatio temporal data progressively suitable many practical applications due advance development statistical methodology computational efficiency present bayesian spatio temporal approach modeling variation wind speed analysis gaussian process model adopted using markov chain monte carlo sampling technique estimate posterior distribution findings show good evidence variation across certain region â© author
10.1063/1.4995120 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028362483&doi=10.1063%2f1.4995120&partnerID=40&md5=de96f27b26ba5fa9304884ca5185055f 2,aim study empirically investigate performance aparch volatility model student error distribution five foreign currency selling rates indonesian rupiah idr including swiss franc chf euro eur british pound gbp japanese yen jpy us dollar usd six years daily closing rates period january december total number observations analysed bayesian inference using efficient independence chain metropolis hastings adaptive random walk metropolis methods markov chain monte carlo mcmc scheme applied estimate parameters model according dic criterion study found aparch model student distribution better fit model normal distribution observed rate return series highest posterior density interval suggested aparch models model idr jpy idr usd volatilities particular idr jpy idr usd data respectively significant negative positive leverage effect rate returns meanwhile optimal power coefficient volatility found statistically different adopting rate return series save idr eur rate return series â© author
10.1049/iet-com.2016.1339 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029225661&doi=10.1049%2fiet-com.2016.1339&partnerID=40&md5=e091d2025d4d177b0b720cf478e5feba 1,study proposes novel approach joint channel estimation detection orthogonal frequency division multiplexing transmission underwater acoustic uwa multipath channels exhibiting cluster sparsity unlike sparse channel estimations authors exploit cluster sparsity characteristic uwa channels without additional prior information adopt modified spike slab prior model non parametric bayesian learning framework avoid need closed form bayesian estimate apply markov chain monte carlo technique joint achieve channel estimation signal detection proposed solution amenable integrated soft input soft output decoding improve performance turbo iteration simulation results demonstrate improved bit error rate proposed algorithm existing algorithms â© institution engineering technology
10.1080/03610926.2016.1161798 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018854345&doi=10.1080%2f03610926.2016.1161798&partnerID=40&md5=60482570ae871510178f13a32a7428e1 0,longitudinal data commonly modeled normal mixed effects models modeling methods based traditional mean regression results non robust estimation suffering extreme values outliers median regression also best choice estimation especially non normal errors compared conventional modeling methods composite quantile regression provide robust estimation results even non normal errors paper based called pseudo composite asymmetric laplace distribution pcald develop bayesian treatment composite quantile regression mixed effects models furthermore location scale mixture representation pcald establish bayesian hierarchical model achieve posterior inference unknown parameters latent variables using markov chain monte carlo mcmc method finally newly developed procedure illustrated monte carlo simulations case analysis hiv aids clinical data set â© taylor francis group llc
10.1080/13696998.2017.1328423 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020247814&doi=10.1080%2f13696998.2017.1328423&partnerID=40&md5=40fc3a24079eb04e63e0cea63fbdb9e0 1,aims study assessed cost effectiveness subcutaneous rankl inhibitor denosumab vs intravenous bisphosphonate zoledronic acid prevention skeletal related events sres patients prostate cancer breast cancer solid tumors ost czech republic materials methods lifetime markov model developed compare effects denosumab zoledronic acid costs including drug costs administration patient management sres adverse events quality adjusted life years qalys incremental cost effectiveness ratios national payer perspective different discount rates time horizons sre rates distributions nature asymptomatic vs sres inclusion treatment discontinuation considered scenario analyses robustness model tested using deterministic probabilistic sensitivity analyses results across tumor types denosumab associated fewer sres improved qalys higher total costs lifetime incremental cost per qaly gained denosumab vs zoledronic acid czk prostate cancer czk breast cancer czk ost incremental costs per sre avoided tumor type czk czk czk respectively scenario analyses results remained similar baseline different discount rates time horizons considered non official willingness pay threshold million czk probabilities denosumab cost effective vs zoledronic acid prostate cancer breast cancer ost respectively limitations sre rates used obtained clinical trials studies suggest rates may higher clinical practice additional evidence real world sre rates improve accuracy modeling conclusions compared zoledronic acid denosumab provides cost effective treatment option prevention sres patients prostate cancer breast cancer ost czech republic â© informa uk limited trading taylor francis group
41.228053111415754 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032274288&partnerID=40&md5=85361d9c3dbdf8597a5f0af54fcd0e52 2,although large amount wells extensively drilled develop unconventional reservoirs uncertainty associated reservoir fracture properties significantly affect evaluation individual wellâ€™s performance simulations history matching point view uncertainty causes non uniqueness solutions obtained robust probabilistic method without overly exhausting simulation resources challenge work proxy based history matching approach deliver unique advantages reducing computational requirement providing probabilistic interpretation work flow presented paper designed exploit full ranges proxy modeling benefits prioritizing significant reservoir properties estimating variation model responses searching multiple history matching solutions reliable probabilistic forecasts screening process introduced initial stage work flow design experiment doe response surface methodology rsm dimensions proxy models reduced addition proxy models progress work flow iterations aim improve accuracy iterative work flow efficiently uses simulation resources use completed runs provide information model responses subsequent iterations work flow iterated multiple proxy models explored history matching solutions markov chain monte carlo mcmc algorithm history matching solutions used evaluate probability distribution long term estimated ultimate recovery eur finally application work flow horizontal well middle bakken presented paper copyright vc society petroleum engineers
10.1061/(ASCE)WR.1943-5452.0000791 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019370206&doi=10.1061%2f%28ASCE%29WR.1943-5452.0000791&partnerID=40&md5=5e1c62bc9a666cdc0aa7473345885d7c 5,combined demand roughness estimation critical step order water distribution system model represent real system adequately novel two level markov chain monte carlo particle filter method joint estimation demand roughness proposed paper first improved particle filter ensemble kalman filter modification proposal density adopted track non gaussian system dynamics estimate demands improved particle filter demand estimation nested markov chain monte carlo simulation roughness estimation method capable quantifying uncertainties associated estimated predicted values without requiring assumptions linearity gaussianity derivatives calculated strong nonlinear benchmark network synthetically generated field data utilized validate performance method results suggest proposed method demonstrated provide satisfactory demand roughness values reliable confidence limits practical issues also discussed enhance application potential method â© american society civil engineers
10.1016/j.cageo.2017.05.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018753417&doi=10.1016%2fj.cageo.2017.05.001&partnerID=40&md5=56a54b9f07d2ac4ba48d7858bea022d1 3,spectral induced polarization sip measurements widely used infer mineralogical hydrogeological properties low frequency electrical properties subsurface mineral exploration environmental sciences present open source program performs fast multi model inversion laboratory complex resistivity measurements using markov chain monte carlo simulation using stochastic method sip parameters uncertainties may obtained cole cole dias models debye warburg decomposition approaches program tested synthetic laboratory data show posterior distribution multiple cole cole model multimodal particular cases warburg debye decomposition approaches yield unique solutions cases shown adaptive metropolis algorithm performs faster less dependent initial parameter values metropolis hastings step method inverting sip data decomposition schemes advantages using adaptive step method well defined cole cole inversion finally influence measurement noise recovered relaxation time distribution explored provide geophysics community open source platform serve base developments stochastic sip data inversion may used perform parameter analysis various sip models â© elsevier ltd
10.1115/1.4036153 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021898678&doi=10.1115%2f1.4036153&partnerID=40&md5=de547d0b2f105857a197295e39fb326b 0,article presents new method estimation thermophysical parameters using hybrid monte carlo hmc algorithm synergistically combines advantages markov chain monte carlo mcmc method molecular dynamics advantages technique conventional mcmc elucidated considering multiparameter estimation heat transfer four situations analyzed first two involve two three parameters estimation lumped capacitance model third involves estimation distributed system fourth involves estimation fin system goal establish potency usefulness hmc method wide class engineering problems copyright â© asme
10.1093/gji/ggx196 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037124190&doi=10.1093%2fgji%2fggx196&partnerID=40&md5=80fc62be870122ce8df3c00772068d5f 1,system aligned vertical fractures fine horizontal shale layers combine form equivalent orthorhombic media weak anisotropy parameters fracture weaknesses play important role description orthorhombic anisotropy oa propose novel approach utilizing seismic reflection amplitudes estimate weak anisotropy parameters fracture weaknesses observed seismic data based azimuthal elastic impedance ei first propose perturbation stiffness matrix terms weak anisotropy parameters fracture weaknesses using perturbation scattering function derive ppwave reflection coefficient azimuthal ei case interface separating two oa media demonstrate approach first use model constrained damped leastsquares algorithm estimate azimuthal ei partially incidence phase angle stack seismic reflection data different azimuths extract weak anisotropy parameters fracture weaknesses estimated azimuthal ei using bayesian markov chain monte carlo inversion method addition new procedure construct rock physics effective model presented estimate weak anisotropy parameters fracture weaknesses well log interpretation results minerals volumes porosity saturation fracture density etc tests synthetic real data indicate unknown parameters including elastic properties p wave impedances density weak anisotropy parameters fracture weaknesses estimated stably case seismic data containing moderate noise approach make reasonable estimation anisotropy fractured shale reservoir â© authors
10.1061/(ASCE)CO.1943-7862.0001336 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018176332&doi=10.1061%2f%28ASCE%29CO.1943-7862.0001336&partnerID=40&md5=3b884613f3a2ec076b3ac88c61fd6973 1,match factor criterion measures efficiency truck loader compatibility used construction industry factor function number trucks loaders truck cycle time loader loading time however parameters uncertain nature equipment failures climate road conditions operator habits fluctuations match factor result truck queues idle loaders waiting lead production losses opportunity costs paper stochastic approach proposed assess risks associated uncertain parameters match factor equation approach based coupling markov chain monte carlo simulations number available equipment ordinary monte carlo simulations loader loading truck cycle times thus variations match factor time series quantified way determine equipment capacity utilization maintenance management strategy case study carried results show proposed approach used tool assist production planning material handling construction industry â© american society civil engineers
10.1016/j.jhydrol.2017.05.051 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019982892&doi=10.1016%2fj.jhydrol.2017.05.051&partnerID=40&md5=7d5654170000660eea1bd1c2cbf491f4 5,apply stochastic newton sn approach solve high dimensional hydraulic inverse problem highly heterogeneous geological media recognizing connection cost function deterministic optimizations posterior probability density stochastic inversions markov chain monte carlo mcmc sampler sn constructed two parts deterministic part corresponds newton step deterministic optimization stochastic part gaussian distribution inverse local hessian covariance matrix hybrid inverse method exploits efficient tools fast solution deterministic inversions improve efficiency mcmc sampler address ill posedness inverse problem priori models generated transition probability geostatistical method conditioned inter well connection data used regularization constraints effectiveness stochastic newton method first demonstrated synthetic test transmissivity field synthetic model highly heterogeneous includes sharp variations inverse approach applied field hydraulic tomography investigation fractured karstified aquifer reconstruct transmissivity field collection real hydraulic head measurements inversions series transmissivity fields produce good correlations inverted measured hydraulic heads obtained inverse approach produced slightly different posteriori transmissivity patterns different priori structure models transmissivity however trend location high transmissivity channels consistent among various realizations addition uncertainty associated realization inverted transmissivity fields quantified â©
10.1016/j.ress.2017.03.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016057787&doi=10.1016%2fj.ress.2017.03.006&partnerID=40&md5=ccc27504ade2b80f3998fe707313fe20 4,microstructure deformation mechanism based fatigue crack initiation life prediction model links microstructure variability polycrystalline material scatter fatigue life validated using uncertainty quantification propagation framework first global sensitivity analysis gsa used identify set influential parameters fatigue life prediction model following gsa posterior distributions influential parameters calculated using bayesian inference framework built based markov chain monte carlo mcmc algorithm quantified uncertainties thus obtained propagated model using monte carlo sampling technique make robust predictions fatigue life model validated comparing predictions experimental fatigue life data â© elsevier ltd
10.1214/16-AAP1255 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028725368&doi=10.1214%2f16-AAP1255&partnerID=40&md5=38bf489a1beb29d2973c55764d9e9abc 2,tuning durations hamiltonian flow hamiltonian monte carlo also called hybrid monte carlo hmc involves tradeoff computational cost sampling quality typically challenging resolve satisfactory way article present analyze randomized hmc method rhmc durations exponential random variables whose mean free parameter focus small time step size limit algorithm rejection free computational cost proportional mean duration limit prove rhmc geometrically ergodic conditions imply geometric ergodicity solution underdamped langevin equations moreover context multidimensional gaussian distribution prove sampling efficiency rhmc unlike constant duration hmc behaves regular way regularity also verified numerically non gaussian target distributions finally suggest variants rhmc time step size required small â© institute mathematical statistics
10.1016/j.microrel.2017.02.012 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015877453&doi=10.1016%2fj.microrel.2017.02.012&partnerID=40&md5=b8964dd1e5c6f8ca1135404913eb8ca6 12,lithium ion batteries widely used power sources various portable electronics hybrid electric vehicles aeronautic aerospace engineering etc ensure uninterruptible power supply remaining useful life rul prediction lithium ion batteries attracted extensive attention recent years paper proposed improved unscented particle filter iupf method lithium ion battery rul prediction based markov chain monte carlo mcmc method uses mcmc solve problem sample impoverishment upf algorithm additionally iupf method proposed basis upf also suppress particle degradation existing standard pf algorithm work iupf method introduced firstly capacity data lithium ion batteries collected empirical capacity degradation model established proposed method used estimate rul lithium ion battery rul prediction results demonstrate effectiveness advantage â© elsevier ltd
10.1109/JSTSP.2017.2722419 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023194336&doi=10.1109%2fJSTSP.2017.2722419&partnerID=40&md5=e8c8997edcf476dfccae0ffdd5e8e727 0,machine learning ml models algorithms enable personalized learning experience students inexpensive scalable manner heart ml driven personalized learning automated analysis student responses assessment items existing statistical models task enable estimation student knowledge question difficulty solely graded response data minimal effort instructors however existing student response models generalized linear models meaning characterize probability student answers question correctly linear combination knowledge question difficulty respect concept assessed models characterize complicated nonlinear student response associations hence lack human interpretability practice paper propose nonlinear student response model called boolean logic analysis blah models student binary valued graded response question output boolean logic function develop markov chain monte carlo inference algorithm learns boolean logic functions question solely graded response data refined blah model improves identifiability tractability interpretability considering restricted set ordered boolean logic functions experimental results variety real world educational datasets demonstrate blah achieves best class prediction performance unobserved student responses datasets also provides easily interpretable parameters questions tagged metadata domain experts provide useful feedback instructors content designers improve quality assessment items â© ieee
10.1177/1748006X17712121 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026917018&doi=10.1177%2f1748006X17712121&partnerID=40&md5=79e93b3f7f912d57cc99b21f5ec4b773 0,ensure power generation level french national electricity supply edf manage producing assets putting place adapted preventive maintenance strategies article fleet identical components considered spread around france one per power plant site components assumed stochastically independent lifetimes made functionally dependent sharing common stock spare parts available spare parts used corrective preventive replacements priority corrective replacements stock empty replacements delayed arrival new spare parts spare parts expensive manufacturing time long makes necessary rigorously define ordering process point article provide decision maker tools take right decision make overhaul two indicators proposed based economic variable called net present value net present value stands difference cumulated discounted cash flows purely corrective policy preventive one including overhaul piecewise deterministic markov processes first considered joint modelling stochastic evolution components stock ordering process without overhaul indicators next expressed respect piecewise deterministic markov processes numerically assessed instead using classical monte carlo simulations suggest alternate methods based quasi monte carlo simulations replace random uniform numbers monte carlo method deterministic sequences called low discrepancy sequences obtained results show real gain quasi monte carlo methods comparison monte carlo method developed tools hence help decision maker take right decision â© institution mechanical engineers
10.3969/j.issn.1001-506X.2017.08.32 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027709156&doi=10.3969%2fj.issn.1001-506X.2017.08.32&partnerID=40&md5=65d8aaf4fa15090169ca18cd8a0e1bd8 0,weilbull distribution typical failure distribution aero equipment order prove effect descriptive statistics objective bayesian reliability evaluation random right censoring aero equipment failure data sensitivity analysis objective bayesian method proposed multiple markov chain algorithm dependent variable censoring rate sample size designed algorithm estimates scale parameter shape parameter weilbull distribution prior information large variance gamma distribution different censoring rates sample sizes deviation estimation judged evaluated mean time failures mean variation factor distribution parameters numerical results show weilbull distribution sample size censoring rate less estimation accuracy objective bayesian acceptable otherwise better reliability evaluation method explored small samples high censoring rates â© editorial office systems engineering electronics right reserved
10.1016/j.jfluidstructs.2017.05.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021211820&doi=10.1016%2fj.jfluidstructs.2017.05.007&partnerID=40&md5=5bbadb0c812eccd85e652c3d6bc9332d 0,work bayesian techniques employed quantify model form predictive uncertainty linear behavior elastically mounted airfoil undergoing pitching plunging motions bayesian model averaging approach used construct adjusted stochastic model different model classes time harmonic incompressible flows set deterministic function approximations construct different stochastic models whose uncertain coefficients calibrated using bayesian inference regard critical flutter velocity results show substantial reductions predictive uncertainties critical flutter speed compared non calibrated stochastic simulations particular shown efficient adjusted model derived considering possible bias random error term posterior predictive distributions flutter index â© elsevier ltd
10.1007/s11242-017-0872-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020095977&doi=10.1007%2fs11242-017-0872-6&partnerID=40&md5=5a179b9615f38efe40690d2f644f4a43 1,work apply recently proposed bayesian markov chain monte carlo framework akbarabadi et al comput geosci â€“ quantify uncertainty three dimensional permeability field rock core process establishes credibility compositional two phase flow model describe displacement brine co co storage saline aquifers investigate predictive capabilities compositional model context unsteady state co brine drainage experiment laboratory scale performed field scale aquifer conditions employ forward models consisting system discretized partial differential equations along relative permeability curves obtained curve fitting experimental measurements consider forward model validated numerical simulations reveal bayesian framework accurately characterized coreâ€™s permeability monte carlo predictions show excellent agreement measured simulated data large set numerical studies accurate compositional simulator shows forward models successfully validated models numerical results show able capture dominant features general trends co saturation fields observed core study consistent design findings real experiments fluid properties relative permeability data measured porosity field physical dimensions thermodynamic conditions reported inâ akbarabadi piri adv water resour â€“ however measured saturation data flow experiments different reported inâ akbarabadi piri presented â© springer science+business media dordrecht
10.1109/TBCAS.2017.2679039 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029314673&doi=10.1109%2fTBCAS.2017.2679039&partnerID=40&md5=65cdd096c34f5a6549668c5eec8c3e12 1,brain extremely energy efficient remarkably robust despite considerable variability noise caused stochastic mechanisms neurons synapses computational modeling powerful tool help us gain insight important aspect brain mechanism deep understanding computational design tools help develop robust neuromorphic electronic circuits hybrid neuroelectronic systems paper present general modeling framework biological neuronal circuits systematically captures nonstationary stochastic behavior ion channels synaptic processes framework fine grained discrete state continuous time markov chain models ion channels synaptic processes treated unified manner modeling framework features mechanism automatic generation corresponding coarse grained continuous state continuous time stochastic differential equation models neuronal variability noise furthermore repurpose non monte carlo noise analysis techniques previously developed analog electronic circuits stochastic characterization neuronal circuits time frequency domain verify fast non monte carlo analysis methods produce results accuracy computationally expensive monte carlo simulations implemented proposed techniques prototype simulator biological neuronal analog electronic circuits simulated together coupled manner â© ieee
10.1007/s10236-017-1074-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020411682&doi=10.1007%2fs10236-017-1074-z&partnerID=40&md5=9c3ec7a06228a69b4ab44c5c1a5cf1f5 2,bayesian estimation inversion commonly used quantify reduce modeling uncertainties coastal ocean model especially framework parameter estimation based bayes rule posterior probability distribution function pdf estimated quantities obtained conditioned available data computed either directly using markov chain monte carlo mcmc approach sequentially processing data following data assimilation approach heavily exploited large dimensional state estimation problems advantage data assimilation schemes mcmc type methods arises ability algorithmically accommodate large number uncertain quantities without significant increase computational requirements however approximate estimates generally obtained approach due restricted gaussian prior noise assumptions generally imposed methods contribution aims evaluating effectiveness utilizing ensemble kalman based data assimilation method parameter estimation coastal ocean model mcmc polynomial chaos pc based scheme focus quantifying uncertainties coastal ocean advanced circulation adcirc model respect manningâ€™s n coefficients based realistic framework observation system simulation experiments osses apply ensemble kalman filter mcmc method employing surrogate adcirc constructed non intrusive pc expansion evaluating likelihood test approaches identical scenarios study sensitivity estimated posteriors respect parameters inference methods including ensemble size inflation factor pc order full analysis methods context coastal ocean model suggests ensemble kalman filter appropriate ensemble size well tuned inflation provides reliable mean estimates uncertainties manningâ€™s n coefficients compared full posterior distributions inferred mcmc â© springer verlag berlin heidelberg
10.1016/j.csda.2017.02.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014835842&doi=10.1016%2fj.csda.2017.02.010&partnerID=40&md5=9b25915325c58f9342d9a4fec07c8d55 0,recent years increasing interest bayesian nonparametric methods due flexibility availability markov chain monte carlo mcmc methods sampling posterior distribution mcmc methods generally time consuming computation need faster methods executed within matter seconds fast alternative mcmc sampling well known widely used dirichlet process mixture dpm model investigated draw approximate independent identically distributed samples posterior distribution latent allocations draw samples weights locations conditional allocations address order depend issue proposed algorithm optimal ordering scheme based sequence optimizations proposed first obtain optimal order data run algorithm ordering fast sampling algorithm assisted parallel computing using commands within matlab â© elsevier b v
10.1007/s00138-017-0840-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018260263&doi=10.1007%2fs00138-017-0840-8&partnerID=40&md5=952e063ecd62ca266d1645f54908ddac 0,paper presents framework predict performance multiple target tracking mtt techniques framework based mathematical descriptors point processes probability generating functional p g fl shown conceptually p g fls mtt techniques interpreted transform marginalized expression encodes information regarding likelihood model well underlying assumptions present given tracking technique order use approach tracker performance prediction video sequences framework combines video quality assessment concepts marginalized transform introduced multiple hypothesis tracker markov chain monte carlo data association methods used test cases introduce transforms perform numerical comparison predict performance identical conditions â© springer verlag berlin heidelberg
10.1177/0962280215586010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027680445&doi=10.1177%2f0962280215586010&partnerID=40&md5=16682eb9eefb1252fb62c4c103c1e78e 1,many longitudinal studies e g observational studies randomized clinical trials collected multiple rating scales visit form patient reported outcomes pros close unit interval propose joint modeling framework address issues following data features multiple correlated pros presence boundary values zeros ones extreme outliers heavy tails pro dependent terminal events death dropout modeling framework consists multivariate augmented mixed effects sub model based beta rectangular distributions multiple longitudinal outcomes cox model terminal events simulation studies suggest presence outliers heavy tails dependent terminal event proposed models provide accurate parameter estimates joint model based beta distributions proposed models applied motivating long term study ls study n = parkinson disease patients â© author
10.1007/s00170-017-0064-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010755516&doi=10.1007%2fs00170-017-0064-0&partnerID=40&md5=36ed9ba0bfa586ccaebaa4b79a677e59 3,work discusses bayesian parameter inference method mechanistic force model machining bayesian inference methods gained popularity recently owing intuitiveness ease empirical knowledge may combined experimental data considering uncertainty first part paper discusses bayesian parameter inference markov chain monte carlo mcmc methods mcmc method effectiveness analyzed changing number particles mcmc estimation changing mcmc move step size second part paper discusses two example applications nonlinear mechanistic force model coefficient identification bayesian inference scheme performs prediction cutting force coefficients training data using coefficients input parameters model cutting force predicted prediction validated using experimental data demonstrated parameter updates predicted force converges measured cutting force paper concluded discussion future work â© springer verlag london
10.1007/s11432-016-0442-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022035848&doi=10.1007%2fs11432-016-0442-1&partnerID=40&md5=a17b92fd54cc4764b05ff5c450139a93 1,differential privacy dp become one important solutions privacy protection recent years previous studies shown prediction accuracy usually increases data mining dm logic considered dp implementation however although one step dm computation decision tree dt model investigated existing research studied scenarios dp embedded two step dm computation three step dm computation whole model dm computation challenging embed dp two steps dm computation since solution space exponentially increases increase computational complexity work propose algorithms making use markov chain monte carlo mcmc method efficiently search computationally infeasible space embed dp dt generation algorithm compare performance embedding dp dt different depths e one step dm computation previous work two step three step whole model find deep combination dp dt help increase prediction accuracy however privacy budget large e g ïµ = may overwhelm complexity dt model increasing trend obvious also find prediction accuracy decreases increase model complexity â© science china press springer verlag gmbh germany
10.4230/LIPIcs.WABI.2017.14 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028747220&doi=10.4230%2fLIPIcs.WABI.2017.14&partnerID=40&md5=fe30b6bea9487a1e8ba0caf5b90dcbbb 0,peptidic natural products pnps highly sought bioactive compounds include many antibiotic antiviral antitumor agents immunosuppressors toxins even though recent advancements mass spectrometry led development accurate sequencing methods nonlinear cyclic branch cyclic peptides requiring picograms input material identification pnps via database search mass spectra remains problematic holds particularly true trying evaluate statistical significance peptide spectrum matches psm especially working non linear peptides often contain non standard amino acids modifications overall complex structure paper describe new way estimating statistical significance psm defined peptide including linear non linear using state art markov chain monte carlo methods addition estimate method also provides uncertainty estimate form confidence bounds well automatic simulation stopping rule ensures sample size sufficient achieve desired level result accuracy â© anastasiia abramova anton korobeynikov
10.1016/j.nucengdes.2017.05.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019363804&doi=10.1016%2fj.nucengdes.2017.05.011&partnerID=40&md5=9368bf1db8a397abfe7923b27ee713a5 6,within bepu best estimate plus uncertainty methodology uncertainties must quantified order prove investigated design remains within acceptance criteria best estimate system thermal hydraulics codes like trace relap significant uncertainties come closure laws used describe transfer terms balance equations accuracy uncertainty information correlations usually unknown code users results user simply ignoring describing using expert opinion personal judgment uncertainty sensitivity analysis purpose paper replace ad hoc expert judgment uncertainty information trace physical model parameters inverse uncertainty quantification uq based oecd nrc bwr full size fine mesh bundle tests bfbt benchmark steady state void fraction data inverse uq seeks statistical descriptions physical model random input parameters consistent experimental data inverse uq always captures uncertainty estimates rather merely determining point estimates best fit input parameters bayesian analysis used establish inverse uq problems based experimental data systematic rigorously derived surrogate models based sparse gird stochastic collocation sgsc global sensitivity analysis including sobolâ€™ indices correlation coefficients used identify important trace input parameters several adaptive markov chain monte carlo mcmc sampling techniques investigated implemented explore posterior probability density functions research solves problem lack uncertainty information trace physical model parameters closure relations quantified uncertainties necessary future uncertainty sensitivity study trace code nuclear reactor system design safety analysis â© elsevier b v
10.1093/annweh/wxx046 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032178285&doi=10.1093%2fannweh%2fwxx046&partnerID=40&md5=8b6728cd4951908578ed9587d6fc50b2 0,objective direct reading instruments valuable tools measuring exposure provide real time measurements rapid decision making however use limited general survey applications part due issues related performance moreover statistical analysis realtime data complicated autocorrelation among successive measurements non stationary time series presence left censoring due limit detection lod bayesian framework proposed accounts non stationary autocorrelation lod issues exposure time series data order model workplace factors affect exposure estimate summary statistics tasks covariates interest method spline based approach used model non stationary autocorrelation relatively assumptions autocorrelation structure left censoring addressed integrating left tail distribution model fit using markov chain monte carlo within bayesian paradigm method flexibly account hierarchical relationships random effects fixed effects covariates method implemented using rjags package r illustrated applying real time exposure data estimates task means covariates bayesian model compared conventional frequentist models including linear regression mixed effects time series models different autocorrelation structures simulations studies also conducted evaluate method performance results simulation studies percent measurements lod ranging showed lowest root mean squared errors task means least biased standard deviations bayesian model compared frequentist models across levels lod application task means bayesian model similar means frequentist models standard deviations different parameter estimates covariates significant frequentist models bayesian model credible intervals contained zero discrepancies observed multiple datasets variance components bayesian model reflected sub stantial autocorrelation consistent frequentist models except auto regressive moving average model plots means bayesian model showed good fit observed data conclusion proposed bayesian model provides approach modeling non stationary autocorrelation hierarchical modeling framework estimate task means standard deviations quantiles parameter estimates covariates less biased better performance characteristics contemporary methods â© author published oxford university press behalf british occupational hygiene society
960.3203265279896 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030252194&partnerID=40&md5=5d6f014572a5f7b93a91d7816e25fa1f 0,propose bayesian approach regression scalar response vector tensor covariates vectorization tensor prior analysis fails exploit structure often leading poor estimation predictive performance introduce novel class multiway shrinkage priors tensor coefficients regression setting present posterior consistency results mild conditions computationally efficient markov chain monte carlo algorithm developed posterior computation simulation studies illustrate substantial gains existing tensor regression methods terms estimation parameter inference approach illustrated neuroimaging application â© rajarshi guhaniyogi shaan qamar david b dunson
10.1016/j.csda.2017.02.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015391635&doi=10.1016%2fj.csda.2017.02.011&partnerID=40&md5=0d819d454d49f9ca3fb81be9ee9d00a6 1,biomedical studies often interest estimate risk profile adverse event related timing intervention example randomized controlled clinical trials bivalent human papillomavirus hpv vaccine investigators interested know miscarriage rate relates timing hpv vaccination risk window defined interval covariate risk adverse event elevated existing methods make simultaneous inference risk window magnitude risk hierarchical bayesian logistic regression model developed estimate risk window miscarriage time conception respect vaccination hierarchical priors proposed used markov chain monte carlo statistical inference performance bayesian model two existing methods evaluated simulation settings varying risk windows relative risks proposed model provides point interval estimates risk window regarding vaccination captures effect modification miscarriage risk pregnancy analysis vaccine trial using proposed model shows significant evidence association hpv vaccine miscarriage risk hierarchical bayesian model useful general analyzing randomized trial epidemiological study effect agent potentially modified temporal factor â© elsevier b v
10.1214/16-AAP1257 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028724242&doi=10.1214%2f16-AAP1257&partnerID=40&md5=8d165b809e4ad3d0127d1181406132a9 1,introduce new gaussian proposals improve efficiency standard hastings metropolis algorithm markov chain monte carlo mcmc methods used sampling target distribution large dimension improved complexity compared complexity standard approach prove asymptotic diffusion limit theorem show relative efficiency algorithm characterised overall acceptance rate asymptotical value independently target distribution numerical experiments confirm theoretical findings â© institute mathematical statistics
10.1371/journal.pone.0180908 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027222934&doi=10.1371%2fjournal.pone.0180908&partnerID=40&md5=9dc8cb489c85e8537f84c373ffaa9ce6 1,present new open source software tool called beastling designed simplify preparation bayesian phylogenetic analyses linguistic data using beast platform beastling transforms comparatively short human readable configuration files xml files used beast specify analyses taking advantage creative commons licensed data glottolog language catalog beastling allows user conveniently filter datasets using names recognised language families impose monophyly constraints inferred language trees backward compatible glottolog classifications assign geographic location data languages phylogeographic analyses support emerging cross linguistic linked data format cldf permits easy incorporation data published cross linguistic linked databases analyses beastling intended make power bayesian analysis accessible historical linguists without strong programming backgrounds hopes encouraging communication collaboration developing computational models language evolution typically linguists relevant domain experts â© maurits et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1111/rssc.12200 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006710869&doi=10.1111%2frssc.12200&partnerID=40&md5=acbfd157ca22de4b46552d3f4f4b97c9 3,investigate causal relationship climate criminal behaviour considering characteristics integer valued time series criminal incidents propose modified granger causality test based generalized auto regressive conditional heteroscedasticity type integer valued time series models analyse relationship number crimes temperature environmental factor precisely employ poisson negative binomial log linear poisson integer valued generalized auto regressive conditional heteroscedasticity models particularly adopt bayesian method analysis bayes factors posterior probability null hypothesis help determine causality variables considered moreover employing adaptive markov chain monte carlo sampling scheme estimate model parameters initial values illustration evaluate test simulation study examine whether temperature affects crime activities apply method data sets categorized sexual offences drug offences theft motor vehicles domestic violence related assault ballina new south wales australia result reveals sexual offences drug offences domestic violence related assaults occur summer seasons year evidence strongly advocates causal relationship crime temperature â© royal statistical society
10.1016/j.dib.2017.05.053 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021689832&doi=10.1016%2fj.dib.2017.05.053&partnerID=40&md5=eaf916e930bab2b016fdb2124f75bc4d 1,data presented article related research article entitled â€œcomparison generalized linear modelling additive bayesian network identification factors associated incidence antibodies leptospira interrogans sv pomona meat workers new zealandâ€� pittavino et al prospective cohort study conducted four sheep slaughtering abattoirs new zealand nz dreyfus et al sera collected twice year meat workers tested microscopic agglutination leptospira interrogans sv pomona pomona infection one common leptospira serovars humans nz article provides extended analysis data illustrating different steps multivariable e generalized linear model especially multivariate tool based additive bayesian networks abn modelling â© authors
10.1016/j.compbiomed.2017.05.032 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020682419&doi=10.1016%2fj.compbiomed.2017.05.032&partnerID=40&md5=9449eda88b9352beae9e010531d46d33 0,summary mathematical models cardiac cell started include markovian representations ionic channels instead traditional hodgkin amp huxley formulations many reasons markov models restricted idea independent gates defining channel allow complex description specific transitions open closed inactivated states importantly states closely related underlying channel structure conformational changes methods used labviewâ® matlabâ® programs implement simulator markolab allow dynamical representation markovian model channel monte carlo simulation used implement stochastic transitions among states user specify voltage protocol setting holding potential step voltage duration stimuli results studied feature channel current flowing happens channel stays open state time revealed low open probability values channel remains inactive closed states focusing channel enters leaves open state missing activity markolab proved quite useful visualize whole behavior channel channel produces current dynamic representation provides complete information channel kinetics powerful tool demonstrate effect gene mutations drugs channel function conclusions markolab provides original way visualizing stochastic behavior channel clarifies concepts recovery inactivation calcium versus voltage dependent inactivation tail currents restricted ionic channels extended transporters exchangers pumps program intended didactical tool illustrate dynamical behavior channel implemented two platforms matlabâ® labviewâ® enhance target users new didactical tool computational cost implementing stochastic simulation within range personal computer performance making markolab suitable run lecture presentation â© elsevier ltd
10.1007/s10064-016-0869-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962157687&doi=10.1007%2fs10064-016-0869-3&partnerID=40&md5=ab4af433616687ec83bf9157f43ddc0f 5,paper presents framework optimization site investigation program within robustness site investigation program investigation effort optimized site investigation program judged robust derived statistics geotechnical property interest robust uncertainties caused limited data availability test error study markov chain monte carlo simulation based bayesian inference approach used characterize statistics intended geotechnical property robustness site investigation program formulated byproduct bayesian inference geotechnical property statistics proposed framework optimization site investigation program implemented bi objective optimization problem considers robustness investigation effort concepts pareto front knee point employed aid making informed decision regarding selection site investigation program effectiveness significance proposed framework demonstrated simulation study â© springer verlag berlin heidelberg
10.1007/s00438-017-1322-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019843658&doi=10.1007%2fs00438-017-1322-4&partnerID=40&md5=70e7feb601260a7a6f791a8043b387c9 1,genome wide association studies gwas identified large amount single nucleotide polymorphisms snps associated complex traits recently developed linear mixed model estimating heritability simultaneously fitting snps suggests common variants explain substantial fraction heritability hints low power single variant analysis typically used gwas consequently many multi locus shrinkage models proposed bayesian framework however use markov chain monte carlo mcmc algorithm time consuming challenging apply gwas data propose fast algorithm bayesian adaptive lasso using variational inference bal vi extensive simulations real data analysis indicate model outperforms well known bayesian lasso bayesian adaptive lasso models accuracy speed bal vi complete simultaneous analysis lung cancer gwas data withâ subjects andâ snps half day â© springer verlag berlin heidelberg
10.1016/j.sste.2017.05.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021141431&doi=10.1016%2fj.sste.2017.05.001&partnerID=40&md5=f200d4285fa3a0706dd20c47e9997047 1,influence climatic variables dynamics human malaria widely highlighted also known mosquito borne infection varies space time however data spatially incomplete popular spatio temporal methods analysis applied directly paper develop two step methodology model spatio temporal dependence malaria incidence local rainfall temperature humidity well regional sea surface temperatures sst northern coast venezuela first fit autoregressive distributed lag model ardl weekly data adjust linear separable spacial vectorial autoregressive model var residuals ardl finally model parameters tuned using markov chain monte carlo mcmc procedure derived metropolis hastings algorithm results show best model account variations malaria incidence endemic municipalities north eastern venezuela logit model included accumulated local precipitation combination local maximum temperature preceding month positive regressors additionally show although malaria dynamics highly heterogeneous space detailed analysis estimated spatial parameters model yield important insights regarding joint behavior disease incidence across different counties study â© elsevier ltd
10.6004/jnccn.2017.0136 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027285984&doi=10.6004%2fjnccn.2017.0136&partnerID=40&md5=b714ea780a3b938a0af09f9452e6c017 1,background completing years adjuvant tamoxifen women estrogen receptor er positive breast cancer benefit years endocrine therapy either tamoxifen aromatase inhibitor ai premenopausal women ovarian ablation oa required starting ai oa ai according soft text studies oa ai improves year disease free survival compared tamoxifen alone suggesting oa ai superior tamoxifen extended endocrine therapy long term costs consequences premature menopause oa unknown estimated cost effectiveness analysis methods markov chain monte carlo simulation model estimated costs benefits extended endocrine strategies hypothetical cohort premenopausal women er positive early breast cancer treatment tamoxifen years extended tamoxifen oa ai years effectiveness measured years life expectancy gain sensitivity analyses accounted uncertainty surrounding various parameters monte carlo simulation estimated number adverse events deaths strategy us population year period results extended tamoxifen yielded higher average life expectancy gain oa ai vs years lower average cost vs premenopausal er positive women simulation estimated deaths treatment extended tamoxifen oa ai respectively additional deaths oa total deaths associated oa ai years follow women expected die oa ai extended tamoxifen conclusions premenopausal women er positive cancer completed adjuvant tamoxifen another years tamoxifen preferable extended endocrine strategy potential long term health consequences oa affect overall survival precedes use ai â© jnccn journal national comprehensive cancer network
10.1016/j.meegid.2017.04.015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018483200&doi=10.1016%2fj.meegid.2017.04.015&partnerID=40&md5=8272c41a419df816aee5b7e497b7a62c 1,study examined molecular evolution fusion protein f gene human respiratory syncytial virus subgroup b hrsv b first performed time scale evolution analyses using bayesian markov chain monte carlo mcmc method next performed genetic distance linear b cell epitope prediction n glycosylation positive negative selection site bayesian skyline plot analyses also constructed structural model f protein mapped amino acid substitutions predicted b cell epitopes mcmc constructed phylogenetic tree indicated hrsv f gene diverged bovine respiratory syncytial virus gene approximately â years ago relatively low evolutionary rate â ã—â âˆ’â â substitutions site year furthermore common ancestor hrsv b diverged approximately â years ago hrsv b diverged three clusters approximately â years genetic similarity present strains high although maximum amino acid substitutions observed structural model f protein one strain possessed amino acid substitution located within palivizumab epitope four epitopes predicted although correspond neutralization sites f protein including palivizumab epitope addition five n glycosylation sites present hrsv b strains inferred positive selection sites identified however many sites found negative selection effective population size gene remained almost constant basis results concluded hrsv b f gene highly conserved f protein hrsv moreover prediction b cell epitopes show palivizumab reaction site may recognized epitope naturally occurring infections â© elsevier b v
10.1177/0037549717698014 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025454088&doi=10.1177%2f0037549717698014&partnerID=40&md5=6e442d8abe1b6655d2985af2cc1442b8 1,paper attempts understand reasons difference value round trip time calculation simulation posited main reason difference combination two factors restricted car capacity randomness behavior elevator traffic system thus leading reduced effective car loading effectively based smaller number passengers car three sources randomness behavior system randomness passenger destinations thus making value round trip time random variable randomness passenger arrival driven poisson passenger arrival model effect elevator bunching thus making value interval random variable using matlab based simulator value round trip time plotted system loading level case single entrance incoming traffic different conditions simulated including constant random passenger arrivals well queues allowed queues allowed conditions varying conditions provides essential insight variation round trip time reasons effect number passengers boarding elevator value round trip time thus value system handling capacity investigated detail â© author
10.1016/j.spa.2016.11.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010619199&doi=10.1016%2fj.spa.2016.11.003&partnerID=40&md5=4da17573262270e967a80f3255ff2198 1,study distributed particle filter proposed boliä‡ et al algorithm involves groups particles interaction groups occurring â€œlocal exchangeâ€� mechanism establish central limit theorem regime fixed mâ†’âˆž formula obtain asymptotic variance interpreted terms colliding markov chains enabling analytic numerical evaluations asymptotic variance behaves time comparison benchmark algorithm consisting independent particle filters prove subject regularity conditions fixed algorithms converge time uniformly rate mâˆ’ use asymptotic variance formula give counter examples satisfying regularity conditions show fixed neither algorithm general converges time uniformly rate mâˆ’ â© elsevier b v
10.1007/s40258-017-0311-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012871305&doi=10.1007%2fs40258-017-0311-4&partnerID=40&md5=d80cce733a5f3ac7d8b8f1e46c78213a 4,background chronic hepatitis b common progressive disease particularly viral replication detected oral antivirals suppress viral replication prevent delay development cirrhosis liver related complications treatments chronic hepatitis b totally cure disease prevent progression hepatocellular carcinoma decreasing levels morbidity mortality date several therapies indicated international guidelines first line treatments management hepatitis b two effective based either tenofovir entecavir objective aim study evaluate cost effectiveness tenofovir entecavir treatment naã¯ve patients chronic hepatitis b two treatments compared â€œno treatmentâ€� one another methods cost effectiveness analysis conducted using markov model patients entered one following health states chronic hepatitis cirrhosis compensated decompensated hepatocellular carcinoma liver transplantation death analysis carried perspective italian national health service considering life time horizon cycles lasting â year costs qalys quality adjusted life years discounted rate results model analysed terms incremental cost effectiveness ratio icer results icers tenofovir entecavir emerging comparison versus â€œno treatmentâ€� equal â‚¬ â‚¬ per qaly gained respectively life time horizon tenofovir dominant direct comparison entecavir indicating qalys lower consumption resources monte carlo simulation demonstrated tenofovir entecavir scenarios performed cost per qaly fell threshold â‚¬ qaly budget impact analysis showed savings tenofovir amounting compared entecavir first year treatment following years conclusions entecavir tenofovir recommended treatment patients chronic hepatitis b italian health system particular tenofovir appeared cost effective drug management chronic hepatitis b virus hbv infections results help decision makers clinicians address decision choosing first line treatment management people affected chronic hbv â© springer international publishing switzerland
10.1051/0004-6361/201630139 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026325057&doi=10.1051%2f0004-6361%2f201630139&partnerID=40&md5=f05ee080611b61260c680c81b08da9e8 1,aims present new iram plateau de bure interferometer observations arp hcn hco+ hn c j = c h n = sio j = hnco jk kâ€² = ch cn cs j = co j = ngc hcn hco+j = c h n = addition present atacama large millimeter submill meter array science verification observations arp cs j = ch cn various lines used analyse physical conditions molecular gas including co co co c abundance ratios observations made available public methods create brightness temperature line ratio maps present different physical conditions across arp ngc addition use radiative transfer code radex monte carlo markov chain likelihood code model co co c lines arp â€²â€² pc scales co c measurements obtained literature results line ratios optically thick lines co show smoothly varying ratios line ratios optically thin lines co show east west gradient across arp hcn hco+ line ratio differs arp ngc arp line ratios ngc radiative transfer analysis solution consistent warm k moderately dense cm molecular gas component averaged two nuclei find co co co c abundance ratios abundance enhancement c explained stellar nucleosynthesis enrichment interstellar medium â© eso
10.1007/s40273-017-0510-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019054747&doi=10.1007%2fs40273-017-0510-8&partnerID=40&md5=6ccff0feed3c0ac6003898b8f2dcbb04 4,volume technical complexity academic commercial research using decision analytic modelling increased rapidly last two decades range software programs used implementation also increased remains true small number programs account vast majority cost effectiveness modelling work report comparison four software programs treeage pro microsoft excel r matlab focus software commonly used building markov models decision trees conduct cohort simulations given predominance published literature around cost effectiveness modelling comparison uses three qualitative criteria proposed eddy et al â€œtransparency validationâ€� â€œlearning curveâ€� â€œcapabilityâ€� addition introduce quantitative criterion processing speed also consider cost program academic users commercial users rank programs based criteria find whilst microsoft excel treeage pro good programs educational purposes producing types analyses typically required health technology assessment agencies efficiency transparency advantages programming languages matlab r become increasingly valuable complex analyses required â© springer international publishing switzerland
10.1007/s10596-017-9646-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017179802&doi=10.1007%2fs10596-017-9646-z&partnerID=40&md5=c106e19910880efe5795ee0329456bb1 3,work addresses estimation parameters earthquake model consequent tsunami application chile event particularly interested bayesian inference location orientation slip okada based model earthquake ocean floor displacement tsunami numerical model based geoclaw software observational data provided single dartâ“‡ buoy propose paper methodology based polynomial chaos expansion construct surrogate model wave height buoy location correlated noise model first proposed order represent discrepancy computational model data step necessary classical independent gaussian noise shown unsuitable modeling error prevent convergence markov chain monte carlo sampler second polynomial chaos model subsequently improved handle variability arrival time wave using preconditioned non intrusive spectral method finally construction reduced model dedicated bayesian inference proposed numerical results presented discussed â© springer international publishing switzerland
10.1177/0962280215590284 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027681882&doi=10.1177%2f0962280215590284&partnerID=40&md5=3d5476d96e138acb3db6db6ff25ff165 2,semicontinuous data featured excessive proportion zeros right skewed continuous positive values arise frequently practice one example substance abuse dependence symptoms data substantial proportion subjects investigated may report zero two part mixed effects models developed analyze repeated measures semicontinuous data longitudinal studies paper propose flexible two part mixed effects model skew distributions correlated semicontinuous alcohol data framework bayesian approach proposed model specification consists two mixed effects models linked correlated random effects model occurrence positive values using generalized logistic mixed effects model part ii model intensity positive values using linear mixed effects model model errors follow skew distributions including skew skew normal distributions part ii proposed method illustrated alcohol abuse dependence symptoms data longitudinal observational study analytic results reported comparing potential models different random effects structures simulation studies conducted assess performance proposed models method â© author
10.1007/s40430-017-0787-8 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024402960&doi=10.1007%2fs40430-017-0787-8&partnerID=40&md5=6a3710d8c5fcfe2bc269ecd264255d96 0,stochastic methods application emergent engineering field leading designers better solutions product development stochastic characteristic system parameters geometric dimensions operating conditions among others may lead unexpected even undesirable behavior making mandatory take account parameters uncertainties aiming robust project approach considered uncertainties distribution model bayesian inference method gives estimation stochastic parameter previous information observations experimental response possible proceed correspondent propagation system response context rotor dynamics stochastic methods yet scattered deterministic approaches still prevail work aims use bayesian inference particularly markov chain monte carlo method simple rotor bearing system model evaluate influence uncertainties journal bearings parameters overall behavior components critical parameters considered radial clearance oil viscosity function temperature â© brazilian society mechanical sciences engineering
10.1089/thy.2016.0572 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027134802&doi=10.1089%2fthy.2016.0572&partnerID=40&md5=f4029f630ac7381ab4305546f93550d6 1,background lenvatinib lenvimaâ® sorafenib nexavarâ® two recently food drug administration approved drugs treating radioiodine refractory differentiated thyroid cancer rr dtc demonstrated superior progression free survival placebo respective phase iii clinical trials study compared cost effectiveness two treatments placebo limited societal perspective methods markov model developed estimate costs health benefits treatment rr dtc probabilities survival rates obtained two phase iii trials select trial comparing lenvatinib placebo decision trial comparing sorafenib placebo bimonthly cycle length half cycle correction used lifetime time horizon medical costs utility data obtained redbook healthcare cost utilization project published literature costs adjusted us discounted annually second order monte carlo simulation distributions conducted obtain acceptability curve address uncertainty around model inputs results base case lenvatinib cost effective treatment compared sorafenib incremental cost effectiveness ratio icer = quality adjusted life year qaly placebo icer = sorafenib also cost effective compared placebo icer = qaly treatment decisions found sensitive treatment costs health utility associated lenvatinib side effects acceptability curve showed lenvatinib optimal time wtp qaly conclusions study suggests lenvatinib optimally cost effective treatment rr dtc although lenvatinib sorafenib cost effective compared placebo â© copyright mary ann liebert inc
10.1073/pnas.1619583114 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026638741&doi=10.1073%2fpnas.1619583114&partnerID=40&md5=71ede27c2970d9db5ea1828526693c7f 1,precise estimation age essential evolutionary anthropology especially infer population age structures understand evolution human life history diversity however small scale societies hunter gatherer populations time often referred calendar years accurate age estimation remains challenge address issue proposing bayesian approach accounts age uncertainty inherent fieldwork data developed gibbs sampling markov chain monte carlo algorithm produces posterior distributions ages individual based ranking order individuals youngest oldest age ranges individual first validate method agta foragers philippines known ages show method generates age estimations superior previously published regression based approaches use data agta collected recent fieldwork demonstrate multiple partial age ranks coming multiple camps hunter gatherers integrated finally exemplify distributions generated method used estimate important demographic parameters small scale societies age specific fertility patterns flexible bayesian approach especially useful improve cross cultural life history datasets small scale societies reliable age records difficult acquire â© national academy sciences rights reserved
10.1136/injuryprev-2016-042057 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987810696&doi=10.1136%2finjuryprev-2016-042057&partnerID=40&md5=42dc076228552fbf41bd8bb24bca1362 0,background objective evaluate costeffectiveness investments bike lanes using new york cityâ€™s nyc fiscal year investment case study also provide generalizable model localities estimate return bike lane investments methods findings evaluate costeffectiveness bike lane construction using two stage model regression analysis estimate marginal addition lane miles expansion bike ridership reveals miles bike lanes nyc constructed cost may increase probability riding bikes second stage constructed markov model estimate cost effectiveness bike lane construction model compares status quo investment consider reduced risk injury increased probability ridership costs associated bike lane implementation maintenance effectiveness due physical activity reduced pollution use monte carlo simulation one way sensitivity analysis test reliability base case result model reveals lifetime people nyc bike lane construction produces additional costs gain quality adjusted life years qalys per person results incremental cost effectiveness ratio qaly gained ci âˆ’ qaly gained qaly gained conclusions conclude investments bicycle lanes come exceptionally good value simultaneously address multiple public health problems investments bike lanes cost effective majority preventive approaches used today â© bmj publishing group rights reserved
10.1002/env.2449 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020226502&doi=10.1002%2fenv.2449&partnerID=40&md5=b5243c0390643863d1c21b6fadf69057 0,predicting occurrence level duration high air pollution concentrations exceeding given critical level enables researchers study health impact road traffic local air quality inform public policy action precise estimates probabilities occurrence level extreme concentrations formidable due combination complex physical chemical processes involved underpins need developing sophisticated extreme value models particular allowing nonstationarity environmental time series paper extremes nitrogen oxide nitrogen dioxide ozone concentrations investigated using two models modelâ based extended peaks threshold pot approach developed c davison r l smith whereby parameters underlying generalized pareto distribution gpd treated functions covariates e traffic meteorological factors new modelâ ii resolves lack threshold stability davisonâ€“smith model constructing special functional form gpd parameters models effects traffic meteorological factors frequency size extreme values estimated using markov chain monte carlo methods finally appropriate goodness fit tests model selection criteria confirm modelâ ii significantly outperforms modelâ estimation forecasting extremes copyright â© john wiley sons ltd
10.1007/s10614-016-9606-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981507133&doi=10.1007%2fs10614-016-9606-z&partnerID=40&md5=0b36bb9fdb5de976ba5aaf78cf39ead4 1,analyze dynamic asymmetric contagion reactions financial markets last subprime crisis paper proposes contagion reaction equation combined generalized auto regressive conditional heteroskedasticity process develop dynamic asymmetric contagion model provides markov chain monte carlo estimation method new model paper constructs empirical study two metals futures china last subprime crisis period applying model measure impact contagion reactions well assess modelâ€™s effectiveness results show financial contagion phenomenon reason financial markets experienced almost corresponding reactions subprime crisis financial contagion reactions behave conspicuously three particular phases subprime crisis financial contagion reactions predictive functions financial market changes provide indicators risk management crisis periods â© springer science+business media new york
10.1016/j.spasta.2017.06.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030557488&doi=10.1016%2fj.spasta.2017.06.006&partnerID=40&md5=2642aaf9fe603e61a06c9c7db98b8571 0,consider online prediction latent dynamic spatiotemporal process estimation associated model parameters based noisy data problem motivated analysis spatial data arriving real time current parameter estimates predictions updated using new data fixed computational cost estimation prediction performed within empirical bayes framework aid markov chain monte carlo samples samples latent spatial field generated using sampling importance resampling algorithm skewed normal proposal temporal parameters using gibbs sampling full conditionals written terms sufficient quantities updated online spatial range parameter estimated novel online implementation empirical bayes method called herein sequential empirical bayes method simulation study shows method gives similar results offline bayesian method also find skewed normal proposal improves traditional gaussian proposal application method demonstrated online monitoring radiation fukushima nuclear accident â© elsevier b v
10.1007/s12035-016-9982-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976285836&doi=10.1007%2fs12035-016-9982-3&partnerID=40&md5=b226d0562a654442a4251748a0951d1e 4,desflurane halothane isoflurane propofol sevoflurane widely used anesthetics pediatric anesthesia adverse effect including emergence agitation postoperative nausea vomiting postoperative pain common prolonged extubation time emergency time also troubling anesthesiologists previous studies noted characteristics various anesthetics pediatric anesthesia results inconclusive conflicting study aimed performing comprehensive network meta analysis concerning emergence recovery characteristics pediatric anesthetics relevant articles retrieved selected according inclusion criteria network meta analysis performed random effect model within bayesian framework ors corresponding â credible intervals calculated markov chain monte carlo methods node splitting method used calculate inconsistency rank probabilities assessed surface cumulative ranking curve sucra propofol recommended efficient safe anesthetic pediatric anesthesia adverse effects desflurane highest incidence emergence agitation worst recovery characteristics halothane regarded efficient anesthetic best recovery characteristics postoperative nausea vomiting common adverse effect isoflurane reported safest concerning postoperative pain cases using sevoflurane pediatric anesthesia reported highest incidence analgesic requirement network meta analysis demonstrated propofol suggested first choice clinical practice efficiency safe pediatric anesthesia â© springer science+business media new york
10.1016/j.tranpol.2017.04.010 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019368109&doi=10.1016%2fj.tranpol.2017.04.010&partnerID=40&md5=3af8980b03980c173d3790e23edfe0c9 3,alleviate congestion many chinese cities adopted either one two car ownership policies namely license plate auction license plate lottery limit number cars road effort address criticism associated administering single car ownership policy cities considering possibility carrying policies simultaneously residents choose whether pay license plate auction get free lottery longer wait time study residentsâ€™ preferences toward two car ownership policies administered time problem investigated literature examine influence car ownership policies choice electric cars also new literature using data collected stated preference survey estimate mixed logit models using hierarchical bayes approach based markov chain monte carlo method results show strong preference heterogeneity exists respondentsâ€™ policy choice proceed conduct regression analysis explain variations preferences toward license plate auction electric cars main results include find prospective car buyers beijing shanghai willing bid yuan yuan shorten wait time get car license plates one year respectively subsidy electric cars reduced yuan beijing yuan shanghai wait time electric car license plate shortened one year car buyers favor license plate auction high income households buying first cars years old promoting adoption electric cars policy incentives making easier obtain electric car license plate providing attractive subsidies important technological advancement electric car manufacturers strive make improving driving range electric cars â© elsevier ltd
10.1088/1475-7516/2017/07/052 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026809528&doi=10.1088%2f1475-7516%2f2017%2f07%2f052&partnerID=40&md5=df5078d662ccc47e8edf8f7c5ecaba59 1,make projections measuring black hole birth rate diffuse supernova neutrino background dsnb future neutrino experiments constrain black hole merger fraction ïµ combined information black hole merger rate gravitational wave experiments ligo dsnb originates neutrinos emitted supernovae universe expected made two components neutrinos neutron star forming supernovae sub dominant component higher energies black hole forming unnovae perform markov chain monte carlo analysis simulated data dsnb experiment similar hyper kamiokande focusing second component since knowledge neutrino emission unnovae comes simulations collapsing stars choose two sets priors one unnovae well understood one neutrino emission poorly known combining black hole birth rate dsnb projected measurements black hole merger rate ligo show fraction black holes lead binary mergers observed today ïµ constrained within range ä‹ â‰¤ ïµ â‰¤ ä‹ ïƒ confidence ten years running experiment like hyper kamiokande â© iop publishing ltd sissa medialab
10.1109/ICC.2017.7996951 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028333655&doi=10.1109%2fICC.2017.7996951&partnerID=40&md5=059c9d3aeee287c629035c4ba48c9bbe 1,development low complexity high performance spatial multiplexing mimo detectors continues important area research capable increasing spectral efficiency capacity wireless networks markov chain monte carlo mcmc detector shown promise high performance method low complexity growth present solution high snr stalling problems previous mcmc detectors near map performance verified simulation real world measurements antenna mimo testbed using ac wifi protocol demonstration shows channel models predominantly used mcmc literature well conditioned provide understanding performance complexity indoor channels additional information provided methods techniques match simulation measurement construct low cost effective antenna mimo testbed â© ieee
10.5334/dsj-2017-037 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030854398&doi=10.5334%2fdsj-2017-037&partnerID=40&md5=713288ebb43ffa0df8621fdfc5fd9063 1,incomplete data ubiquitous social sciences consequence available data inefficient ineffective often biased literature multiple imputation known standard method handle missing data theory multiple imputation known decades implementation difficult due complicated nature random draws posterior distribution thus several computational algorithms software data augmentation da fully conditional specification fcs expectation maximization bootstrapping emb although literature full comparisons joint modeling da emb conditional modeling fcs little known relative superiority mcmc algorithms da fcs non mcmc algorithm emb mcmc stands markov chain monte carlo based simulation experiments current study contends emb confidence proper confidence supporting multiple imputation algorithm without imputation iterations thus emb user friendly da fcs â© author
10.1098/rsta.2016.0404 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021091114&doi=10.1098%2frsta.2016.0404&partnerID=40&md5=aff9627cbb08c101efa5f36f298af47e 0,atomistic simulations thermal desorption spectra effusion bulk materials characterize binding trapping sites challenging task large system sizes well extended time scales required introduce approach combine kinetic monte carlo analytic approximation superbasins within framework absorbing markov chains apply approach effusion hydrogen bcc iron diffusion within bulk grains coarse grained using absorbingmarkov chains provide exact solution dynamics within superbasin analytic approximation superbasin transferable respect grain size elliptical shapes applied simulations constant temperature well constant heating rate resulting thermal desorption spectra close agreement direct kinetic monte carlo simulations calculations computationally much efficient approach thus applicable much larger system sizes provides first step towards atomistic understanding influence structural features position shape peaks thermal desorption spectra â© author published royal society rights reserved
10.1109/ICC.2017.7996439 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028310441&doi=10.1109%2fICC.2017.7996439&partnerID=40&md5=3b3859c5e993b139d7fd1994fbe9d4b0 2,fronthaul bridged network attracted attention way efficiently constructing centralized radio access network c ran architecture change functional split c ran employ time division duplex tdd data rate fronthaul become variable global synchronization fronthaul streams occur feature results increase queuing delay fronthaul bridges among fronthaul flows paper proposes novel low latency routing scheme designed satisfy latency requirements fronthaul networks path control protocols proposed scheme formulates maximum queuing delay defining competitive links flows selects set paths satisfy latency requirements markov chain monte carlo method using machine learning mcmc ml initial paths selected candidate paths using learned solutions path reselection performed mcmc method confirmed computer simulations proposed scheme compute routes flows satisfy delay requirements also confirmed route computation accelerated learned solutions even flow distribution changes â© ieee
10.1145/3087801.3087815 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027891279&doi=10.1145%2f3087801.3087815&partnerID=40&md5=8aaf1b2f13039a683ac6285013bdfaec 1,local computation linial focs naor stockmeyer stoc concerns question whether locally definable distributed computing problem solved locally specifically given local csp constraint satisfaction problem whether csp solution constructed distributed algorithm using local information paper consider problem sampling uniform csp solution distributed algorithms ask whether locally definable joint distribution sampled locally broadly consider sampling gibbs distributions induced weighted local csps especially markov random fields mrfs local model give two markov chain based distributed algorithms believe represent two fundamental approaches sampling gibbs distributions via distributed algorithms first algorithm generically parallelizes single site sequential markov chain updating step variables random independent set parallel achieves î” log n time upper bound local model î” maximum degree dobrushin condition gibbs distribution satisfied second algorithm novel parallel markov chain proposes update variables simultaneously yet still guarantees converge correctly bias surprisingly parallelizes intrinsically sequential process stabilizing joint distribution massive local dependencies may achieve optimal log n time upper bound independent maximum degree î” stronger mixing condition also show strong î© diam lower bound sampling particular sampling independent set graphs maximum degree î” â‰¥ independent sets trivial construct locally sampling lower bound holds even every node aware entire graph gives strong separation sampling constructing locally checkable labelings â© association computing machinery
10.1080/00949655.2017.1326119 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019612859&doi=10.1080%2f00949655.2017.1326119&partnerID=40&md5=fc0effe14bfbc1092100705d2bd1ddb9 1,article consider problem estimation stressâ€“strength parameter î´ = p x based progressively first failure censored samples x follow two parameter generalized inverted exponential distribution different unknown shape scale parameters maximum likelihood estimator î´ asymptotic confidence interval based observed fisher information constructed two parametric bootstrap boot p boot confidence intervals proposed also apply markov chain monte carlo techniques carry bayes estimation procedures bayes estimate squared error loss function hpd credible interval î´ obtained using informative non informative priors monte carlo simulation study carried comparing proposed methods estimation finally methods developed illustrated couple real data examples â© informa uk limited trading taylor francis group
10.1109/ICRA.2017.7989169 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027959995&doi=10.1109%2fICRA.2017.7989169&partnerID=40&md5=47b71257726340d179ddaa09f963eb03 0,publicly available map services widely used humans navigation nowadays provide almost complete road network data utilizing maps autonomous navigation mobile robots one faced problem inaccuracies map uncertainty position robot relative map paper present probabilistic approach autonomous robot navigation using data openstreetmap associates tracks open streeetmap trails detected robot based lidar data combines semantic terrain information derived lidar data markov chain monte carlo technique match tracks openstreetmap sensor data enables robot utilize openstreetmap navigation planning still stay trails execution plans present results extensive experiments carried real world settings demonstrate robustness system regarding alignment vehicle pose relative openstreetmap data â© ieee
10.1007/s10961-017-9610-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025442487&doi=10.1007%2fs10961-017-9610-z&partnerID=40&md5=8fb77a911dd9587180228a316307078a 0,year united states invests billion research conducted federal researchers within federal laboratories efforts generate extensive social benefits results transferred private sector important effectively quantify economic societal impact federal technology transfer activities inform taxpayers policymakers value public investments form research argus ii device artificial retina commercialized united states second sight provides rich example private sector innovation enhanced research collaborations federal labs academia year journey idea product second sight carried research development collaborations six department energy national laboratories seven universities case argus ii also offers valuable insight private industry academia government work together bring socially beneficial innovations fruition tradeoffs inherent publicâ€“private collaborations paper use markov model estimate realized potential future social benefits associated argus ii provide interactive tool used replicate findings modify assumptions using updated patient information becomes available also provide insight aspects federal involvement surrounding development argus ii contributed successful commercialization discuss spillover benefits publicâ€“private collaborations â© springer science+business media llc
10.1063/1.4992683 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026679089&doi=10.1063%2f1.4992683&partnerID=40&md5=90564fcf8e1fc5383028f4910cbdd19f 0,item response theory irt become one popular scoring frameworks measurement data frequently used computerized adaptive testing cognitively diagnostic assessment test equating according andrade et al irt defined set mathematical models item response models irm constructed represent probability individual giving right answer item particular test number item responsible models available measurement analysis increased considerably last fifteen years due increasing computer power due demand accuracy meaningful inferences grounded complex data developments modeling item response theory related developments estimation theory remarkably bayesian estimation markov chain monte carlo algorithms patz junker popularity item response theory also implied numerous overviews books journals many connections irt statistical estimation procedures factor analysis structural equation modeling made repeatedly van der lindem hambleton stated item response theory covers variety measurement models ranging basic one dimensional models dichotomously polytomously scored items multidimensional analogues models incorporate information cognitive sub processes influence overall item response process aim work introduce main concepts associated one dimensional models item response theory specify logistic models one two three parameters discuss properties models present main estimation procedures â© author
10.1002/sim.7292 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017556494&doi=10.1002%2fsim.7292&partnerID=40&md5=ba593054226d97b4ed8218c79a309960 1,studies reproductive physiology involve rapid sampling protocols result time series hormone concentrations signature pattern times series pulses hormone release various statistical models quantifying pulsatile release features exist currently models fitted separately individual resulting estimates averaged arrive post hoc population level estimates signal noise ratio small time observation short e g h two stage estimation approach fail work extends single subject modelling framework population framework similar exists complex pharamacokinetics data goal leverage information across subjects clearly identify pulse locations improve estimation model parameters modelling extension proven difficult pulse number locations unknown show simultaneously modelling group subjects computationally feasible bayesian framework using birthâ€“death markov chain monte carlo estimation algorithm via simulation show population based approach reduces false positive negative pulse detection rates results less biased estimates population level parameters frequency pulse size hormone elimination apply approach reproductive study healthy women approximately one third subjects study appropriate fits using single subject fitting approach using population model produced precise biologically plausible estimates model parameters copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.3847/1538-4357/aa77f4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026345600&doi=10.3847%2f1538-4357%2faa77f4&partnerID=40&md5=b764d0f516460993cfafc6af0787281f 6,redshifted cm monopole expected powerful probe epoch first stars galaxies z global cm signal sensitive thermal ionization state hydrogen gas thus provides tracer sources energetic photons primarily hot stars accreting black holes ionize heat high redshift intergalactic medium igm paper presents strategy observations global spectrum realizable instrument placed low altitude lunar orbit performing night time mhz spectral observations farside avoid terrestrial radio frequency interference ionospheric corruption solar radio emissions frequency structure uniformity large scales unpolarized state redshifted cm spectrum distinct spectrally featureless spatially varying polarized emission bright foregrounds allows clean separation primordial signal foregrounds signal extraction model foreground instrument cm spectrum eigenmodes calculated via singular value decomposition analyses using markov chain monte carlo algorithm explore parameter space defined coefficients associated modes illustrate spectrum measured astrophysical parameters e g igm properties first star characteristics constrained presence foregrounds using dark ages radio explorer dare â© american astronomical society rights reserved
10.1109/ICSE.2017.28 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027707946&doi=10.1109%2fICSE.2017.28&partnerID=40&md5=4506c68a3a30c52694c37746c1d78299 3,program obfuscation common practice software development obscure source code binary code order prevent humans understanding purpose logic software protects intellectual property deters malicious attacks tremendous efforts devoted development various obfuscation techniques relatively little knowledge effectively use together biggest challenge lies identifying effective combination obfuscation techniques paper presents unified framework optimize program obfuscation given input program p set obfuscation transformations technique automatically identify sequence seq = tn forall element n ti element applying ti order p yields optimal obfuscation performance model process searching seq mathematical optimization problem key technical contributions paper obscurity language model assess obfuscation effectiveness optimality guided stochastic algorithm based markov chain monte carlo methods search optimal solution seq realized framework tool closureâˆ— javascript evaluated starred javascript projects github k lines code machinery study shows closureâˆ— outperforms well known google closure compiler defending attacks initiated jsnice human study also reveals closureâˆ— practical reduce human attack success rate â© ieee
10.1186/s12879-017-2592-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024858212&doi=10.1186%2fs12879-017-2592-5&partnerID=40&md5=ff6802e9fb814d921a162bd5fb3893dc 2,background china high prevalence human papillomavirus hpv consequently high burden disease respect cervical cancer hpv vaccine proved effective preventing cervical cancer part routine immunization programs worldwide also proved cost effective study aimed assess cost effectiveness valent hpv vaccines hereafter hpv combined current screening strategies china methods markov model developed cohort hpv free girls simulate natural history hpv infection three recommended screening methods liquid based cytology test + hpv dna test pap smear cytology test + hpv dna test visual inspection acetic acid three types hpv vaccination program hpv incorporated intervention options incremental cost effectiveness ratio icer calculated determine dominant strategies costs transition probabilities utilities obtained review literature national databases one way sensitivity analyses threshold analyses performed key variables different vaccination scenarios results hpv combined screening showed highest health impact terms reducing hpv related diseases increasing number quality adjusted life years qalys current thresholds willingness pay wtp times per capita gdp usd hpv proved highly cost effective hpv combined screening cost less cost effective screening coverage increased hpv screening combination strategy become economically feasible conclusions combination hpv vaccine current screening strategies adolescent girls highly cost effective significant impact reducing hpv infection related disease burden mainland china â© author
10.3390/e19070327 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024911892&doi=10.3390%2fe19070327&partnerID=40&md5=1626cbaf4b871abe3078e09245ddf6c6 0,coupling dark energy dark matter provides possible approach mitigate coincidence problem cosmological standard model paper assumed interacting term related hubble parameter energy density dark energy equation state dark energy interaction rate dark energy dark matter constant parameter q = hî¾ + wx ï�x based markov chain monte carlo method made global fitting interacting dark energy model planck cosmic microwave background anisotropy observational hubble data found observational data sets slightly favored small interaction rate dark energy dark matter however wasnot obvious evidence interaction ïƒ level â© authors
10.1016/j.eswa.2017.02.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012974071&doi=10.1016%2fj.eswa.2017.02.003&partnerID=40&md5=a6764dcb19a34839368144c4ea265ca7 3,user experience ux design become important factor product success one important issues involved ux design evaluate ux research ux evaluation quantitatively fulfilled cumulative prospect theory ux perceived perspective decision making procedure two alternative design profiles furthermore study influence affective states ux prospect evaluation shaping affective parameters involved ux design account multiple sources uncertainties develop hierarchical bayesian model via markov chain monte carlo technique parameter estimation three affective states also aircraft cabin interior design studied case study demonstrate potential feasibility proposed method â© elsevier ltd
10.1016/j.scitotenv.2017.03.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014555894&doi=10.1016%2fj.scitotenv.2017.03.003&partnerID=40&md5=79f25c5ee2652fbb42e5bfbf47dbf0e1 0,selecting proper rate equations kinetic models essential quantify biotransformation processes environment bayesian model selection method used evaluate candidate models however comparisons plausible models result high computational cost limiting number candidate models may lead biased results work developed integrated bayesian method simultaneously perform model selection parameter estimation using generalized rate equation approach model hypotheses represented discrete parameters rate constants represented continuous parameters bayesian inference kinetic models solved implementing markov chain monte carlo simulation parameter estimation mixed e discrete continuous priors validity approach illustrated synthetic case nitrogen transformation experimental study showed method successfully identify plausible models parameters well uncertainties therein thus method provide powerful tool reveal insightful information complex biotransformation processes â© elsevier b v
10.1016/j.neuroimage.2017.04.069 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019367608&doi=10.1016%2fj.neuroimage.2017.04.069&partnerID=40&md5=03600c1d3135f6d94a94f5816ea23650 1,propose voxel wise general linear model autoregressive noise heteroscedastic noise innovations glmh analyzing functional magnetic resonance imaging fmri data model analyzed bayesian perspective benefit automatically weighting time points close motion spikes data driven manner develop highly efficient markov chain monte carlo mcmc algorithm allows bayesian variable selection among regressors model mean e design matrix variance makes possible include broad range explanatory variables mean variance e g time trends activation stimuli head motion parameters temporal derivatives compute posterior probability inclusion mcmc output variable selection also applied lags autoregressive noise process making possible infer lag order data simultaneously model parameters use simulated data real fmri data openfmri illustrate importance proper modeling heteroscedasticity fmri data analysis results show glmh tends detect brain activity compared homoscedastic counterpart allowing variance change time depending degree head motion â© elsevier inc
10.1093/bioinformatics/btx248 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024488834&doi=10.1093%2fbioinformatics%2fbtx248&partnerID=40&md5=ae2d5b638aa19ae6871da877ea2d1f52 0,motivation epigenome wide association studies provide novel insights regulation genes involved traits diseases rapid emergence bisulfite sequencing technologies enables performing genome wide studies resolution single nucleotides however analysis data produced bisulfite sequencing poses statistical challenges owing low uneven sequencing depth well presence confounding factors recently introduced mixed model association count data via data augmentation macau address challenges via generalized linear mixed model confounding encoded via single variance component however macau used presence multiple variance components additionally macau uses computationally expensive markov chain monte carlo mcmc procedure directly approximate model likelihood results present new method mixed model association via laplace approximation malax computationally efficient macau allows model multiple variance components malax uses laplace approximation rather mcmc based approximations enables directly approximate model likelihood extensive analysis simulated real data demonstrate malax successfully addresses statistical challenges introduced bisulfite sequencing controlling complex sources confounding faster state art â© author published oxford university press rights reserved
10.1093/bioinformatics/btx253 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024502073&doi=10.1093%2fbioinformatics%2fbtx253&partnerID=40&md5=ad2b930ddfa4e8fe9edaa0e73b52295e 1,motivation biological cells operate noisy regime influenced intrinsic extrinsic external noise leads large differences individual cell states stochastic effects must taken account characterize biochemical kinetics accurately since exact solution chemical master equation governs underlying stochastic process derived biochemical systems approximate methods used obtain solution results study method efficiently simulate various sources noise simultaneously proposed benchmarked several examples method relies combination sigma point approach describe extrinsic external variability ï„ leaping algorithm account stochasticity due probabilistic reactions comparison method extensive monte carlo calculations demonstrates immense computational advantage losing acceptable amount accuracy additionally application parameter optimization problems stochastic biochemical reaction networks shown rarely applied due huge computational burden give insight matlab script provided including proposed method applied simple toy example gene expression â© author published oxford university press rights reserved
10.1103/PhysRevE.96.012406 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026447085&doi=10.1103%2fPhysRevE.96.012406&partnerID=40&md5=3092103d19a76f245fa42c42f5f01bb9 1,signaling enzymatic networks typically triggered environmental fluctuations resulting series stochastic chemical reactions leading corruption signal noise example information flow initiated binding extracellular ligands receptors transmitted cascade involving kinase phosphatase stochastic chemical reactions class networks develop general field theoretic approach calculate error signal transmission function appropriate control variable application theory simple push pull network module kinase phosphatase cascade recovers exact results error signal transmission previously obtained using umbral calculus hinczewski thirumalai phys rev x physrevx illustrate generality theory studying minimal errors noise reduction reaction cascade two connected push pull modules cascade behaves effective three species network pseudointermediate case optimal information transfer resulting smallest square error input output occurs time delay given inverse decay rate pseudointermediate surprisingly examples minimum error computed using simulations take nonlinearities discrete nature molecules account coincides predictions linear theory contrast substantial deviations simulations predictions linear theory error signal propagation enzymatic push pull network certain range parameters inclusion second order perturbative corrections shows differences simulations theoretical predictions minimized study establishes field theoretic formulation stochastic biological signaling offers systematic way understand error propagation networks arbitrary complexity â© us published american physical society
10.1109/PTC.2017.7981039 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034736302&doi=10.1109%2fPTC.2017.7981039&partnerID=40&md5=bd06f4bf4209579dd878387c9b0f7acb 0,adequate modelling harmonic load required analyse harmonic impact perform propagation studies since nonlinear loads connected network energy saving lamps electric vehicles photovoltaics systems etc accurate modelling harmonic injection new appliances becomes important paper bottom stochastic model proposed modelling harmonic loads residential networks first markov chain monte carlo approach employed household occupancy modelling time use survey database occupancy weather conditions neighbourhood features behavioural survey data subsequently applied obtain loading patterns household appliances harmonic spectra various appliances established based measurements based harmonic load flow run calculate harmonic load household measurements harmonic magnitude carried residential low voltage network netherlands used validate proposed approach â© ieee
10.1145/3105831.3105860 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028061039&doi=10.1145%2f3105831.3105860&partnerID=40&md5=6dd34a6caa9e6158c7aa2ebd248a0667 0,protection copyrighted contents crucial activity digital content producers order avoid unauthorized use artifacts worse order prevent sensible information stealth e g private documents administrative board common solution uniquely identify copy embedding distinguishing features activity usually known fingerprinting k watermarking embedded content referred fingerprinting code order make process robust possible malicious users attacks mandatory hide positions code embedded however even case positions code embedded hidden users group malicious users referred follows pirates may establish coalition order compare copies identify positions differ positions fingerprinting code embedded kind attack named coalition attack coalition succeeds identification process pirates arbitrarily change fingerprint code embedded distributed copy correspond original fingerprinting codes pirates however purpose designing proper protection strategies assumed know positions hidden code bits codes agreed therefore alter positions assumption referred marking condition collusion resistant fingerprinting code built randomized procedure choose codewords code generation tracing algorithm tailored tracing one pirates based codewords forged codeword read unauthorized copy distributed pirates obviously avoid two type errors accusing innocent user accusing pirate respect tracing algorithm fails falsely accuses innocent user outputs accused user mentioned errors occur small probability problem largely investigated literature approaches proposed far shares common terminology introduce order ease reading next sections detail briefly recall following key terms â€¢ alphabet size codewords sequences fixed alphabet î usually fingerprinting codes built leveraging binary alphabet î = however larger alphabets used thus size î alphabet important parameter â€¢ codelength parameter refers length codewords usually denoted n â€¢ number users usually denoted n coincides number codewords â€¢ pirate coalition size parameter takes account actual size coalition lower expected one say c case accusation algorithm achieve small error probability â€¢ error probability code âˆˆ secure coalition c pirates probability error accusation algorithm e set c pirates performing arbitrary pirate strategy produce forged codeword marking assumption â€¢ code rate rate r fingerprinting code computed r = log n n logarithm binary goal fingerprinting schemes find efficient secure fingerprinting codes taking account high cost embedding every single digit code several real world applications fingerprinting codes may short case fingerprinting text documents due intrinsic difficulty embedding information text however literature many proposal defined based seminal work tardos state many interesting theoretical results generation short codes conditions guarantees possibility finding guilty users tardos fingerprinting scheme optimum generates fingerprinting codes sufficient deal n users c pirates guarantee probability accusing innocent bounded constant e length asymptotically minimum moreover accusation algorithm allows detect traitor looking code assigned disregarding codes assigned users type attack performed worth noticing literature defined many approaches slightly outperforms tardos scheme asymptotic complexity unfortunately tardos based fingerprinting effective accusation processes leveraged code short instance case code embedded textual document applying modification words phrases generally speaking tokens appearing text document described document pages long expected longest fingerprint embedded bit long case tardos accusation algorithm fails accusing user suitable probability guilty instance case maximum coalition size desired probability guilty requires code length least bits accuse user code length impractical many scenarios order overcome mentioned limitations new approaches proposed one interesting joint decoding joint decoders compute guilty probability set users instead single one first proposal made however algorithms tailored small coalition scale properly drawback occurs search space computation grows exponentially w r number users maximum expected number users may conjecture form coalition spreading pirated copy ameliorate problem joint decoding investigated theoretical viewpoint order define efficient approaches work properly real life situations respect markov chain monte carlo mcmc based approach proposed proposed approach leverages gibbs sampling estimating marginal probability user joined coalition generating pirated copy however approach turns ineffective code length greater bit due low quality probability estimation noted authors main limitation mentioned tardos based approaches perform satisfactorily dealing image video fingerprinting use textual documents turns ineffective detail textual document watermarking prone several types attacks even simple ones like called cut paste attack attack allows completely strip watermark corresponding fingerprinting code simply extracting text source document inserting brand new document latter cause deletion eventual watermark inserted source text type attack causes fingerprint pirated copy empty thus avoiding accuse users using tardos based schemes order overcome limitations propose simpler still effective accusation model based metropolis hastings mh sampling next sections devoted describe proposal â© acm
10.3390/ijerph14070765 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024118513&doi=10.3390%2fijerph14070765&partnerID=40&md5=bd53d2708ddafbde0ba7747d583a371f 0,study presents approach obtaining realization sets parameters nitrogen removal pilot scale waste stabilization pond wsp system proposed approach designed optimal parameterization local sensitivity analysis global uncertainty analysis dynamic simulation model wsp using r software package flexible modeling environment r fme markov chain monte carlo mcmc method additionally generalized likelihood uncertainty estimation glue integrated fme evaluate major parameters affect simulation outputs study wsp comprehensive modeling analysis used simulate assess nine parameters concentrations n nh n n results indicate integrated fme glue based model good nash sutcliffe coefficients correlation coefficients successfully simulates concentrations n nh n n moreover arrhenius constant parameter sensitive model performances n nh n simulations however nitrosomonas growth rate denitrification constant maximum growth rate â°c sensitive n n simulation measured using global sensitivity â© authors licensee mdpi basel switzerland
10.1088/1742-6596/869/1/012073 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028705069&doi=10.1088%2f1742-6596%2f869%2f1%2f012073&partnerID=40&md5=31139223b8d334e91017a363d812dec0 0,present observation transit exoplanet tres b newly commissioned robotic telescope trappist north located oukaimeden observatory morocco obtained light curve reaches photometric precison ppm bayesian analysis markov chain monte carlo code enables us refine radius planet rp = + rjup results demonstrate high potential trappist north high photometry exoplanet transits â© published licence iop publishing ltd
10.1016/j.bpj.2017.05.048 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022100207&doi=10.1016%2fj.bpj.2017.05.048&partnerID=40&md5=a1f2c50bc60fa13bc10e32c1928fa2aa 6,circadian clocks must able entrain time varying signals keep oscillations phase day night rhythm hand must also exhibit input compensation period must remain approximately one day different constant environments posttranslational oscillator kai system entrained transient oscillatory changes atp fraction yet insensitive constant changes fraction study three different models system two seemingly conflicting criteria met find one recently published paijmans model exhibits best tradeoff input compensation entrainability footing equal phase response curves exhibits strongest input compensation performing stochastic simulations level individual hexamers allows us identify new knowledge mechanism employed paijmans model achieve input compensation lower atp fraction individual hexamers make shorter cycle phosphorylation state space compensates slower pace traverse cycle â© biophysical society
10.12989/sem.2017.63.1.047 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026235284&doi=10.12989%2fsem.2017.63.1.047&partnerID=40&md5=2e81b8d29299c06c0d57e60de18861e3 1,fundamental goal study minimize uncertainty median fragility curve assess structural vulnerability earthquake excitation bayesian inference markov chain monte carlo mcmc simulation presented efficient collapse response assessment independent intake water tower intake tower significantly used diversion type hydropower station maintaining power plant reservoir spillway tunnel therefore seismic fragility assessment intake tower pivotal component estimating total system risk reservoir investigation asymmetrical independent slender reinforced concrete structure considered bayesian inference method provides flexibility integrate prior information collapse response data numerical analysis results preliminary information risk data obtained various sources like experiments existing studies simplified linear dynamic analysis nonlinear static analysis conventional lognormal model used plotting fragility curve using data time history simulation nonlinear static pushover analysis respectively bayesian inference approach applied integrating data analyses help mcmc simulation method achieves meaningful improvement uncertainty associated fragility curve provides significant statistical computational efficiency â© techno press ltd
10.3390/ijerph14070734 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022183663&doi=10.3390%2fijerph14070734&partnerID=40&md5=dcab45d06ebd7f5e2a7f81aac401e218 0,implemented spatial model analysing pm maxima across mexico city metropolitan area period assumed maxima follow non identical generalized extreme value gev distribution modeled trend introducing multivariate smoothing spline functions probability gev distribution flexible three stage hierarchical bayesian approach developed analyse distribution pm maxima space time evaluated statistical modelâ€™s performance using simulation study results showed strong evidence positive correlation pm maxima longitude latitude relationship time pm maxima negative indicating decreasing trend time finally high risk pm maxima presenting levels î¼g return period yr observed northwestern region study area â© authors licensee mdpi basel switzerland
10.3390/ijerph14070735 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022023896&doi=10.3390%2fijerph14070735&partnerID=40&md5=e329f5feac462a0da2e8336596fe9241 2,considerable effort devoted incorporate temporal trends disease mapping line work describes importance including effect seasonality particular setting related suicides particular number suicide related emergency calls modeled means autoregressive approach spatio temporal disease mapping allows incorporating possible interaction temporal spatial effects results show importance including seasonality effect differences number suicide related emergency calls four seasons year â© authors licensee mdpi basel switzerland
10.1080/10543406.2016.1167075 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974698238&doi=10.1080%2f10543406.2016.1167075&partnerID=40&md5=4a5da59bf962fee47996df1fae9a2279 6,develop efficient markov chain monte carlo algorithm mixed effects model repeated measures mmrm class pattern mixture models pmms via monotone data augmentation mda proposed algorithm particularly useful multiple imputation pmms illustrated analysis antidepressant trial also describe full data augmentation fda algorithm mmrm pmms show marginal posterior distributions model parameters mda fda algorithms â© taylor francis
10.1080/02664763.2016.1221903 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982261366&doi=10.1080%2f02664763.2016.1221903&partnerID=40&md5=54c3a94a709d05574cd50fe484a93480 0,variables taking value rates proportions frequently analyzed researchers instance political social data well human development index hdi however sometimes type data modeled adequately using unique distribution case use mixture distributions powerful flexible probabilistic tool manuscript deals mixture simplex distributions model proportional data fully bayesian approach proposed inference includes reversible jump markov chain monte carlo procedure usefulness proposed approach confirmed using simulated mixture data several different scenarios using methodology analyze municipal hdi data cities towns northeast region sã paulo state brazil analysis shows among cities northeast appear similar hdi cities sã paulo state â© informa uk limited trading taylor francis group
10.1080/02664763.2016.1214692 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980369586&doi=10.1080%2f02664763.2016.1214692&partnerID=40&md5=c029266616835d18f362f3dc4d1a2265 1,paper estimation parameters generalized inverted exponential distribution based progressively first failure type ii right censored sample studied expectationâ€“maximization em algorithm developed obtain maximum likelihood estimates unknown parameters well reliability hazard functions using missing value principle fisher information matrix obtained constructing asymptotic confidence intervals exact interval exact confidence region parameters also constructed bayesian procedures based markov chain monte carlo methods developed approximate posterior distribution parameters interest addition deduce corresponding credible intervals performances maximum likelihood bayes estimators compared terms mean squared errors simulation study furthermore bayes two sample point interval predictors obtained future sample ordinary order statistics squared error linear exponential general entropy loss functions considered obtaining bayes estimators predictors illustrate discussed procedures set real data analyzed â© informa uk limited trading taylor francis group
10.5194/esurf-5-331-2017 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022025733&doi=10.5194%2fesurf-5-331-2017&partnerID=40&md5=157f70e69a816538fec9f2e5ec274494 2,rate low lying sandy areas temperate regions campine plateau ne belgium eroding quaternary matter debate current knowledge average pace landscape evolution campine area largely based geological inferences modern analogies performed bayesian inversion situ produced concentration depth profile infer average long term erosion rate together two parameters surface exposure age inherited concentration compared latest advances probabilistic inversion cosmogenic radionuclide crn data approach following two innovative components uses markov chain monte carlo mcmc sampling accounts certain assumptions contribution model errors posterior uncertainty investigate extent approach differs state art practice comparison bayesian inversion method implemented cronuscalc program made approaches identify similar maximum posteriori map parameter values posterior parameter predictive uncertainty derived using method taken cronuscalc moderately underestimated simple way producing consistent uncertainty estimates cronuscalc like method presence model errors therefore suggested inferred erosion rate â± mmkyr ïƒ relatively large comparison landforms erode comparable paleo climates elsewhere world evaluate value light erodibility substrate sudden base level lowering middle pleistocene denser sampling scheme two nuclide concentration depth profile allow better inferred erosion rate resolution including uncertain parameters mcmc inversion â© author
10.1080/17415977.2016.1215446 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982845425&doi=10.1080%2f17415977.2016.1215446&partnerID=40&md5=92553813a1057dd43d0d224937d68408 4,bayesian techniques widely used finite element model fem updating attraction techniques ability quantify characterize uncertainties associated dynamic systems order update fem bayesian formulation requires evaluation posterior distribution function large systems function difficult solve analytically cases use sampling techniques often provides good approximation posterior distribution function hybrid monte carlo hmc method classic sampling method used approximate high dimensional complex problems however acceptance rate hmc sensitive system size well time step used evaluate molecular dynamics trajectory shadow hmc technique shmc modified version hmc method developed improve sampling large system sizes drawing modified shadow hamiltonian function however shmc algorithm performance limited use non separable modified hamiltonian function moreover two additional parameters required sampling procedure computationally expensive overcome weaknesses separable shadow hmc hmc method introduced method uses transformation different parameter space generate samples paper analyse application performance algorithms including parameters used algorithm limitations effects model updating accuracy efficiency algorithms demonstrated updating finite element models two real mechanical structures observed hmc algorithm number advantages algorithms example hmc algorithm able efficiently sample larger time steps using fewer parameters algorithms â© informa uk limited trading taylor francis group
10.1080/10618600.2017.1336446 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026506363&doi=10.1080%2f10618600.2017.1336446&partnerID=40&md5=b6745e772d114d9f885f5909fc9268a2 1,common subsample markov chain output reduce storage burden geyer shows discarding k âˆ’ every k observations improve statistical efficiency quantified variance given computational budget observation often taken mean thinning markov chain monte carlo mcmc output improve statistical efficiency suppose costs one unit time advance markov chain î gt units time compute sampled quantity interest thinned process cost î incurred less often advanced stages provide examples show thinning improve statistical efficiency î large sample autocorrelations decay slowly enough lag â„“ â©¾ autocorrelations scalar measurement satisfy ï�â„“ gt ï�â„“ + gt always î lt âˆž thinning becomes efficient averages scalar many sample autocorrelation functions resemble first order ar processes ï�â„“ = ï� â„“ âˆ’ lt ï� lt ar process possible compute efficient subsampling frequency k optimal k grows rapidly ï� increases toward resulting efficiency gain depends primarily î ï� taking k = thinning optimal ï� â©½ ï� gt optimal î â©½ âˆ’ ï� ï� efficiency gain never exceeds + î article also gives efficiency bounds autocorrelations bounded two ar processes supplementary materials article available online â© american statistical association institute mathematical statistics interface foundation north america
10.1080/16843703.2016.1226593 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020170245&doi=10.1080%2f16843703.2016.1226593&partnerID=40&md5=01a2de5c339d74ab8f3ee1f9ac07d7f5 0,degradation data provide useful information reliability assessment highly reliable long lifetime products motivated laser degradation data new degradation modelling approach proposed degradation path linear mean linear standard deviation functions article population degradation modelling individual real time reliability assessment discussed bayesian framework proposed integrate population degradation information individual degradation data population degradation path characterized random effect independent increment process random effect captures unit unit variation markov chain monte carlo mcmc method used estimate unknown parameters obtain individual real time reliability assessment parameters updated iteratively using bayesian theory based updated results residual use life individual real time reliability evaluation obtained illustration usefulness validity proposed model method numerical example laser data given â© international chinese association quantitative management
10.1080/00031305.2017.1305289 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031813125&doi=10.1080%2f00031305.2017.1305289&partnerID=40&md5=37da6a77046edd84e126f3b220f8e81b 0,students statistics taught ideas methods widely used practice help understand world statistics today means teaching bayesian methods article present ideas teaching undergraduate bayesian course uses markov chain monte carlo second course strong students first course statistics â© american statistical association
10.1080/10586458.2016.1158134 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981725342&doi=10.1080%2f10586458.2016.1158134&partnerID=40&md5=58a5bd0bdb133d433fabef1309a4d3a1 6,describe markov chain monte carlo algorithm used generate naturally labeled n element posets random probability distribution oneâ€™s choice implementing algorithm uniform distribution explore approach asymptotic regime almost every poset takes three layer structure described kleitman rothschild kr tracking n dependence several order invariants among height poset observe oscillatory behavior unlike monotonic approach kr regime around n = â€œfinite size danceâ€� appear give way gradual crossover asymptopia lasts n = largest n simulated â© taylor francis
10.1080/01621459.2016.1260465 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032470183&doi=10.1080%2f01621459.2016.1260465&partnerID=40&md5=870a34fcdca93747e28d957ada7155fc 0,finding functional modules gene regulation networks important task systems biology many methods proposed finding communities static networks however application methods limited due dynamic nature gene regulation networks article first propose statistical framework detecting common modules drosophila melanogaster time varying gene regulation network develop significance test robustness test identified modular structure apply enrichment analysis community findings reveals interesting results moreover investigate consistency property proposed method time varying stochastic block model framework temporal correlation structure although focus gene regulation networks work method general applied time varying networks supplementary materials article available online â© american statistical association
10.1080/03610918.2015.1134570 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011629272&doi=10.1080%2f03610918.2015.1134570&partnerID=40&md5=3d79f6534dd8b1a03171aa386d7777c3 0,paper investigates new prior distribution unobserved autoregressive conditional heteroscedasticity arch unit root test monte carlo simulations show sample size seriously effective efficiency bayesian test improve performance bayesian test unit root propose new bayesian test robust presence stationary nonstationary unobserved arch finite sample property proposed test statistic evaluated using monte carlo studies applying developed method test policy daily exchange rate german marc respect greek drachma â© taylor francis group llc
10.1080/13696998.2017.1301943 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015203890&doi=10.1080%2f13696998.2017.1301943&partnerID=40&md5=6542a6ddfde43f6ff006f0eee4000eb6 3,background aims ideglira fixed ratio combination insulin degludec glucagon like peptide receptor agonist liraglutide utilizes complementary mechanisms action two agents improve glycemic control low risk hypoglycemia avoidance weight gain aim present analysis assess long term cost effectiveness ideglira vs liraglutide added basal insulin patients type diabetes achieving glycemic control basal insulin us setting methods projections lifetime costs clinical outcomes made using ims core diabetes model treatment effect data patients receiving ideglira liraglutide added basal insulin modeled based outcomes published indirect comparison head head clinical trial data currently available costs accounted us dollars healthcare payer perspective results ideglira associated small improvements quality adjusted life expectancy compared liraglutide added basal insulin vs discounted quality adjusted life years qalys key driver improved clinical outcomes greater reduction glycated hemoglobin associated ideglira ideglira associated mean costs savings patient lifetimes vs liraglutide added basal insulin resulting lower treatment costs cost savings result complications avoided conclusions present long term modeling analysis found ideglira dominant vs liraglutide added basal insulin patients type diabetes failing achieve glycemic control basal insulin us improving clinical outcomes reducing direct costs â© informa uk limited trading taylor francis group
10.1080/03610918.2015.1130837 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011590490&doi=10.1080%2f03610918.2015.1130837&partnerID=40&md5=e6ab96f1c63c9fac6f56057b5f94efa1 0,consider bayesian nonignorable model accommodate nonignorable selection mechanism predicting small area proportions main objective extend model selection bias previously published paper coauthored four authors accommodate small areas authors assume survey weights reciprocals also call selection probabilities available simple relation binary responses selection probabilities capture nonignorable selection bias within area assume binary responses selection probabilities correlated accommodate small areas extend model hierarchical bayesian nonignorable model use markov chain monte carlo methods fit illustrate methodology using numerical example obtained data activity limitation u national health interview survey also perform simulation study assess effect correlation binary responses selection probabilities â© taylor francis group llc
10.1080/10618600.2017.1297240 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021884581&doi=10.1080%2f10618600.2017.1297240&partnerID=40&md5=00d2edf3efc4b9d4a488c5ebf58bc654 0,present diagnostic monitoring convergence markov chain monte carlo mcmc sampler target distribution contrast popular existing methods monitor convergence joint target distribution directly rather select scalar projection method uses simple nonparametric posterior approximation based state space partition obtained clustering pooled draws multiple chains convergence determined estimated posterior probabilities partition elements chain sufficiently similar framework applies wide variety problems generalizes directly non euclidean state spaces method also provides approximate high posterior density regions characterization differences nonconverged chains little additional computational burden demonstrate approach applications sampling posterior distributions rp graphs partitions supplementary materials article available online â© public domain
10.1080/01621459.2016.1189337 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017447336&doi=10.1080%2f01621459.2016.1189337&partnerID=40&md5=7a332e642a8d62188b92ab2a48016138 0,time average covariance matrix tacm âˆ‘ âˆ‘kïµz î“k î“k auto covariance function important quantity inference mean rd valued stationary process â©¾ article proposes two recursive estimators î optimal asymptotic mean square error amse different strengths serial dependence optimal estimator involves batch size selection requires knowledge smoothness parameter ï’î² = âˆ‘kïµz k î² î“k î² article also develops recursive estimators ï’î² combining two estimators obtain fully automatic procedure optimal online estimation î consistency convergence rates proposed estimators derived applications confidence region construction markov chain monte carlo convergence diagnosis discussed supplementary materials article available online â© american statistical association
10.1080/01621459.2016.1192545 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017457839&doi=10.1080%2f01621459.2016.1192545&partnerID=40&md5=e3c58bdf228a34a992e0853c7c3f77f2 5,spite recent surge interest quantile regression joint estimation linear quantile planes remains great challenge statistics econometrics propose novel parameterization characterizes collection noncrossing quantile planes arbitrarily shaped convex predictor domains dimension means unconstrained scalar vector function valued parameters statistical models based parameterization inherit fast computation likelihood function enabling penalized likelihood bayesian approaches model fitting introduce complete bayesian methodology using gaussian process prior distributions function valued parameters develop robust efficient markov chain monte carlo parameter estimation resulting method shown offer posterior consistency mild tail regularity conditions present several illustrative examples new method compared existing approaches found offer better accuracy coverage model fit supplementary materials article available online â© american statistical association
10.1371/journal.pntd.0005696 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026291462&doi=10.1371%2fjournal.pntd.0005696&partnerID=40&md5=1928ba301aa628bcc6fa4874a93f090c 8,aim study model association weekly time series dengue case counts meteorological variables high incidence city colombia applying bayesian hierarchical dynamic generalized linear models period january august additionally evaluate modelâ€™s short term performance predicting dengue cases methodology shows dynamic poisson log link models including constant time varying coefficients meteorological variables calendar effects modeled using constant first second order random walk time varying coefficients meteorological variables modeled using constant coefficients first order random walk time varying coefficients applied markov chain monte carlo simulations parameter estimation deviance information criterion statistic dic model selection assessed short term predictive performance selected final model several time points within study period using mean absolute percentage error results showed best model including first order random walk time varying coefficients calendar trend first order random walk time varying coefficients meteorological variables besides computational challenges interpreting results implies complete analysis time series dengue respect parameter estimates meteorological effects found small values mean absolute percentage errors one two weeks sample predictions prediction points associated low volatility periods dengue counts discuss advantages limitations dynamic poisson models studying association time series dengue disease meteorological variables key conclusion study dynamic poisson models account dynamic nature variables involved modeling time series dengue disease producing useful models decision making public health â© martã­nez bello et al
10.1002/qre.2071 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989318600&doi=10.1002%2fqre.2071&partnerID=40&md5=86dbb07b4efc745c58334a638b02af86 0,markov chain monte carlo mcmc techniques extensively developed accepted solving various real world problems however process capabilities rarely analyzed means mcmc study integrates mcmc technique bayesian models assessing well known quality loss index cpm gamma weibull process distributions mcmc iterations completed quality manager make reliable decisions via proposed credible intervals furthermore study provides performance comparisons estimators cpm obtained mcmc bootstrap techniques simulations show mcmc technique performs better bootstrap technique cases considered copyright â© john wiley amp sons ltd copyright â© john wiley sons ltd
10.1134/S0361768817040053 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025817868&doi=10.1134%2fS0361768817040053&partnerID=40&md5=6b32001574a3b37bea10051ffc473f55 1,paper considers problem multiple person tracking present algorithm automatic people tracking surveillance videos recorded static cameras proposed algorithm extension approach based tracking detection people heads data association using markov chain monte carlo mcmc short track fragments tracklets built local tracking people heads tracklet postprocessing accurate results interpolation shown reduce number false positives use position deviations tracklets revised entry exit points factor separate pedestrians false positives paper presents new method estimate body position increases precision tracker finally switched hog based detector cascade one evaluation shows proposed modifications significantly increase tracking quality â© pleiades publishing ltd
10.1109/JPHOTOV.2017.2690876 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019005272&doi=10.1109%2fJPHOTOV.2017.2690876&partnerID=40&md5=ee6280092e9de224a3e4558d9a963a75 1,paper presents alternative approach obtain experimental measurements physical parameters organic solar cells associated given model order get rid limitations common fitting methods use specific markov chain monte carlo technique method applied two dimensional model organic solar cell measurements carried dark one sun conditions two complementary cells allow access reliable values active layer parameters corresponding set parameters generates jv curves excellent agreement measurements range different illumination intensities similar extractions applied temperature dependent parameters experimental data acquired various temperatures simulation results reproduce measurement data rather well show approach also useful test determine governing law associated temperature dependent parameters addition analyzing simulated responses model allows identification model limitations approach discussed paper specific organic solar cells applied large range condensed matter topics â© ieee
10.1016/j.jmva.2017.05.009 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033401268&doi=10.1016%2fj.jmva.2017.05.009&partnerID=40&md5=7e251079b22e098075609596ab73f28b 1,markov chain monte carlo mcmc simulation method commonly used estimating expectations respect given distribution consider estimating covariance matrix asymptotic multivariate normal distribution vector sample means geyer developed monte carlo error estimation method estimating univariate mean propose novel multivariate version geyer method provides asymptotically valid estimator covariance matrix results stable monte carlo estimates finite sample properties proposed method investigated via simulation experiments â© elsevier inc
10.1103/PhysRevD.96.014015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027071555&doi=10.1103%2fPhysRevD.96.014015&partnerID=40&md5=4d4d7035269ddba678620695d49346c1 2,present new procedure determine parton distribution functions pdfs based markov chain monte carlo mcmc methods aim paper show replace standard ï‡ minimization procedures grounded statistical methods bayesian inference particular thus offering additional insight rich field pdfs determination basic introduction techniques introduce algorithm chosen implement namely hybrid hamiltonian monte carlo algorithm initially developed lattice qcd turns interesting applied pdfs determination global analyses show allows us circumvent difficulties due high dimensionality problem particular concerning acceptance first feasibility study performed presented indicates markov chain monte carlo successfully applied extraction pdfs uncertainties â© american physical society
10.1145/3071178.3071234 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026386995&doi=10.1145%2f3071178.3071234&partnerID=40&md5=bf0841e7fb0bfec294f0eeb6daf44d40 0,genetic algorithms genetic programming lend well field machine learning involves solving test case based problems however traditional multi objective selection methods work scalar objectives minimizing false negative false positive rates computed underlying test cases paper propose new fuzzy selection operator takes account statistical nature machine learning problems based test cases rather use pareto rank strength computed scalar objectives nsga spea compute probability pareto optimality accomplished covariance estimation markov chain monte carlo simulation order generate probabilistic objective scores individual compute probability individual generate pareto optimal solution probability directly used roulette wheel selection technique method performance evaluated evolution feature selection vector binary classification eight different activities fuzzy selection performance varies outperforming nsga spea speed measured generations solution quality measured area curve cases underperforming others â© acm
10.1007/s00477-016-1279-6 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975297914&doi=10.1007%2fs00477-016-1279-6&partnerID=40&md5=4e1650f9b5642b8ff4339f1fdc501f29 3,creeping characteristics drought make possible mitigate droughtâ€™s effects accurate forecasting models drought forecasts inevitably plagued uncertainties making necessary derive forecasts probabilistic framework study proposed new probabilistic scheme forecast droughts used discrete time finite state space hidden markov model hmm aggregated representative concentration pathway rcp precipitation projection hmm rcp standardized precipitation index spi month time scale employed represent drought status selected stations south korea new scheme used reversible jump markov chain monte carlo algorithm inference model parameters performed rcp precipitation projection transformed spi rcp spi weight corrected post processing hmm based drought forecasting perform probabilistic forecast spi month time scale considered uncertainties point forecasts derived hmm rcp forecast mean values measured forecasting skill scores much accurate conventional models climatology reference model various lead times also used probabilistic forecast verification found hmm rcp provided probabilistic forecast satisfactory evaluation different drought categories even long lead times drought event analysis hmm rcp accurately predicted â drought events validation period forecasted mean duration error less â months mean severity error results showed hmm rcp good potential probabilistic drought forecasting â© springer verlag berlin heidelberg
10.1016/j.csda.2017.01.006 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012273138&doi=10.1016%2fj.csda.2017.01.006&partnerID=40&md5=08bf4a4e60949c855ff75cb3782dce95 0,novel approach perform unsupervised sequential learning functional data proposed goal extract reference shapes referred templates noisy deformed censored realizations curves images proposed model generalizes bayesian dense deformable template model hierarchical model template function estimated deformation nuisance assumed random known prior distribution templates estimated using monte carlo version online expectationâ€“maximization em algorithm designed sequential inference framework significantly computationally efficient equivalent batch learning algorithms especially missing data high dimensional numerical illustrations curve registration problem templates extraction images provided support methodology â© elsevier b v
10.1016/j.csda.2017.01.007 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014116003&doi=10.1016%2fj.csda.2017.01.007&partnerID=40&md5=14d2c7478a46d68c947b4c936ac01607 0,authors develop bayesian local influence method semiparametric structural equation models effects minor perturbations individual observations prior distributions parameters sampling distribution statistical inference assessed various perturbation schemes bayesian perturbation manifold constructed characterize perturbation schemes first second order influence measures proposed quantify degree minor perturbations different aspects statistical model via objective functions bayes factor simulation studies conducted evaluate empirical performance bayesian local influence procedure application study bone mineral density presented â© elsevier b v
10.1016/j.ijfatigue.2017.03.043 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017244056&doi=10.1016%2fj.ijfatigue.2017.03.043&partnerID=40&md5=1effb7decd0370c5399b077416e0372d 1,problem minimizing number specimens required fatigue data analysis considered research assuming unknown hyperparameters described via prior distributions hierarchical bayesian model accumulated prior information proposed deal issue one main advantages hierarchical bayesian model empirical bayesian model prior distributions hierarchical structure incorporate structural prior subjective prior simultaneously probabilistic stress cycle p n curves generated predictive distributions involving randomness parameters scatter observations calculated identical hierarchical structure numerical calculation done via gibbs sampler makes whole process simple intuitive â© elsevier ltd
10.1061/(ASCE)EM.1943-7889.0001240 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018745372&doi=10.1061%2f%28ASCE%29EM.1943-7889.0001240&partnerID=40&md5=306544545c7347558a8e275c02558f7d 9,paper addresses statistical uncertainties associated estimation depth dependent trend function spatial variation trend function using limited site specific geotechnical data specifically statistical uncertainties associated following elements considered functional form shape trend function parameters trend function e g intercept gradient random field parameters describing spatial variation trend function namely standard deviation ïƒ scale fluctuation î´ problem resolved two step bayesian framework step set suitable basis functions parameterize trend function selected using sparse bayesian learning step advanced markov chain monte carlo method adopted bayesian analysis two step approach shown consistent well defined sense resulting bayesian confidence interval region contains actual trend actual ïƒ î´ chance close inconsistency occur spatial variability large ïƒ large î´ relative data record length â© american society civil engineers
10.1002/biot.201600613 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013230729&doi=10.1002%2fbiot.201600613&partnerID=40&md5=41c5727bef74ffaeed30dbbc563bbe8b 2,biotechnological separation processes routinely designed optimized using parallel high throughput experiments serial experiments well characterized processes optimized using mechanistic models cases â€“ serial parallel experiments modeling â€“ iterative strategies customarily applied planning novel experiments simulations based previously acquired knowledge process optimization typically complicated conflicting design targets productivity yield address issues introducing novel algorithm combines recently developed approaches utilizing statistical regression models multi objective optimization proposed algorithm demonstrated simultaneous optimization elution gradient pooling strategy chromatographic separation three component system respect purity yield processing time gaussian process regression models gpm used estimating functional relationships design variables gradient pooling performance indicators purity yield time pareto front iteratively approximated planning new experiments maximize expected hypervolume improvement ehvi determined gpm markov chain monte carlo mcmc sampling comprehensive monte carlo study silico data illustrates efficiency effectiveness robustness presented multi objective global optimization mogo algorithm determining best compromises conflicting objectives comparably low experimental effort copyright â© wiley vch verlag gmbh co kgaa weinheim
10.1007/s00477-016-1230-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010218923&doi=10.1007%2fs00477-016-1230-x&partnerID=40&md5=a2432a6cd816d2baf3bdd575de079d12 7,empirical tsunami fragility curves developed based bayesian framework accounting uncertainty input tsunami hazard data systematic comprehensive manner three fragility modeling approaches e lognormal method binomial logistic method multinomial logistic method considered applied extensive tsunami damage data tohoku earthquake unique aspect study uncertainty tsunami inundation data e input hazard data fragility modeling quantified comparing two tsunami inundation run datasets one ministry land infrastructure transportation japanese government tohoku tsunami joint survey group propagated bayesian statistical methods assess effects tsunami fragility models systematic implementation data methods facilitates quantitative comparison tsunami fragility models different assumptions comparison shows binomial logistic method un binned data preferred among considered models nevertheless investigations related multinomial logistic regression un binned data required finally developed tsunami fragility functions integrated building damage loss models investigate influences different tsunami fragility curves tsunami loss estimation numerical results indicate uncertainty input tsunami data negligible coefficient variation neglecting input data uncertainty leads overestimation model uncertainty â© author
10.1007/s11222-016-9667-9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016107399&doi=10.1007%2fs11222-016-9667-9&partnerID=40&md5=de998998e32a07f8003c48bb26061021 1,consider continuous time markovian processes populations individual agents interact stochastically according kinetic rules despite increasing prominence models fields ranging biology smart cities bayesian inference systems remains challenging continuous time discrete state systems potentially infinite state space propose novel efficient algorithm joint state parameter posterior sampling population markov jump processes introduce class pseudo marginal sampling algorithms based random truncation method enables principled treatment infinite state spaces extensive evaluation number benchmark models shows approach achieves considerable savings compared state art methods retaining accuracy fast convergence also present results synthetic biology data set showing potential practical usefulness work â© author
67.88668540608734 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028889741&partnerID=40&md5=b30bf30af115a617f6ed63e12c708c99 0,paper proposed approach bayesian inference structural equation modelling sem evaluate accident causation underground coal mines india statistics accident events reportable incidents shown corresponding levels improvement area major hazards control mining industry emphasized mainly past experiences lessons learnt however conventional risk management processes able achieve goal zero accident potential zap due tonne reasons bayesian inference sem necessary develop models coefficient parameter estimation markov chain monte carlo sampling form gibbs sampling applied sampling posterior distribution results revealed coefficients sem parameters statistically significant bayesian error statistics reveals model provides approach reduce accidents underground coal mines india
10.2436/20.8080.02.63 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039429624&doi=10.2436%2f20.8080.02.63&partnerID=40&md5=4012bee3c87f377c126f262fa2279727 0,aging societies given rise important challenges field health insurance elderly policyholders need provided fair premiums based individual health status whereas insurance companies want plan potential costs tackling lifetimes mean expectations article focus large cohort policyholders barcelona spain aged years shared parameter joint model proposed analyse relationship annual demand emergency claims time death outcomes subject left truncation compare different functional forms association processes furthermore illustrate fitted model provides time dynamic predictions survival probabilities parameter estimation performed bayesian framework using markov chain monte carlo methods
10.1109/TSTE.2016.2637916 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028833608&doi=10.1109%2fTSTE.2016.2637916&partnerID=40&md5=ff36cef93d774cfe8fb1963475fe9f55 6,due intermittent nature wind power large scale wind farm integration creates technical challenges increase peak valley net load difference uncertainty generation energy storage essential providing flexibility ensuring system reliability storage sizing problem widely studied given demand curve needed storage capacity achieve certain level peak shaving performance analyzed paper probabilistic model storage sizing peak shaving policy optimization required matching probability established minimize net cost considering time variant energy price storage used reducing energy deficit keeping generation reliable also energy shifting obtain higher profit cyclic nonhomogeneous markov chain cnhmc steady state analysis method proposed serving efficient way test probability constraint commonly used time consuming sequential monte carlo simulation cnhmc used stored power modeling representing diurnal variation wind power load probability constraint tested obtained analytical expression matching probability numerical test shows reliable power supply achieved little profit sacrifice peak valley net load difference decreases little increment storage capacity proposed solution method fast accurate â© ieee
10.1007/s00477-016-1319-2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988311257&doi=10.1007%2fs00477-016-1319-2&partnerID=40&md5=7856aa694ecc0214555f7a27eb5596a7 5,parameter uncertainty hydrologic modeling crucial flood simulation forecasting bayesian approach allows one estimate parameters according prior expert knowledge well observational data model parameter values study assesses performance two popular uncertainty analysis ua techniques e generalized likelihood uncertainty estimation glue bayesian method implemented markov chain monte carlo sampling algorithm evaluating model parameter uncertainty flood simulations two methods applied semi distributed topographic hydrologic model topmodel includes five parameters case study carried small humid catchment southeastern china performance assessment glue bayesian methods conducted advanced tools suited probabilistic simulations continuous variables streamflow graphical tools scalar metrics used test several attributes simulation quality selected flood events deterministic accuracy accuracy â prediction probability uncertainty band ppu sensitivity analysis conducted identify sensitive parameters largely affect model output results subsequently glue bayesian methods used analyze uncertainty sensitive parameters produce posterior distributions based posterior parameter samples topmodelâ€™s simulations corresponding ua results conducted results show form exponential decline conductivity overland flow routing velocity sensitive parameters topmodel case small changes two parameters lead large differences flood simulation results results also suggest ua techniques streamflow observations bracketed ppu containing ratio value larger â comparison glue gave narrower prediction uncertainty bands bayesian method found mode estimates parameter posterior distributions suitable result better performance deterministic outputs â percentiles glue bayesian analyses addition simulation results calibrated rosenbrock optimization algorithm show better agreement observations uaâ€™s â percentiles slightly worse hydrographs mode estimates results clearly emphasize importance using model uncertainty diagnostic approaches flood simulations â© springer verlag berlin heidelberg
10.1111/1365-2435.12844 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015198625&doi=10.1111%2f1365-2435.12844&partnerID=40&md5=f65d9e9be68de067794f8c3286acea9b 0,several dynamic models shown dynamics legumes grasses result periodic behaviour oscillations arise due delays nitrogen flows coupled differences ability compete light however long term time series legume dynamics used test predictions models almost non existent examine legume oscillations semi natural mountain grassland using long term tilde â years data series aboveground biomass individual species nitrogen phosphorus content time using autocorrelation analysis show strong periodicity period â€“ â years legume grass biomass nitrogen content grass biomass three variables fairly stable phase shifts relative grass peak followed peak câ â n ratio grasses followed legume peak phosphorus content either legume grass biomass show synchronous cycling legume grass biomass nitrogen content grass fitting dynamic linear model data showed legumes affect nitrogen content grasses grass biomass affects affected nitrogen content contrast negative effect grasses legumes indicating process must responsible legume decline manuring occasionally applied plots also seem affect cycling second order term legumes showed evidence self inhibitory effects legumes phosphorus content legumes shows support phosphorus limitation likely explanation legume decline sought elsewhere pathogens soil biota etc synthesis long term data support existing claim legume dynamics key driver nitrogen dynamics nutrient poor semi natural grasslands grasses benefit nutrient enrichment due legume cycling passive element play role legume limitation apart role nutrient cycling legume driven nutrient dynamics also constitutes processes long term richness meadows maintained â© authors functional ecology â© british ecological society
10.1007/s10458-016-9359-z https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010796734&doi=10.1007%2fs10458-016-9359-z&partnerID=40&md5=8dac76656160b8f4937860699483637e 4,consider autonomous agent facing stochastic partially observable multiagent environment order compute optimal plan agent must accurately predict actions agents since influence state environment ultimately agentâ€™s utility propose special case interactive partially observable markov decision process agent explicitly model agentsâ€™ beliefs preferences instead represents stochastic processes implemented probabilistic deterministic finite state controllers pdfcs agent maintains probability distribution pdfc models agents updates belief using bayesian inference since number nodes pdfcs unknown unbounded agent places bayesian nonparametric prior distribution infinitely dimensional set pdfcs allows size learned models adapt complexity observed behavior deriving posterior distribution case complex amenable analytical computation therefore provide markov chain monte carlo algorithm approximates posterior beliefs agentsâ€™ pdfcs given sequence possibly imperfect observations behavior experimental results show learned models converge behaviorally true ones consider two settings one agent first learns interacts agents one learning planning interleaved show agentâ€™s performance increases result learning situations moreover analyze dynamics ensue two agents simultaneously learning interacting showing example environment coordination emerges naturally approach furthermore demonstrate agent exploit learned models perform indirect inference state environment via modeled agentâ€™s actions â© author
10.1007/s11222-016-9663-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969785532&doi=10.1007%2fs11222-016-9663-0&partnerID=40&md5=a9d3eb8512f234bcd346d637ff289dca 1,present parallel interacting stochastic approximation annealing pisaa algorithm stochastic simulation procedure global optimisation extends improves stochastic approximation annealing saa using population monte carlo ideas efficiency standard saa algorithm crucially depends self adjusting mechanism presents stability issues high dimensional rugged optimisation problems proposed algorithm involves simulating population saa chains interact manner significantly improves stability self adjusting mechanism search global optimum sampling space well inherits saa desired convergence properties square root cooling schedule used implemented parallel computing environments order mitigate computational overhead result pisaa address complex optimisation problems difficult saa satisfactory address demonstrate good performance proposed algorithm challenging applications including bayesian network learning protein folding numerical comparisons suggest pisaa outperforms simulated annealing stochastic approximation annealing annealing evolutionary stochastic approximation monte carlo â© springer science+business media new york
10.1017/aer.2017.37 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021078954&doi=10.1017%2faer.2017.37&partnerID=40&md5=82e67d55f73997831608e978d1b8e561 1,assimilation discrete data points model predictions used achieve reduction uncertainty model input parameters generate accurate predictions problem investigated involves prediction limit cycle oscillations using high dimensional harmonic balance hdhb method efficiency hdhb method exploited enable calibration structural input parameters using bayesian inference technique markov chain monte carlo employed sample posterior distributions parameter estimation carried pitch plunge aerofoil two goland wing configurations cases significant refinement achieved distribution possible structural parameters allowing better predictions true deterministic values additionally comparison two approaches extract true values posterior distributions presented â© royal aeronautical society
10.1016/j.chinastron.2017.08.008 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028298202&doi=10.1016%2fj.chinastron.2017.08.008&partnerID=40&md5=cad694766df74b534abc4cf4f376de44 0,astrometry effective measure detect exoplanets many advantages detection methods bear providing three dimensional planetary orbit determining planetary mass etc astrometry enrich sample exoplanets high precision astrometric satellite gaia global astrometry interferometer astrophysics launched predictable abundant long period jupiter size planets discovered gaia paper specify î± centauri hd gj systems generate synthetic astrometric data single time astrometric precision gaia use lomb scargle periodogram analyze periodical signal planetary orbit use markov chain monte carlo mcmc algorithm make orbit inversion planetary system obtained result well coincident initial parameters planet â© elsevier b v
10.1016/j.spl.2017.02.035 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015225401&doi=10.1016%2fj.spl.2017.02.035&partnerID=40&md5=589d19df413f3977931cd70d1f0530c1 0,propose new non iterative simple accurate bayesian inference procedure stochastic volatility model requirement approach solve large sparse linear system avoid iteration â© elsevier b v
10.1016/j.ecosta.2016.08.003 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032823531&doi=10.1016%2fj.ecosta.2016.08.003&partnerID=40&md5=a6247d7fd5112e004bd10b35ebab7eea 1,multivariate stochastic volatility models leverage expected play important roles financial applications asset allocation risk management however models suffer two major difficulties many parameters estimate using daily asset returns estimated covariance matrices guaranteed positive definite approach takes advantage realized covariances achieve efficient estimation parameters incorporating additional information co volatilities considers cholesky decomposition guarantee positive definiteness covariance matrices framework flexible model proposed stylized facts financial markets dynamic correlations leverage effects among volatilities using bayesian approach markov chain monte carlo implementation described simple efficient sampling scheme model applied data nine u stock returns compared models basis portfolio performances â© ecosta econometrics statistics
10.1007/s11222-016-9660-3 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969837191&doi=10.1007%2fs11222-016-9660-3&partnerID=40&md5=4b19479c6699aa2b7152b028f786fc86 2,consider task generating discrete time realisations nonlinear multivariate diffusion process satisfying itã´ stochastic differential equation conditional observation taken fixed future time point realisations typically termed diffusion bridges since general closed form expression exists transition densities process interest widely adopted solution works eulerâ€“maruyama approximation replacing intractable transition densities gaussian approximations however density conditioned discrete time process remains intractable necessitating use computationally intensive methods markov chain monte carlo designing efficient proposal mechanism applied noisy partially observed system exhibits nonlinear dynamics challenging problem focus paper partitioning process two parts one accounts nonlinear dynamics deterministic way another residual stochastic process develop class novel constructs bridge residual process via linear approximation addition adapt recently proposed construct partial noisy observation regime compare performance new construct number existing approaches using three applications â© author
10.1016/j.ecosta.2016.08.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032827548&doi=10.1016%2fj.ecosta.2016.08.002&partnerID=40&md5=895a5431afbab5d14847a7b00a4f7400 1,efficient method bayesian inference stochastic volatility models uses linear state space representation define gibbs sampler volatilities jointly updated method involves choice offset parameter illustrate choice important effect posterior inference metropolisâ€“hastings algorithm developed robustify approach choice offset parameter method illustrated simulated data known parameters daily log returns eurostoxx index bayesian vector autoregressive model stochastic volatility â© ecosta econometrics statistics
10.1002/bimj.201600086 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016013502&doi=10.1002%2fbimj.201600086&partnerID=40&md5=58f70816b0ff4d082911cdb227c3f087 0,present generalization usual independent mixture model accommodate markovian first order mixing distribution propose data driven reversible jump markov chain monte carlo mcmc procedure estimating posteriori probability model model selection procedure estimating corresponding parameters simulated datasets show excellent performance proposed method convergence model selection precision parameters estimates finally apply proposed method analyze usa diabetes incidence datasets â© wiley vch verlag gmbh co kgaa weinheim
10.1016/j.ifacol.2017.08.1072 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031823981&doi=10.1016%2fj.ifacol.2017.08.1072&partnerID=40&md5=b54736f14ec3a33060262cb038406eca 1,modelling simulating loads agricultural machinery different variable loading conditions important tool optimising design machines developed models based real conditions machine face service life paper load time series four rotor swather acquired normal working conditions performing infield swathing headland turning turning points loads modelled using switching markov chains order model switching two operating modes e swathing headland turning based developed model total monte carlo simulations performed assess proposed methodology comparison measured simulated loads performed calculating correlation coefficient power spectral density psd two signals mean value standard deviation correlation coefficient comparing psd monte carlo simulations psd measured load respectively th th percentile respectively â©
10.1109/TASE.2015.2443132 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027683238&doi=10.1109%2fTASE.2015.2443132&partnerID=40&md5=282ef38feafac6843d3e95164da54b86 2,digital networked control systems growing importance safety critical systems perform indispensable function complex systems today networked degradations transmission delay packet dropout cause systems fail satisfy performance requirements eventually affect overall reliability necessary get model verify evaluate system reliability early design phase prior implementation however existing probabilistic models provide partial descriptions coupled networks control system paper new stochastic model represented linear discrete time approach proposed considering data packet transmissions channels controller actuator sensor controller different pervious works historical behaviors networked degradations modeled multistate markov chains uncertainties releasing assumption faults periods independent concept domain requirements systems considered contributing integration control reliability engineering methodologies quantitatively assessing reliability single sequential control goal derived monte carlo method example industrial heat exchanger digital networked control system provided illustrate effectiveness model method â© ieee
10.1007/s11276-016-1226-y https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958824933&doi=10.1007%2fs11276-016-1226-y&partnerID=40&md5=41581631e2a18df5d6181c58e83c3937 5,ieee standard introduced low latency low energy consumption wireless sensor networks better support requirements industrial applications use standard limited low latency deterministic network lldn mechanism ieee e amendment proposed paper develop three dimensional markov chain model ieee e lldn mechanism estimate stationary probability distribution chain order derive theoretical expressions performance metrics reliability energy consumption throughput delay jitter conduct comparative study ieee e lldn ieee slotted carrier sense multiple access collision avoidance csma ca numerical results show deterministic behavior lldn mechanism significantly reduces collision probability providing best performances terms reliability energy consumption throughput delay compared ieee slotted csma ca finally accuracy theoretical analysis validated monte carlo simulations â© springer science+business media new york
10.1016/j.jvir.2017.02.031 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016599363&doi=10.1016%2fj.jvir.2017.02.031&partnerID=40&md5=a1f8c24ce2c90ecbc490edfd4ed7aacc 1,purpose estimate least costly routine exchange frequency percutaneous nephrostomies pcns placed malignant urinary obstruction measured annual hospital charges estimate financial impact patient compliance materials methods patients pcns placed malignant urinary obstruction studied exchanges classified routine due complication types mechanical tube dislodgment obstruction infection representative cases identified median representative charges used inputs model accelerated failure time markov chain monte carlo models used estimate distribution exchange types annual hospital charges different routine exchange frequency compliance scenarios results long term pcn management required patients total exchange encounters median representative hospital charges pyelonephritis obstruction times greater respectively routine exchange projected proportion routine exchanges increased projected proportion infection related exchanges decreased moving day exchange compliance day exchange compliance associated projected reduction annual charges projected cost reductions resulting increased compliance generally greater reductions resulting changes exchange frequency conclusions simulation model suggests optimal routine exchange interval pcn exchange patients malignant urinary obstruction approximately days degree reduction charges likely depends patient compliance exact exchange interval â© sir
10.1007/s10985-016-9361-4 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961198156&doi=10.1007%2fs10985-016-9361-4&partnerID=40&md5=cb9bca96271a98283beab7898f81362d 1,flexible incorporation geographical patterning risk effects cancer survival models becoming increasingly important due part recent availability large cancer registries spatial survival models stochastically order survival curves different subpopulations however common survival curves two subpopulations cross epidemiological cancer studies thus interpretable standard survival models used without modification common fixes inclusion time varying regression effects proportional hazards model fully nonparametric modeling either destroys easy interpretability fitted model address issue develop generalized accelerated failure time model allows stratification continuous categorical covariates well providing per variable tests whether stratification necessary via novel approximate bayes factors model interpretable terms median survival changes able capture crossing survival curves presence spatial correlation detailed markov chain monte carlo algorithm presented posterior inference freely available function frailtygaft provided fit model r package spbayessurv apply approach subset prostate cancer data gathered louisiana surveillance epidemiology end results program national cancer institute â© springer science+business media new york
10.1093/ageing/afw249 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021771961&doi=10.1093%2fageing%2fafw249&partnerID=40&md5=699d2f311d0a5b4a689967989c9ce943 0,objective measure impact power attorney media campaign number new power attorney poa registrations scotland setting poa registrations scotland processed office public guardian january june methods multilevel poisson models poa registrations nested council annual quarter run using markov chain monte carlo methods adjusting time campaign variable ranging dependent intensity campaign measured number media platforms received offset term mid year population estimate aged years+ years+ results poa registrations saw reduction overall increased poa registrations rose glasgow city campaign began rest scotland saw rise data modelled relative risk rr poa registration increased increasing intensity campaign area receipt full campaign rr = area campaign council variation persisted adjustment campaign variance = conclusions period campaign area level increases poa registrations observed associated power attorney timing location approximate dose response relationship campaign intensity suggesting likely due campaign began glasgow city â© author published oxford university press behalf british geriatrics society rights reserved
10.1631/jzus.B1600143 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025100922&doi=10.1631%2fjzus.B1600143&partnerID=40&md5=724296554e9dd1f8bc4304656f1badb1 1,background antithrombotic therapy using new oral anticoagulants noacs patients atrial fibrillation af generally shown favorable risk benefit profile since dispute risks gastrointestinal bleeding gib intracranial hemorrhage ich sought conduct systematic review network meta analysis using bayesian inference analyze risks gib ich af patients taking noacs methods analyzed data randomized controlled trials af patients receiving anticoagulants antiplatelet drugs placebo bayesian network meta analysis two different evidence networks performed using binomial likelihood model based network different agents doses treated separate nodes odds ratios ors confidence intervals cis modeled using markov chain monte carlo methods results indirect comparisons bayesian model confirmed aspirin+clopidogrel significantly increased risk gib af patients compared placebo ci â€“ warfarin identified greatly increasing risk ich compared edoxaban mg ci â€“ dabigatran mg ci â€“ ranked noacs lowest risk gib apixaban mg ich apixaban mg dabigatran mg edoxaban mg conclusion bayesian network meta analysis treatment nonvalvular af patients anticoagulants suggested noacs increase risks gib ich compared â© zhejiang university springer verlag gmbh germany
10.1016/j.ifacol.2017.08.2585 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044333643&doi=10.1016%2fj.ifacol.2017.08.2585&partnerID=40&md5=9dc1bceb5183c561730e8fea14097a85 0,particle gibbs ancestor sampling pgas particle markov chain monte carlo method pmcmc bayesian inference learning pgas conditions reference state trajectory underlying particle filter using ancestor sampling paper leverage pgas identification cornering stiffness parameters road vehicles using production grade sensors cornering stiffness parameters essential describing motion vehicle show pgas adapted efficiently learn stiffness parameters conditioning noise input trajectory instead state trajectory verify three minute long experimental test drive method correctly identifies tire stiffness parameters â©
10.1002/mats.201700039 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021842720&doi=10.1002%2fmats.201700039&partnerID=40&md5=1e86fdf9bac36940ae0036788e351856 1,selected aspects copolymerization processes carried constant comonomer concentrations analyzed theoretically modeled monte carlo method confirmed combinations initial parameters lead stationary conditions copolymer formation irreversible reversible systems regarded first order markov chain process however study shows many copolymerization systems stationary conditions attained high number average degree polymerization dpn reversible copolymerizations attaining equilibrium stationary conditions observed analysis shows chain length distribution cld copolymerization carried steady state conditions constant comonomer concentrations equal equilibrium concentrations infinitely high dpn approximately described modified bessel exponential functions type cld analytically proved confirmed monte carlo simulations analogous homopolymerization process â© wiley vch verlag gmbh co kgaa weinheim
10.1051/0004-6361/201628986 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022204170&doi=10.1051%2f0004-6361%2f201628986&partnerID=40&md5=644533fc5742ebb497c05da1778bdb49 2,goal population spectral synthesis pss also referred inverse semi empirical evolutionary fossil record approach decipher spectrum galaxy mass age metallicity constituent stellar populations technique reverse complementary evolutionary synthesis established fundamental tool extragalactic research extensively applied large spectroscopic data sets notably sdss leading important insights galaxy assembly history however despite significant improvements past decade current pss codes suffer two major deficiencies inhibit us gaining sharp insights star formation history sfh galaxies potentially introduce substantial biases studies physical properties e g stellar mass mass weighted stellar age specific star formation rate neglect nebular emission spectral fits consequently ii lack mechanism ensures consistency best fitting sfh observed nebular emission characteristics star forming sf galaxy e g hydrogen balmer line luminosities equivalent widths ews shape continuum region around balmer paschen jump article present fado fitting analysis using differential evolution optimization conceptually novel publicly available pss tool distinctive capability permitting identification sfh reproduces observed nebular characteristics sf galaxy far unique self consistency concept allows us significantly alleviate degeneracies current spectral synthesis thereby opening new avenue exploration assembly history galaxies innovative character fado augmented mathematical foundation fado first pss code employing genetic differential evolution optimization conjunction various currently unique elements mathematical concept numerical realization e g mid analysis optimization spectral library using artificial intelligence test convergence procedure inspired markov chain monte carlo techniques quasi parallelization embedded within modular architecture results key improvements respect computational efficiency uniqueness best fitting sfhs furthermore fado incorporates within single code entire chain pre processing modeling post processing storage graphical representation relevant output pss including emission line measurements estimates uncertainties primary secondary products spectral synthesis e g mass contributions individual stellar populations mass luminosity weighted stellar ages metallicities integrated concept greatly simplifies accelerates lengthy sequence individual time consuming steps generally involved pss modeling enhancing overall efficiency code inviting automated application large spectroscopic data sets â© eso
10.1371/journal.pone.0181929 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025842159&doi=10.1371%2fjournal.pone.0181929&partnerID=40&md5=5ab179d039de6a740cee71ee451b23a8 2,contacts across strait gibraltar pleistocene studied different research papers demonstrated apparent barrier permeable human fauna movements directions study based genetic analysis wild boar sus scrofa suggests contact africa europe strait gibraltar late pleistocene least last years shown partial analysis mitochondrial dna cytochrome b control region north african wild boar indicate close relationship european wild boar even specimens belong common haplotype europe analyses suggest transformation wild boar phylogeography north africa emergence natural communication route times sea levels fell due climatic changes possibly human action since contacts coincide last glacial period increasing human dispersion via strait â© soria boix et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1115/1.4035898 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014955854&doi=10.1115%2f1.4035898&partnerID=40&md5=9acd8ff3f8e02282afa67dca3ccb7bfe 2,uncertainty quantification uq emerging field focuses characterizing quantifying potentially reducing uncertainties associated computer simulation models used wide range applications although successfully applied computer simulation models areas structural engineering climate forecasting medical sciences powerful research area still lagging behind materials simulation models broadly defined physics based predictive models developed predict material behavior e processing microstructure property relations recently received considerable interest advent emerging concepts integrated computational materials engineering icme need effective tools quantifying uncertainties associated materials simulation models identified high priority research area recent roadmapping efforts field paper present one first efforts conducting systematic uq physics based materials simulation model used predicting evolution precipitates advanced nickel titanium shape memory alloys smas subject heat treatment specifically bayesian calibration approach used conduct calibration precipitation model using synthesis experimental computer simulation data focus constructing gaussian process based surrogate modeling approach achieving task benchmark predictive accuracy calibrated model model calibrated using traditional markov chain monte carlo mcmc methods â© copyright asme
10.1016/j.ifacol.2017.08.1183 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031798806&doi=10.1016%2fj.ifacol.2017.08.1183&partnerID=40&md5=73fc9294138b915735d076f6f29744cb 0,creating driving cycle dc design validation new vehicles important step influence efficiency functionality performance final systems work dc synthesis method introduced based multi dimensional markov chain velocity road slope investigated particularly improvements dc synthesis method proposed reach realistic slope profile accurate fuel consumption co emission estimates effects using synthesized dcs fuel consumption investigated considering three different vehicle models conventional ice full hybrid mild hybrid electric vehicles results show short representative synthetic dcs results realistic fuel consumption estimates e g range much faster simulations using results proposed method also eliminates need use simplified dcs new european driving cycle nedc long measured dcs â©
10.1016/j.ress.2017.02.002 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013851421&doi=10.1016%2fj.ress.2017.02.002&partnerID=40&md5=2ae6fbca6f22230eda8e5922522f3516 4,efficient life cycle management civil infrastructure systems continuous deterioration improved studying sensitivity optimised preventive maintenance decisions respect changes model parameters sensitivity analysis maintenance optimisation problems important calculation cost preventive maintenance strategies sufficiently robust use maintenance model generate optimised maintenances strategies cost effective probabilistic sensitivity analysis methods particularly variance based ones partially respond issue use limited evaluating extent uncertainty input contributes overall output variance methods take account decision making problem straightforward manner address issue use concept expected value perfect information evpi perform decision informed sensitivity analysis identify key parameters problem quantify value learning certain aspects life cycle management civil infrastructure system approach allows us quantify benefits maintenance strategies terms expected costs light accumulated information model parameters aspects system ageing process use gamma process model represent uncertainty associated asset deterioration illustrating use evpi perform sensitivity analysis optimisation problem age based condition based preventive maintenance strategies evaluation evpi indices computationally demanding markov chain monte carlo techniques helpful overcome computational difficulty approximate evpi indices using gaussian process emulators implications worked numerical examples discussed context analytical efficiency organisational learning â©
10.1002/pst.1807 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018379336&doi=10.1002%2fpst.1807&partnerID=40&md5=b1386aed8faa3a462fcb5cd37ee64b03 6,children represent large underserved population â€œtherapeutic orphans â€� estimated children treated label however pediatric drug development often faces substantial challenges including economic logistical technical ethical barriers among others among many efforts trying remove barriers increased recent attention paid extrapolation leveraging available data adults older age groups draw conclusions pediatric population bayesian statistical paradigm natural setting permits combining â€œborrowingâ€� information across disparate sources adult pediatric data paper authored pediatric subteam drug information association bayesian scientific working group adaptive design working group develop illustrate provide suggestions bayesian statistical methods used design improved pediatric development programs use available information efficient manner variety relevant bayesian approaches described several illustrated case studies extrapolating adult efficacy data expand labeling remicade include pediatric ulcerative colitis extrapolating adult exposure response information antiepileptic drugs pediatrics copyright â© john wiley sons ltd
10.1002/pst.1815 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020070905&doi=10.1002%2fpst.1815&partnerID=40&md5=7f661d896e01fd6ec0ad8eda0050f26f 0,borrowing historical control data efficient way improve treatment effect estimate current control group randomized clinical trial historical current control data consistent borrowing historical data increase power reduce type error rate however sources data inconsistent may result combination biased estimates reduced power inflation type error rate situations inconsistency historical current control data may caused systematic variation measured baseline prognostic factors appropriately addressed statistical modeling paper propose bayesian hierarchical model incorporate patient level baseline covariates enhance appropriateness exchangeability assumption current historical control data performance proposed method shown simulation studies application clinical trial design amyotrophic lateral sclerosis described proposed method developed scenarios involving multiple imbalanced prognostic factors thus meaningful implications clinical trials evaluating new treatments heterogeneous diseases amyotrophic lateral sclerosis copyright â© john wiley sons ltd
10.1371/journal.pcbi.1005653 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026631540&doi=10.1371%2fjournal.pcbi.1005653&partnerID=40&md5=a48ae6e1d70d1da1db21dfe84f8b6b50 3,recent years huge rise number publicly available transcriptional profiling datasets massive compendia comprise billions measurements provide special opportunity predict function unstudied genes based co expression well studied pathways analyses challenging however since biological pathways modular may exhibit co expression specific contexts overcome challenges introduce clic clustering inferred co expression clic accepts input pathway consisting two genes uses bayesian partition model simultaneously partition input gene set coherent co expressed modules cems assigning posterior probability dataset support cem clic expands cem scanning transcriptome additional co expressed genes quantified integrated log likelihood ratio llr score weighted dataset byproduct clic automatically learns conditions datasets within cem operative implemented clic using compendium mouse microarray datasets microarrays human microarray datasets microarrays clic analysis reveals canonical biological pathways consist strongly co expressed gene modules new members predicted example clic predicts functional connection protein c orf fmc mitochondrial atp synthase complex experimentally validated clic freely available www gene clic org anticipate clic valuable revealing new components biological pathways well conditions active â© li et al
10.1371/journal.pone.0180331 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022338184&doi=10.1371%2fjournal.pone.0180331&partnerID=40&md5=a3b97b9e0f67176530394f18693fcde7 1,sulfolobus solfataricus thermoacidophilic archaeon thrives terrestrial hot springs solfatares optimal growth c ph â€“ catabolizes specific carbon sources glucose pyruvate via modified entner doudoroff ed pathway pathway two parallel branches semi phosphorylative non phosphorylative however strategy solfataricus endure extreme environment terms robustness adaptation yet completely understood present first dynamic mathematical model ed pathway parameterized quantitative experimental data data consist enzyme activities branched pathway c c metabolomics data temperatures wild type metabolic engineered knockout semi phosphorylative branch use validated model address two questions system robust perturbations optimal growth temperature ed robust deletion perturbations employed systems biology approach answer questions gain knowledge emergent properties biological system specifically applied deterministic stochastic approaches study sensitivity robustness system respectively mathematical model present shows steady state metabolite concentrations ed pathway consistently robust stochastic internal perturbations c c metabolite concentrations highly robust faced knockout either branch connected observation two branches show different properties level metabolite production flux control new results reveal enzyme kinetics metabolomics synergizes mathematical modelling unveil new systemic properties ed pathway solfataricus terms adaptation robustness â© figueiredo et al open access article distributed terms creative commons attribution license permits unrestricted use distribution reproduction medium provided original author source credited
10.1016/j.apm.2017.03.020 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020286365&doi=10.1016%2fj.apm.2017.03.020&partnerID=40&md5=c03381074fa00a455858555cebf469ca 3,model r=p x x usually represent strength system stress applied r measure system reliability paper bayes estimation r=p x studied assumption x independent weibull random variables arbitrary scale shape parameters show first time compute bayes estimates credible intervals r case first closed form expression r derived prior distributions assumed weibull parameters posterior distribution presented next proposing universal sample based method according monte carlo markov chain mcmc method draw samples compute bayes estimates credible intervals r monte carlo simulations two real data examples proposed method demonstrated robust satisfactory â© elsevier inc
10.1016/j.ifacol.2017.08.2278 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031825175&doi=10.1016%2fj.ifacol.2017.08.2278&partnerID=40&md5=3ce6b102db1d7ecad6eb4c560fa8d5f3 0,dynamical system paint masterpieces da vinci mona lisa monet water lilies moreover dynamical system chaotic sense although trajectories sensitive initial conditions painting created every time setting aside creative aspect painting picture work develop novel algorithm reproduce paintings photographs combining ideas ergodic theory control theory construct chaotic dynamical system predetermined statistical properties one makes spatial distribution colors picture target distribution akin human algorithm first captures large scale features goes refine small scale features beyond reproducing paintings approach expected wide variety applications uncertainty quantification sampling efficient inference scalable machine learning big data developing effective strategies search rescue particular preliminary studies demonstrate algorithm provides significant acceleration higher accuracy competing methods monte carlo quasi monte carlo markov chain monte carlo mcmc â©
10.1093/sysbio/syw101 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021806470&doi=10.1093%2fsysbio%2fsyw101&partnerID=40&md5=0c1415f53d4a6227a6241db2205becbe 18,application genomic data phylogenetics become routine number cases arisen alternative data sets strongly support conflicting conclusions sensitivity analytical decisions prevented firm resolution recalcitrant nodes tree life better understand causes nature sensitivity analyzed several phylogenomic data sets using alternativemeasure topological support bayes factor demonstrates averts several limitations frequently employed support measures asmarkov chain monte carlo estimates posterior probabilities bayes factors reveal important previously hidden differences across six phylogenomic data sets collected resolve phylogenetic placement turtles within amniota data sets vary substantially support forwell established amniote relationships particularly proportion genes contain extreme amounts information aswell proportion strongly reject uncontroversial relationships six data sets contain little information resolve phylogenetic placement turtles relative amniotes bayes factors also reveal small number extremely influential genes less genes data set fundamentally change significant phylogenetic conclusions one example genes shown contain previously unrecognized paralogs study demonstrates resolution difficult phylogenomic problems remains sensitive seemingly minor analysis details bayes factors valuable tool identifying solving challenges â© author published oxford university press behalf society systematic biologists rights reserved
10.1175/JHM-D-17-0030.1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023161212&doi=10.1175%2fJHM-D-17-0030.1&partnerID=40&md5=bfb952584bde7fdd5d283b688cfefd00 0,land surface models notorious containing many parameters control exchange heat moisture land atmosphere properly modeling partitioning total evapotranspiration et transpiration evaporation critical accurate hydrological modeling depends heavily treatment turbulence within canopies previous work constrained estimates evapotranspiration partitioning using statistical approaches calibrate land surface model parameters assimilating situ measurements studies however silent impacts accounting uncertainty within statistical calibration framework present study calibrates aerodynamic leaf boundary layer stomatal resistance parameters partially control canopy turbulent exchange thus evapotranspiration flux partitioning using adaptive metropolis hastings algorithm construct markov chain draws joint posterior distribution resistance parameters ensemble model realizations generated latent sensible heat fluxes top soil layer temperature optimized set five calibration experiments demonstrate model performance sensitive accounting various sources uncertainty field observations model output critical account model structural uncertainty calibration modeled fluxes top soil layer temperature largely free bias calibration approach successfully informs characterizes uncertainty parameters essential model improvement development key points paper markov chain monte carlo calibration approach successfully improves modeled turbulent fluxes et partitioning estimates hinge representation uncertainties model data despite inherent uncertainties constrained posterior estimates et partitioning emerge â© american meteorological society
10.1016/j.econlet.2017.04.011 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018365794&doi=10.1016%2fj.econlet.2017.04.011&partnerID=40&md5=11445899840db335f392d05ee81fa358 0,consider bayesian inference mean binary variable subject misclassification error error probabilities known estimated parameter partially identified several reasonable intuitive prior distributions misclassification probabilities derive new analytical expressions posterior distribution results circumvent need markov chain monte carlo simulation priors use lead regions identified set posteriori likely others â© elsevier b v
10.1016/j.ifacol.2017.08.632 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031814034&doi=10.1016%2fj.ifacol.2017.08.632&partnerID=40&md5=d19a4617d0bc95da933b0aa6f5f46ba6 0,strong interest emergency planning response attack accidental release harmful chemical biological radiological nuclear substances circumstances paramount importance determine location release rate hazardous source forecast future harm may cause employ methods minimize disturbance paper sensor data collection strategy proposed whereby autonomous mobile sensor guided address problem high degree accuracy short amount time first parameters release source estimated using markov chain monte carlo sampling approach informative manoeuvre set possible choices selected using concept maximum entropy sampling numerical simulations demonstrate superior performance proposed algorithm compared traditional approaches terms estimation accuracy number measurements required â©
10.1016/j.ifacol.2017.08.1555 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031810110&doi=10.1016%2fj.ifacol.2017.08.1555&partnerID=40&md5=5c04066dd5d86710fb99a7a62dbde8b1 1,propose method nonparametric identification hammerstein models gaussian process models impulse response linear block input nonlinearity interpreting gaussian processes prior distributions estimate unknowns using posterior means given data estimate hyperparameters set iterative scheme reminiscent expectation maximization method posterior expectation complete likelihood iteratively maximized hammerstein case posterior density intractable general admit closed form expression work propose two approximation approaches estimate posterior mean first make particle approximation posterior using markov chain monte carlo second use variational bayes approach mean field hypothesis validate proposed methods synthetic datasets hammerstein systems â©
10.3847/1538-3881/aa71ef https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024408952&doi=10.3847%2f1538-3881%2faa71ef&partnerID=40&md5=bc505427fc32987081d1c32eb13ac4eb 22,conduct uniform analysis transit timing variations ttvs planets kepler multiplanet systems infer planet masses eccentricities eighty planets previously reported mass eccentricity measurements employ two complementary methods fit ttvs markov chain monte carlo simulations based n body integration analytic fitting approach mass measurements planets including without previously reported masses meet criterion classification robust using mass radius measurements infer masses planets gaseous envelopes ttv sample transiting planets radial velocity observations insight analytic ttv formulae allows us partially circumvent degeneracies inherent inferring eccentricities ttv observations find planet eccentricities generally small typically percent many instances nonzero â© american astronomical society rights reserved
10.1093/sysbio/syx037 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017541124&doi=10.1093%2fsysbio%2fsyx037&partnerID=40&md5=0885faf3b78d0b8b3ae29c376609da72 56,bayesian analysis macroevolutionary mixtures bamm statistical framework uses reversible jump markov chain monte carlo infer complex macroevolutionary dynamics diversification phenotypic evolution phylogenetic trees recent article moore et al mea reported number theoretical practical concerns bamm major claims mea bamm likelihood function incorrect account unobserved rate shifts ii posterior distribution number rate shifts overly sensitive prior iii diversification rate estimates bamm unreliable show conclusions mea generally incorrect unjustified first demonstrate mea numerical assessment bamm likelihood compromised use invalid likelihood function show unobserved rate shifts appear irrelevant biologically plausible parameterizations diversification process find purportedly extreme prior sensitivity reported bymea replicated standard usage bammv version conventional bayesian model selection performed finally demonstrate bamm performs well estimating diversification rate variation across âˆ¼ simulated trees inmea data set theoretically possible infer rate shifts confidence due ascertainment bias remaining purportedly variable rate phylogenies statistically indistinguishable produced constant rate birth death process thus poorly suited summary statistics used performance assessment demonstrate inferences diversification rates accurate consistent across major previous releases bamm software recognize acute need address theoretical foundations rate shift models phylogenetic trees expect bamm modeling frameworks improve response mathematical computational innovations however remain optimistic imperfect tools currently available comparative biologists provided continue provide important insights diversification life earth â© author published oxford university press behalf society systematic biologists rights reserved
10.1007/s11222-016-9674-x https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975260806&doi=10.1007%2fs11222-016-9674-x&partnerID=40&md5=fcbd2d30d0b3cdce812b4021b2b2b96e 0,complex biological processes usually experimented along time among collection individuals longitudinal data available statistical challenge better understand underlying biological mechanisms standard statistical approach mixed effects model regression function highly developed describe precisely biological processes solutions multi dimensional ordinary differential equations partial differential equation classical estimation method relies coupling stochastic version em algorithm monte carlo markov chain algorithm algorithm requires many evaluations regression function clearly prohibitive solution numerically approximated time consuming solver paper meta model relying gaussian process emulator proposed approximate regression function leads called mixed meta model uncertainty meta model approximation incorporated model control distance maximum likelihood estimates mixed meta model maximum likelihood estimates exact mixed model guaranteed eventually numerical simulations performed illustrate efficiency approach â© springer science+business media new york
10.1109/IPDPSW.2017.127 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028062086&doi=10.1109%2fIPDPSW.2017.127&partnerID=40&md5=87a33a4cbc0716928879cdc2453afca5 0,coalescent genealogy samplers effective tools study population genetics used estimate historical parameters population based upon sampling present day genetic information popular approach employs markov chain monte carlo mcmc methods effective methods computationally intensive often taking weeks run although attempts made leverage parallelism effort reduce runtimes resulted scalable solutions due inherently sequential nature mcmc methods performance suffered diminishing returns applied large scale computing clusters interests reduced runtimes higher quality solutions sophisticated form parallelism required paper describes novel way apply recently discovered generalization mcmc purpose new approach exploits multiple proposal mechanism generalized method enable desired scalable parallelism maintaining accuracy original technique â© ieee
10.1109/FCCM.2017.9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027713187&doi=10.1109%2fFCCM.2017.9&partnerID=40&md5=88631ad0b65100d84dcacdaf33f2000c 0,markov chain monte carlo mcmc based methods main tool bayesian inference years recently find increasing applications modern statistics machine learning nevertheless availability large datasets increasing complexity bayesian models mcmc methods becoming prohibitively expensive real world problems heart methods lies computation likelihood functions requires access input data points iteration method current approaches based data subsampling aim accelerate algorithms reducing number data points likelihood evaluations mcmc iteration however existing work consider properties modern memory hierarchies treats memory one monolithic storage space paper proposes communication aware mcmc framework takes account underlying performance memory subsystem framework based novel subsampling algorithm utilises unbiased likelihood estimator based probability proportional size pps sampling allowing information performance memory system taken account sampling stage proposed mcmc sampler mapped fpga device performance evaluated using bayesian logistic regression model mnist dataset proposed system achieves x speed highly optimised traditional fpga design therefore risk estimates based generated samples largely decreased â© ieee
10.1002/sim.7278 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014880678&doi=10.1002%2fsim.7278&partnerID=40&md5=8a45181fef21d8c4a68bf798288fa8f8 0,important statistical task disease mapping problems identify divergent regions unusually high low risk disease leave one cross validatory loocv model assessment gold standard estimating predictive p values flag divergent regions however actual loocv time consuming one needs rerun markov chain monte carlo analysis posterior distribution observation held test case paper introduces new method called integrated importance sampling iis estimating loocv predictive p values markov chain samples drawn posterior based full data set key step iis integrate away latent variables associated test observation respect conditional distribution without reference actual observation following general theory importance sampling formula used iis proved equivalent loocv predictive p value compare iis three existing methods literature two disease mapping datasets empirical results show predictive p values estimated iis almost identical predictive p values estimated actual loocv outperform given existing three methods namely posterior predictive checking ordinary importance sampling ghosting method marshall spiegelhalter copyright â© john wiley sons ltd copyright â© john wiley sons ltd
10.1109/FCCM.2017.56 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027717985&doi=10.1109%2fFCCM.2017.56&partnerID=40&md5=01ca9b9ef22e334efb3c6ef994ea7a9c 1,markov chain monte carlo mcmc algorithms used obtain samples target probability distribution widely used stochastic processing techniques stochastic processing techniques machine learning image processing need compute large amounts data real time thus high throughput mcmc samplers utmost importance parallel tempering pt mcmc proven better mixing convergence high dimensional multi modal distributions compared popular mcmc algorithms paper employ special case dth order markov chains modify pt mcmc algorithm named multiple parallel tempering mpt modification converts one mcmc sampler multiple independent samplers generate interleave samples one output line clock cycle fully scalable pipelined hardware accelerator pt proposed mpt sampler designed implemented artix xilinx fpga chain numbers post place route fpga implementation results indicate throughput proposed mpt sampler chain numbers achieves x x x respectively higher compared pt sampler chain number configuration â© ieee
10.1002/sim.7255 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013677589&doi=10.1002%2fsim.7255&partnerID=40&md5=02ea8106df2bffc03850ddaef27545c6 0,normality assumption typically adopted random effects clustered longitudinal data analysis using linear mixed model however assumption always realistic may lead potential biases estimates especially variable selection taken account furthermore flexibility nonparametric assumptions e g dirichlet process random effects may potentially cause centering problems leading difficulty interpretation fixed effects variable selection motivated problems proposed bayesian method fixed random effects selection nonparametric random effects models modeled regression coefficients via centered latent variables distributed probit stick breaking scale mixtures using mixture priors centered latent variables along covariance decomposition avoid aforementioned problems allow efficient selection fixed random effects model demonstrated advantages proposed approach competing alternatives simulated example also via illustrative application data set periodontal disease study copyright â© john wiley sons ltd copyright â© john wiley sons ltd
272.55599009582807 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028975755&partnerID=40&md5=1a613190893683fd15626b6ddad04fda 0,important consider changing states hedging markov regime switching dynamic correlation multivariate stochastic volatility mrs dc msv model proposed solve issue dc msv model mrs dc msv model used calculate time varying hedging ratios compare hedging performance markov chain monte carlo mcmc method used estimate parameters results showed obviously two economic states chinese financial market two models well hedging performance mrs dc msv model better reduce risk nearly thus hedging period changing states factor neglected copyright â© editorial board journal donghua university shanghai china
10.3389/fmicb.2017.01139 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021775606&doi=10.3389%2ffmicb.2017.01139&partnerID=40&md5=ab4bdb0185568fdc8b56f46e34461921 0,different techniques available assessing differences virulence bacterial foodborne pathogens use animal models human volunteers expedient various reasons use epidemiological data often hampered lack crucial data paper describe static sequential gastrointestinal tract git model system foodborne pathogens exposed simulated gastric intestinal contents human digestive tract including interaction pathogens intestinal epithelium system employed foodborne bacterial pathogens five strains salmonella heidelberg one strain salmonella typhimurium used assess robustness system four heidelberg strains originated outbreak fifth heidelberg strain typhimurium strain originated routine meat inspections data plate counts collected determining numbers surviving bacteria stage used quantify experimental uncertainty biological variability pathogen survival throughout system hierarchical bayesian framework using markov chain monte carlo mcmc employed model system able distinguish serovars strains vitro infectivity accounting within strain biological variability experimental uncertainty â© wijnands teunis kuijpers delfgou van asch pielaat
10.1103/PhysRevE.95.062135 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022182648&doi=10.1103%2fPhysRevE.95.062135&partnerID=40&md5=1a777a7a5b909b42186291ebac835e12 0,use stochastic models study dynamics infectious diseases important tool understand epidemiological process several directly transmitted diseases reinfection relevant process expressed endogenous reactivation pathogen exogenous reinfection due direct contact infected individual smaller reinfection rate ïƒî² infection rate î² paper examine stochastic susceptible infected recovered infected siri model simulating endogenous reactivation spontaneous reaction exogenous reinfection catalytic reaction analyzing mean field approximations site pairs sites monte carlo mc simulations particular case exogenous reinfection obtained continuous phase transitions involving endemic epidemic transmission phases simple approach approach pairs better describe phase transition endemic phase susceptible infected susceptible sis like model epidemic phase susceptible infected removed recovered sir like model considering comparison mc results reinfection increases peaks outbreaks system reaches endemic phase particular case endogenous reactivation approach pairs leads continuous phase transition endemic phase sis like model transmission phase finally phase transition effects taken account hope results study generalized susceptible exposed infected removed recovered seirie model state exposed infected infectious describing realistically transmitted diseases tuberculosis future work also intend investigate effect network topology phase transitions siri model describes transmitted diseases ïƒ social contagions ïƒ â© american physical society
10.1109/SIU.2017.7960520 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026287266&doi=10.1109%2fSIU.2017.7960520&partnerID=40&md5=094171694d441bf3e7597fbbf8096c85 0,propose monte carlo markov chain mcmc based method image registration formulate image registration problem within bayesian framework generate samples resulting posterior density registration parameters using mcmc thus posterior density characterized samples drawn mcmc principle posterior density multimodal samples different modes posterior lead different meaningful solutions image registration problem perform experiments pairs test images may admit multiple registration solutions preliminary results demonstrate potential proposed approach â© ieee
10.1364/OE.25.015441 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021347269&doi=10.1364%2fOE.25.015441&partnerID=40&md5=fdf0951ddb7f658c27c69b5cd1d7e77b 1,investigate influence mo layer thickness euv reflectance mo si mirrors set unpolished interface polished mo si c multilayer mirrors mo layer thickness varied range nm nm use novel combination specular di use intensity measurements determine interface roughness throughout multilayer stack rely scanning probe measurements surface combination euv x ray reflectivity measurements near normal incidence euv di use scattering allows reconstruct mo layer thicknesses determine interface roughness power spectral density data analysis conducted applying matrix method specular reflection distorted wave born approximation di use scattering introduce markov chain monte carlo method field order determine respective confidence intervals reconstructed parameters unambiguously detect threshold thickness mo sample sets specular reflectance goes local minimum correlated distinct increase di use scatter attribute known appearance amorphous crystallization transition certain thickness threshold altered sample system polishing â© optical society america
10.1186/s12876-017-0639-0 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021255935&doi=10.1186%2fs12876-017-0639-0&partnerID=40&md5=7919c75d04640633697f36bc828e7be7 3,background controversies persist regarding effect prokinetics treatment functional dyspepsia fd study aimed assess comparative efficacy prokinetic agents treatment fd methods randomized controlled trials rcts prokinetics treatment fd identified core databases symptom response rates extracted analyzed using odds ratios ors bayesian network meta analysis performed using markov chain monte carlo method winbugs netmetaxl results total rcts included patients fd treated different prokinetics placebo identified analyzed metoclopramide showed best surface cumulative ranking curve sucra probability followed trimebutine mosapride however therapeutic efficacy metoclopramide significantly different trimebutine credible interval mosapride credible interval domperidone credible interval metoclopramide showed better efficacy itopride credible interval acotiamide credible interval domperidone sucra probability showed better efficacy itopride credible interval acotiamide credible interval conclusions metoclopramide trimebutine mosapride domperidone showed better efficacy treatment fd itopride acotiamide considering adverse events related metoclopramide domperidone short term use agents alternative use trimebutine mosapride recommended symptomatic relief fd â© author
10.1186/s12918-017-0433-1 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021207880&doi=10.1186%2fs12918-017-0433-1&partnerID=40&md5=d366595b20a37db902e18cfcf7f2b71e 6,background quantitative biology mathematical models used describe analyze biological processes parameters models usually unknown need estimated experimental data using statistical methods particular markov chain monte carlo mcmc methods become increasingly popular allow rigorous analysis parameter prediction uncertainties without need assuming parameter identifiability removing non identifiable parameters broad spectrum mcmc algorithms proposed including single multi chain approaches however selecting tuning sampling algorithms suited given problem remains challenging comprehensive comparison different methods far available results present results thorough benchmarking state art single multi chain sampling methods including adaptive metropolis delayed rejection adaptive metropolis metropolis adjusted langevin algorithm parallel tempering parallel hierarchical sampling different initialization adaptation schemes considered ensure comprehensive fair comparison consider problems range features bifurcations periodical orbits multistability steady state solutions chaotic regimes problem properties give rise various posterior distributions including uni multi modal distributions non normally distributed mode tails objective comparison developed pipeline semi automatic comparison sampling results conclusion comparison mcmc algorithms initialization adaptation schemes revealed overall multi chain algorithms perform better single chain algorithms cases performance increased using preceding multi start local optimization scheme results inform selection sampling methods benchmark collection serve evaluation new algorithms furthermore results confirm need address exploration quality mcmc chains applying commonly used quality measure effective sample size prevent false analysis conclusions â© author
10.1109/TCSVT.2017.2718225 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021811747&doi=10.1109%2fTCSVT.2017.2718225&partnerID=40&md5=fb1c825688c03e002d0566eb2d67d1af 0,correspondence problems challenging due complexity real world scenes one way solve problem improve graph matching gm process flexible matching non rigid objects gm classified three categories correspond variety object functions first order second order high order matching graph hypergraph matching proposed separately previous works former equivalent second order gm latter equivalent high order gm use terms second high order gm unify terminology paper second high order gm fit well different types problems key goal processes find better optimized algorithms optimal problems second high order gm different propose two novel optimized algorithms paper second order gm first introduce k nearest neighbor pooling matching knnpm method integrates feature pooling gm reduces complexity meanwhile evaluate matching candidate using discriminative weights k nearest neighbors knn taking locality well sparsity consideration high order gm introduces numerous outliers precision rarely considered related methods therefore propose sub pattern structure construct robust high order gm method better integrates geometric information narrow search space solve optimization problem new prior strategy cell algorithm based markov chain monte carlo mcmc framework proposed respectively addition experiments demonstrate robustness improvements algorithms respect matching accuracy compared state art algorithms ieee
10.1080/03610926.2015.1116581 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014796745&doi=10.1080%2f03610926.2015.1116581&partnerID=40&md5=08f6b6316ad58ab94eafe6bdd343e4f8 1,paper consider shared gamma frailty model reversed hazard rate rhr two different baseline distributions namely generalized inverse rayleigh exponentiated gumbel distributions two baseline distributions propose two different shared frailty models develop bayesian estimation procedure using markov chain monte carlo technique estimate parameters involved models present simulation study compare true values parameters estimated values search literature suggests currently work done two baseline distributions shared gamma frailty rhr far also apply two models using real life bivariate survival data set australian twin data given duffy etâ better model suggested data â© taylor francis group llc
10.1109/ICASSP.2017.7952555 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023757502&doi=10.1109%2fICASSP.2017.7952555&partnerID=40&md5=e0da1eb3df7851fb56b112e4f432a477 3,stochastic gradient markov chain monte carlo sg mcmc methods become popular modern data analysis problems due computational efficiency even though proved useful many statistical models application sg mcmc non negative matrix factorization nmf models yet extensively explored study develop two parallel sg mcmc algorithms broad range nmf models exploit conditional independence structure nmf models utilize stratified sub sampling approach enabling parallelization illustrate proposed algorithms image restoration task report encouraging results â© ieee
10.1002/2017GL073159 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020099128&doi=10.1002%2f2017GL073159&partnerID=40&md5=29a396104ad6e15a842f3d0aff73d071 16,juno microwave radiometer measured thermal emission jupiter atmosphere cloud tops â bar deep hundred bars pressure first flyby jupiter pj nadir brightness temperatures show equatorial zone likely ideal adiabat allows determination deep ammonia abundance range + ppm combination markov chain monte carlo method tikhonov regularization studied invert jupiter global ammonia distribution assuming prescribed temperature profile result shows ammonia depleted globally â€“ â bars except within degrees equator north equatorial belt depleted ammonia elsewhere ammonia concentration shows slight inversion starting â bars â bars results robust regardless choice water abundance â© american geophysical union rights reserved
10.1007/978-3-319-12385-1_7 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034737632&doi=10.1007%2f978-3-319-12385-1_7&partnerID=40&md5=322729bb51f77890b097e43ff0251fcf 6,lecture notes highlight mathematical computational structure relating formulation development algorithms bayesian approach inverse problems differential equations approach fundamental quantification uncertainty within applications involving blending mathematical models data finite dimensional situation described first along motivational examples development probability measures separable banach space undertaken using random series infinite set functions construct draws probability measures used priors bayesian approach inverse problems regularity draws priors studied natural sobolev besov spaces implied choice functions random series construction kolmogorov continuity theorem used extend regularity considerations space hã¶lder continuous functions bayes theorem derived prior setting interpreted finding conditions posterior absolutely continuous respect prior determining formula radon nikodym derivative terms likelihood data established form posterior describe various properties common infinite dimensional setting properties include well posedness approximation theory existence maximum posteriori estimators describe measure preserving dynamics infinite dimensional space including markov chain monte carlo sequential monte carlo methods measure preserving reversible stochastic differential equations formulating theory algorithms underlying infinite dimensional space obtain framework suitable rigorous analysis accuracy reconstructions computational complexity well naturally constructing algorithms perform well mesh refinement since inherently well defined infinite dimensions
10.1109/ICASSP.2017.7952876 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023758943&doi=10.1109%2fICASSP.2017.7952876&partnerID=40&md5=cb8283102db21a81f5fcaed9b6ad9d48 1,particle filters among effective filtering algorithms nonlinear non gaussian models state dimension high known suffer weight degeneracy sequential markov chain monte carlo smcmc methods proposed alternative sequential inference technique perform better high dimensional state spaces paper propose construct composite metropolis hastings mh kernel within smcmc framework using invertible particle flow simulation results show proposed kernel significantly increases acceptance rate improves estimation accuracy compared state art filtering algorithms high dimensional simulation examples â© ieee
10.1007/978-3-319-12385-1_69 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034732177&doi=10.1007%2f978-3-319-12385-1_69&partnerID=40&md5=ba2b31e748bfabfd1a8afa3c155aa06d 0,cubic splines commonly used numerical analysis also become popular analysis computer experiments thanks adoption software jmp chapter bayesian version cubic spline method proposed random function represents prior uncertainty taken specific stationary gaussian process output computer experiment markov chain monte carlo mcmc procedure developed updating prior given observed values simulation examples real data application given show proposed bayesian method performs better frequentist cubic spline method standard method based gaussian correlation function
10.1007/978-3-319-12385-1_67 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034750088&doi=10.1007%2f978-3-319-12385-1_67&partnerID=40&md5=d55ad5b4f1670413006d0d5a352b12dc 0,salient task uncertainty quantification uq study dependence quantity interest qoi input variables representing system uncertainties relying linear expansions qoi orthogonal polynomial bases inputs polynomial chaos expansions pces among widely used methods uq exists smoothness solution approximated pce exhibits sparsity small fraction expansion coefficients significant exploiting sparsity compressive sampling also known compressed sensing provides natural framework accurate pce using relatively evaluations qoi manner require intrusion legacy solvers pce possesses rich structure qoi approximated polynomials input variables used perform approximation qoi evaluated chapter insights provided structure summarizing portion current literature pce via compressive sampling within context uq
10.1007/978-3-319-12385-1_56 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021140868&doi=10.1007%2f978-3-319-12385-1_56&partnerID=40&md5=91ccaccf4436c140a0f77af82b989ebc 2,uq toolkit uqtk collection tools uncertainty quantification ranging intrusive nonintrusive forward propagation uncertainty inverse problems sensitivity analysis chapter first outlines uqtk design philosophy followed overview available methods way implemented uqtk second part chapter detailed example illustrates uq workflow surrogate construction calibration forward propagation attribution
10.1007/978-3-319-12385-1_49 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034776680&doi=10.1007%2f978-3-319-12385-1_49&partnerID=40&md5=9e7f28c0cc9bac28210584a29df07131 0,chapter describes use predictive capability maturity model pcmm oberkampf et al predictive capability maturity model computational modeling simulation technical report sand sandia national laboratories applied nuclear reactor simulation application pcmm discussed relative review nuclear regulatory commission regulatory environment one takes role lawyer presenting evidence judge prosecuting attorney allowed cross examine type hostile environment structured process logically presents evidence helpful addition many simulations multi scale multi physics multicode level complexity easy get lost details pcmm method adapted multi physics multi code software since key provide regulator confidence software capable predicting quantity interest qoi well quantified uncertainty pcmm approach natural solution
10.1007/978-3-319-12385-1_53 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034763370&doi=10.1007%2f978-3-319-12385-1_53&partnerID=40&md5=c5d5cdd60ba60613921a38a607bc73db 0,chapter gives overview capabilities psuade acronym problem solving environment uncertainty analysis design exploration software package developed support many operations involved typical nonintrusive e simulation codes treated black boxes uncertainty quantification uq study sample generation ensemble simulations analysis simulation results specifically software enables users perform detailed uq analysis uncertainty analysis computing statistical moments probability distributions sensitivity analysis e g variance decomposition parameter screening selection response surface analysis statistical inferences optimization uncertainty addition rich suite uq capabilities accessible via either batch command line processing psuade also provides many tools data manipulation visualization may useful immersive data analysis psuade public domain software released lgpl license since
10.1007/978-3-319-12385-1_58 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031915105&doi=10.1007%2f978-3-319-12385-1_58&partnerID=40&md5=f7140778bb4f81ea590adebcde4df8dd 2,gaussian process models simulation analysis gpmsa package set functions written matlab programming language aimed emulating computer model system studied calibrating computer model observations system giving predictions expected system response collectively capabilities comprise uncertainty quantification uq model supported inference chapter first discuss background motivation gpmsa code demonstrate code function interfaces context series illustrative example problems
10.1007/978-3-319-12385-1_57 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034760420&doi=10.1007%2f978-3-319-12385-1_57&partnerID=40&md5=10d06a3e5a6f8160f5833c02d1b9633b 1,parallel c++ statistical library quantification uncertainty estimation simulation optimization queso collection statistical algorithms programming constructs supporting research quantification uncertainty models predictions queso primarily focused solving statistical inverse problems using bayes theorem expresses distribution possible values set uncertain parameters posterior distribution terms existing knowledge system prior noisy observations physical process represented likelihood distribution posterior distribution often known analytically requires computational methods typical compute probabilities moments posterior distribution often high dimensional object standard riemann type methods quadrature become prohibitively expensive approach queso takes regard rely markov chain monte carlo mcmc methods well suited evaluating quantities probabilities moments high dimensional probability distributions queso intended use tool assist facilitate coupling uncertainty quantification specific application called forward problem many libraries presently exist solve bayesian inference problems queso specialized piece software primarily designed solve problems utilizing parallel environments demanded large scale forward problems queso written c++ uses mpi utilizes libraries already available scientific community thus target audience library researchers solid background bayesian methods comfortable unix concepts command line knowledge programming language preferably c c++
10.3390/ijerph14060648 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021125811&doi=10.3390%2fijerph14060648&partnerID=40&md5=3afd3b47f88d63c7de43ce989d69a479 0,cardiovascular disease cvd associated behavioural metabolic risk factors constitute major public health concern global level many reports worldwide documented different risk profiles populations demographic variations objective study examine geographic variations top leading cardio metabolic behavioural risk factors luxembourg order provide overall picture cvd burden across country analysis conducted based data nationwide oriscav lux survey including subjects aged years self reported questionnaire physical examination blood sampling performed age sex adjusted risk profile maps generated using multivariate bayesian geo additive regression models based markov chain monte carlo techniques used evaluate significance spatial effects distribution range cardio metabolic risk factors namely smoking high body mass index bmi high blood pressure high fasting plasma glucose alcohol use high total cholesterol low glomerular filtration rate physical inactivity higher prevalence smoking observed northern regions higher overweight obesity abdominal obesity clustered central belt whereas hypertension spotted particularly southern part country maps revealed subjects residing luxembourg canton significantly less likely hypertensive overweight obese whereas less likely practice physical activity â‰¥ metabolic equivalent task met min week patterns also observed municipality level luxembourg statistically non significant spatial patterns regarding smoking diabetes total serum cholesterol low glomerular filtration rate risk distribution comprehensive risk profile mapping showed remarkable geographic variations cardio metabolic behavioural risk factors considering prominent burden cvd research provides opportunities tailored interventions may help better fight escalating public health problem â© authors licensee mdpi basel switzerland
10.1109/ICASSP.2017.7953064 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023767613&doi=10.1109%2fICASSP.2017.7953064&partnerID=40&md5=8f25ce6e88549f89278ea8491fd18525 0,object paper introduce new estimation algorithm specifically designed latent high order autoregressive models implements concept filter based maximum likelihood approach fully deterministic less computationally demanding traditional monte carlo markov chain techniques simulation experiments real world data processing confirm interest approach â© ieee
10.1016/j.cma.2017.01.042 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017390579&doi=10.1016%2fj.cma.2017.01.042&partnerID=40&md5=315e4e019792025512daa54401cc13fd 1,bayesian model selection augmented automatic relevance determination ard perform model reduction complex dynamical systems modelled nonlinear stochastic ordinary differential equations ode given noisy measurement data parametrically flexible model envisioned represent dynamical system bayesian model selection problem posed find best model nested envisioned model model selection problem transferred model space hyper parameter space regularizing parameter posterior space parametrized prior distribution called ard prior resulting joint prior pdf combination parametrized ard priors assigned parameters whose relevance system dynamics questionable known prior pdf parameters whose relevance known priori hyper parameter ard prior explicitly represents relevance corresponding model parameter hyper parameters estimated using measurement data performing evidence maximization type ii maximum likelihood superfluous model parameters switched evidence maximization corresponding ard prior forcing model parameter irrelevant prediction purposes efficient numerical implementation evidence computation using markov chain monte carlo sampling parameter posterior distribution presented case analytical evaluation evidence possible ard approach validated synthetic measurements generated nonlinear unsteady aeroelastic oscillator consisting naca airfoil undergoing limit cycle oscillation set intentionally flexible stochastic odes different state space formulation proposed model synthetic data ard used obtain optimal nested model corresponding proposed model optimal nested model maximum posterior model probability chosen overall optimal model ard provides flexible bayesian platform find optimal nested model eliminating need propose candidate nested models prior pdfs â© elsevier b v
10.1109/TSP.2017.2684747 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019161661&doi=10.1109%2fTSP.2017.2684747&partnerID=40&md5=91857fa7aac9a909843c4334b1c15afa 0,time varying mixture models useful representing complex dynamic distributions components mixture model appear disappear persisting components evolve allows great flexibility streaming data applications model adjusted new data arrives fitting mixture model computational guarantees meet real time requirements challenging existing algorithms especially model order vary time existing approximate inference methods may require multiple restarts search good local solution monte carlo methods used jointly estimate model order model parameters distribution mixand high dimensional parameter space suffer curse dimensionality slow convergence paper proposes generative model time varying mixture models tailored mixtures discrete time markov chains novel deterministic inference procedure introduced shown suitable applications requiring real time estimation method guaranteed converge time step motivating application model predict traffic patterns transportation network experiments illustrate performance scheme offer insights regarding tuning algorithm parameters experiments also investigate predictive power proposed model compared less complex models demonstrate superiority mixture model approach prediction traffic routes real data â© ieee
10.1093/bioinformatics/btx088 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021317839&doi=10.1093%2fbioinformatics%2fbtx088&partnerID=40&md5=2a792e16d6c033df94586e097289c158 4,motivation advances sequencing technology continue deliver increasingly large molecular sequence datasets often heavily partitioned order accurately model underlying evolutionary processes phylogenetic analyses partitioning strategies involve estimating conditionally independent models molecular evolution different genes different positions within genes requiring large number evolutionary parameters estimated leading increased computational burden analyses past two decades also seen rise multi core processors central processing unit cpu graphics processing unit processor markets enabling massively parallel computations yet fully exploited many software packages multipartite analyses results propose markov chain monte carlo mcmc approach using adaptive multivariate transition kernel estimate parallel large number parameters split across partitioned data exploiting multi core processing across several real world examples demonstrate approach enables estimation multipartite parameters efficiently standard approaches typically use mixture univariate transition kernels one case estimating relative rate parameter non coding partition heterochronous dataset mcmc integration efficiency improves fold availability implementation implementation part beast code base widely used open source software package perform bayesian phylogenetic inference â© author published oxford university press rights reserved
10.1103/PhysRevD.95.123507 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022341145&doi=10.1103%2fPhysRevD.95.123507&partnerID=40&md5=1dfd737228bc6701f70296737c84f0fe 3,future galaxy surveys promise probe local primordial non gaussianity unprecedented precision ïƒ fnl study implications multifield inflation considering spectator models inflation driven inflaton field primordial perturbations partially generated second spectator field perform markov chain monte carlo likelihood analysis using planck data study quantitative predictions fnl observables range spectator models show models primordial perturbations dominated spectator field fine tuned within broader parameter space typically predict fnl order unity therefore upcoming galaxy clustering measurements constitute stringent test whether generation primordial perturbations accelerated expansion inflationary universe due separate phenomena â© american physical society
10.1103/PhysRevD.95.123540 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022339047&doi=10.1103%2fPhysRevD.95.123540&partnerID=40&md5=722f35c2e30c1f7272892e68b42750cd 15,model late time cosmic acceleration within framework generalized proca theories exists de sitter attractor preceded dark energy equation state wde= positive constant run markov chain monte carlo code confront model observational data cosmic microwave background cmb baryon acoustic oscillations supernovae type ia local measurements hubble expansion rate background cosmological solutions obtain bound s= + confidence level c l existence additional parameter î› cold dark matter î›cdm model allows reduce tensions hubble constant h cmb low redshift measurements including cosmic growth data redshift space distortions galaxy power spectrum taking account ghost stability conditions cosmological perturbations find bound shifted s= + c l hence model still favored î›cdm model apart quantities h today matter density parameter î©m constraints model parameters associated perturbations less stringent reflecting fact different sets parameters give rise similar cosmic expansion growth history â© american physical society
10.1103/PhysRevD.95.123512 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022346673&doi=10.1103%2fPhysRevD.95.123512&partnerID=40&md5=8f667b44263965d0f11b0e777f8046e5 17,next generation weak lensing surveys e lsst euclid wfirst require exquisite control systematic effects paper address shear calibration present realistic forecast date lsst euclid wfirst cmb lensing stage cmb experiment cmb use cosmolike code simulate joint analysis two point functions galaxy density galaxy shear cmb lensing convergence include full gaussian non gaussian covariances explore resulting joint likelihood monte carlo markov chains constrain shear calibration biases simultaneously varying cosmological parameters galaxy biases photometric redshift uncertainties find cmb lensing cmb enables calibration shear biases ten tomographic bins lsst âˆ¼ requirements tomographic bins ten bins euclid ten bins wfirst given lensing survey method works best high redshift shear calibration otherwise challenging self calibration robust gaussian photometric redshift uncertainties reasonable level intrinsic alignment also robust changes beam effectiveness component separation cmb experiment slowly dependent depth making possible third generation cmb experiments advact spt g well simons observatory â© american physical society
10.1145/3062341.3062375 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025116056&doi=10.1145%2f3062341.3062375&partnerID=40&md5=5bc3fcbc24964be5e295698b34504fa4 2,problem probabilistic modeling inference high level viewed constructing model query inference tuple inference algorithm implements query model notably derivation inference algorithms difficult error prone task hence researchers explored ideas probabilistic pro gramming applied context constructing tuples probabilistic programming seen taking language based approach probabilistic modeling inference instance using appropriate languages expressing models queries devising inference techniques operate encodings models queries program expressions task inference automated paper describe compiler transforms probabilistic model written restricted modeling language query posterior samples given observed data markov chain monte carlo mcmc inference algorithm implements query compiler uses sequence intermediate languages ils guide gradually successively refining declarative specification probabilistic model query executable mcmc inference algorithm compilation strategy produces composable mcmc algorithms execution cpu gpu copyright held owner author
10.1088/1755-1315/69/1/012155 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021843162&doi=10.1088%2f1755-1315%2f69%2f1%2f012155&partnerID=40&md5=d76787ad99b17e335e239bfa2f9952dd 0,aiming problem parameter estimation multiple unresolved targets within radar beam using joint bin processing model method jointly estimating number position targets proposed based reversible jump markov chain monte carlo rj mcmc reasonable assumptions prior distributions bayesian theory adopted obtain posterior probability density function estimated parameters conditional likelihood function observation acceptance ratios birth death update moves given update move hybrid metropolis hastings mh sampling algorithm used make better exploration parameter space simulation results show new method outperforms method ml mld proposed x zhang similar estimation accuracy achieved fewer sub pulses needed â© published licence iop publishing ltd
10.1088/1742-6596/855/1/012061 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023626066&doi=10.1088%2f1742-6596%2f855%2f1%2f012061&partnerID=40&md5=2a225de7176012c5d6acc344e20d39d4 0,hierarchical data structures common throughout many areas research beforehand existence type data less noticed analysis appropriate statistical analysis handle type data hierarchical linear model hlm article focus random intercept model rim subclass hlm model assumes intercept models lowest level varied among models slopes fixed differences intercepts suspected affected variables upper level intercepts therefore regressed upper level variables predictors purpose paper demonstrate proven work proposed two level rim modeling per capita household expenditure maluku utara five characteristics first level three characteristics districts cities second level per capita household expenditure data first level captured three parameters gamma distribution model therefore complex due interaction many parameters representing hierarchical structure distribution pattern data simplify estimation processes parameters computational bayesian method couple markov chain monte carlo mcmc algorithm gibbs sampling employed â© published licence iop publishing ltd
10.1088/1742-6596/855/1/012026 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023601360&doi=10.1088%2f1742-6596%2f855%2f1%2f012026&partnerID=40&md5=e0c47d094a6a8425eea1f1dcf8e1516e 0,stocks known financial instruments traded capital market high level risk risks indicated uncertainty return accepted investors future higher risk faced higher return gained therefore measurements need made risk value risk var popular risk measurement method frequently ignore pattern return uni modal normal calculation risks using var method normal mixture autoregressive mnar approach considered paper proposes var method couple mixture laplace autoregressive mlar implemented analysing first three biggest capitalization islamic stock return jii namely pt astra international tbk asii pt telekomunikasi indonesia tbk tlmk pt unilever indonesia tbk unvr parameter estimation performed employing bayesian markov chain monte carlo mcmc approaches â© published licence iop publishing ltd
10.1088/1742-6596/855/1/012054 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023603623&doi=10.1088%2f1742-6596%2f855%2f1%2f012054&partnerID=40&md5=1ef8e45c4027a0d84723fc505371d5b3 1,regression analysis statistical analmodelling among statistical methods frequently needed analyzing quantitative data especially model relationship response explanatory variables nowadays statistical models developed various directions model various type complex relationship data rich varieties advanced recent statistical modelling mostly available open source software one r however advanced statistical modelling friendly novice r users since based programming script command line interface research aims developed web interface based r shiny recent advanced statistical modelling readily available accessible applicable web previously made interface form e tutorial several modern advanced statistical modelling r especially independent responses including linear models lm generalized linier models glm generalized additive model gam generalized additive model location scale shape gamlss research unified form data analysis including model using computer intensive statistics bootstrap markov chain monte carlo mcmc readily accessible online virtual statistics laboratory web interface make statistical modeling becomes easier apply easier compare order find appropriate model data â© published licence iop publishing ltd
10.1080/02664763.2016.1214245 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979647976&doi=10.1080%2f02664763.2016.1214245&partnerID=40&md5=36217d538ac1c25ec54bab031ebb77f0 1,paper point interval estimations parameters exponentiated exponential ee distribution studied based progressive first failure censored data bayes estimates computed based squared error linex loss functions using markov chain monte carlo mcmc algorithm also based censoring scheme approximate confidence intervals parameters ee distribution developed monte carlo simulation study carried compare performances different methods computing estimated risks ers well akaike information criteria aic bayesian information criteria bic estimates finally real data set introduced analyzed using ee weibull distributions comparison carried mentioned models based corresponding kolmogorovâ€“smirnov kâ€“s test statistic emphasize ee model fits data efficiency model point interval estimation parameters studied based real data set illustrative example â© informa uk limited trading taylor francis group
10.1080/02664763.2016.1204596 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979021789&doi=10.1080%2f02664763.2016.1204596&partnerID=40&md5=721f999866c1a5e5b7559ba12215732d 0,paper conducts simulation based comparison several stochastic volatility models leverage effects two new variants asymmetric stochastic volatility models subject logarithmic transformation squared asset returns proposed leverage effect introduced model correlation either innovations observation equation latent process logarithm squared asset returns latent process suitable markov chain monte carlo algorithms developed parameter estimation model comparison simulation results show proposed formulation leverage effect accompanying inference methods give rise reasonable parameter estimates applications two data sets uncover negative correlation interpreted leverage effect observed returns volatilities negative correlation logarithm squared returns volatilities â© informa uk limited trading taylor francis group
10.1093/mnras/stx420 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017282801&doi=10.1093%2fmnras%2fstx420&partnerID=40&md5=ac2283b10ae44cd1b070a3a8ed7c8e95 7,recent low value planck collaboration xlvii integrated optical depth thomson scattering suggests reionization occurred fairly suddenly disfavouring extended reionization scenarios significant impact cm power spectrum using seminumerical framework improve model instantaneous include time integrated ionization recombination effects find leads sudden reionization also yields larger hii bubbles lead order magnitude cm power large scales suppressing small scale ionization power local fluctuations neutral hydrogen density play dominant role boosting cm power spectrum large scales recombinations subdominant use monte carlo markov chain approach constrain model observations star formation rate functions z = bouwens et al planck collaboration xlvii optical depth measurements becker bolton ionizing emissivity data z use constrained model perform cm forecasting low frequency array hydrogen epoch reionization array square kilometre array order determine well data characterize sources driving reionization find mock cm power spectrum alone somewhat constrain halo mass dependence ionizing sources photon escape fraction ionizing amplitude combining mock cm data current observations enables us separately constrain parameters framework illustrates future cm data play key role understanding sources topology reionization observations improve â© authors published oxford university press behalf royal astronomical society
10.3847/1538-4357/aa73d9 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021118683&doi=10.3847%2f1538-4357%2faa73d9&partnerID=40&md5=e25f8cf11211b4a98d1e2486799708a9 10,paper collect hydrogen deficient superluminous supernovae slsne fit light curves temperature evolution velocity evolution based magnetar powered model obtain best fitting parameters incorporate markov chain monte carlo approach get rather good fits seven events ï‡ dof = good fits another seven events ï‡ dof = find initial periods p magnetic strength b p magnetars supposedly power slsne range âˆ¼ ms g respectively inferred masses ejecta slsne values gamma ray opacity cm g also calculate fraction initial rotational energy magnetars harbored centers remnants slsne converted kinetic energy ejecta find fraction âˆ¼ different values p b p indicating acceleration effect neglected moreover find initial kinetic energies slsne small â‰² ã— erg easily explained neutrino driven mechanism results help clarify important issues related energy source mechanisms explosion mechanisms reveal nature slsne â© american astronomical society rights reserved
10.1016/j.jsv.2017.03.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014538746&doi=10.1016%2fj.jsv.2017.03.001&partnerID=40&md5=5279161e2c2ee74bff5288548a873f79 3,paper offline approach output bayesian identification stochastic nonlinear systems presented approach based parameterization joint posterior distribution parameters define postulated state space stochastic model class parameterization state predictive distribution included marginalized estimated recursively state estimation step using unscented kalman filter bypassing state augmentation required existing online methods applications expectations functions parameters interest requires evaluation potentially high dimensional integrals markov chain monte carlo adopted sample posterior distribution estimate expectations proposed approach suitable nonlinear systems subjected non stationary inputs whose realization unknown modeled stochastic processes numerical verification experimental validation examples illustrate effectiveness advantages approach including increased numerical stability respect augmented state unscented kalman filtering avoiding divergence estimates forcing input unmeasured ii ability handle arbitrary prior posterior distributions experimental validation approach conducted using data large scale structure tested shake table shown approach robust inherent modeling errors description system forcing input providing accurate prediction dynamic response excitation history unknown â© elsevier ltd
10.1088/1475-7516/2017/06/015 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021676975&doi=10.1088%2f1475-7516%2f2017%2f06%2f015&partnerID=40&md5=95c527afc4f2b60b93b9eb3f5918e379 1,katrin experiment aims determine absolute neutrino mass measuring endpoint region tritium î² spectrum large scale experiment sharp energy resolution high source luminosity low background may also capable testing certain theories neutrino interactions beyond standard model sm example non sm interaction right handed currents mediated right handed w bosons left right symmetric model lrsm extension sm additional su r symmetry high energy limit introduced naturally includes sterile neutrinos predicts seesaw mechanism tritium î² decay leads additional term interference left right handed interactions enhances suppresses certain regions near endpoint beta spectrum work sensitivity katrin right handed currents estimated scenario light sterile neutrino mass ev analysis performed bayesian analysis using markov chain monte carlo mcmc simulations show principle katrin able set sterile neutrino mass dependent limits interference strength sensitivity significantly increased q value î² decay sufficiently constrained however sensitivity high enough improve current upper limits right handed w boson searches lhc â© iop publishing ltd sissa medialab srl
10.1103/PhysRevB.95.241104 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026897832&doi=10.1103%2fPhysRevB.95.241104&partnerID=40&md5=6af4a91997fc3736ce92bcca3a0d3b02 19,develop self learning monte carlo slmc method general purpose numerical method recently introduced simulate many body systems studying interacting fermion systems method uses highly efficient update algorithm design dub cumulative update generate new candidate configurations markov chain based self learned bosonic effective model general analysis numerical study double exchange model example find slmc cumulative update drastically reduces computational cost simulation remaining statistically exact remarkably computational complexity far less conventional algorithm local updates â© american physical society
10.1088/1751-8121/aa7231 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020775264&doi=10.1088%2f1751-8121%2faa7231&partnerID=40&md5=0e7b7687703054644124a59a523ac8f3 4,implement scale free version pivot algorithm use sample pairs three dimensional self avoiding walks purpose efficiently calculating observable corresponds probability pairs self avoiding walks remain self avoiding concatenated study properties markov chain use find critical exponent î³ self avoiding walks unprecedented accuracy final estimate î³ â© iop publishing ltd
10.1371/journal.pbio.2001323 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021646961&doi=10.1371%2fjournal.pbio.2001323&partnerID=40&md5=76dde2cb1138be9368fa242fe759dd95 9,deciding alternative options rational agent chooses basis desirability outcome including associated costs different options typically result different actions effort associated action essential cost parameter humans discount physical effort deciding movements used action selection task characterize subjective effort depends parameters arm transport movements controlled potential confounding factors delay discounting performance first repeatedly asking subjects choose arm movements different amplitudes durations performed different levels force identified parameter combinations subjects experienced identical effort isoeffort curves movements long duration judged effortful short duration movements force movement amplitudes influence effort biomechanics movements also affected effort movements towards body midline preferred movements away second introducing movement repetitions determined cost function choosing effortful movements quadratic relationship force choices made basis logarithm costs results show effort based action selection reaching easily explained metabolic costs instead force loaded reaches widely occurring natural behavior imposed effort cost decision making similar cost functions motor control results thereby support idea motor control economic choice governed partly overlapping optimization principles â© morel et al
10.1016/j.bpj.2017.04.035 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020263192&doi=10.1016%2fj.bpj.2017.04.035&partnerID=40&md5=662994204b71210dfd440ee781cd9d81 1,large conductance ca + dependent k+ bkca channels important regulators electrical activity channels colocalize form ion channel complexes voltage dependent ca + cav channels recent stochastic simulations bkca cav complex stoichiometry given important insight local control bkca channels fluctuating nanodomains ca + however monte carlo simulations computationally expensive therefore suitable large scale simulations cellular electrical activity work extend stochastic model realistic bkca cav complexes n stoichiometry analyze single complex model markov chain theory description single bkca cav complex using arguments based timescale analysis derive concise model whole cell bkca currents readily analyzed inserted models cellular electrical activity illustrate usefulness results inserting bkca description previously published whole cell models perform simulations electrical activity various cell types show bkca cav stoichiometry affect whole cell behavior substantially work provides simple formulation whole cell bkca current respects local interactions bkca cav complexes indicates local global coupling ion channels may affect cell behavior â© biophysical society
10.1080/17415977.2016.1209749 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978957729&doi=10.1080%2f17415977.2016.1209749&partnerID=40&md5=f5cde5732adce414bf2e56e16b5b03f2 1,present work addresses problem structural damage identification built statistical inversion approach damage state structure continuously described cohesion parameter spatially discretized finite element method inverse problem damage identification posed determination posterior probability densities nodal cohesion parameters markov chain monte carlo method implemented metropolisâ€“hastings algorithm considered order approximate posterior probabilities drawing samples desired joint posterior probability density function approach prior information sought parameters used uncertainty concerning known values material properties quantified estimation cohesion parameters assessment proposed approach performed means numerical simulations simply supported eulerâ€“bernoulli beam damage identification assessment performed considering time domain response data different damage scenarios noise levels addressed demonstrating feasibility proposed approach â© informa uk limited trading taylor francis group
10.1080/2150704X.2017.1306139 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034607530&doi=10.1080%2f2150704X.2017.1306139&partnerID=40&md5=2f367912e45000fb1cb789e268b0bfeb 0,building rooftop extraction one challenging tasks field remote sensing image analysis existing methods usually perform poorly due complexity object background letter propose novel framework rooftop localization geometric structure recovery via combining strength top bottom methods specifically novel energy function combining region term shape term penalty term proposed eliminate effect unclosed contours disturbances park lots shadows order take advantage bottom cues new penalty term proposed position determined directional spatial relationship building shadow orientation possible rooftop estimated spatial context simulated annealing sa algorithm applied optimizing function fused markov chain monte carlo mcmc technique special transition kernels designed order achieve convergent extraction results get rid local minimum experiments ikonos images demonstrate robustness accuracy method â© informa uk limited trading taylor francis group
10.1016/j.jhydrol.2017.03.073 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018514592&doi=10.1016%2fj.jhydrol.2017.03.073&partnerID=40&md5=ffc3978b5d3e6c8d43355877a73e9ce0 8,paper presents bayesian approach using metropolisâ€“hastings markov chain monte carlo algorithm applies method daily river flow rate forecast uncertainty quantification zhujiachuan river using data collected qiaotoubao gage station gage stations zhujiachuan watershed china proposed method also compared conventional maximum likelihood estimation mle parameter estimation quantification associated uncertainties bayesian method performs similarly estimating mean value daily flow rate performs conventional mle method uncertainty quantification providing relatively narrower reliable interval mle confidence interval thus precise estimation using related information regional gage stations bayesian mcmc method might favorable uncertainty analysis risk management â© elsevier b v
10.1109/TASC.2016.2642834 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015221043&doi=10.1109%2fTASC.2016.2642834&partnerID=40&md5=e868ff5202ec597bbeb332b54f5eda15 0,next generation radiation detectors high precision cosmology astronomy particle astrophysics experiments rely heavily superconducting microwave resonators kinetic inductance devices understanding physics energy loss devices particular low temperatures powers vital present comprehensive analysis framework using markov chain monte carlo methods characterize loss due two level system concert quasi particle dynamics thin film nb resonators ghz range â© ieee
10.1007/s11263-016-0967-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032342092&doi=10.1007%2fs11263-016-0967-5&partnerID=40&md5=f854fc7afcfbae4059cd087ee4ec38bc 2,present novel fully probabilistic method interpret single face image morphable model new method based bayesian inference makes use unreliable image based information rather searching single optimal solution infer posterior distribution model parameters given target image method stochastic sampling algorithm propose verify architecture based metropolisâ€“hastings algorithm stochastic method robustly integrate unreliable information therefore rely feed forward initialization integrative concept based two ideas separation proposal moves verification model data driven markov chain monte carlo filtering metropolis acceptance rule need gradients less prone local optima standard fitters also introduce new collective likelihood models average difference model target image rather individual pixel differences average value shows natural tendency towards normal distribution even individual pixel wise difference gaussian employ new fitting method calculate posterior models face reconstructions single real world images direct application algorithm morphable model leads us fully automatic face recognition system competitive performance multi pie database without database adaptation â© springer science+business media new york
10.1007/s11263-016-0967-5 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028240219&doi=10.1007%2fs11263-016-0967-5&partnerID=40&md5=77d362cf06ebb4646cd34c71dcf3a2e2 3,present novel fully probabilistic method interpret single face image morphable model new method based bayesian inference makes use unreliable image based information rather searching single optimal solution infer posterior distribution model parameters given target image method stochastic sampling algorithm propose verify architecture based metropolisâ€“hastings algorithm stochastic method robustly integrate unreliable information therefore rely feed forward initialization integrative concept based two ideas separation proposal moves verification model data driven markov chain monte carlo filtering metropolis acceptance rule need gradients less prone local optima standard fitters also introduce new collective likelihood models average difference model target image rather individual pixel differences average value shows natural tendency towards normal distribution even individual pixel wise difference gaussian employ new fitting method calculate posterior models face reconstructions single real world images direct application algorithm morphable model leads us fully automatic face recognition system competitive performance multi pie database without database adaptation â© springer science+business media new york
10.1016/j.engstruct.2017.03.001 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014946192&doi=10.1016%2fj.engstruct.2017.03.001&partnerID=40&md5=72638591e5759c2bea9db15c788d62dc 7,paper reports step step procedures identification rail sleeper ballast system use measured vibration data situ sleeper existing ballasted track rail sleeper ballast modeling method used modal based model updating used fit measured time domain vibration field test however match measured model predicted responses good measured locations based observed discrepancy rail sleeper ballast modeling method modified paper suitable use time domain model updating based field test data modified modeling method study puts forward time domain markov chain monte carlo mcmc based bayesian model updating model class selection method identification rail sleeper ballast system mcmc used ensure proposed method applied even problem unidentifiable proposed method identified distribution railway ballast stiffness low amplitude vibration â€œequivalentâ€� rail stiffness mass using impact hammer test data model updating results confirmed ballast stiffness sleeper uniform implies ballast damage tested sleeper based proposed method comprehensive study carried quantify posterior uncertainties identified ballast stiffness different amounts measured information used model updating results showed uncertainty identified ballast stiffness acceptable level even using measured data one sensor â© elsevier ltd
